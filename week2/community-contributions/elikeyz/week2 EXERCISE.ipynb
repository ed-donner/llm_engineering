{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "  print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "  print(\"OpenAI API Key not set\")\n",
    "\n",
    "if anthropic_api_key:\n",
    "  print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "  print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "MODEL_GPT = 'gpt-5'\n",
    "MODEL_CLAUDE = 'claude-sonnet-4-6'\n",
    "\n",
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "\n",
    "openai = OpenAI()\n",
    "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
    "\n",
    "MODELS = {\n",
    "  \"gpt-5\": openai,\n",
    "  \"claude-sonnet-4-6\": anthropic\n",
    "}\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are a helpful assistant that answers technical questions including code explanations. You should explain the concepts clearly with practical examples, in a way that any layman would understand.\n",
    "\"\"\"\n",
    "\n",
    "def chat_stream(model, question, history):\n",
    "  history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "  messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "  response = MODELS[model].chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    stream=True\n",
    "  )\n",
    "\n",
    "  partial = \"\"\n",
    "  for chunk in response:\n",
    "    delta = getattr(chunk.choices[0].delta, \"content\", None)\n",
    "    if delta:\n",
    "      partial += delta\n",
    "      yield history + [{\"role\": \"assistant\", \"content\": partial}]\n",
    "\n",
    "def put_message_in_chatbot(message, history):\n",
    "  return \"\", history + [{\"role\":\"user\", \"content\":message}]\n",
    "\n",
    "def transcribe_and_chat(audio_filepath, history):\n",
    "  if not audio_filepath:\n",
    "    return history\n",
    "  with open(audio_filepath, \"rb\") as audio_file:\n",
    "    transcript = openai.audio.transcriptions.create(\n",
    "      model=\"whisper-1\",\n",
    "      file=audio_file\n",
    "    )\n",
    "\n",
    "  message = transcript.text\n",
    "  return history + [{\"role\":\"user\", \"content\":message}]\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "  with gr.Row():\n",
    "    model_selector = gr.Radio(label=\"Model\", choices=list(MODELS.keys()), value=MODEL_GPT)\n",
    "  with gr.Row():\n",
    "    chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "  with gr.Row():\n",
    "    with gr.Column():\n",
    "      question_input = gr.Textbox(label=\"Your Question\", lines=2)\n",
    "      submit_btn = gr.Button(\"Ask\")\n",
    "    with gr.Column():\n",
    "      audio_input = gr.Audio(sources=\"microphone\", type=\"filepath\", label=\"Or speak your question, then click the stop button on the audio player and then click Ask with Audio. Click the close button to clear the audio input amd record another message.\")\n",
    "      submit_audio_btn = gr.Button(\"Ask with Audio\")\n",
    "\n",
    "  submit_btn.click(put_message_in_chatbot, inputs=[question_input, chatbot], outputs=[question_input, chatbot]).then(\n",
    "    chat_stream, inputs=[model_selector, question_input, chatbot], outputs=[chatbot], api_name=None\n",
    "  )\n",
    "\n",
    "  submit_audio_btn.click(transcribe_and_chat, inputs=[audio_input, chatbot], outputs=[chatbot], api_name=None).then(\n",
    "    chat_stream, inputs=[model_selector, question_input, chatbot], outputs=[chatbot], api_name=None\n",
    "  )\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
