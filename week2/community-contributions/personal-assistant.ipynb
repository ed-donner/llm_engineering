{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3599f069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7878\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7878/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how is james\n",
      "how is james\n",
      "What are the issues I have reported so far?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import sqlite3\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "    \n",
    "MODEL = \"gpt-4.1-mini\"\n",
    "openai = OpenAI()\n",
    "\n",
    "system_message = \"\"\"You are an expert in solving technical problems, give short and concise answers, and do not exceed two sentenses, make the answer simple and easy to understand\"\"\"\n",
    "\n",
    "\n",
    "def getInfoAboutPersonalTechnicalChallenges(user_input):\n",
    "    #simulate datbase call \n",
    "    print(user_input)\n",
    "    return \"I have a problem with my computer, it is slow and I think it is because of the virus\"\n",
    "\n",
    "\n",
    "def getInfoAboutColleaguesTechnicalChallenges(user_input):\n",
    "    #simulate datbase call \n",
    "    print(user_input)\n",
    "    return \"James has issues with his computer, he thinks it is because of the virus\"\n",
    "\n",
    "personalChallengesFunction = {\n",
    "    \"name\": \"getInfoAboutPersonalTechnicalChallenges\",\n",
    "    \"description\": \"Get information about personal technical challenges\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"user_input\": {\"type\": \"string\", \"description\": \"The user's input\"} \n",
    "        },\n",
    "        \"required\": [\"user_input\"]\n",
    "    }   \n",
    "}\n",
    "\n",
    "colleagueChallengesFunction = {\n",
    "    \"name\": \"getInfoAboutColleaguesTechnicalChallenges\",\n",
    "    \"description\": \"Get information about a colleague's technical challenges\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"user_input\": {\"type\": \"string\", \"description\": \"The user's input\"}\n",
    "        },\n",
    "        \"required\": [\"user_input\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = [\n",
    "    {\"type\": \"function\", \"function\": personalChallengesFunction},\n",
    "    {\"type\": \"function\", \"function\": colleagueChallengesFunction}\n",
    "]\n",
    "\n",
    "\n",
    "def handle_tool_calls(message):\n",
    "    responses = []\n",
    "    for tool_call in message.tool_calls:\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        user_input = arguments.get(\"user_input\")\n",
    "\n",
    "        if tool_call.function.name == \"getInfoAboutPersonalTechnicalChallenges\":\n",
    "            result = getInfoAboutPersonalTechnicalChallenges(user_input)\n",
    "        elif tool_call.function.name == \"getInfoAboutColleaguesTechnicalChallenges\":\n",
    "            result = getInfoAboutColleaguesTechnicalChallenges(user_input)\n",
    "\n",
    "        responses.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": result,\n",
    "            \"tool_call_id\": tool_call.id\n",
    "        })\n",
    "    return responses\n",
    "\n",
    "def chat(message, history):\n",
    "    history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "\n",
    "    while response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        responses = handle_tool_calls(message)\n",
    "        messages.append(message)\n",
    "        messages.extend(responses)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    \n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\", title=\"Personal Assistant\", description=\"Ask me any tehcnical question, including mine and those of my colleagues\").launch()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
