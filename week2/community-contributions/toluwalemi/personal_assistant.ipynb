{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Multi-Tool Personal Assistant\n",
    "\n",
    "A multi-modal personal agent built with Gradio and OpenAI Function Calling.\n",
    "I am building upon my earlier work in Week1 ([Proverb Generator](../../../week1/community-contributions/toluwalemi/proverb_generator.ipynb) and [Football Tactical Explainer](../../../week1/community-contributions/toluwalemi/week_one_exercise.ipynb)), integrating concepts like Tool Calling, Stateful UIs, DALL-E 3, and TTS.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key ends in ...{openai_api_key[-4:]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set. Features like TTS and DALL-E will fail.\")\n",
    "\n",
    "openrouter_api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "if openrouter_api_key:\n",
    "    print(f\"OpenRouter API Key ends in ...{openrouter_api_key[-4:]}\")\n",
    "else:\n",
    "    print(\"OpenRouter API Key not set. The main agent orchestration will fail\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "openai = OpenAI(api_key=openai_api_key)\n",
    "openrouter = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=openrouter_api_key\n",
    ")\n",
    "AGENT_MODEL = \"openai/gpt-4o-mini\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Python Functions"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fetch_proverb_chapter(chapter_number):\n",
    "    \"\"\"Reaches out to the Bible API to pull text from the requested chapter.\"\"\"\n",
    "    print(f\"Executing fetch_proverb_chapter tool for chapter {chapter_number}...\")\n",
    "    response = requests.get(f\"https://bible-api.com/proverbs+{chapter_number}\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return f\"Text from Proverbs Chapter {chapter_number}:\\n\" + data.get('text', '')\n",
    "    else:\n",
    "        return f\"Failed to fetch chapter {chapter_number}. Status Code: {response.status_code}\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_football_analogy(pattern_name, team_or_player):\n",
    "    print(f\"Executing extract_football_analogy tool for {pattern_name} and {team_or_player}...\")\n",
    "    prompt_format = f\"\"\"\n",
    "    You are an expert software engineer and a massive football (soccer) fan.\n",
    "    Explain the coding pattern '{pattern_name}' using a detailed tactical analogy based on the football team or player '{team_or_player}'.\n",
    "    Include a popular historical moment from {team_or_player} to illustrate this concept.\n",
    "    Return the response as nicely formatted markdown.\n",
    "    \"\"\"\n",
    "    return prompt_format"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def artist(prompt_description):\n",
    "    \"\"\"Uses OpenAI DALL-E 3 to create an image based on the generated LLM text.\"\"\"\n",
    "    print(f\"Executing DALL-E 3 generation...\")\n",
    "    try:\n",
    "        image_response = openai.images.generate(\n",
    "                model=\"dall-e-3\",\n",
    "                prompt=f\"Create an image for this concept: {prompt_description}\",\n",
    "                size=\"1024x1024\",\n",
    "                n=1,\n",
    "                response_format=\"b64_json\",\n",
    "            )\n",
    "        image_base64 = image_response.data[0].b64_json\n",
    "        image_data = base64.b64decode(image_base64)\n",
    "        return Image.open(BytesIO(image_data))\n",
    "    except Exception as e:\n",
    "        print(f\"DALL-E Error: {e}\")\n",
    "        return None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def talker(message_text):\n",
    "    \"\"\"Uses OpenAI TTS to turn the agent's response into an audio\"\"\"\n",
    "    print(f\"Executing TTS generation...\")\n",
    "    try:\n",
    "        response = openai.audio.speech.create(\n",
    "          model=\"gpt-4o-mini-tts\",\n",
    "          voice=\"coral\",\n",
    "          input=message_text\n",
    "        )\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        print(f\"TTS Error: {e}\")\n",
    "        return None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tool JSON Schemas"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fetch_proverb_schema = {\n",
    "    \"name\": \"fetch_proverb_chapter\",\n",
    "    \"description\": \"Fetch the raw text from a specific chapter of the Book of Proverbs.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"chapter_number\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The chapter number to fetch, e.g., 3.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"chapter_number\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "football_analogy_schema = {\n",
    "    \"name\": \"extract_football_analogy\",\n",
    "    \"description\": \"Construct an expert prompt instructing an LLM to explain a coding pattern using a tactical football analogy.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"pattern_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The coding pattern, e.g., 'Two Pointers'.\",\n",
    "            },\n",
    "            \"team_or_player\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The football team or player to use in the analogy.\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"pattern_name\", \"team_or_player\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = [\n",
    "    {\"type\": \"function\", \"function\": fetch_proverb_schema},\n",
    "    {\"type\": \"function\", \"function\": football_analogy_schema}\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Agent Orchestrator State Machine"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "SYSTEM_MESSAGE = \"\"\"\nYou are Toluwalemi's Universal Assistant. \nYou have access to tools that can generate Proverb of the Days from the Bible API or generate Football tactical analogies for computer science concepts.\nAlways use the tools available to fulfill user requests.\nWhen explaining either a Proverb or a Football Analogy, return your description formatted in clean Markdown.\nAfter resolving the user's primary request, conclude your message with a rich, unique 1-sentence prompt description representing the output, so the DALL-E 3 engine can draw an image of your output.\nThe 1-sentence prompt description MUST strictly be embedded inside angle brackets: e.g. <art: A vivid watercolor of a tactical football whiteboard showing overlapping fullbacks>\n\"\"\"\n\ndef execute_tool(name, args):\n    \"\"\"Dispatches a tool call to the appropriate Python function.\"\"\"\n    if name == \"fetch_proverb_chapter\":\n        return fetch_proverb_chapter(args.get(\"chapter_number\", 1))\n    elif name == \"extract_football_analogy\":\n        return extract_football_analogy(args.get(\"pattern_name\"), args.get(\"team_or_player\"))\n    return f\"Unknown tool: {name}\"",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def chat(history):\n",
    "    \"\"\"\n",
    "    Streaming agent loop. Streams text token-by-token to the Gradio chatbot,\n",
    "    handles tool calls when needed, then generates image and audio.\n",
    "    \"\"\"\n",
    "    backend_history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": SYSTEM_MESSAGE}] + backend_history\n",
    "    history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
    "\n",
    "    while True:\n",
    "        stream = openrouter.chat.completions.create(\n",
    "            model=AGENT_MODEL, messages=messages, tools=tools, stream=True\n",
    "        )\n",
    "        reply_text = \"\"\n",
    "        tool_calls_by_index = {}\n",
    "        finish_reason = None\n",
    "\n",
    "        for chunk in stream:\n",
    "            choice = chunk.choices[0]\n",
    "            finish_reason = choice.finish_reason or finish_reason\n",
    "            delta = choice.delta\n",
    "            # Stream text content to the chatbot\n",
    "            if delta.content:\n",
    "                reply_text += delta.content\n",
    "                history[-1][\"content\"] = reply_text\n",
    "                yield history, None, None\n",
    "\n",
    "            if delta.tool_calls:\n",
    "                for tc_delta in delta.tool_calls:\n",
    "                    idx = tc_delta.index\n",
    "                    if idx not in tool_calls_by_index:\n",
    "                        tool_calls_by_index[idx] = {\"id\": \"\", \"name\": \"\", \"arguments\": \"\"}\n",
    "                    if tc_delta.id:\n",
    "                        tool_calls_by_index[idx][\"id\"] = tc_delta.id\n",
    "                    if tc_delta.function and tc_delta.function.name:\n",
    "                        tool_calls_by_index[idx][\"name\"] = tc_delta.function.name\n",
    "                    if tc_delta.function and tc_delta.function.arguments:\n",
    "                        tool_calls_by_index[idx][\"arguments\"] += tc_delta.function.arguments\n",
    "\n",
    "        if finish_reason != \"tool_calls\" or not tool_calls_by_index:\n",
    "            break\n",
    "\n",
    "        # Append assistant message with tool calls to the conversation\n",
    "        assistant_msg = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"tool_calls\": [\n",
    "                {\n",
    "                    \"id\": data[\"id\"],\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\"name\": data[\"name\"], \"arguments\": data[\"arguments\"]}\n",
    "                }\n",
    "                for data in tool_calls_by_index.values()\n",
    "            ]\n",
    "        }\n",
    "        messages.append(assistant_msg)\n",
    "\n",
    "        # Execute tools and append results\n",
    "        for data in tool_calls_by_index.values():\n",
    "            result = execute_tool(data[\"name\"], json.loads(data[\"arguments\"]))\n",
    "            messages.append({\"role\": \"tool\", \"content\": result, \"tool_call_id\": data[\"id\"]})\n",
    "\n",
    "    # Extract DALL-E prompt and clean the reply\n",
    "    match = re.search(r'<art:\\s*(.*?)>', reply_text)\n",
    "    image_prompt = None\n",
    "    if match:\n",
    "        image_prompt = match.group(1)\n",
    "        reply_text = reply_text.replace(match.group(0), \"\").strip()\n",
    "        history[-1][\"content\"] = reply_text\n",
    "        yield history, None, None\n",
    "\n",
    "    # Generate audio and image\n",
    "    audio_buffer = talker(reply_text)\n",
    "    image = artist(image_prompt) if image_prompt else None\n",
    "\n",
    "    yield history, audio_buffer, image"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Gradio UI Configuration"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "def put_message_in_chatbot(message, history):\n    return \"\", history + [{\"role\": \"user\", \"content\": message}]\n\nwith gr.Blocks(theme=gr.themes.Soft()) as ui:\n    gr.Markdown(\"# Toluwalemi's Universal Assistant\")\n    gr.Markdown(\"Powered by Gradio, OpenRouter, and OpenAI DALL-E/TTS.\\nAsk for a daily proverb, or ask for a tactical football analogy of a coding concept!\")\n    \n    with gr.Row():\n        with gr.Column(scale=2):\n            chatbot = gr.Chatbot(height=600, type=\"messages\")\n            message_input = gr.Textbox(label=\"Message Agent:\", placeholder=\"e.g. Generate a proverb from chapter 3... or Explain 2-pointers using Mikel Arteta's Arsenal\")\n        with gr.Column(scale=1):\n            image_output = gr.Image(label=\"Generated Scene\", height=500, interactive=False)\n            audio_output = gr.Audio(label=\"Voice Output\", autoplay=True)\n\n    message_input.submit(\n        put_message_in_chatbot, \n        inputs=[message_input, chatbot], \n        outputs=[message_input, chatbot]\n    ).then(\n        chat, \n        inputs=chatbot, \n        outputs=[chatbot, audio_output, image_output]\n    )\n\nui.launch(inbrowser=True)",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
