{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "eb40b1ed",
      "metadata": {},
      "source": [
        "# Additional End of week Exercise - week 2\n",
        "\n",
        "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
        "\n",
        "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
        "\n",
        "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
        "\n",
        "I will publish a full solution here soon - unless someone beats me to it...\n",
        "\n",
        "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4206885d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9abafed9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenRouter API key is invalid\n",
            "Google API key is valid\n"
          ]
        }
      ],
      "source": [
        "load_dotenv(override=True)\n",
        "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "\n",
        "if openrouter_api_key and openrouter_api_key.startswith('-sk-or') and len(openrouter_api_key) > 10:\n",
        "    print(\"OpenRouter API key is valid\")\n",
        "else:\n",
        "    print(\"OpenRouter API key is invalid\")\n",
        "\n",
        "if google_api_key and google_api_key.startswith('AIza') and len(google_api_key) > 10:\n",
        "    print(\"Google API key is valid\")\n",
        "else:\n",
        "    print(\"Google API key is invalid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "04b416a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
        "GOOGLE_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "27842d2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"\n",
        "You are an expert technical assistant. You specialize in answering technical questions with clear, accurate, and detailed responses. Provide step-by-step explanations and share your expertise to help users fully understand the concepts behind their inquiries.\n",
        "\"\"\"\n",
        "user_prompt = \"\"\"\n",
        "Can you explain the differences between multiprocessing and multithreading in Python, and when to use each approach?\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "14a80906",
      "metadata": {},
      "outputs": [],
      "source": [
        "gemini_client = OpenAI(api_key=google_api_key, base_url=GOOGLE_BASE_URL)\n",
        "openrouter_client = OpenAI(api_key=openrouter_api_key, base_url=OPENROUTER_BASE_URL)\n",
        "\n",
        "def chat_with_selected_model(history, selected_model):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history\n",
        "\n",
        "    # Pick client based on selected model\n",
        "    if selected_model == \"gemini-2.5-flash-lite\":\n",
        "        client = gemini_client\n",
        "    else:\n",
        "        client = openrouter_client\n",
        "\n",
        "    stream = client.chat.completions.create(\n",
        "        model=selected_model,\n",
        "        messages=messages,\n",
        "        stream=True,\n",
        "    )\n",
        "\n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or \"\"\n",
        "        yield history + [{\"role\": \"assistant\", \"content\": response}]\n",
        "\n",
        "    if response == \"\":\n",
        "        yield history + [{\"role\": \"assistant\", \"content\": \"\"}]\n",
        "\n",
        "def put_message_in_chatbot(message, history):\n",
        "        return \"\", history + [{\"role\":\"user\", \"content\":message}]\n",
        "\n",
        "def set_model(choice):\n",
        "    print(choice)\n",
        "    return \"gemini-2.5-flash-lite\" if choice == \"Gemini\" else \"gpt-4o-mini\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c16c9e9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "with gr.Blocks() as ui:\n",
        "    selected_model = gr.State(\"gemini-2.5-flash-lite\")\n",
        "\n",
        "    with gr.Row():\n",
        "        chatbot = gr.Chatbot(height=400, type=\"messages\")\n",
        "\n",
        "    with gr.Row():\n",
        "        message = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
        "\n",
        "    with gr.Row():\n",
        "        model_selector = gr.Dropdown(\n",
        "            choices=[\"Gemini\", \"OpenRouter\"],\n",
        "            value=\"Gemini\",\n",
        "            label=\"Model\"\n",
        "        )\n",
        "\n",
        "    model_selector.change(\n",
        "        set_model,\n",
        "        inputs=model_selector,\n",
        "        outputs=selected_model\n",
        "    )\n",
        "    message.submit(\n",
        "        put_message_in_chatbot,\n",
        "        inputs=[message, chatbot],\n",
        "        outputs=[message, chatbot]\n",
        "    ).then(\n",
        "        chat_with_selected_model,\n",
        "        inputs=[chatbot, selected_model], \n",
        "        outputs=[chatbot]\n",
        "    )\n",
        "ui.launch()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
