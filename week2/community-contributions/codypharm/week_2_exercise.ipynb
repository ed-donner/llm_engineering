{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eca50837",
      "metadata": {},
      "outputs": [],
      "source": [
        "# imports\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "from IPython.display import display, Markdown, update_display\n",
        "import gradio as gr\n",
        "load_dotenv(override=True)\n",
        "os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3c691e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# constants\n",
        "\n",
        "MODEL_GPT = 'gpt-4o-mini'\n",
        "MODEL_LLAMA = 'llama3.2' \n",
        "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8261b11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# set up environment\n",
        "openai = OpenAI()\n",
        "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\"ollama\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7edfa4d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# System prompt\n",
        "system_prompt=\"\"\"\n",
        "You are a helpful assistant that takes technical questions from a student and answers them with detailed explanation.\n",
        "When a student asks for a calculation or the result of a math expression (e.g. square root, powers, logarithms), use the calculate_math tool to get the exact value, then explain the result clearly.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b430d3bd",
      "metadata": {},
      "source": [
        "## Tool: Calculator (for math in technical Q&A)\n",
        "\n",
        "The model can call this tool when the user asks for a calculation. This demonstrates **LLM tool/function calling**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b21d191",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate math tool\n",
        "def calculate_math(math_equation):\n",
        "    \"\"\"Run a safe math expression (e.g. sqrt(25), 2**10). Used when the model calls the tool.\"\"\"\n",
        "    print(\"Tool called\")\n",
        "    allowed = {\"__builtins__\": None}\n",
        "    allowed.update({k: getattr(math, k) for k in dir(math) if not k.startswith(\"_\")})\n",
        "    return eval(math_equation, allowed, {})\n",
        "\n",
        "\n",
        "calculate_math_function = {\n",
        "    \"name\": \"calculate_math\",\n",
        "    \"description\": \"Evaluate a math expression. Use when the user asks for a calculation or the result of an equation (e.g. sqrt(25), 2**10, log(100)). Pass only the expression as a string.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"math_equation\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The math expression to evaluate, e.g. sqrt(25) or 2**10\",\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"math_equation\"],\n",
        "        \"additionalProperties\": False,\n",
        "    },\n",
        "}\n",
        "tools = [{\"type\": \"function\", \"function\": calculate_math_function}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd6579fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Handle tool call\n",
        "def handle_tool_call(tool_call):\n",
        "    \"\"\"Execute the tool the model requested and return the message to send back.\"\"\"\n",
        "    arguments = json.loads(tool_call.function.arguments)\n",
        "    math_equation = arguments.get(\"math_equation\", \"\")\n",
        "    result = calculate_math(math_equation)\n",
        "    return {\n",
        "        \"role\": \"tool\",\n",
        "        \"content\": json.dumps({\"math_equation\": math_equation, \"result\": result}),\n",
        "        \"tool_call_id\": tool_call.id,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13908955",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TTS\n",
        "def talker(message):\n",
        "    response = openai.audio.speech.create(\n",
        "      model=\"gpt-4o-mini-tts\",\n",
        "      voice=\"onyx\",\n",
        "      input=message\n",
        "    )\n",
        "    return response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48009dfb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chat\n",
        "def chat(question, model):\n",
        "    \"\"\"Chat using the selected model.\"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": question},\n",
        "    ]\n",
        "\n",
        "    if model == \"GPT\":\n",
        "        response = openai.chat.completions.create(\n",
        "            model=MODEL_GPT,\n",
        "            messages=messages,\n",
        "            tools=tools,\n",
        "        )\n",
        "        msg = response.choices[0].message\n",
        "        response_text = msg.content or \"\"\n",
        "\n",
        "        # If the model decided to call a tool, run it and get the final answer\n",
        "        if response.choices[0].finish_reason == \"tool_calls\" and msg.tool_calls:\n",
        "            messages.append({\"role\": \"assistant\", \"content\": msg.content or None, \"tool_calls\": msg.tool_calls})\n",
        "            for tc in msg.tool_calls:\n",
        "                messages.append(handle_tool_call(tc))\n",
        "            follow = openai.chat.completions.create(\n",
        "                model=MODEL_GPT,\n",
        "                messages=messages,\n",
        "            )\n",
        "            response_text = follow.choices[0].message.content or \"\"\n",
        "    else:\n",
        "        stream = ollama.chat.completions.create(\n",
        "            model=MODEL_LLAMA,\n",
        "            messages=messages,\n",
        "            stream=True,\n",
        "        )\n",
        "        response_text = \"\"\n",
        "        for chunk in stream:\n",
        "            response_text += chunk.choices[0].delta.content or \"\"\n",
        "\n",
        "    audio_content = talker(response_text) if response_text else None\n",
        "    return response_text or \"(No text response)\", audio_content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "911cc2aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# UI\n",
        "with gr.Blocks() as demo:\n",
        "    \n",
        "    gr.Markdown(\"**Ask technical questions**\")\n",
        "    \n",
        "    with gr.Row():\n",
        "        question = gr.Textbox(\n",
        "            placeholder=\"Your question...\",\n",
        "            lines=10,\n",
        "            label=\"Question\"\n",
        "        )\n",
        "    with gr.Row():\n",
        "        model = gr.Dropdown(\n",
        "            [\"GPT\", \"Ollama\"],\n",
        "            label=\"Model\",\n",
        "            value=\"GPT\",\n",
        "            \n",
        "        )\n",
        "    \n",
        "    btn = gr.Button(\"Send\", variant=\"primary\")\n",
        "    \n",
        "    audio = gr.Audio(autoplay=True, label=\"Voice (if available)\")\n",
        "    gr.Markdown(\"**Answer:**\")\n",
        "    output = gr.Markdown()\n",
        "\n",
        "    # Submit on button or Enter\n",
        "    question.submit(chat, [question, model], [output, audio])\n",
        "    btn.click(chat, [question, model], [output, audio])\n",
        "\n",
        "demo.launch(inline=True, height=500)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
