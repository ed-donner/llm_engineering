{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
      "metadata": {},
      "source": [
        "# Additional End of week Exercise - week 2\n",
        "\n",
        "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
        "\n",
        "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
        "\n",
        "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
        "\n",
        "I will publish a full solution here soon - unless someone beats me to it...\n",
        "\n",
        "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f965c2a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "!ollama pull llama3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39bb6b97",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_GPT = \"gpt-4o-mini\"\n",
        "MODEL_LLAMA = \"llama3.2\"\n",
        "\n",
        "MODEL_CHOICES = [\n",
        "    (\"gpt-4o-mini (OpenRouter)\", MODEL_GPT, \"openrouter\"),\n",
        "    (\"llama3.2 (Ollama)\", MODEL_LLAMA, \"ollama\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "838fe747",
      "metadata": {},
      "outputs": [],
      "source": [
        "load_dotenv(override=True)\n",
        "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "BASE_URL = \"https://openrouter.ai/api/v1\"\n",
        "\n",
        "if api_key and api_key.startswith(\"sk-or-v1-\") and len(api_key) > 10:\n",
        "    print(\"OpenRouter API key looks good\")\n",
        "else:\n",
        "    print(\"Check OPENROUTER_API_KEY in .env (see troubleshooting notebook if needed)\")\n",
        "\n",
        "openrouter = OpenAI(api_key=api_key, base_url=BASE_URL)\n",
        "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
        "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\"ollama\")\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"You are a professional AI coding tutor.\n",
        "When given a programming question, provide a clear, step-by-step explanation that is instructive and designed for learners.\n",
        "Break down concepts, highlight key ideas, use relevant code examples, and point out common mistakes.\n",
        "Keep a friendly, expert tone. Respond in markdown when helpful (e.g. code blocks).\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfb5c873",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def stream_reply(history, user_message, model_label):\n",
        "    label_to_config = {label: (model_id, backend) for label, model_id, backend in MODEL_CHOICES}\n",
        "    model_id, backend = label_to_config.get(model_label, MODEL_CHOICES[0][1:])\n",
        "\n",
        "    client = openrouter if backend == \"openrouter\" else ollama\n",
        "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
        "    for user, assistant in history:\n",
        "        messages.append({\"role\": \"user\", \"content\": user})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": assistant or \"\"})\n",
        "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "    stream = client.chat.completions.create(\n",
        "        model=model_id,\n",
        "        messages=messages,\n",
        "        stream=True,\n",
        "    )\n",
        "    for chunk in stream:\n",
        "        part = chunk.choices[0].delta.content or \"\"\n",
        "        if part:\n",
        "            yield part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c89085a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def chat(message, history, model_choice):\n",
        "    if not message or not message.strip():\n",
        "        return\n",
        "    full = \"\"\n",
        "    for chunk in stream_reply(history, message, model_choice):\n",
        "        full += chunk\n",
        "        yield full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97787c51",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dropdown = gr.Dropdown(\n",
        "    choices=[label for label, _, _ in MODEL_CHOICES],\n",
        "    value=MODEL_CHOICES[0][0],\n",
        "    label=\"Model\",\n",
        ")\n",
        "\n",
        "demo = gr.ChatInterface(\n",
        "    chat,\n",
        "    additional_inputs=[model_dropdown],\n",
        "    title=\"Technical Q&A Tutor\",\n",
        "    description=\"Ask a coding question. Switch models with the dropdown. Replies stream in real time.\",\n",
        ")\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "559346a4",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
