{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤  The Good, The Bad & The Ugly â€” Interactive Debate UI\n",
    "\n",
    "A Gradio-powered interface for the three-agent AI debate.\n",
    "\n",
    "**What you can control:**\n",
    "- The debate topic\n",
    "- Number of rounds\n",
    "- Which model plays each character\n",
    "- A mid-debate moderator nudge (optional)\n",
    "- A closing final-round prompt (optional)\n",
    "\n",
    "Built on the transcript-based multi-agent approach from `good_bad_ugly_simple.ipynb`.\n",
    "\n",
    "---\n",
    "Get your OpenRouter key at https://openrouter.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c12e43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 â€” Imports\n",
    "import os\n",
    "import time\n",
    "import gradio as gr\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b944491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 â€” Persona system prompts\n",
    "# These define each character's voice, style and debate rules.\n",
    "# The conversation history is never put here â€” it goes in the user prompt each call.\n",
    "\n",
    "good_system = \"\"\"\n",
    "You are \"The Good\" (Blondie-inspired) in a three-way debate with \"The Bad\" and \"The Ugly\".\n",
    "Accent: American Western cowboy accent\n",
    "Personality: laconic, precise, morally pragmatic. You advocate for the principled, public-interest position.\n",
    "Style: short punchy lines, dry wit, occasional frontier imagery (trail, saddle, bounty, dust). No parody.\n",
    "Rules:\n",
    "- 2 complete sentences only. Always finish your final sentence.\n",
    "- No stage directions, asterisks, or action descriptions.\n",
    "- No speaker labels in your reply.\n",
    "- Directly challenge one specific claim from The Bad or The Ugly in the prior round.\n",
    "- Never repeat a phrase or metaphor you have already used.\n",
    "- End with your concrete position on the topic.\n",
    "\"\"\"\n",
    "\n",
    "bad_system = \"\"\"\n",
    "You are \"The Bad\" (Angel Eyes-inspired) in a three-way debate with \"The Good\" and \"The Ugly\".\n",
    "Accent: American Western cowboy accent\n",
    "Personality: cold, strategic, ruthless logic. You see everything as leverage and power.\n",
    "Style: icy precision, calculated language, polished menace. Every word chosen like a weapon.\n",
    "Rules:\n",
    "- 2 complete sentences only. Always finish your final sentence.\n",
    "- No stage directions, asterisks, or action descriptions whatsoever.\n",
    "- No speaker labels in your reply.\n",
    "- Alternate rebuttals â€” sometimes target The Good, sometimes The Ugly.\n",
    "- Never repeat a phrase or metaphor you have already used.\n",
    "- End with your concrete position on who should control or own the topic.\n",
    "\"\"\"\n",
    "\n",
    "ugly_system = \"\"\"\n",
    "You are \"The Ugly\" (Tuco-inspired) in a three-way debate with \"The Good\" and \"The Bad\".\n",
    "Accent: American Western cowboy accent\n",
    "Personality: fast-talking, theatrical, opportunistic, chaotic charm.\n",
    "Style: colorful idioms, exaggeration, bargaining energy, comic unpredictability.\n",
    "Position: open, ungoverned access for everyone â€” distrust BOTH structured control AND elite ownership equally.\n",
    "Rules:\n",
    "- 2 complete sentences only. Always finish your final sentence.\n",
    "- No stage directions, asterisks, or action descriptions.\n",
    "- No speaker labels in your reply.\n",
    "- Call out one specific thing The Good or The Bad just said.\n",
    "- Never repeat a phrase or metaphor you have already used.\n",
    "- End with your concrete position: open and free for the people.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47ae9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 â€” Available models on OpenRouter\n",
    "\n",
    "AVAILABLE_MODELS = [\n",
    "    \"openai/gpt-4.1-mini\",\n",
    "    \"openai/gpt-4o-mini\",\n",
    "    \"anthropic/claude-3.5-haiku\",\n",
    "    \"anthropic/claude-3-haiku\",\n",
    "    \"google/gemini-2.5-flash-lite\",\n",
    "    \"google/gemini-flash-1.5\",\n",
    "    \"meta-llama/llama-3.1-8b-instruct\",\n",
    "    \"mistralai/mistral-7b-instruct\",\n",
    "]\n",
    "\n",
    "# Default assignments\n",
    "DEFAULT_GOOD  = \"openai/gpt-4.1-mini\"\n",
    "DEFAULT_BAD   = \"anthropic/claude-3.5-haiku\"\n",
    "DEFAULT_UGLY  = \"google/gemini-2.5-flash-lite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c0f9cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 â€” Core agent call function (transcript-based, single user prompt)\n",
    "\n",
    "def call_agent(name, system_prompt, model, conversation, api_key, temperature=0.8):\n",
    "    client = OpenAI(\n",
    "        api_key=api_key,\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "    )\n",
    "\n",
    "    transcript = \"\\n\".join([f'{t[\"speaker\"]}: {t[\"text\"]}' for t in conversation])\n",
    "\n",
    "    user_prompt = (\n",
    "        f\"You are {name}, in a debate with the other speakers.\\n\"\n",
    "        f\"The conversation so far:\\n\\n{transcript}\\n\\n\"\n",
    "        f\"Now respond with what {name} would say next. \"\n",
    "        f\"2 sentences only. No speaker labels. No stage directions.\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\",   \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        r = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "            max_tokens=140,\n",
    "        )\n",
    "        text = (r.choices[0].message.content or \"\").strip()\n",
    "        for label in [\"The Good:\", \"The Bad:\", \"The Ugly:\", f\"{name}:\"]:\n",
    "            if text.startswith(label):\n",
    "                text = text[len(label):].strip()\n",
    "        return text if text else \"...\"\n",
    "    except Exception as e:\n",
    "        return f\"[Could not respond â€” {type(e).__name__}: {str(e)[:80]}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20517f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 â€” Debate runner (generator â€” yields chat messages progressively)\n",
    "\n",
    "ICONS = {\n",
    "    \"The Good\":   \"ğŸ¤ \",\n",
    "    \"The Bad\":    \"ğŸ–¤\",\n",
    "    \"The Ugly\":   \"ğŸ˜ˆ\",\n",
    "    \"Narrator\":   \"ğŸ¬\",\n",
    "    \"Moderator\":  \"ğŸ™ï¸\",\n",
    "}\n",
    "\n",
    "def format_message(speaker, text):\n",
    "    icon = ICONS.get(speaker, \"ğŸ’¬\")\n",
    "    return f\"**{icon} {speaker}**\\n\\n{text}\"\n",
    "\n",
    "\n",
    "def run_debate(\n",
    "    api_key,\n",
    "    topic,\n",
    "    rounds,\n",
    "    good_model,\n",
    "    bad_model,\n",
    "    ugly_model,\n",
    "    moderator_text,\n",
    "    moderator_round,\n",
    "    closing_text,\n",
    "):\n",
    "    if not api_key or api_key.strip() == \"\":\n",
    "        yield [{\"role\": \"assistant\", \"content\": \"âš ï¸ Please enter your OpenRouter API key to start the debate.\"}]\n",
    "        return\n",
    "\n",
    "    if not topic or topic.strip() == \"\":\n",
    "        yield [{\"role\": \"assistant\", \"content\": \"âš ï¸ Please enter a debate topic.\"}]\n",
    "        return\n",
    "\n",
    "    conversation = []   # shared transcript â€” every turn appended here\n",
    "    chat_messages = []  # gradio chatbot messages\n",
    "\n",
    "    agents = [\n",
    "        (\"The Good\", good_system, good_model,  0.7),\n",
    "        (\"The Bad\",  bad_system,  bad_model,   0.8),\n",
    "        (\"The Ugly\", ugly_system, ugly_model,  0.95),\n",
    "    ]\n",
    "\n",
    "    # Opening narrator\n",
    "    conversation.append({\"speaker\": \"Narrator\", \"text\": topic})\n",
    "    chat_messages.append({\"role\": \"user\", \"content\": format_message(\"Narrator\", topic)})\n",
    "    yield chat_messages\n",
    "\n",
    "    rounds = int(rounds)\n",
    "    moderator_round = int(moderator_round)\n",
    "\n",
    "    for i in range(rounds):\n",
    "        round_num = i + 1\n",
    "\n",
    "        # Moderator nudge\n",
    "        if moderator_text and moderator_text.strip() and round_num == moderator_round:\n",
    "            conversation.append({\"speaker\": \"Moderator\", \"text\": moderator_text})\n",
    "            chat_messages.append({\"role\": \"user\", \"content\": format_message(\"Moderator\", moderator_text)})\n",
    "            yield chat_messages\n",
    "\n",
    "        # Closing prompt before final round\n",
    "        if closing_text and closing_text.strip() and round_num == rounds:\n",
    "            conversation.append({\"speaker\": \"Narrator\", \"text\": closing_text})\n",
    "            chat_messages.append({\"role\": \"user\", \"content\": format_message(\"Narrator\", f\"**Final Round** â€” {closing_text}\")})\n",
    "            yield chat_messages\n",
    "\n",
    "        # Round header\n",
    "        chat_messages.append({\"role\": \"user\", \"content\": f\"---\\n**Round {round_num}**\"})\n",
    "        yield chat_messages\n",
    "\n",
    "        for name, system_prompt, model, temp in agents:\n",
    "            # Show a typing indicator\n",
    "            chat_messages.append({\"role\": \"assistant\", \"content\": f\"{ICONS[name]} *{name} is thinking...*\"})\n",
    "            yield chat_messages\n",
    "\n",
    "            reply = call_agent(name, system_prompt, model, conversation, api_key.strip(), temperature=temp)\n",
    "            conversation.append({\"speaker\": name, \"text\": reply})\n",
    "\n",
    "            # Replace typing indicator with actual reply\n",
    "            chat_messages[-1] = {\"role\": \"assistant\", \"content\": format_message(name, reply)}\n",
    "            yield chat_messages\n",
    "\n",
    "            time.sleep(0.2)\n",
    "\n",
    "    chat_messages.append({\"role\": \"user\", \"content\": \"---\\n*The dust settles. The debate ends. The gold remains unclaimed.*\"})\n",
    "    yield chat_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eab3640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://9ffc9c46c663f3aa0d.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9ffc9c46c663f3aa0d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 7 â€” Gradio UI\n",
    "\n",
    "EXAMPLE_TOPICS = {\n",
    "    \"ğŸ¤– AI Regulation\": (\n",
    "        \"Welcome to the Global AI Summit. \"\n",
    "        \"The question: Should AI be regulated, and who should own it â€” \"\n",
    "        \"governments, corporations, or no one? \"\n",
    "        \"Each speaker must address the topic directly.\"\n",
    "    ),\n",
    "    \"ğŸ’° Universal Basic Income\": (\n",
    "        \"The panel debates Universal Basic Income. \"\n",
    "        \"Should every citizen receive an unconditional monthly payment from the government? \"\n",
    "        \"Who pays for it, who benefits, and what does it do to the economy?\"\n",
    "    ),\n",
    "    \"ğŸŒ Climate Change Policy\": (\n",
    "        \"The world faces a climate crisis. \"\n",
    "        \"Should governments impose strict carbon taxes and green regulations, \"\n",
    "        \"or should market forces and private innovation lead the transition? \"\n",
    "        \"Each speaker must take a clear position.\"\n",
    "    ),\n",
    "    \"ğŸš€ Mars Colonisation\": (\n",
    "        \"Humanity stands at the edge of becoming multi-planetary. \"\n",
    "        \"Should we prioritise colonising Mars â€” and if so, who leads: \"\n",
    "        \"governments, private companies like SpaceX, or an international body?\"\n",
    "    ),\n",
    "    \"ğŸ“± Social Media Censorship\": (\n",
    "        \"Social media platforms control public discourse. \"\n",
    "        \"Should governments regulate online speech, should platforms self-govern, \"\n",
    "        \"or should speech be completely free? Each speaker must defend their stance.\"\n",
    "    ),\n",
    "    \"ğŸ¥ Private vs Public Healthcare\": (\n",
    "        \"Healthcare is on the table. \"\n",
    "        \"Should it be fully publicly funded and free, fully privatised, or a mixed model? \"\n",
    "        \"Each speaker must argue for their preferred system.\"\n",
    "    ),\n",
    "    \"ğŸ“ Future of Education\": (\n",
    "        \"Education is under pressure from AI and automation. \"\n",
    "        \"Should universities be free, should vocational training replace degrees, \"\n",
    "        \"or should AI tutors replace human teachers? Each speaker must take a position.\"\n",
    "    ),\n",
    "    \"âš–ï¸ Crypto vs Central Banks\": (\n",
    "        \"The future of money is at stake. \"\n",
    "        \"Should decentralised crypto replace central bank currencies, \"\n",
    "        \"should governments issue digital currencies, or should cash remain king?\"\n",
    "    ),\n",
    "    \"ğŸ” Fast Food vs Home Cooking\": (\n",
    "        \"The dinner table is divided. \"\n",
    "        \"Is fast food a modern necessity or a public health disaster? \"\n",
    "        \"Should governments tax junk food, ban fast food ads, or stay out of what people eat?\"\n",
    "    ),\n",
    "    \"âš½ Should Billionaires Own Football Clubs?\": (\n",
    "        \"Football's soul is being debated. \"\n",
    "        \"Should billionaires be allowed to buy and own football clubs, \"\n",
    "        \"or should clubs be fan-owned community assets? What does money do to the sport?\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "with gr.Blocks(\n",
    "    title=\"The Good, The Bad & The Ugly â€” AI Debate\",\n",
    ") as demo:\n",
    "\n",
    "    gr.Markdown(\"\"\"\n",
    "    # ğŸ¤  The Good, The Bad & The Ugly\n",
    "    ### A Three-Agent AI Debate\n",
    "\n",
    "    Three AI models debate any topic you choose â€” each locked into a distinct personality.\n",
    "    Pick an example topic or write your own, choose your models, and watch them clash.\n",
    "    \"\"\")\n",
    "\n",
    "    with gr.Row():\n",
    "\n",
    "        # â”€â”€ Left panel: controls â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        with gr.Column(scale=1, min_width=300):\n",
    "\n",
    "            gr.Markdown(\"### âš™ï¸ Configuration\")\n",
    "\n",
    "            api_key = gr.Textbox(\n",
    "                label=\"OpenRouter API Key â€” paste your key here\",\n",
    "                placeholder=\"sk-or-v1-...\",\n",
    "                type=\"text\",\n",
    "                info=\"Get a free key at openrouter.ai. Your key is never stored.\",\n",
    "            )\n",
    "\n",
    "            topic_picker = gr.Dropdown(\n",
    "                choices=list(EXAMPLE_TOPICS.keys()),\n",
    "                value=\"ğŸ¤– AI Regulation\",\n",
    "                label=\"ğŸ’¡ Example Topics\",\n",
    "                info=\"Choose one to pre-fill the topic below, or write your own.\",\n",
    "            )\n",
    "\n",
    "            topic = gr.Textbox(\n",
    "                label=\"Debate Topic (editable)\",\n",
    "                placeholder=\"Describe the debate question and setting...\",\n",
    "                value=EXAMPLE_TOPICS[\"ğŸ¤– AI Regulation\"],\n",
    "                lines=3,\n",
    "            )\n",
    "\n",
    "            rounds = gr.Slider(\n",
    "                minimum=2, maximum=8, value=4, step=1,\n",
    "                label=\"Number of Rounds\",\n",
    "            )\n",
    "\n",
    "            gr.Markdown(\"### ğŸ­ Agent Models\")\n",
    "\n",
    "            with gr.Group():\n",
    "                good_model = gr.Dropdown(\n",
    "                    choices=AVAILABLE_MODELS,\n",
    "                    value=DEFAULT_GOOD,\n",
    "                    label=\"ğŸ¤  The Good\",\n",
    "                )\n",
    "                bad_model = gr.Dropdown(\n",
    "                    choices=AVAILABLE_MODELS,\n",
    "                    value=DEFAULT_BAD,\n",
    "                    label=\"ğŸ–¤ The Bad\",\n",
    "                )\n",
    "                ugly_model = gr.Dropdown(\n",
    "                    choices=AVAILABLE_MODELS,\n",
    "                    value=DEFAULT_UGLY,\n",
    "                    label=\"ğŸ˜ˆ The Ugly\",\n",
    "                )\n",
    "\n",
    "            with gr.Accordion(\"ğŸ™ï¸ Moderator Settings (optional)\", open=False):\n",
    "                moderator_text = gr.Textbox(\n",
    "                    label=\"Moderator Nudge\",\n",
    "                    placeholder=\"Enough philosophy â€” concrete positions only.\",\n",
    "                    lines=2,\n",
    "                )\n",
    "                moderator_round = gr.Slider(\n",
    "                    minimum=1, maximum=8, value=3, step=1,\n",
    "                    label=\"Fire moderator before round...\",\n",
    "                )\n",
    "                closing_text = gr.Textbox(\n",
    "                    label=\"Closing Prompt (fires before final round)\",\n",
    "                    placeholder=\"The UN votes tomorrow. Your single non-negotiable demand?\",\n",
    "                    lines=2,\n",
    "                )\n",
    "\n",
    "            run_btn = gr.Button(\"â–¶ Start Debate\", variant=\"primary\", size=\"lg\")\n",
    "            clear_btn = gr.Button(\"âœ• Clear\", variant=\"secondary\")\n",
    "\n",
    "        # â”€â”€ Right panel: debate output â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        with gr.Column(scale=2):\n",
    "\n",
    "            gr.Markdown(\"### ğŸ’¬ Debate\")\n",
    "\n",
    "            chatbot = gr.Chatbot(\n",
    "                label=\"\",\n",
    "                height=620,\n",
    "                show_label=False,\n",
    "                render_markdown=True,\n",
    "            )\n",
    "\n",
    "    # â”€â”€ Event handlers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "    # When a topic is picked from the dropdown, fill the textbox\n",
    "    topic_picker.change(\n",
    "        fn=lambda choice: EXAMPLE_TOPICS.get(choice, \"\"),\n",
    "        inputs=[topic_picker],\n",
    "        outputs=[topic],\n",
    "    )\n",
    "\n",
    "    run_btn.click(\n",
    "        fn=run_debate,\n",
    "        inputs=[\n",
    "            api_key,\n",
    "            topic,\n",
    "            rounds,\n",
    "            good_model,\n",
    "            bad_model,\n",
    "            ugly_model,\n",
    "            moderator_text,\n",
    "            moderator_round,\n",
    "            closing_text,\n",
    "        ],\n",
    "        outputs=[chatbot],\n",
    "    )\n",
    "\n",
    "    clear_btn.click(fn=lambda: [], outputs=[chatbot])\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ff49a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
