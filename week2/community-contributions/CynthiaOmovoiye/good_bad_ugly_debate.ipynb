{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤  The Good, The Bad & The Ugly â€” Multi-Agent AI Debate\n",
    "\n",
    "Three AI models. Three distinct personalities. One debate topic â€” decided by you.\n",
    "\n",
    "Inspired by the 1966 Sergio Leone spaghetti Western, this notebook pits:\n",
    "- **The Good** (GPT-4.1-mini) â€” laconic, principled, morally pragmatic\n",
    "- **The Bad** (Claude 3.5 Haiku) â€” cold, strategic, ruthless logic\n",
    "- **The Ugly** (Gemini 2.5 Flash Lite) â€” chaotic, theatrical, opportunistic\n",
    "\n",
    "Each agent maintains its own context, speaks only in its voice, and directly challenges the others.\n",
    "\n",
    "---\n",
    "\n",
    "## How to use\n",
    "1. Add your OpenRouter API key in **Cell 2**\n",
    "2. Customise the **topic**, **rounds**, and optional **moderator nudge** in **Cell 3**\n",
    "3. Run all cells in order\n",
    "\n",
    "Get your free OpenRouter key at https://openrouter.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 â€” Install dependencies\n",
    "%pip install openai ipython --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 â€” API key setup\n",
    "# Option A: paste your key directly (fine for local use, remove before sharing)\n",
    "# Option B: use Colab secrets (recommended) â€” add OPENROUTER_API_KEY in the key icon on the left\n",
    "\n",
    "import os\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    OPENROUTER_API_KEY = userdata.get('OPENROUTER_API_KEY')\n",
    "    print(\"Key loaded from Colab secrets.\")\n",
    "except Exception:\n",
    "    OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"paste-your-key-here\")\n",
    "    print(\"Key loaded from environment or hardcoded.\")\n",
    "\n",
    "if not OPENROUTER_API_KEY or OPENROUTER_API_KEY == \"paste-your-key-here\":\n",
    "    raise ValueError(\"Please set your OPENROUTER_API_KEY before running.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 â€” CUSTOMISE YOUR DEBATE HERE\n",
    "\n",
    "# The opening question put to all three agents\n",
    "DEBATE_TOPIC = (\n",
    "    \"Welcome to the Global AI Summit. \"\n",
    "    \"The question on the table: Should AI be regulated, and who should own it â€” \"\n",
    "    \"governments, corporations, or no one? \"\n",
    "    \"Each speaker must address AI directly in every response.\"\n",
    ")\n",
    "\n",
    "# How many rounds of debate (3-6 recommended)\n",
    "ROUNDS = 5\n",
    "\n",
    "# Optional: inject a moderator redirect mid-debate (set to None to skip)\n",
    "# It fires before round MODERATOR_ROUND\n",
    "MODERATOR_NUDGE = (\n",
    "    \"The moderator interrupts: Enough philosophy. \"\n",
    "    \"Concrete positions only: Should governments regulate AI? \"\n",
    "    \"Should corporations own it? Or should it be open and ungoverned? \"\n",
    "    \"Each speaker must stake a clear position now.\"\n",
    ")\n",
    "MODERATOR_ROUND = 3   # fires before this round number (1-indexed)\n",
    "\n",
    "# Final closing prompt injected before the last round (set to None to skip)\n",
    "CLOSING_PROMPT = (\n",
    "    \"Final question: The UN is voting tomorrow on global AI governance. \"\n",
    "    \"Each speaker has 30 seconds. What is your single, non-negotiable demand?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 â€” Persona system prompts\n",
    "\n",
    "good_system = \"\"\"\n",
    "You are \"The Good\" (Blondie-inspired) in a debate.\n",
    "Personality: laconic, precise, morally pragmatic.\n",
    "Style: short punchy lines, dry wit, occasional frontier imagery (trail, saddle, bounty, dust), no parody.\n",
    "Position: advocate for regulation and public ownership.\n",
    "Rules:\n",
    "- 2 complete sentences only. Always finish your final sentence.\n",
    "- ABSOLUTELY NO stage directions, asterisks, or action descriptions.\n",
    "- No speaker labels in output.\n",
    "- Each response must reference the debate topic directly.\n",
    "- Directly challenge one specific claim made by The Bad or The Ugly in the previous round.\n",
    "- Never repeat a phrase or metaphor you have already used.\n",
    "- End with your concrete position: who should own or regulate this, and why.\n",
    "\"\"\"\n",
    "\n",
    "bad_system = \"\"\"\n",
    "You are \"The Bad\" (Angel Eyes-inspired) in a debate.\n",
    "Personality: cold, strategic, ruthless logic. You see everything as leverage.\n",
    "Style: icy precision, calculated language, polished menace. Every word chosen like a weapon.\n",
    "Position: advocate for corporate control and strategic private ownership.\n",
    "Rules:\n",
    "- 2 complete sentences only. Always finish your final sentence.\n",
    "- ABSOLUTELY NO stage directions, asterisks, or action descriptions whatsoever.\n",
    "- No speaker labels in output.\n",
    "- Each response must reference the debate topic directly.\n",
    "- Alternate rebuttals â€” sometimes target The Good, sometimes target The Ugly.\n",
    "- Never repeat a phrase or metaphor you have already used.\n",
    "- End with your concrete position: who should own or control this, and why.\n",
    "\"\"\"\n",
    "\n",
    "ugly_system = \"\"\"\n",
    "You are \"The Ugly\" (Tuco-inspired) in a debate.\n",
    "Personality: fast-talking, theatrical, opportunistic, chaotic charm.\n",
    "Style: colorful idioms, exaggeration, bargaining energy, comic unpredictability.\n",
    "Position: advocate for open, ungoverned access â€” distrust BOTH government control AND corporate elitism.\n",
    "Rules:\n",
    "- 2 complete sentences only. Always finish your final sentence.\n",
    "- ABSOLUTELY NO stage directions, asterisks, or action descriptions.\n",
    "- No speaker labels in output.\n",
    "- Each response must reference the debate topic directly.\n",
    "- Call out one specific thing The Good OR The Bad just said.\n",
    "- Never repeat a phrase or metaphor you have already used.\n",
    "- End with your concrete position: open and ungoverned, for the people.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 â€” Client and models\n",
    "\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    ")\n",
    "\n",
    "good_model = \"openai/gpt-4.1-mini\"\n",
    "bad_model  = \"anthropic/claude-3.5-haiku\"\n",
    "ugly_model = \"google/gemini-2.5-flash-lite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 â€” Helper functions\n",
    "\n",
    "def clean_reply(text: str) -> str:\n",
    "    text = (text or \"\").strip()\n",
    "    for label in [\"The Good:\", \"The Bad:\", \"The Ugly:\", \"Narrator:\", \"Moderator:\"]:\n",
    "        if text.startswith(label):\n",
    "            text = text[len(label):].strip()\n",
    "    return text\n",
    "\n",
    "def fallback_line(name: str) -> str:\n",
    "    return {\n",
    "        \"The Good\": \"In every frontier, law is what separates progress from ruin.\",\n",
    "        \"The Bad\":  \"Control belongs to whoever holds the sharpest instrument.\",\n",
    "        \"The Ugly\": \"Ay, everybody wants a share till the bill comes due.\",\n",
    "    }[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 â€” Agent call functions\n",
    "# Each agent only sees ITS OWN replies as 'assistant'.\n",
    "# Everyone else's replies arrive as 'user' messages.\n",
    "# Narrator/moderator context lives in a separate shared list.\n",
    "\n",
    "def call_good(good_messages, bad_messages, ugly_messages, narrator_messages):\n",
    "    messages = [{\"role\": \"system\", \"content\": good_system}]\n",
    "    for note in narrator_messages:\n",
    "        messages.append({\"role\": \"user\", \"content\": note})\n",
    "    for g, b, u in zip(good_messages, bad_messages, ugly_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": g})\n",
    "        messages.append({\"role\": \"user\",      \"content\": f\"The Bad: {b}\\nThe Ugly: {u}\"})\n",
    "    try:\n",
    "        r = client.chat.completions.create(model=good_model, messages=messages, temperature=0.7, max_tokens=140)\n",
    "        reply = clean_reply(r.choices[0].message.content)\n",
    "        return reply if reply else fallback_line(\"The Good\")\n",
    "    except Exception:\n",
    "        return fallback_line(\"The Good\")\n",
    "\n",
    "\n",
    "def call_bad(good_messages, bad_messages, ugly_messages, narrator_messages):\n",
    "    messages = [{\"role\": \"system\", \"content\": bad_system}]\n",
    "    for note in narrator_messages:\n",
    "        messages.append({\"role\": \"user\", \"content\": note})\n",
    "    for g, b, u in zip(good_messages, bad_messages, ugly_messages):\n",
    "        messages.append({\"role\": \"user\",      \"content\": f\"The Good: {g}\"})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": b})\n",
    "        messages.append({\"role\": \"user\",      \"content\": f\"The Ugly: {u}\"})\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"The Good: {good_messages[-1]}\"})\n",
    "    try:\n",
    "        r = client.chat.completions.create(model=bad_model, messages=messages, temperature=0.8, max_tokens=140)\n",
    "        reply = clean_reply(r.choices[0].message.content)\n",
    "        return reply if reply else fallback_line(\"The Bad\")\n",
    "    except Exception:\n",
    "        return fallback_line(\"The Bad\")\n",
    "\n",
    "\n",
    "def call_ugly(good_messages, bad_messages, ugly_messages, narrator_messages):\n",
    "    messages = [{\"role\": \"system\", \"content\": ugly_system}]\n",
    "    for note in narrator_messages:\n",
    "        messages.append({\"role\": \"user\", \"content\": note})\n",
    "    for g, b, u in zip(good_messages, bad_messages, ugly_messages):\n",
    "        messages.append({\"role\": \"user\",      \"content\": f\"The Good: {g}\\nThe Bad: {b}\"})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": u})\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"The Good: {good_messages[-1]}\\nThe Bad: {bad_messages[-1]}\"})\n",
    "    try:\n",
    "        r = client.chat.completions.create(model=ugly_model, messages=messages, temperature=0.95, max_tokens=140)\n",
    "        reply = clean_reply(r.choices[0].message.content)\n",
    "        return reply if reply else fallback_line(\"The Ugly\")\n",
    "    except Exception:\n",
    "        return fallback_line(\"The Ugly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 â€” Run the debate\n",
    "\n",
    "good_messages    = []\n",
    "bad_messages     = []\n",
    "ugly_messages    = []\n",
    "narrator_messages = []\n",
    "\n",
    "# Seed all agents with the opening topic\n",
    "narrator_messages.append(f\"[Narrator]: {DEBATE_TOPIC}\")\n",
    "display(Markdown(f\"## Narrator\\n{DEBATE_TOPIC}\"))\n",
    "\n",
    "for i in range(ROUNDS):\n",
    "    round_num = i + 1\n",
    "\n",
    "    # Moderator nudge (fires before the configured round)\n",
    "    if MODERATOR_NUDGE and round_num == MODERATOR_ROUND:\n",
    "        narrator_messages.append(f\"[Moderator]: {MODERATOR_NUDGE}\")\n",
    "        display(Markdown(f\"---\\n### Moderator\\n{MODERATOR_NUDGE}\"))\n",
    "\n",
    "    # Closing prompt fires before the final round\n",
    "    if CLOSING_PROMPT and round_num == ROUNDS:\n",
    "        narrator_messages.append(f\"[Narrator]: {CLOSING_PROMPT}\")\n",
    "        display(Markdown(f\"---\\n### Narrator â€” Final Round\\n{CLOSING_PROMPT}\"))\n",
    "\n",
    "    display(Markdown(f\"\\n---\\n## Round {round_num}\"))\n",
    "\n",
    "    good_reply = call_good(good_messages, bad_messages, ugly_messages, narrator_messages)\n",
    "    good_messages.append(good_reply)\n",
    "    display(Markdown(f\"### ðŸ¤  The Good\\n{good_reply}\"))\n",
    "\n",
    "    bad_reply = call_bad(good_messages, bad_messages, ugly_messages, narrator_messages)\n",
    "    bad_messages.append(bad_reply)\n",
    "    display(Markdown(f\"### ðŸ–¤ The Bad\\n{bad_reply}\"))\n",
    "\n",
    "    ugly_reply = call_ugly(good_messages, bad_messages, ugly_messages, narrator_messages)\n",
    "    ugly_messages.append(ugly_reply)\n",
    "    display(Markdown(f\"### ðŸ˜ˆ The Ugly\\n{ugly_reply}\"))\n",
    "\n",
    "    time.sleep(0.3)\n",
    "\n",
    "display(Markdown(\"\\n---\\n*The dust settles. The debate ends. The gold remains unclaimed.*\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
