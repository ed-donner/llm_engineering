{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Markdown.__init__() got an unexpected keyword argument 'lines'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     32\u001b[39m \t\t\t\u001b[38;5;28;01myield\u001b[39;00m result\n\u001b[32m     35\u001b[39m message_input = gr.Textbox(label=\u001b[33m\"\u001b[39m\u001b[33mYour question:\u001b[39m\u001b[33m\"\u001b[39m, info=\u001b[33m\"\u001b[39m\u001b[33mEnter a question to be answered\u001b[39m\u001b[33m\"\u001b[39m, lines=\u001b[32m7\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m message_output = \u001b[43mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMarkdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAnswer:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m view = gr.Interface(\n\u001b[32m     39\u001b[39m     fn=message_gpt,\n\u001b[32m     40\u001b[39m     title=\u001b[33m\"\u001b[39m\u001b[33mQuestion Answerer\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m   (...)\u001b[39m\u001b[32m     44\u001b[39m     flagging_mode=\u001b[33m\"\u001b[39m\u001b[33mnever\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     45\u001b[39m     )\n\u001b[32m     46\u001b[39m view.launch()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm_engineering/.venv/lib/python3.12/site-packages/gradio/component_meta.py:189\u001b[39m, in \u001b[36mupdateable.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Markdown.__init__() got an unexpected keyword argument 'lines'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n",
    "\n",
    "\n",
    "MODEL = 'gpt-5-nano'\n",
    "openai = OpenAI()\n",
    "\n",
    "\n",
    "system_message = \"You are a helpful assistant\"\n",
    "\n",
    "def message_gpt(prompt):\n",
    "\tmessages = [{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": prompt}]\n",
    "\tstream = openai.chat.completions.create(\n",
    "\t\t\tmodel=MODEL,\n",
    "\t\t\tmessages=messages,\n",
    "\t\t\tstream=True\n",
    "\t)    \n",
    "\tresult = \"\"\n",
    "\tfor chunk in stream:\n",
    "\t\t\tresult += chunk.choices[0].delta.content or \"\"\n",
    "\t\t\tyield result\n",
    "\t\t\n",
    "\n",
    "message_input = gr.Textbox(label=\"Your question:\", info=\"Enter a question to be answered\", lines=7)\n",
    "message_output = gr.Markdown(label=\"Answer:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    title=\"Question Answerer\", \n",
    "    inputs=[message_input], \n",
    "    outputs=[message_output], \n",
    "    examples=[\"What is the capital of France?\", \"What is the capital of Germany?\"], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
