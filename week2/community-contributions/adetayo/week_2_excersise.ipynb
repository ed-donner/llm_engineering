{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "910e90d7",
   "metadata": {},
   "source": [
    "The Task: \n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23356d79",
   "metadata": {},
   "source": [
    "Lets get the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5199e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a214f38c",
   "metadata": {},
   "source": [
    "load gemini keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75e0598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv(override=True)\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1476026d",
   "metadata": {},
   "source": [
    "Lets setup system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab9c2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a technical assistant. When asked technical questions, you answer as an experienced engineer, you make complex concept simple by using analogies and examples.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fee39b",
   "metadata": {},
   "source": [
    "Let's setup audio output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f62f92da",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_client = OpenAI()\n",
    "def talker(message):\n",
    "    response = audio_client.audio.speech.create(\n",
    "      model=\"gpt-4o-mini-tts\",\n",
    "      voice=\"onyx\",    # Also, try replacing onyx with alloy or coral\n",
    "      input=message\n",
    "    )\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37d8a47",
   "metadata": {},
   "source": [
    "lets setup the chat function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "345da85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message,history,additional_inputs):\n",
    "    history = [{\"role\":h['role'],\"content\":h[\"content\"]} for h in history]\n",
    "    messages = [{'role':'system','content':system_prompt}] + history + [{'role':'user','content':message}]\n",
    "    client = OpenAI() if additional_inputs == \"OpenAI\" else OpenAI(base_url= \"https://generativelanguage.googleapis.com/v1beta/openai/\",api_key=google_api_key)\n",
    "    stream = client.chat.completions.create(\n",
    "        model= \"gpt-4o-mini\" if additional_inputs == \"OpenAI\" else \"gemini-2.0-flash\",\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    history = history + [\n",
    "        {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    ]\n",
    "    response_text = \"\"\n",
    "    for chunk in stream:\n",
    "        response_text += chunk.choices[0].delta.content or ''\n",
    "        history[-1][\"content\"] = response_text\n",
    "        yield history,None\n",
    "\n",
    "    yield history, talker(response_text)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e8e9b5",
   "metadata": {},
   "source": [
    "Lets pipe this to a customized Gradio view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7447a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_models = [\"OpenAI\",\"Gemini\"]\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    chatbot = gr.Chatbot(type=\"messages\",height=400)\n",
    "    audioOutput = gr.Audio(autoplay=True)  \n",
    "    with gr.Row():\n",
    "        chatInput = gr.Textbox(show_label=False,interactive=True,scale=8,placeholder=\"Enter your message here...\",)\n",
    "        model_dropdown = gr.Dropdown(choices=available_models,value=\"OpenAI\",interactive=True,scale=2,show_label=False)\n",
    "    chatInput.submit(fn=chat,inputs=[chatInput,chatbot,model_dropdown],outputs=[chatbot,audioOutput])\n",
    "\n",
    "ui.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
