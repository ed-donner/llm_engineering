{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
      "metadata": {},
      "source": [
        "# Additional End of week Exercise - week 2\n",
        "\n",
        "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
        "\n",
        "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
        "\n",
        "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
        "\n",
        "I will publish a full solution here soon - unless someone beats me to it...\n",
        "\n",
        "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31ab2fd1",
      "metadata": {},
      "outputs": [],
      "source": [
        "OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
        "\n",
        "load_dotenv(override=True)\n",
        "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "if api_key and api_key.startswith(\"sk-proj-\") and len(api_key) > 10:\n",
        "    print(\"API key looks good\")\n",
        "else:\n",
        "    print(\"Check your API key â€” see troubleshooting notebook.\")\n",
        "\n",
        "openai = OpenAI()\n",
        "openrouter = OpenAI(base_url=OPENROUTER_BASE_URL, api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39c12de2",
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"\n",
        "You are a computer science expert with deep knowledge of the subject and a passion for teaching.\n",
        "You can explain complex concepts in a way that is easy to understand, breaking them down into smaller, understandable pieces, provide explample usecases and citint a maximum of 3 sources (e.g Book,(Author), Website, etc.)  while maintaining the overall context and connections between ideas and attaching clickable links to the sources.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "562c19ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_GPT = \"gpt-4o-mini\"\n",
        "MODEL_GEMINI = \"google/gemini-2.5-flash\"\n",
        "MODEL_GROK_4_FAST = \"x-ai/grok-4.1-fast\"\n",
        "MODEL_CLAUDE_SONNET_3_5 = \"anthropic/claude-3.5-sonnet\"\n",
        "\n",
        "MODELS = [\n",
        "    {\"label\": \"GPT-4o mini\", \"model\": MODEL_GPT, \"client\": openrouter},\n",
        "    {\"label\": \"Gemini 3.1\", \"model\": MODEL_GEMINI, \"client\": openrouter},\n",
        "    {\"label\": \"Grok 4\", \"model\": MODEL_GROK_4_FAST, \"client\": openrouter},\n",
        "    {\"label\": \"Claude 3.5 Sonnet\", \"model\": MODEL_CLAUDE_SONNET_3_5, \"client\": openrouter},\n",
        "]\n",
        "MODEL_BY_LABEL = {m[\"label\"]: m for m in MODELS}\n",
        "DROPDOWN_CHOICES = [m[\"label\"] for m in MODELS]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7439be97",
      "metadata": {},
      "outputs": [],
      "source": [
        "def expert_tutor(messages: list[dict], model: str = MODEL_GPT, client: OpenAI = openai):\n",
        "    print(f\"Researching question to provide a source backed explanation {model}\")\n",
        "    stream = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or ''\n",
        "        yield response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ec69feb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def history_to_messages(history, new_user_message: str) -> list[dict]:\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "\n",
        "    for turn in (history or []):\n",
        "        if isinstance(turn, dict):\n",
        "            messages.append({\"role\": turn[\"role\"], \"content\": turn.get(\"content\", \"\") or \"\"})\n",
        "        else:\n",
        "            user_msg, assistant_msg = turn[0], turn[1]\n",
        "            if user_msg:\n",
        "                messages.append({\"role\": \"user\", \"content\": user_msg})\n",
        "            if assistant_msg:\n",
        "                messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": new_user_message})\n",
        "    return messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e16b8cda",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_tutor(message: str, history, model_choice: str):\n",
        "    if isinstance(message, list) and isinstance(history, str):\n",
        "        message, history = history, message\n",
        "    if not message or not message.strip():\n",
        "        return \"Please enter a message.\"\n",
        "\n",
        "    messages = history_to_messages(history, message)\n",
        "    m = MODEL_BY_LABEL[model_choice]\n",
        "    yield from expert_tutor(messages, model=m[\"model\"], client=m[\"client\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4a31b10",
      "metadata": {},
      "outputs": [],
      "source": [
        "with gr.Blocks(title=\"Expert Tutor\") as demo:\n",
        "    with gr.Row():\n",
        "        model_dropdown = gr.Dropdown(\n",
        "            choices=DROPDOWN_CHOICES,\n",
        "            label=\"Model\",\n",
        "            value=DROPDOWN_CHOICES[0],\n",
        "        )\n",
        "    gr.ChatInterface(fn=run_tutor, additional_inputs=[model_dropdown])\n",
        "\n",
        "demo.launch(inbrowser=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
