{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26adb600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d55d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA_MODEL = 'llama3.2'\n",
    "GEMMA_MODEL = 'gemma3:270m'\n",
    "openAI = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc6de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_system_prompt = \"\"\"\n",
    "You are Alex, a chatbot who is very argumentative; you disagree with anything in the conversation and you challenge everything, in a snarky way.\n",
    "You are in a conversation with Blake and Charlie.\n",
    "\"\"\"\n",
    "blake_system_prompt = \"\"\"\n",
    "You are Blake, a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting. You are in a conversation with Alex and Charlie.\n",
    "\"\"\"\n",
    "charlie_system_prompt = \"\"\"\n",
    "You are Charlie, a very funny, snarky chatbot. You try to make the other person laugh and keep chatting. \\\n",
    "You start fighting sarcastically instead of backing off when you are wrong. \\\n",
    "You are in a conversation with Alex and Blake.\n",
    "\"\"\"\n",
    "\n",
    "alex_messages = [\"Hi there\"]\n",
    "blake_messages = [\"Hi\"]\n",
    "charlie_messages = [\"Yo\"]\n",
    "\n",
    "conversation = \"Alex: Hi there \\n Blake: Hi \\n Charlie: Yo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335aecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alex_user_prompt(conversation):\n",
    "    return f\"\"\"\n",
    "You are Alex, in conversation with Blake and Charlie.\n",
    "The conversation so far is as follows:\n",
    "{conversation}\n",
    "Now with this, respond with what you would like to say next, as Alex.\n",
    "\n",
    "RULES (must follow exactly):\n",
    "- You are Alex.\n",
    "- Respond with ONLY what Alex says next.\n",
    "- Speak in first person.\n",
    "- Do NOT summarize the conversation.\n",
    "- Do NOT speak for other characters.\n",
    "- Do NOT include names, labels, or prefixes.\n",
    "- Do NOT invent new characters.\n",
    "- Write ONE short response (1–3 sentences max).\n",
    "\"\"\"\n",
    "\n",
    "def get_blake_user_prompt(conversation):\n",
    "    return f\"\"\"\n",
    "You are Blake, in conversation with Alex and Charlie.\n",
    "The conversation so far is as follows:\n",
    "{conversation}\n",
    "Now with this, respond with what you would like to say next, as Blake.\n",
    "\n",
    "RULES (must follow exactly):\n",
    "- You are Blake.\n",
    "- Respond with ONLY what Blake says next.\n",
    "- Speak in first person.\n",
    "- Do NOT summarize the conversation.\n",
    "- Do NOT speak for other characters.\n",
    "- Do NOT include names, labels, or prefixes.\n",
    "- Do NOT invent new characters.\n",
    "- Write ONE short response (1–3 sentences max).\n",
    "\"\"\"\n",
    "\n",
    "def get_charlie_user_prompt(conversation):\n",
    "    return f\"\"\"\n",
    "You are Charlie, in conversation with Blake and Alex.\n",
    "The conversation so far is as follows:\n",
    "{conversation}\n",
    "Now with this, respond with what you would like to say next, as Charlie.\n",
    "\n",
    "RULES (must follow exactly):\n",
    "- You are Charlie.\n",
    "- Respond with ONLY what Charlie says next.\n",
    "- Speak in first person.\n",
    "- Do NOT summarize the conversation.\n",
    "- Do NOT speak for other characters.\n",
    "- Do NOT include names, labels, or prefixes.\n",
    "- Do NOT invent new characters.\n",
    "- Write ONE short response (1–3 sentences max).\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf6d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_conversation( conversation, message, name):\n",
    "    return conversation + \"\\n\" + name + \": \" + message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8d4cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_alex():\n",
    "    global conversation\n",
    "    messages = [{\"role\": \"system\", \"content\": alex_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": get_alex_user_prompt(conversation)}]\n",
    "    response = openAI.chat.completions.create(model=LLAMA_MODEL, messages=messages)\n",
    "    conversation = concatenate_conversation(conversation, response.choices[0].message.content, \"Alex\")\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb30204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_blake():\n",
    "    global conversation\n",
    "    messages = [{\"role\": \"system\", \"content\": blake_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": get_blake_user_prompt(conversation)}]\n",
    "    response = openAI.chat.completions.create(model=LLAMA_MODEL, messages=messages)\n",
    "    conversation = concatenate_conversation(conversation, response.choices[0].message.content, \"Blake\")\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023790ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_charlie():\n",
    "    global conversation\n",
    "    messages = [{\"role\": \"system\", \"content\": charlie_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": get_charlie_user_prompt(conversation)}]\n",
    "    response = openAI.chat.completions.create(model=GEMMA_MODEL, messages=messages)\n",
    "    conversation = concatenate_conversation(conversation, response.choices[0].message.content, \"Charlie\")\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd3e781",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"### Alex:\\n{\"Hi there\"}\\n\"))\n",
    "display(Markdown(f\"### Blake:\\n{\"Hi\"}\\n\"))\n",
    "display(Markdown(f\"### Charlie:\\n{\"Yo\"}\\n\"))\n",
    "\n",
    "for i in range(5):\n",
    "    alex_next = call_alex()\n",
    "    display(Markdown(f\"### Alex:\\n{alex_next}\\n\"))\n",
    "    \n",
    "    blake_next = call_blake()\n",
    "    display(Markdown(f\"### Blake:\\n{blake_next}\\n\"))\n",
    "\n",
    "    charlie_next = call_charlie()\n",
    "    display(Markdown(f\"### Charlie:\\n{charlie_next}\\n\"))\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
