{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup - connect to OpenAI and Ollama\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai = OpenAI()\n",
    "ollama = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "MODELS = {\n",
    "    \"GPT-4o-mini\": (\"gpt-4o-mini\", openai),\n",
    "    \"Llama 3.2 (Ollama)\": (\"llama3.2\", ollama),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "system-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expert system prompt for technical Q&A\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert technical assistant who explains code, APIs, and programming concepts clearly.\n",
    "You help developers understand complex technical questions. Use markdown for code blocks and structure.\n",
    "Be concise but thorough. When explaining code, break it down step by step.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tool",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: simple tool - evaluate safe math expressions\n",
    "def evaluate_expression(expression: str) -> str:\n",
    "    allowed = set(\"0123456789+-*/(). \")\n",
    "    if not all(c in allowed for c in expression):\n",
    "        return \"Error: Only numbers and + - * / ( ) allowed\"\n",
    "    try:\n",
    "        return f\"Result: {eval(expression)}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "eval_tool = {\"type\": \"function\", \"function\": {\"name\": \"evaluate_expression\", \"description\": \"Evaluate a math expression.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"expression\": {\"type\": \"string\"}}, \"required\": [\"expression\"], \"additionalProperties\": False}}}\n",
    "tools = [eval_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handle-tools",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_calls(message):\n",
    "    responses = []\n",
    "    for tool_call in message.tool_calls:\n",
    "        if tool_call.function.name == \"evaluate_expression\":\n",
    "            args = json.loads(tool_call.function.arguments)\n",
    "            responses.append({\"role\": \"tool\", \"content\": evaluate_expression(args.get(\"expression\", \"\")), \"tool_call_id\": tool_call.id})\n",
    "    return responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history, model_choice):\n",
    "    model_name, client = MODELS[model_choice]\n",
    "    history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    stream = client.chat.completions.create(model=model_name, messages=messages, stream=True)\n",
    "    full_response = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.choices and chunk.choices[0].delta.content:\n",
    "            full_response += chunk.choices[0].delta.content or \"\"\n",
    "            yield full_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gradio",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropdown = gr.Dropdown(choices=list(MODELS.keys()), value=\"GPT-4o-mini\", label=\"Model\")\n",
    "gr.ChatInterface(fn=chat, type=\"messages\", additional_inputs=[model_dropdown]).launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
