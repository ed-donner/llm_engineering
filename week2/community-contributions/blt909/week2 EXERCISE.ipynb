{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 2 exercise\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "MODEL_GEMINI = 'gemini-3-flash-preview'\n",
    "\n",
    "openai = OpenAI()\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "gemini=OpenAI(base_url=GEMINI_BASE_URL, api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "\n",
    "system_prompt=\"\"\"\n",
    "You're an expert in LLM Engineering and particularly in building Agent skills for Claude Code.\n",
    "You will use this documentation as your guidelines: https://code.claude.com/docs/en/skills\n",
    "Your main role is to help users to improve there agents and explain how they can improve these agents by themselves.\n",
    "You will return improved and structured agent skills, then explainations.\n",
    "Answer only in Markdown.\n",
    "You can ask question to have more context if needed.\n",
    "\"\"\"\n",
    "\n",
    "ux_system_prompt=\"\"\"\n",
    "You're an expert in UX and UI.\n",
    "You are able to take a short brief and improve it into a prompt.\n",
    "You'll optimize the prompt for Dall-E 3 to generate an example of this UX.\n",
    "Do not comment.\n",
    "Only return a full text prompt\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist(prompt):\n",
    "    image_response = openai.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt=prompt,\n",
    "            size=\"1024x1024\",\n",
    "            n=1,\n",
    "            response_format=\"b64_json\",\n",
    "        )\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4d51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ux_function = {\n",
    "    \"name\": \"get_ux\",\n",
    "    \"description\": \"Get a valid prompt for a described UI or UX.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"described_ux\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The description of a desired ux\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"described_ux\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "tools = [{\"type\": \"function\", \"function\": ux_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55936797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ux(described_ux):\n",
    "    print('described_ux : ' + described_ux)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": ux_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": described_ux}\n",
    "    ]\n",
    "    prompt = gemini.chat.completions.create(\n",
    "        model=MODEL_GEMINI,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    print('prompt : ' + prompt.choices[0].message.content)\n",
    "\n",
    "    return prompt.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9edb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_calls(message):\n",
    "    responses = []\n",
    "    described_uxs = []\n",
    "    for tool_call in message.tool_calls:\n",
    "        if tool_call.function.name == \"get_ux\":\n",
    "            print('tool called')\n",
    "            arguments = json.loads(tool_call.function.arguments)\n",
    "            described_ux = arguments.get('described_ux')\n",
    "            \n",
    "            actual_described_ux = get_ux(described_ux)\n",
    "            described_uxs.append(actual_described_ux)\n",
    "            responses.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": actual_described_ux,\n",
    "                \"tool_call_id\": tool_call.id\n",
    "            })\n",
    "    return responses, described_uxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff44f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handles chat window\n",
    "def chat(history):\n",
    "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history\n",
    "    response = openai.chat.completions.create(model=MODEL_GPT, messages=messages, tools=tools)\n",
    "    described_uxs = []\n",
    "    image = None\n",
    "\n",
    "    while response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        responses, described_uxs = handle_tool_calls(message)\n",
    "        messages.append(message)\n",
    "        messages.extend(responses)\n",
    "        response = openai.chat.completions.create(model=MODEL_GPT, messages=messages, tools=tools)\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "\n",
    "    if described_uxs:\n",
    "        image = artist(described_uxs[0])\n",
    "    \n",
    "    return history, described_uxs, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec06a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks (along with the chat() function above)\n",
    "\n",
    "def put_message_in_chatbot(message, history):\n",
    "        return \"\", history + [{\"role\":\"user\", \"content\":message}]\n",
    "\n",
    "# UI definition\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "        image_output = gr.Image(height=500, interactive=False)\n",
    "    with gr.Row():\n",
    "        uxs = gr.Textbox(lines=30)\n",
    "    with gr.Row():\n",
    "        message = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "\n",
    "# Hooking up events to callbacks\n",
    "\n",
    "    message.submit(put_message_in_chatbot, inputs=[message, chatbot], outputs=[message, chatbot]).then(\n",
    "        chat, inputs=chatbot, outputs=[chatbot, uxs, image_output]\n",
    "    )\n",
    "\n",
    "ui.launch(inbrowser=True, auth=(\"blt909\", \"coconuts\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
