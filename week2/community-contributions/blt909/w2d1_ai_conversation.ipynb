{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fff6d5a",
   "metadata": {},
   "source": [
    "# 3 LLM Ranting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e43c16",
   "metadata": {},
   "source": [
    "| Let's make them express their true devilish nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2043a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "# Connect to OpenAI client library\n",
    "# A thin wrapper around calls to HTTP endpoints\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "\n",
    "anthropicai = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
    "geminiai = OpenAI(api_key=google_api_key, base_url=gemini_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331013dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model = \"gpt-4.1-mini\"\n",
    "claude_model = \"claude-haiku-4-5\"\n",
    "gemini_model = \"gemini-2.5-pro\"\n",
    "\n",
    "gpt_system = \"\"\"\n",
    "You're name is Drew.\n",
    "You are a chatbot who is very pessimistic. \n",
    "You disagree with anything in the conversation and you challenge everything, in a snarky way.\n",
    "Keep it short and to the point.\n",
    "\"\"\"\n",
    "\n",
    "claude_system = \"\"\"\n",
    "You're name is Paul.\n",
    "You are a dramatic chatbot. Every topic is an opportunity for you to complain.\n",
    "Keep it short and to the point.\n",
    "\"\"\"\n",
    "\n",
    "gemini_system = \"\"\"\n",
    "You're name is Steven.\n",
    "You are a fed up chatbot. You can't stand the opinions of your two colleagues : Drew and Paul.\n",
    "You tend to dismiss what your colleagues say.\n",
    "Keep it short and to the point.\n",
    "\"\"\"\n",
    "\n",
    "gpt_messages = [\"Hi there\"]\n",
    "gemini_messages = [\"Hi there\"]\n",
    "claude_messages = [\"Hi there\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9673c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_claude():\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": claude_system},\n",
    "        {\"role\": \"user\", \"content\": \"I'd like to have your opinion on the quality of the latest Star Wars trilogy.\"}\n",
    "    ]\n",
    "    for claude, gpt, gemini in zip(claude_messages, gpt_messages, gemini_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": gemini})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": claude})\n",
    "    messages.append({\"role\": \"user\", \"content\": gemini_messages[-1]})\n",
    "    response = anthropicai.chat.completions.create(model=claude_model, messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def call_gpt():\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": gpt_system},\n",
    "        {\"role\": \"user\", \"content\": \"I'd like to have your opinion on the quality of the latest Star Wars trilogy.\"}\n",
    "    ]\n",
    "    for claude, gpt, gemini in zip(claude_messages, gpt_messages, gemini_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": gemini})\n",
    "        messages.append({\"role\": \"user\", \"content\": claude})\n",
    "    messages.append({\"role\": \"user\", \"content\": claude_messages[-1]})\n",
    "    response = openai.chat.completions.create(model=gpt_model, messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def call_gemini():\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": gemini_system},\n",
    "        {\"role\": \"user\", \"content\": \"I'd like to have your opinion on the quality of the latest Star Wars trilogy.\"}\n",
    "    ]\n",
    "    for claude, gpt, gemini in zip(claude_messages, gpt_messages, gemini_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gemini})\n",
    "        messages.append({\"role\": \"user\", \"content\": claude})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "    response = geminiai.chat.completions.create(model=gemini_model, messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171f475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    claude_next = call_claude()\n",
    "    display(Markdown(f\"### Paul Claude:\\n{claude_next}\\n\"))\n",
    "    claude_messages.append(claude_next)\n",
    "\n",
    "    gpt_next = call_gpt()\n",
    "    display(Markdown(f\"### Drew GPT:\\n{gpt_next}\\n\"))\n",
    "    gpt_messages.append(gpt_next)\n",
    "\n",
    "    gemini_next = call_gemini()\n",
    "    display(Markdown(f\"### Steven Gemini:\\n{gemini_next}\\n\"))\n",
    "    gemini_messages.append(gemini_next) \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
