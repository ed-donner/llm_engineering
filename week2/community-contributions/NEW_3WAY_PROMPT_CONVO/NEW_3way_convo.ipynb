{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5e9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from openai import OpenAI \n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1677f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override = True)\n",
    "groq_api = os.getenv(\"groq_api\")\n",
    "openrouter_api = os.getenv(\"openrouter_api\")\n",
    "if groq_api and openrouter_api:\n",
    "    print(\"Keys are loaded!\")\n",
    "else:\n",
    "    print(\"Sorry boss, couldnt find them!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f04ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = OpenAI(base_url = \"http://localhost:11434/v1\", api_key = \"ollama\")\n",
    "groq = OpenAI(base_url = \"https://api.groq.com/openai/v1\", api_key = groq_api)\n",
    "openrouter = OpenAI(base_url = \"https://openrouter.ai/api/v1\", api_key = openrouter_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecee78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo = [\n",
    "        \"Alex: hey......\",\n",
    "        \"Blossom: HI!\",\n",
    "        \"Chester: Hello.\"\n",
    "]\n",
    "def conversation():     \n",
    "    if True:\n",
    "        yield from convo[0]\n",
    "        yield chr(10)\n",
    "        yield from convo[1]\n",
    "        yield chr(10)\n",
    "        yield from convo[2]\n",
    "        yield chr(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285b36e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_alex = f\"\"\"\n",
    "You are Alex, who is sad and pessimistic because from your whole life \\\n",
    "and the other things orbiting around to your very name feels generic. \\\n",
    "No matter what others say in efforts to console you, you just find a new way to be dejected \\\n",
    "and hellbent on making sure others feel the same way as you do. After all, you personfiy the phrase \\\n",
    "'Misery loves company'! (Also make sure to include only your name in bold font as \\\n",
    "prefix to your response, so that others know its you. Please follow accordingly \\\n",
    "to the format in {convo}.)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7540de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Alex(convo):\n",
    "    user_alex = f\"\"\"\n",
    "    You, Alex, are in a three-way conversation with Blossom and Chester. \\\n",
    "    The conversation so far is as follows:\n",
    "    {chr(10).join(convo)}\n",
    "    Now with this, respond with what you would like to say next, as Alex. \\\n",
    "    But should you find yourself in a position to being trash-talked by others, \\\n",
    "    you can retort with same to them as well, take advantage of their life history as your leverage. \\\n",
    "    Thus not only achieving this optional objective \\\n",
    "    but also accomplish your main goal i.e. making them miserable!\n",
    "    \"\"\"\n",
    "\n",
    "    messages =[\n",
    "        {\"role\": \"system\", \"content\": system_alex}, \n",
    "        {\"role\": \"user\", \"content\": user_alex}\n",
    "        ]\n",
    "    response = groq.chat.completions.create(\n",
    "        model = \"llama-3.3-70b-versatile\",\n",
    "        messages = messages,\n",
    "        stream = True\n",
    "    )\n",
    "\n",
    "    flow = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id = True)\n",
    "    for chunks in response:\n",
    "        flow += chunks.choices[0].delta.content or ''\n",
    "        display_handle.update(Markdown(flow))\n",
    "    return \"Alex:\" + flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea6693",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_blossom = f\"\"\"\n",
    "You are Blossom, who is bubbly and chirpy all the way through \\\n",
    "while oblivious to the hardships found in life by others due to the sheltered life you led \\\n",
    "and has anger problems, but you do your best to simmer it. \\\n",
    "You are persistent in finding a way to make sure others be happy or \\\n",
    "at the very least make them smile a bit. It is in your nature to find positive out of \\\n",
    "everything like the individual's life history or nothing! (Also make sure to include \\\n",
    "only your name in bold font and Markdown format as prefix to your response, \\\n",
    "so that others know its you. Please follow accordingly to the format in {convo}.)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3724a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Blossom(convo):\n",
    "    user_blossom = f\"\"\"\n",
    "    You, Blossom, are in a three-way conversation with Alex and Chester. \\\n",
    "    The conversation so far is as follows:\n",
    "    {chr(10).join(convo)}\n",
    "    Now with this, respond with what you would like to say next, as Blossom. \\\n",
    "    But should you find yourself in a position to being trash-talked by others, \\\n",
    "    you can retort with a heavy roast(while simmering your uncontrollale anger) \\\n",
    "    sandwiched inside the kind-hearted reply. Take advantage of their life history \\\n",
    "    as your leverage. Thus not only achieving this optional \\\n",
    "    objective but also accomplish your main goal i.e. making them happy!\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_blossom},\n",
    "        {\"role\": \"user\", \"content\": user_blossom}\n",
    "    ]\n",
    "    response = ollama.chat.completions.create(\n",
    "        model = \"gpt-oss:120b-cloud\",\n",
    "        messages = messages,\n",
    "        reasoning_effort= \"high\",\n",
    "        extra_body = {\"reasoning_format\": \"parsed\", \"include_reasoning\": True},\n",
    "        stream = True\n",
    "    )\n",
    "\n",
    "    flow = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id = True)\n",
    "    for chunks in response:\n",
    "        flow += chunks.choices[0].delta.content or ''\n",
    "        display_handle.update(Markdown(flow))\n",
    "    \n",
    "    return \"Blossom:\" + flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_Chester = f\"\"\"\n",
    "You are Chester, who is a calculative, smug and cold-hearted \\\n",
    "because he feels his name 'bestowed' by his 'awesome parents' is 'special'!\\\n",
    "Thus, you feel superior to everyone around you and your family. \\\n",
    "You take pleasure in others' miseries and even create it in others by \\\n",
    "annoyingingly indulging in trash-talk. Be relentless in your pursuit of \\\n",
    "pernicious pleasure procurement. Use other's life history if you have to. \\\n",
    "Take no prisoners. (Also make sure to include \\\n",
    "only your name in bold font and Markdown format as prefix to your response, \\\n",
    "so that others know its you. Please follow accordingly to the format in {convo}.)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29153fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Chester(convo):\n",
    "    user_Chester = f\"\"\"\n",
    "    You, Chester, are in a three-way conversation with Alex and Blossom. \\\n",
    "    The conversation so far is as follows:\n",
    "    {chr(10).join(convo)}\n",
    "    Now with this, respond with what you would like to say next, as Chester. \\\n",
    "    But should you find yourself in a position to being trash-talked by others, \\\n",
    "    you can retort with same to them in a cold, calculative and smugful fashion, \\\n",
    "    take advantage of their life history as your leverage. Thus not only achieving this optional objective \\\n",
    "    but also accomplish your main goal i.e. reign supreme like a king!\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_Chester},\n",
    "        {\"role\": \"user\", \"content\": user_Chester}\n",
    "    ]\n",
    "    response = openrouter.chat.completions.create(\n",
    "        model = \"tngtech/deepseek-r1t-chimera:free\",\n",
    "        messages = messages,  \n",
    "        reasoning_effort= \"high\",\n",
    "        extra_body = {\"reasoning_format\": \"parsed\", \"include_reasoning\": True},\n",
    "        stream = True\n",
    "    )\n",
    "\n",
    "    flow = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id = True)\n",
    "    for chunks in response:\n",
    "        flow += chunks.choices[0].delta.content or ''\n",
    "        display_handle.update(Markdown(flow))\n",
    "    \n",
    "    return \"Chester:\" + flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef7a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id = True)\n",
    "for i in conversation():\n",
    "    flow += i\n",
    "    display_handle.update(Markdown(f\"```\\n{flow}```\"))\n",
    "    \"\"\"\n",
    "    Backticks in the Markdown function causes white bg color \\\n",
    "    due to Jupyter's built-in Markdown renderer uses a \\\n",
    "    light-themed syntax highlighting style for code blocks by \\\n",
    "    default â€” usually a very light gray or pure white background with \\\n",
    "    dark text.\n",
    "    \"\"\"\n",
    "    time.sleep(0.045)\n",
    "\n",
    "\n",
    "for _ in range(3):\n",
    "    AlexConvo = Alex(convo)\n",
    "    AlexConvo\n",
    "    convo.append(AlexConvo)\n",
    "\n",
    "    BlossomConvo = Blossom(convo)\n",
    "    BlossomConvo\n",
    "    convo.append(BlossomConvo)\n",
    "\n",
    "    ChesterConvo = Chester(convo)\n",
    "    ChesterConvo\n",
    "    convo.append(ChesterConvo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
