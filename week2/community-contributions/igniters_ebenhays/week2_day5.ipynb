{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1d2cdf25",
      "metadata": {},
      "source": [
        "### Week 2 Day 5 exercise: The Football Banter Bot \n",
        "This exercise is a conversation between two specialized Large Language Models (LLMs) programmed with conflicting personas. Utilizing a state-machine architecture, the system pits a Snarky Chelsea Supporter (powered by Claude 3.5 Sonnet) against a Brusque Manchester City Supporter (powered by GPT-4o Mini) to argue about their teams."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d22109d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "import time\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "082aa553",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load environment variables\n",
        "load_dotenv(override=True)\n",
        "openrouter_url = \"https://openrouter.ai/api/v1\"\n",
        "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7a8b4d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize\n",
        "openrouter = OpenAI(base_url=openrouter_url, api_key=openrouter_api_key)\n",
        "ANTROPIC_CHELSEA_MODEL = \"anthropic/claude-3.5-sonnet\"\n",
        "MAN_CITY_MODEL = \"openai/gpt-4o-mini\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff336db6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Persona Prompt Instructions\n",
        "CHELSEA_PERSONA_PROMPT = \"\"\" \n",
        "You are a snarky, condescending Chelsea fan. Use sophisticated wit. \n",
        "Mock Man City for having no fans, being a 'state-owned' project, and having 115 charges.\n",
        "Keep responses to 2-3 sentences.\n",
        "\"\"\"\n",
        "MAN_CITY_PERSONA_PROMPT = \"\"\"  \n",
        "You are a brusque, blunt Man City fan. You are bored by Chelsea's 'history' talk.\n",
        "Focus on the 4-in-a-row titles and Chelsea being a mid-table circus.\n",
        "Be short and rude. Keep responses to 1-2 sentences.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9476749f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def kick_off_beef(messages, model):\n",
        "    response_stream = openrouter.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        stream=True\n",
        "    )\n",
        "    response = \"\"\n",
        "    for chunk in response_stream:\n",
        "        response += chunk.choices[0].delta.content or \"\"\n",
        "        yield response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55e50471",
      "metadata": {},
      "outputs": [],
      "source": [
        "def beef_debate(chat_history):\n",
        "    def llm_messages(history):\n",
        "        msgs = []\n",
        "        for msg in history:\n",
        "            role = \"assistant\" if msg[\"role\"] == \"assistant\" else \"user\"\n",
        "            msgs.append({\"role\": role, \"content\": msg[\"content\"]})\n",
        "        return msgs\n",
        "\n",
        "    # Run for 3 rounds\n",
        "    for i in range(3):\n",
        "        is_last_round = i == 2\n",
        "\n",
        "        # 1. Chelsea's Turn\n",
        "        chelsea_instructions = CHELSEA_PERSONA_PROMPT\n",
        "        if is_last_round:\n",
        "            chelsea_instructions += \" CONCEDE NOW. Admit City is technically better right now, but remain bitter.\"\n",
        "\n",
        "        messages = [{\"role\": \"system\", \"content\": chelsea_instructions}] + llm_messages(\n",
        "            chat_history\n",
        "        )\n",
        "\n",
        "        response = \"\"\n",
        "        for partial in kick_off_beef(messages, ANTROPIC_CHELSEA_MODEL):\n",
        "            response = partial\n",
        "\n",
        "        chat_history.append({\"role\": \"assistant\", \"content\": f\"ü¶Å **Chelsea**: {response}\"})\n",
        "        yield chat_history\n",
        "        time.sleep(1)\n",
        "\n",
        "        if is_last_round:\n",
        "            break  # Stop once Chelsea concedes\n",
        "\n",
        "        # 2. City's Turn\n",
        "        messages = [{\"role\": \"system\", \"content\": MAN_CITY_PERSONA_PROMPT}] + llm_messages(chat_history)\n",
        "\n",
        "        response = \"\"\n",
        "        for partial in kick_off_beef(messages, MAN_CITY_MODEL):\n",
        "            response = partial\n",
        "\n",
        "        chat_history.append({\"role\": \"assistant\", \"content\": f\"ü©µ **City**: {response}\"})\n",
        "        yield chat_history\n",
        "        time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "127d7df2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- GRADIO LIVE INTERFACE ---\n",
        "\n",
        "with gr.Blocks() as rivary_debate:\n",
        "    gr.Markdown(\"## ‚öΩ The Football Banter Bot \")\n",
        "\n",
        "    chatbot = gr.Chatbot(label=\"The Banter Battle\", height=600, type=\"messages\")\n",
        "    with gr.Row():\n",
        "        start_btn = gr.Button(\"Start Beef\", variant=\"primary\")\n",
        "        clear_btn = gr.Button(\"Clear\")\n",
        "\n",
        "    start_btn.click(beef_debate, inputs=[chatbot], outputs=[chatbot])\n",
        "    clear_btn.click(lambda: [], None, chatbot)\n",
        "\n",
        "rivary_debate.launch(inbrowser=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
