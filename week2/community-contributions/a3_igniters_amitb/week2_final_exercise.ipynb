{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3c67e517",
      "metadata": {},
      "source": [
        "## Multi-modal AI Tutor with UI, streaming, tool calls, and support for multiple model switching\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da7390cb",
      "metadata": {},
      "source": [
        "### Define imports and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "9811ff2c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import sqlite3\n",
        "\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "from openai import OpenAI\n",
        "\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "8e8b3b9f",
      "metadata": {},
      "outputs": [],
      "source": [
        "DEFAULT_MODEL = 'openai/gpt-4o-mini'\n",
        "OPENROUTER_URL = \"https://openrouter.ai/api/v1\"\n",
        "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "8c3fb690",
      "metadata": {},
      "outputs": [],
      "source": [
        "openrouter = OpenAI(base_url=OPENROUTER_URL, api_key=OPENROUTER_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "20f4a668",
      "metadata": {},
      "outputs": [],
      "source": [
        "from prompts.ai_tutor import SYSTEM_PROMPT, USER_PROMPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "ae712b3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "ERROR_TEMPLATE = \"I'm sorry, I couldn't find an answer to your question.\\nError: {error_message}\\n\"\n",
        "ERROR_MSG_NO_RESPONSE = \"No response from AI Tutor\"\n",
        "ERROR_MSG_NO_QUERY = \"Query not found. Please ask a technical question!\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45166578",
      "metadata": {},
      "source": [
        "### Take user query and pass it to the AI Tutor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "b8bc6ad7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_response(question: str):\n",
        "    \"\"\"\n",
        "    This function takes a user query and passes it to the AI Tutor.\n",
        "    Args:\n",
        "        question (str): user query\n",
        "    Returns:\n",
        "        response (str): response from the AI Tutor prompt\n",
        "    \"\"\"\n",
        "    if not question:\n",
        "        return ERROR_TEMPLATE.format(error_message=ERROR_MSG_NO_QUERY)\n",
        "    response = openrouter.chat.completions.create(\n",
        "        model=DEFAULT_MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": USER_PROMPT.format(question=question)}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content if response.choices[0] else \\\n",
        "        ERROR_TEMPLATE.format(error_message=ERROR_MSG_NO_RESPONSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2675251b",
      "metadata": {},
      "source": [
        "### Move prompt options/list records to database (SQLite3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a928b233",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "AVAILABLE_MODELS = [\n",
        "    \"openai/gpt-4o-mini\",\n",
        "    \"openai/gpt-4o\",\n",
        "    \"anthropic/claude-3-5-sonnet\",\n",
        "    \"google/gemini-2.0-flash-001\",\n",
        "    \"meta-llama/llama-3.3-70b-instruct\",\n",
        "]\n",
        "\n",
        "DB = \"database/topics.db\"\n",
        "\n",
        "def get_topic_resources(topic: str) -> str:\n",
        "    print(f\"DATABASE TOOL CALLED: Getting resources for {topic}\", flush=True)\n",
        "    with sqlite3.connect(DB) as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\n",
        "            \"SELECT url FROM topic_resources WHERE ? LIKE '%' || topic || '%'\",\n",
        "            (topic.lower(),)\n",
        "        )\n",
        "        results = cursor.fetchall()\n",
        "    if results:\n",
        "        return f\"Resources for {topic}:\\n\" + \"\\n\".join(f\"- {row[0]}\" for row in results)\n",
        "    return f\"No specific resources found for '{topic}'. Try official docs or Stack Overflow.\"\n",
        "\n",
        "get_topic_resources_fn = {\n",
        "    \"name\": \"get_topic_resources\",\n",
        "    \"description\": \"Get curated learning resources and documentation links for a technical topic.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"topic\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The technical topic to fetch resources for (e.g. Python, SQL, Machine Learning, LLMs)\",\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"topic\"],\n",
        "        \"additionalProperties\": False\n",
        "    }\n",
        "}\n",
        "tools = [{\"type\": \"function\", \"function\": get_topic_resources_fn}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "faf77f59",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DB ready: topics.db\n"
          ]
        }
      ],
      "source": [
        "with sqlite3.connect(DB) as conn:\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS topic_resources (\n",
        "            topic TEXT,\n",
        "            url   TEXT\n",
        "        )\n",
        "    \"\"\")\n",
        "    cursor.execute(\"SELECT COUNT(*) FROM topic_resources\")\n",
        "    if cursor.fetchone()[0] == 0:\n",
        "        cursor.executemany(\"INSERT INTO topic_resources (topic, url) VALUES (?, ?)\", [\n",
        "            (\"python\",           \"https://docs.python.org/3/\"),\n",
        "            (\"python\",           \"https://realpython.com/\"),\n",
        "            (\"sql\",              \"https://www.w3schools.com/sql/\"),\n",
        "            (\"sql\",              \"https://sqlzoo.net/\"),\n",
        "            (\"machine learning\", \"https://scikit-learn.org/stable/\"),\n",
        "            (\"machine learning\", \"https://www.kaggle.com/learn/\"),\n",
        "            (\"deep learning\",    \"https://www.deeplearning.ai/\"),\n",
        "            (\"deep learning\",    \"https://pytorch.org/tutorials/\"),\n",
        "            (\"data science\",     \"https://pandas.pydata.org/docs/\"),\n",
        "            (\"data science\",     \"https://numpy.org/doc/\"),\n",
        "            (\"llm\",              \"https://huggingface.co/docs\"),\n",
        "            (\"llm\",              \"https://platform.openai.com/docs\"),\n",
        "        ])\n",
        "    conn.commit()\n",
        "    print(f\"DB ready: {DB}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa1791e0",
      "metadata": {},
      "source": [
        "### Build image generation method with openrouter multimodal capability\n",
        "Reference - https://openrouter.ai/docs/guides/overview/multimodal/image-generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "8e2bb32e",
      "metadata": {},
      "outputs": [],
      "source": [
        "IMAGE_MODEL = \"google/gemini-3-pro-image-preview\"\n",
        "\n",
        "def generate_diagram(question: str) -> Image.Image | None:\n",
        "    try:\n",
        "        prompt = (\n",
        "            f\"Create a clean, educational diagram or visual illustration to explain: '{question}'. \"\n",
        "            \"Use a white background, clear labels, and a minimalist style. \"\n",
        "            \"Show key concepts, relationships, or steps visually. No paragraphs of text.\"\n",
        "        )\n",
        "        response = openrouter.chat.completions.create(\n",
        "            model=IMAGE_MODEL,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            modalities=[\"image\", \"text\"]\n",
        "        )\n",
        "        images = response.choices[0].message.model_dump().get('images', [])\n",
        "        if not images:\n",
        "            print(\"Diagram generation failed: no images in response\", flush=True)\n",
        "            return None\n",
        "        image_data = base64.b64decode(images[0]['image_url']['url'].split(\",\", 1)[1])\n",
        "        return Image.open(BytesIO(image_data))\n",
        "    except Exception as e:\n",
        "        print(f\"Diagram generation failed: {e}\", flush=True)\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9839587",
      "metadata": {},
      "source": [
        "### Building chat, history, and handling tool calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "5b772ca9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def handle_tool_calls(message):\n",
        "    responses = []\n",
        "    for tool_call in message.tool_calls:\n",
        "        if tool_call.function.name == \"get_topic_resources\":\n",
        "            arguments = json.loads(tool_call.function.arguments)\n",
        "            topic = arguments.get('topic')\n",
        "            print(f\"TOOL CALLED: get_topic_resources({topic})\", flush=True)\n",
        "            responses.append({\n",
        "                \"role\": \"tool\",\n",
        "                \"content\": get_topic_resources(topic),\n",
        "                \"tool_call_id\": tool_call.id\n",
        "            })\n",
        "    return responses\n",
        "\n",
        "\n",
        "def put_message_in_chatbot(message, history):\n",
        "    return \"\", history + [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "\n",
        "def chat(history, model):\n",
        "    user_message = history[-1][\"content\"]\n",
        "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
        "    for h in history[:-1]:\n",
        "        messages.append({\"role\": h[\"role\"], \"content\": h[\"content\"]})\n",
        "    messages.append({\"role\": \"user\", \"content\": USER_PROMPT.format(question=user_message)})\n",
        "\n",
        "    response = openrouter.chat.completions.create(\n",
        "        model=model or DEFAULT_MODEL,\n",
        "        messages=messages,\n",
        "        tools=tools\n",
        "    )\n",
        "\n",
        "    while response.choices[0].finish_reason == \"tool_calls\":\n",
        "        tool_message = response.choices[0].message\n",
        "        tool_responses = handle_tool_calls(tool_message)\n",
        "        messages.append(tool_message)\n",
        "        messages.extend(tool_responses)\n",
        "        response = openrouter.chat.completions.create(\n",
        "            model=model or DEFAULT_MODEL,\n",
        "            messages=messages,\n",
        "            tools=tools\n",
        "        )\n",
        "\n",
        "    history += [{\"role\": \"assistant\", \"content\": \"\"}]\n",
        "    stream = openrouter.chat.completions.create(\n",
        "        model=model or DEFAULT_MODEL,\n",
        "        messages=messages,\n",
        "        stream=True\n",
        "    )\n",
        "    for chunk in stream:\n",
        "        history[-1][\"content\"] += chunk.choices[0].delta.content or ''\n",
        "        yield history, None\n",
        "\n",
        "    diagram = generate_diagram(user_message)\n",
        "    yield history, diagram"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95f24b0f",
      "metadata": {},
      "source": [
        "### Add Gradio UI Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "8d65bd0d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7864\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with gr.Blocks() as ui:\n",
        "    gr.Markdown(\"# AI Tutor\")\n",
        "    model_selector = gr.Dropdown(\n",
        "        choices=AVAILABLE_MODELS,\n",
        "        value=DEFAULT_MODEL,\n",
        "        label=\"Model\"\n",
        "    )\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3):\n",
        "            chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
        "            message = gr.Textbox(label=\"Ask your question:\")\n",
        "        with gr.Column(scale=1):\n",
        "            image_output = gr.Image(label=\"Visual Aid\", interactive=False, height=500)\n",
        "\n",
        "    message.submit(\n",
        "        put_message_in_chatbot,\n",
        "        inputs=[message, chatbot],\n",
        "        outputs=[message, chatbot]\n",
        "    ).then(\n",
        "        chat,\n",
        "        inputs=[chatbot, model_selector],\n",
        "        outputs=[chatbot, image_output]\n",
        "    )\n",
        "\n",
        "ui.launch(inbrowser=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cc99051",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
