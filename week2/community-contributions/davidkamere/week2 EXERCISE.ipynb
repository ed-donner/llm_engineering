{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7c22307",
   "metadata": {},
   "source": [
    "# Week 2 Exercise - Simple Technical Tutor\n",
    "\n",
    "A simple prototype with Gradio UI, streaming, model switch (Llama/OpenRouter), SQLite tool calling, and optional image input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4482ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import mimetypes\n",
    "import sqlite3\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a345109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "MODEL_LLAMA = \"llama3.2\"\n",
    "MODEL_OPENROUTER = \"openai/gpt-4o-mini\"\n",
    "DB_PATH = \"week2_kb.db\"\n",
    "\n",
    "load_dotenv(override=True)\n",
    "ollama_client = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "openrouter_client = OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=os.getenv(\"OPENROUTER_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3235f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# database and tools\n",
    "def init_db():\n",
    "    with sqlite3.connect(DB_PATH) as conn:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"CREATE TABLE IF NOT EXISTS knowledge (topic TEXT PRIMARY KEY, answer TEXT NOT NULL)\")\n",
    "        seed = [\n",
    "            (\"rag\", \"RAG retrieves relevant external context before generation to improve grounding.\"),\n",
    "            (\"embedding\", \"Embeddings convert text into vectors to support semantic similarity search.\"),\n",
    "            (\"hallucination\", \"Hallucination is when the model generates unsupported or incorrect information.\"),\n",
    "            (\"vector database\", \"A vector database stores embeddings and retrieves nearest neighbors for RAG.\")\n",
    "        ]\n",
    "        cur.executemany(\"INSERT OR IGNORE INTO knowledge(topic, answer) VALUES (?, ?)\", seed)\n",
    "        conn.commit()\n",
    "\n",
    "def lookup_topic(topic):\n",
    "    with sqlite3.connect(DB_PATH) as conn:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"SELECT topic, answer FROM knowledge WHERE lower(topic)=lower(?)\", (topic,))\n",
    "        row = cur.fetchone()\n",
    "    if row:\n",
    "        return {\"topic\": row[0], \"answer\": row[1]}\n",
    "    return {\"topic\": topic, \"answer\": \"No database entry found.\"}\n",
    "\n",
    "def save_topic(topic, answer):\n",
    "    with sqlite3.connect(DB_PATH) as conn:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"INSERT INTO knowledge(topic, answer) VALUES (?, ?) ON CONFLICT(topic) DO UPDATE SET answer=excluded.answer\", (topic, answer))\n",
    "        conn.commit()\n",
    "    return {\"status\": \"saved\", \"topic\": topic}\n",
    "\n",
    "init_db()\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"lookup_topic\",\n",
    "            \"description\": \"Look up a technical AI topic in the SQLite knowledge base.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\"topic\": {\"type\": \"string\"}},\n",
    "                \"required\": [\"topic\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"save_topic\",\n",
    "            \"description\": \"Save or update a technical topic in the SQLite knowledge base.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"topic\": {\"type\": \"string\"},\n",
    "                    \"answer\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"topic\", \"answer\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "TOOL_REGISTRY = {\"lookup_topic\": lookup_topic, \"save_topic\": save_topic}\n",
    "\n",
    "def execute_tool_call(tool_call, tool_activity):\n",
    "    name = tool_call.function.name\n",
    "    try:\n",
    "        args = json.loads(tool_call.function.arguments or \"{}\")\n",
    "        result = TOOL_REGISTRY[name](**args)\n",
    "        tool_activity.append(f\"{name}({args}) -> {result}\")\n",
    "        return {\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": json.dumps(result)}\n",
    "    except Exception as e:\n",
    "        err = {\"error\": str(e), \"tool\": name}\n",
    "        tool_activity.append(f\"{name} error -> {err}\")\n",
    "        return {\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": json.dumps(err)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eabaa30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts and streaming\n",
    "system_prompt = \"You are a technical tutor for AI and RAG. Use concise explanations with sections: Short answer, How it works, Example, Analogy. Use tool results when available.\"\n",
    "\n",
    "def image_to_data_url(path):\n",
    "    if not path:\n",
    "        return None\n",
    "    mime = mimetypes.guess_type(path)[0] or \"image/png\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    return f\"data:{mime};base64,{b64}\"\n",
    "\n",
    "def build_messages(question, image_path=None):\n",
    "    if image_path:\n",
    "        data_url = image_to_data_url(image_path)\n",
    "        user_content = [\n",
    "            {\"type\": \"text\", \"text\": question},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": data_url}}\n",
    "        ]\n",
    "    else:\n",
    "        user_content = question\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "    ]\n",
    "\n",
    "def stream_llama(question, image_path=None):\n",
    "    text_question = question if not image_path else question + \" (User uploaded an image, but local Llama path is text-only.)\"\n",
    "    messages = build_messages(text_question, image_path=None)\n",
    "    stream = ollama_client.chat.completions.create(model=MODEL_LLAMA, messages=messages, temperature=0.2, stream=True)\n",
    "    result = \"\"\n",
    "    tool_trace = \"No tools used (Llama path).\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result, tool_trace\n",
    "\n",
    "def stream_openrouter(question, image_path=None):\n",
    "    if not os.getenv(\"OPENROUTER_API_KEY\"):\n",
    "        yield \"OPENROUTER_API_KEY is missing. Add it to your .env file.\", \"\"\n",
    "        return\n",
    "\n",
    "    messages = build_messages(question, image_path=image_path)\n",
    "    tool_activity = []\n",
    "    response = openrouter_client.chat.completions.create(model=MODEL_OPENROUTER, messages=messages, tools=tools, temperature=0.2)\n",
    "\n",
    "    iterations = 0\n",
    "    while response.choices[0].finish_reason == \"tool_calls\" and iterations < 5:\n",
    "        iterations += 1\n",
    "        message = response.choices[0].message\n",
    "        tool_messages = [execute_tool_call(tc, tool_activity) for tc in (message.tool_calls or [])]\n",
    "        messages.append(message)\n",
    "        messages.extend(tool_messages)\n",
    "        response = openrouter_client.chat.completions.create(model=MODEL_OPENROUTER, messages=messages, tools=tools, temperature=0.2)\n",
    "\n",
    "    tool_trace = \"\\n\".join(tool_activity) if tool_activity else \"No tools were called.\"\n",
    "    stream = openrouter_client.chat.completions.create(model=MODEL_OPENROUTER, messages=messages, temperature=0.2, stream=True)\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result, tool_trace\n",
    "\n",
    "def stream_answer(question, model_choice, image_path):\n",
    "    if not question.strip():\n",
    "        yield \"Please enter a technical question.\", \"\"\n",
    "        return\n",
    "    if model_choice == \"Llama\":\n",
    "        yield from stream_llama(question, image_path=image_path)\n",
    "    elif model_choice == \"OpenRouter\":\n",
    "        yield from stream_openrouter(question, image_path=image_path)\n",
    "    else:\n",
    "        yield \"Unknown model selected.\", \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e784caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradio ui\n",
    "question_input = gr.Textbox(label=\"Your technical question\", lines=4)\n",
    "model_selector = gr.Dropdown([\"Llama\", \"OpenRouter\"], label=\"Select model\", value=\"OpenRouter\")\n",
    "image_input = gr.Image(type=\"filepath\", label=\"Optional image (multimodal)\")\n",
    "answer_output = gr.Markdown(label=\"Answer\")\n",
    "tool_output = gr.Textbox(label=\"Tool Activity\", lines=8)\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_answer,\n",
    "    inputs=[question_input, model_selector, image_input],\n",
    "    outputs=[answer_output, tool_output],\n",
    "    title=\"Week 2 Technical Tutor\",\n",
    "    description=\"Simple streaming tutor with model switch, SQLite tools, optional image input, and tool trace panel.\",\n",
    "    examples=[\n",
    "        [\"What is RAG and why does it reduce hallucinations?\", \"OpenRouter\", None],\n",
    "        [\"Look up embedding in the knowledge base and explain it with an analogy.\", \"OpenRouter\", None],\n",
    "        [\"What is a vector database?\", \"Llama\", None]\n",
    "    ],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "\n",
    "view.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
