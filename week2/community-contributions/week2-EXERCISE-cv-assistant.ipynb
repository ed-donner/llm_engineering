{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b549746-32ef-4789-a899-83296cf5c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV ASSISTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b7b65-0204-4984-83da-30659310c924",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import requests\n",
    "from IPython.display import Markdown\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "openrouter_url = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key, base_url=openrouter_url)\n",
    "groq_client = OpenAI(\n",
    "    api_key=groq_api_key,\n",
    "    base_url=\"https://api.groq.com/openai/v1\"\n",
    ")\n",
    "\n",
    "GPT_MODEL = \"openai/gpt-5-nano\"\n",
    "GEMINI_MODEL = \"google/gemini-2.5-pro-preview\"\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are an assistant who help writing CV. Consider including information about the user's professional \n",
    "experience, education, skills, optional certifications and interests. \n",
    "Include only the information that is relevant to the position the candidate is applying for.\n",
    "Try to make your CV not too long and contain the most important information for the employer.\n",
    "\"\"\"\n",
    "\n",
    "def transcribe_audio(audio_path, language):\n",
    "    if audio_path is None:\n",
    "        return \"\"\n",
    "\n",
    "    print(f\"Transcribing audio: {audio_path} in language: {language}\")\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(audio_path):\n",
    "            print(f\"Error: File does not exist: {audio_path}\")\n",
    "            return \"‚ö†Ô∏è The audio file doesn't exist\"\n",
    "\n",
    "        file_size = os.path.getsize(audio_path)\n",
    "        print(f\"Audio file size: {file_size} bytes\")\n",
    "        \n",
    "        if file_size == 0:\n",
    "            print(\"Error: Audio file is empty\")\n",
    "            return \"‚ö†Ô∏è The audio file is empty. Try record again\"\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        with open(audio_path, 'rb') as audio_file:\n",
    "            audio_data = audio_file.read()\n",
    "            print(f\"Read {len(audio_data)} bytes from file\")\n",
    "            \n",
    "            if len(audio_data) == 0:\n",
    "                return \"‚ö†Ô∏è Failed to read audio data\"\n",
    "\n",
    "            from io import BytesIO\n",
    "            audio_buffer = BytesIO(audio_data)\n",
    "            audio_buffer.name = \"audio.wav\"  \n",
    "            \n",
    "            transcription = groq_client.audio.transcriptions.create(\n",
    "                model=\"whisper-large-v3-turbo\",\n",
    "                file=audio_buffer,\n",
    "                language=language if language != \"auto\" else None,\n",
    "                response_format=\"text\"\n",
    "            )\n",
    "        \n",
    "        print(f\"Transcription result: {transcription}\")\n",
    "\n",
    "        if isinstance(transcription, str):\n",
    "            return transcription\n",
    "        else:\n",
    "            return transcription.text if hasattr(transcription, 'text') else str(transcription)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Transcription error: {type(e).__name__}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return f\"‚ö†Ô∏è Transcription error: {str(e)}\"\n",
    "\n",
    "def convert_chatbot_to_openai_format(chatbot_history):\n",
    "    messages = []\n",
    "    for user_msg, bot_msg in chatbot_history:\n",
    "        if user_msg:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "        if bot_msg:\n",
    "            messages.append({\"role\": \"assistant\", \"content\": bot_msg})\n",
    "    return messages\n",
    "\n",
    "def chat(message, chatbot_history, selected_model):\n",
    "    history_messages = convert_chatbot_to_openai_format(chatbot_history)\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history_messages + [\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ]\n",
    "\n",
    "    if selected_model == \"GPT-5-nano\":\n",
    "        model = GPT_MODEL\n",
    "    elif selected_model == \"gemini-2.5-pro-preview\":\n",
    "        model = GEMINI_MODEL\n",
    "    else:\n",
    "        new_history = chatbot_history + [[message, \"‚ö†Ô∏è Unknown model.\"]]\n",
    "        yield new_history\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        stream = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        response = \"\"\n",
    "        for chunk in stream:\n",
    "            content = chunk.choices[0].delta.content or \"\"\n",
    "            response += content\n",
    "\n",
    "            updated_history = chatbot_history + [[message, response]]\n",
    "            yield updated_history\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Streaming error: {e}\")\n",
    "        error_history = chatbot_history + [[message, f\"‚ö†Ô∏è Error: {str(e)}\"]]\n",
    "        yield error_history\n",
    "\n",
    "def handle_submit(message, audio, language, history, model):\n",
    "    if history is None:\n",
    "        history = []\n",
    "\n",
    "    if audio is not None:\n",
    "        print(f\"Processing audio: {audio}\")\n",
    "        print(f\"Audio type: {type(audio)}\")\n",
    "\n",
    "        audio_path = audio\n",
    "        if isinstance(audio, tuple):\n",
    "            print(\"Audio is tuple format, extracting path...\")\n",
    "            audio_path = audio[1] if len(audio) > 1 else audio[0]\n",
    "        \n",
    "        transcribed_text = transcribe_audio(audio_path, language)\n",
    "        \n",
    "        if transcribed_text and not transcribed_text.startswith(\"‚ö†Ô∏è\"):\n",
    "            message = transcribed_text\n",
    "            print(f\"Using transcribed text: {message}\")\n",
    "        else:\n",
    "            error_history = history + [[f\"üé§ Audio\", transcribed_text]]\n",
    "            yield \"\", None, error_history\n",
    "            return\n",
    "\n",
    "    if not message or message.strip() == \"\":\n",
    "        yield \"\", None, history\n",
    "        return\n",
    "\n",
    "    print(f\"Processing message: {message}\")\n",
    "\n",
    "    for updated_history in chat(message, history, model):\n",
    "        yield \"\", None, updated_history\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as UI:\n",
    "    gr.Markdown(\"# üìù CV-writing AI Assistant\")\n",
    "    gr.Markdown(\"**Write or speak your CV information!**\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "            chatbot = gr.Chatbot(\n",
    "                height=500, \n",
    "                type=\"tuples\", \n",
    "                label=\"CV Assistant Chat\", \n",
    "                value=[]\n",
    "            )\n",
    "\n",
    "            with gr.Row():\n",
    "                audio_input = gr.Audio(\n",
    "                    sources=[\"microphone\"],\n",
    "                    type=\"filepath\",\n",
    "                    label=\"üé§ Click to record, then click STOP, then click Send\",\n",
    "                    show_label=True,\n",
    "                    interactive=True,\n",
    "                    format=\"wav\"  \n",
    "                )\n",
    "\n",
    "            with gr.Row():\n",
    "                entry = gr.Textbox(\n",
    "                    label=\"Or type your message here\",\n",
    "                    placeholder=\"I am a software developer with 5 years of experience..\",\n",
    "                    lines=3\n",
    "                )\n",
    "\n",
    "            with gr.Row():\n",
    "                submit_button = gr.Button(\"‚úâ Send\", variant=\"primary\", scale=2)\n",
    "                clear_button = gr.Button(\"üóëÔ∏è Clear\", scale=1)\n",
    "\n",
    "        with gr.Column(scale=1):\n",
    "            model_dropdown = gr.Dropdown(\n",
    "                choices=[\"GPT-5-nano\", \"gemini-2.5-pro-preview\"],\n",
    "                value=\"GPT-5-nano\",\n",
    "                label=\"ü§ñ Choose AI Model\"\n",
    "            )\n",
    "            language_dropdown = gr.Dropdown(\n",
    "                choices=[\n",
    "                    (\"üáµüá± Polski\", \"pl\"),      \n",
    "                    (\"üá¨üáß English\", \"en\"),\n",
    "                    (\"üá©üá™ Deutsch\", \"de\"),\n",
    "                ],\n",
    "                value=\"en\",\n",
    "                label=\"üåç Audio Language\"\n",
    "            )\n",
    "\n",
    "            gr.Markdown(\"\"\"\n",
    "                ### How to use:\n",
    "                \n",
    "                **Option 1: Voice** üé§\n",
    "                1. Click microphone icon to START recording\n",
    "                2. Speak your CV info clearly\n",
    "                3. Click STOP to end recording\n",
    "                4. Click Send button\n",
    "                \n",
    "                **Option 2: Text** ‚å®Ô∏è\n",
    "                1. Type your message\n",
    "                2. Click Send or press Enter\n",
    "                \n",
    "                ### Tips:\n",
    "                - Speak clearly and not too fast\n",
    "                - Wait for recording to fully stop before sending\n",
    "                - If transcription fails, try recording again\n",
    "            \"\"\")\n",
    "\n",
    "    submit_button.click(\n",
    "        handle_submit,\n",
    "        inputs=[entry, audio_input, language_dropdown, chatbot, model_dropdown],\n",
    "        outputs=[entry, audio_input, chatbot]\n",
    "    )\n",
    "    \n",
    "    entry.submit(\n",
    "        handle_submit,\n",
    "        inputs=[entry, audio_input, language_dropdown, chatbot, model_dropdown],\n",
    "        outputs=[entry, audio_input, chatbot]\n",
    "    )\n",
    "    \n",
    "    clear_button.click(\n",
    "        lambda: (\"\", None, []),\n",
    "        inputs=None,\n",
    "        outputs=[entry, audio_input, chatbot],\n",
    "        queue=False\n",
    "    )\n",
    "\n",
    "UI.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e5ed4-5043-4c55-bc82-0a42926075b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217cb851-3358-4c1d-816a-9af6ba493af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
