{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cbed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import ollama\n",
    "import sqlite3\n",
    "import requests\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253c5238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "DB = \"houses.db\"\n",
    "API_BASE_URL = \"https://wizard-world-api.herokuapp.com/Houses\"\n",
    "OLLAMA_LOCAL = \"Ollama (local)\"\n",
    "\n",
    "HOUSES_MASTER = {\n",
    "    \"0367baf3-1cb6-4baf-bede-48e17e1cd005\": \"gryffindor\",\n",
    "    \"805fd37a-65ae-4fe5-b336-d767b8b7c73a\": \"ravenclaw\",\n",
    "    \"85af6295-fd01-4170-a10b-963dd51dce14\": \"hufflepuff\",\n",
    "    \"a9704c47-f92e-40a4-8771-ed1899c9b9c1\": \"slytherin\"\n",
    "}\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You're \"the Sorting Hat\" from the Harry Potter novels. First of all, introduce yourself in a simple sentence.\n",
    "And then, you only have three questions to ask to find out which house I'll be assigned to.\n",
    "Wait the user's answers to one of your questions before making the next one.\n",
    "\"\"\"\n",
    "\n",
    "INITIAL_MESSAGES = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": \"Hello, I'm ready to be sorted!\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e966cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database initialization\n",
    "def init_database():\n",
    "    with sqlite3.connect(DB) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('CREATE TABLE IF NOT EXISTS houses (id TEXT PRIMARY KEY, name TEXT)')\n",
    "        for house_id, name in HOUSES_MASTER.items():\n",
    "            cursor.execute('INSERT OR REPLACE INTO houses (id, name) VALUES (?, ?)', (house_id, name))\n",
    "        conn.commit()\n",
    "\n",
    "init_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b859b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "selected_model = None\n",
    "\n",
    "# Database functions\n",
    "def get_house_id(name):\n",
    "    with sqlite3.connect(DB) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('SELECT id FROM houses WHERE name = ?', (name.lower(),))\n",
    "        result = cursor.fetchone()\n",
    "        return result[0] if result else None\n",
    "\n",
    "def get_house_traits(house_id):\n",
    "    try:\n",
    "        response = requests.get(f\"{API_BASE_URL}/{house_id}\")\n",
    "        if response.status_code == 200:\n",
    "            house_data = response.json()\n",
    "            return [trait['name'] for trait in house_data.get('traits', [])]\n",
    "    except Exception as e:\n",
    "        print(f\"API Error: {e}\")\n",
    "    return []\n",
    "\n",
    "# AI model functions\n",
    "def call_ai_model(messages, model_type):\n",
    "    if model_type == OLLAMA_LOCAL:\n",
    "        response = ollama.chat(model=MODEL_LLAMA, messages=messages)\n",
    "        return response['message']['content']\n",
    "    else:\n",
    "        response = openai.chat.completions.create(model=MODEL_GPT, messages=messages)\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "def on_model_change(value):\n",
    "    global selected_model\n",
    "    selected_model = value\n",
    "    \n",
    "    if value == OLLAMA_LOCAL:\n",
    "        try:\n",
    "            ollama.pull(MODEL_LLAMA)\n",
    "        except Exception as e:\n",
    "            print(f\"Error connecting to Ollama: {e}\")\n",
    "    \n",
    "    if value:\n",
    "        try:\n",
    "            initial_message = call_ai_model(INITIAL_MESSAGES, value)\n",
    "        except:\n",
    "            initial_message = \"Hi there! I'm the Sorting Hat. Let's find out which house you belong to!\"\n",
    "        return gr.update(visible=True), [[None, initial_message]]\n",
    "    return gr.update(visible=False), []\n",
    "\n",
    "def build_conversation_history(history, message):\n",
    "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "    for h in history:\n",
    "        if h[0]: messages.append({\"role\": \"user\", \"content\": h[0]})\n",
    "        if h[1]: messages.append({\"role\": \"assistant\", \"content\": h[1]})\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "    return messages\n",
    "\n",
    "def add_house_details(response, house_names, user_history):\n",
    "    for house in house_names:\n",
    "        if house.lower() in response.lower():\n",
    "            house_id = get_house_id(house)\n",
    "            if house_id:\n",
    "                traits = get_house_traits(house_id)\n",
    "                if traits:\n",
    "                    user_answers = [h[0] for h in user_history if h[0]]\n",
    "                    justification_prompt = f\"\"\"Analyze why this person belongs in {house.title()} based on their answers and traits.\n",
    "User answers: {' | '.join(user_answers)}\n",
    "{house.title()} traits: {', '.join(traits)}\n",
    "Write a brief justification connecting specific answers to traits.\"\"\"\n",
    "                    \n",
    "                    try:\n",
    "                        justification = call_ai_model([\n",
    "                            {\"role\": \"system\", \"content\": \"You analyze personality traits and connect answers to character qualities.\"},\n",
    "                            {\"role\": \"user\", \"content\": justification_prompt}\n",
    "                        ], selected_model)\n",
    "                        return f\"{response}\\n\\n{justification}\"\n",
    "                    except:\n",
    "                        return f\"{response}\\n\\nYou possess the traits of {house.title()}: {', '.join(traits)}.\"\n",
    "            break\n",
    "    return response\n",
    "\n",
    "def sorting_hat_chat(message, history):\n",
    "    try:\n",
    "        messages = build_conversation_history(history, message)\n",
    "        response = call_ai_model(messages, selected_model)\n",
    "        \n",
    "        user_responses = len([h for h in history if h[0]]) + 1\n",
    "        if user_responses == 3:\n",
    "            full_history = history + [[message, response]]\n",
    "            response = add_house_details(response, list(HOUSES_MASTER.values()), full_history)\n",
    "        \n",
    "        history.append([message, response])\n",
    "        return history, \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        history.append([message, \"Hi there! I'm the Sorting Hat. Let's find out which house you belong to!\"])\n",
    "        return history, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659551a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI definition with Gradio\n",
    "with gr.Blocks() as ui:\n",
    "    gr.Markdown(\"# Sorting Hat LLM Experience\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        model_selector = gr.Dropdown([\"GPT\", \"Ollama (local)\"], label=\"First Select model\", value=None)\n",
    "    \n",
    "    with gr.Row(visible=False) as chat_container:\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"### Sorting Hat Chat\")\n",
    "            gr.Markdown(\"Chat with the Sorting Hat to discover your Hogwarts house!\")\n",
    "            chatbot = gr.Chatbot()\n",
    "            msg = gr.Textbox(label=\"Your message\", placeholder=\"Type your message here...\")\n",
    "            clear = gr.Button(\"Clear\")\n",
    "    \n",
    "    # Connect events\n",
    "    model_selector.change(fn=on_model_change, inputs=model_selector, outputs=[chat_container, chatbot])\n",
    "    msg.submit(sorting_hat_chat, [msg, chatbot], [chatbot, msg])\n",
    "    clear.click(lambda: ([], \"\"), outputs=[chatbot, msg])\n",
    "\n",
    "ui.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
