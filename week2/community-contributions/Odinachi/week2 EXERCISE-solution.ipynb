{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
      "metadata": {},
      "source": [
        "# Additional End of week Exercise - week 2\n",
        "\n",
        "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
        "\n",
        "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
        "\n",
        "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
        "\n",
        "I will publish a full solution here soon - unless someone beats me to it...\n",
        "\n",
        "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "\n",
        "openai = OpenAI()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eba06c66",
      "metadata": {},
      "outputs": [],
      "source": [
        "load_dotenv(override=True)\n",
        "\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "if openai_api_key:\n",
        "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
        "else:\n",
        "    print(\"OpenAI API Key not set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "275fa524",
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message = \"\"\"\n",
        "You are a helpful assistant that can answer questions about the code. and give a detailed explanation. and example.\n",
        "your response should be in markdown format. and well structured.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "def chat(history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
        "    response = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\n",
        "    reply = response.choices[0].message.content\n",
        "    history += [{\"role\": \"assistant\", \"content\": reply}]\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe7e69eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def put_message_in_chatbot(message, history):\n",
        "    return \"\", history + [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "def process_audio(audio_filepath, history):\n",
        "    if audio_filepath is None:\n",
        "        return history, None\n",
        "    text = transcribe(audio_filepath)\n",
        "    history = history + [{\"role\": \"user\", \"content\": text}]\n",
        "    return history, None\n",
        "\n",
        "def chat(history):\n",
        "    history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
        "    response = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\n",
        "    reply = response.choices[0].message.content\n",
        "    history += [{\"role\": \"assistant\", \"content\": reply}]\n",
        "    return history\n",
        "\n",
        "def transcribe(audio_filepath):\n",
        "    with open(audio_filepath, \"rb\") as audio_file:\n",
        "        result = openai.audio.transcriptions.create(\n",
        "            model=\"whisper-1\",\n",
        "            file=audio_file,\n",
        "        )\n",
        "    return result.text\n",
        "\n",
        "with gr.Blocks() as ui:\n",
        "    with gr.Row():\n",
        "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
        "    with gr.Row():\n",
        "        message = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
        "        audio_input = gr.Audio(\n",
        "            sources=[\"microphone\", \"upload\"],\n",
        "            type=\"filepath\",\n",
        "            label=\"Or speak your question\",\n",
        "        )\n",
        "\n",
        "    message.submit(\n",
        "        put_message_in_chatbot, inputs=[message, chatbot], outputs=[message, chatbot]\n",
        "    ).then(\n",
        "        chat, inputs=chatbot, outputs=chatbot\n",
        "    )\n",
        "\n",
        "    audio_input.change(\n",
        "        process_audio, inputs=[audio_input, chatbot], outputs=[chatbot, audio_input]\n",
        "    ).then(\n",
        "        chat, inputs=chatbot, outputs=chatbot\n",
        "    )\n",
        "\n",
        "ui.launch(inbrowser=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3538bd92",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
