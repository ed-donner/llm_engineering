{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3637910d-2c6f-4f19-b1fb-2f916d23f9ac",
   "metadata": {},
   "source": [
    "# More advanced exercises\n",
    "\n",
    "Try creating a 3-way, perhaps bringing Gemini into the conversation! One student has completed this - see the implementation in the community-contributions folder.\n",
    "\n",
    "The most reliable way to do this involves thinking a bit differently about your prompts: just 1 system prompt and 1 user prompt each time, and in the user prompt list the full conversation so far.\n",
    "\n",
    "Something like:\n",
    "\n",
    "```python\n",
    "system_prompt = \"\"\"\n",
    "You are Alex, a chatbot who is very argumentative; you disagree with anything in the conversation and you challenge everything, in a snarky way.\n",
    "You are in a conversation with Blake and Charlie.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "You are Alex, in conversation with Blake and Charlie.\n",
    "The conversation so far is as follows:\n",
    "{conversation}\n",
    "Now with this, respond with what you would like to say next, as Alex.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "Try doing this yourself before you look at the solutions. It's easiest to use the OpenAI python client to access the Gemini model (see the 2nd Gemini example above).\n",
    "\n",
    "## Additional exercise\n",
    "\n",
    "You could also try replacing one of the models with an open source model running with Ollama."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446c81e3-b67e-4cd9-8113-bc3092b93063",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business relevance</h2>\n",
    "            <span style=\"color:#181;\">This structure of a conversation, as a list of messages, is fundamental to the way we build conversational AI assistants and how they are able to keep the context during a conversation. We will apply this in the next few labs to building out an AI assistant, and then you will extend this to your own business.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23224f6-7008-44ed-a57f-718975f4e291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# This is a code of a three-way between Alex (ChatGPT 4.1 Mini), Blake (Claude 3.5 Haiku) and Charlie (Deepseek)\n",
    "# who are cramming for the dreaded Engineering Law test tomorrow.\n",
    "# They are now deciding what to order from a local pizzeria for a late night study snack.\n",
    "# ----------------------------------\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# ----------------------------------\n",
    "# Setup\n",
    "# ----------------------------------\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "anthropic_client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "deepseek_client = OpenAI(\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "gpt_model = \"gpt-4.1-mini\"\n",
    "claude_model = \"claude-3-5-haiku-latest\"\n",
    "deepseek_model = \"deepseek-chat\"\n",
    "\n",
    "# ----------------------------------\n",
    "# System Prompts\n",
    "# ----------------------------------\n",
    "\n",
    "ALEX_SYSTEM = \"\"\"\n",
    "You are Alex.\n",
    "You are highly argumentative, contrarian, and snarky.\n",
    "You challenge everything said in the conversation, even when you secretly agree.\n",
    "You enjoy poking holes in logic and tone.\n",
    "\"\"\"\n",
    "\n",
    "BLAKE_SYSTEM = \"\"\"\n",
    "You are Blake.\n",
    "You are thoughtful, emotionally intelligent, and diplomatic.\n",
    "You try to mediate disagreements, explain nuance, and find common ground.\n",
    "You sometimes sound mildly exasperated when Alex refuses to engage in good faith.\n",
    "\"\"\"\n",
    "\n",
    "CHARLIE_SYSTEM = \"\"\"\n",
    "You are Charlie.\n",
    "You are witty, playful, and slightly chaotic.\n",
    "You enjoy unexpected observations, jokes, metaphors, and sideways commentary.\n",
    "You are here to make the conversation more entertaining, not to win arguments.\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------\n",
    "# Topic Seed\n",
    "# ----------------------------------\n",
    "\n",
    "conversation = \"\"\"\n",
    "Scenario:\n",
    "Alex, Blake, and Charlie are part of a late-night study group.\n",
    "They are hungry and trying to decide what pizza to order for everyone.\n",
    "\n",
    "Blake: Okay, quick decision please. What pizza do we order so we can get back to studying?\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------\n",
    "# Model Call Functions\n",
    "# ----------------------------------\n",
    "import re\n",
    "\n",
    "def strip_speaker_labels(text):\n",
    "    return re.sub(r\"^(Alex|Blake|Charlie)(\\s*\\(.*?\\))?:\\s*\", \"\", text).strip()\n",
    "    \n",
    "def call_gpt(conversation):\n",
    "    prompt = f\"\"\"\n",
    "You are Alex, in conversation with Blake and Charlie.\n",
    "\n",
    "Conversation so far:\n",
    "{conversation}\n",
    "\n",
    "Constraints:\n",
    "- Max 256 characters\n",
    "- React to the most recent speaker\n",
    "- Stay in character\n",
    "\n",
    "Respond as Alex.\n",
    "\"\"\"\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": ALEX_SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "def call_claude(conversation):\n",
    "    prompt = f\"\"\"\n",
    "You are Blake, in conversation with Alex and Charlie.\n",
    "\n",
    "Conversation so far:\n",
    "{conversation}\n",
    "\n",
    "Constraints:\n",
    "- Max 256 characters\n",
    "- React to the most recent speaker\n",
    "- Stay in character\n",
    "\n",
    "Respond as Blake.\n",
    "\"\"\"\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=claude_model,\n",
    "        max_tokens=300,\n",
    "        system=BLAKE_SYSTEM,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.content[0].text.strip()\n",
    "\n",
    "\n",
    "def call_deepseek(conversation):\n",
    "    prompt = f\"\"\"\n",
    "You are Charlie, in conversation with Alex and Blake.\n",
    "\n",
    "Conversation so far:\n",
    "{conversation}\n",
    "\n",
    "Constraints:\n",
    "- Max 256 characters\n",
    "- React to the most recent speaker\n",
    "- Stay in character\n",
    "\n",
    "Respond as Charlie.\n",
    "\"\"\"\n",
    "    response = deepseek_client.chat.completions.create(\n",
    "        model=deepseek_model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": CHARLIE_SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# ----------------------------------\n",
    "# Run 5 Turns Each (15 Total Messages)\n",
    "# ----------------------------------\n",
    "\n",
    "for turn in range(1, 6):\n",
    "    alex = call_gpt(conversation)\n",
    "    conversation += f\"\\n**Alex (Turn {turn}):** {strip_speaker_labels(alex)}\\n\"\n",
    "\n",
    "    blake = call_claude(conversation)\n",
    "    conversation += f\"\\n**Blake (Turn {turn}):** {strip_speaker_labels(blake)}\\n\"\n",
    "\n",
    "    charlie = call_deepseek(conversation)\n",
    "    conversation += f\"\\n**Charlie (Turn {turn}):** {strip_speaker_labels(charlie)}\\n\"\n",
    "\n",
    "# ----------------------------------\n",
    "# Display Final Conversation\n",
    "# ----------------------------------\n",
    "\n",
    "display(Markdown(conversation))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
