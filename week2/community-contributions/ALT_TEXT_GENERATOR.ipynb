{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "115e525c",
      "metadata": {},
      "source": [
        "# Alt Text for an image from multiple providers using Gradio UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "7a3fa481",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8a8bf166",
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio as gr  # oh yeah!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eab86d3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key exists and begins sk-proj-\n",
            "Anthropic API Key exists and begins sk-ant-\n",
            "Google API Key exists and begins AIzaSyAM\n"
          ]
        }
      ],
      "source": [
        "load_dotenv(override=True)\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
        "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
        "\n",
        "if openai_api_key:\n",
        "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
        "else:\n",
        "    print(\"OpenAI API Key not set\")\n",
        "    \n",
        "if anthropic_api_key:\n",
        "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
        "else:\n",
        "    print(\"Anthropic API Key not set\")\n",
        "\n",
        "if google_api_key:\n",
        "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
        "else:\n",
        "    print(\"Google API Key not set\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cefa1a4",
      "metadata": {},
      "source": [
        "# Reusable function to send image file to OpenAI computer vision endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56d07690",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This call fetches the image from the local file system\n",
        "\n",
        "from openai import OpenAI\n",
        "openai_client = OpenAI()  # use a unique name so the Anthropic cell doesn't overwrite it\n",
        "\n",
        "system_prompt = \"You are an expert in web accessibility whose job it is to write alt text for images that will be added to different websites, including sites for big corporations. When you write alt text you are looking for a balance between brevity and specificity. You should describe the crucial features of the image and omit the details that are not as important. Aim for a limit of 500 characters\"\n",
        "\n",
        "def vision_gpt(file_path):\n",
        "    file = openai_client.files.create(\n",
        "        file=open(file_path, \"rb\"),\n",
        "        purpose=\"user_data\"\n",
        "    )\n",
        "\n",
        "    response = openai_client.responses.create(\n",
        "        model=\"gpt-5\",\n",
        "        input=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"input_image\",\n",
        "                        \"file_id\": file.id,\n",
        "                        \"detail\": \"high\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"type\": \"input_text\",\n",
        "                        \"text\": system_prompt,\n",
        "                    },\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return response.output_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92ce00ef",
      "metadata": {},
      "source": [
        "# Reusable function to send image file to Anthropic computer vision endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25fcc6e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import anthropic\n",
        "\n",
        "anthropic_client = anthropic.Anthropic()  # use a unique name so it doesn't overwrite openai_client\n",
        "system_prompt = \"You are an expert in web accessibility whose job it is to write alt text for images that will be added to websites, including sites for big corporations. When you write alt text you are looking for a balance between brevity and specificity. You should describe the crucial features of the image and omit the details that are not as important. Aim for a limit of 500 characters\"\n",
        "\n",
        "\n",
        "def vision_anthropic(file_path):\n",
        "    base_name = os.path.basename(file_path) # Use filepath basename only for Anthropic API\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        file_upload = anthropic_client.beta.files.upload(file=(base_name, f, \"image/jpeg\"))\n",
        "\n",
        "    message = anthropic_client.beta.messages.create(\n",
        "        model=\"claude-sonnet-4-5\",\n",
        "        max_tokens=1024,\n",
        "        betas=[\"files-api-2025-04-14\"],\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"image\",\n",
        "                        \"source\": {\n",
        "                            \"type\": \"file\",\n",
        "                            \"file_id\": file_upload.id\n",
        "                        }\n",
        "                    },\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": system_prompt\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "    return message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "734c04db",
      "metadata": {},
      "source": [
        "# Helper function to route the requests to different models/providers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "b3193d5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def stream_model(file_path, model):\n",
        "    file_path = file_path.strip()\n",
        "    if model == \"GPT\":\n",
        "        result = vision_gpt(file_path)\n",
        "    elif model == \"Claude\":\n",
        "        result = vision_anthropic(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model\")\n",
        "    # Anthropic returns message.content (list of blocks); extract text for display\n",
        "    if isinstance(result, list):\n",
        "        result = \"\\n\".join(\n",
        "            getattr(block, \"text\", str(block)) for block in result\n",
        "        )\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7e787f8",
      "metadata": {},
      "source": [
        "# Gradio UI to select file path and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5454af0e",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'stream_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m model_selector = gr.Dropdown([\u001b[33m\"\u001b[39m\u001b[33mGPT\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mClaude\u001b[39m\u001b[33m\"\u001b[39m], label=\u001b[33m\"\u001b[39m\u001b[33mSelect model\u001b[39m\u001b[33m\"\u001b[39m, value=\u001b[33m\"\u001b[39m\u001b[33mGPT\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m vision_output = gr.Textbox(label=\u001b[33m\"\u001b[39m\u001b[33mAlt text\u001b[39m\u001b[33m\"\u001b[39m, lines=\u001b[32m15\u001b[39m)\n\u001b[32m      5\u001b[39m view = gr.Interface(\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     fn=\u001b[43mstream_model\u001b[49m,\n\u001b[32m      7\u001b[39m     title=\u001b[33m\"\u001b[39m\u001b[33mLLMs\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     inputs=[file_input, model_selector],\n\u001b[32m      9\u001b[39m     outputs=[vision_output],\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m view.launch()\n",
            "\u001b[31mNameError\u001b[39m: name 'stream_model' is not defined"
          ]
        }
      ],
      "source": [
        "file_input = gr.File(label=\"Select image file\")\n",
        "model_selector = gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\", value=\"GPT\")\n",
        "vision_output = gr.Textbox(label=\"Alt text\", lines=15)\n",
        "\n",
        "view = gr.Interface(\n",
        "    fn=stream_model,\n",
        "    title=\"LLMs\",\n",
        "    inputs=[file_input, model_selector],\n",
        "    outputs=[vision_output],\n",
        ")\n",
        "view.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76cb3bd6",
      "metadata": {},
      "source": [
        "Next Steps\n",
        "* submit the damn thing !!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
