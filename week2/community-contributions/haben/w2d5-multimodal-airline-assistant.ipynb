{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚úàÔ∏è FlightAI Multimodal Assistant\n",
    "\n",
    "## Why I Built This\n",
    "\n",
    "Customer service in the airline industry has always been a challenge. Travelers need quick answers, but traditional systems require navigating complex menus, waiting on hold, or filling out lengthy forms. \n",
    "\n",
    "What if customers could simply **talk** to an AI assistant that:\n",
    "- Understands their needs naturally\n",
    "- Searches real-time flight data from PostgreSQL\n",
    "- Shows them destinations visually with AI-generated images\n",
    "- Speaks responses back for hands-free access\n",
    "\n",
    "That's exactly what **FlightAI Multimodal Assistant** does. Built during the **Andela LLM Engineering program**, this project demonstrates how AI can revolutionize customer interactions in the travel industry.\n",
    "\n",
    "Instead of:\n",
    "- ‚ùå Navigating complex booking systems\n",
    "- ‚ùå Waiting for human agents  \n",
    "- ‚ùå Searching through multiple pages\n",
    "- ‚ùå Reading long text responses\n",
    "\n",
    "Customers can now:\n",
    "- ‚úÖ Ask naturally: *\"What flights go to Paris?\"*\n",
    "- ‚úÖ Book instantly: *\"Book a flight to Tokyo for John Doe\"*\n",
    "- ‚úÖ See destinations: *\"Show me what London looks like\"*\n",
    "- ‚úÖ Hear responses: *\"Read me the flight information with audio\"*\n",
    "\n",
    "This isn't just a demo‚Äîit's a blueprint for the future of customer service in travel.\n",
    "\n",
    "---\n",
    "\n",
    "## What This Does\n",
    "\n",
    "FlightAI helps travelers find and book flights through natural conversation. You tell it what you need, and it:\n",
    "- üîç Searches the PostgreSQL database intelligently\n",
    "- üí≥ Books flights directly through conversation\n",
    "- üñºÔ∏è Generates beautiful destination images\n",
    "- üîä Speaks flight information back to you\n",
    "\n",
    "**Tech:** OpenAI GPT-4o-mini (via OpenRouter) ‚Ä¢ DALL-E ‚Ä¢ TTS ‚Ä¢ PostgreSQL ‚Ä¢ Gradio UI ‚Ä¢ Function Calling\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** This is a demonstration. Image and audio generation require OpenAI API access (may work via OpenRouter depending on your plan)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Dependencies\n",
    "\n",
    "We need `psycopg2-binary` to connect to PostgreSQL. This cell installs it if missing.\n",
    "\n",
    "**Note:** If installation succeeds, restart the kernel before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install psycopg2-binary if needed\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Check if already installed\n",
    "try:\n",
    "    import psycopg2\n",
    "    print(\"‚úì psycopg2-binary is already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing psycopg2-binary...\")\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"psycopg2-binary\", \"--break-system-packages\", \"--quiet\"],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úì Installation successful!\")\n",
    "        print(\"\\n‚ö†Ô∏è  IMPORTANT: Restart the kernel now (Kernel ‚Üí Restart Kernel)\")\n",
    "        print(\"   Then run the import cell again.\")\n",
    "    else:\n",
    "        print(f\"‚úó Installation failed: {result.stderr}\")\n",
    "        raise RuntimeError(\"Failed to install psycopg2-binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setup\n",
    "\n",
    "Loading API keys securely, setting up the OpenAI client via OpenRouter, and connecting to PostgreSQL.\n",
    "\n",
    "**The foundation:** Everything starts here‚ÄîAPI access, database connection, and the AI client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and initialization\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import re\n",
    "import tempfile\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "\n",
    "# Import psycopg2 - ensure kernel is using the correct Python environment\n",
    "try:\n",
    "    import psycopg2\n",
    "    print(\"‚úì psycopg2 imported successfully\")\n",
    "except ImportError:\n",
    "    print(f\"‚ö†Ô∏è  psycopg2 not found in current Python: {sys.executable}\")\n",
    "    print(\"\\nüìã To fix this:\")\n",
    "    print(\"1. Run the installation cell above\")\n",
    "    print(\"2. ‚ö†Ô∏è  RESTART THE KERNEL (Kernel ‚Üí Restart Kernel) - This is required!\")\n",
    "    print(\"3. Then run this cell again\")\n",
    "    raise ImportError(\n",
    "        \"psycopg2-binary is not available. \"\n",
    "        \"Please run the installation cell, then RESTART THE KERNEL, then run this cell again.\"\n",
    "    )\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# OpenRouter configuration\n",
    "api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "base_url = os.getenv('OPENROUTER_BASE_URL', 'https://openrouter.ai/api/v1')\n",
    "MODEL = os.getenv('OPENROUTER_MODEL', 'openai/gpt-4o-mini')\n",
    "\n",
    "if api_key:\n",
    "    print(f\"‚úì OpenRouter API Key loaded (begins with {api_key[:8]}...)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  OpenRouter API Key not set\")\n",
    "\n",
    "client = OpenAI(base_url=base_url, api_key=api_key)\n",
    "\n",
    "# Database connection helper\n",
    "def get_db_connection():\n",
    "    \"\"\"Create a connection to PostgreSQL database\"\"\"\n",
    "    return psycopg2.connect(\n",
    "        host=os.getenv('DB_HOST', 'localhost'),\n",
    "        port=os.getenv('DB_PORT', '5432'),\n",
    "        database=os.getenv('DB_NAME', 'andela_ai_engineering_bootcamp'),\n",
    "        user=os.getenv('DB_USER', 'postgres'),\n",
    "        password=os.getenv('DB_PASSWORD')\n",
    "    )\n",
    "\n",
    "print(\"‚úì Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Database Functions\n",
    "\n",
    "These are the core functions that interact with PostgreSQL. When someone asks *\"What flights go to Paris?\"*, the AI translates that into:\n",
    "```python\n",
    "get_ticket_price(destination_city=\"Paris\")\n",
    "```\n",
    "\n",
    "**The magic:** The AI figures out which function to call and what parameters to use - no rigid commands needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database functions\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    \"\"\"Search for available flights to a destination city\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT flight_number, origin, destination, price, departure_time, arrival_time\n",
    "        FROM flights\n",
    "        WHERE LOWER(destination) = LOWER(%s)\n",
    "        ORDER BY departure_time\n",
    "        LIMIT 5\n",
    "    \"\"\", (destination_city,))\n",
    "    flights = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    if flights:\n",
    "        result = f\"Flights to {destination_city}:\\n\"\n",
    "        for flight in flights:\n",
    "            result += f\"- {flight[0]}: {flight[1]} ‚Üí {flight[2]}, ${float(flight[3])}, Departs: {flight[4]}\\n\"\n",
    "        return result\n",
    "    return f\"Sorry, we don't have flights to {destination_city} available.\"\n",
    "\n",
    "def book_flight(destination_city, passenger_name):\n",
    "    \"\"\"Book a flight for a passenger\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "        SELECT flight_id, flight_number, price\n",
    "        FROM flights\n",
    "        WHERE LOWER(destination) = LOWER(%s)\n",
    "        ORDER BY departure_time\n",
    "        LIMIT 1\n",
    "    \"\"\", (destination_city,))\n",
    "    flight = cur.fetchone()\n",
    "    \n",
    "    if flight:\n",
    "        flight_id, flight_number, price = flight\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO bookings (flight_id, passenger_name, status)\n",
    "            VALUES (%s, %s, 'confirmed')\n",
    "            RETURNING booking_id\n",
    "        \"\"\", (flight_id, passenger_name))\n",
    "        booking_id = cur.fetchone()[0]\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        return f\"Booking confirmed! {passenger_name}, your flight {flight_number} to {destination_city} is reserved. Booking ID: {booking_id}, Price: ${float(price)}\"\n",
    "    \n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return f\"Sorry, we cannot book flights to {destination_city} at this time.\"\n",
    "\n",
    "print(\"‚úì Database functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Multimodal Functions\n",
    "\n",
    "**Images:** When customers want to see destinations, we generate beautiful travel images using DALL-E.\n",
    "\n",
    "**Audio:** The AI can speak its responses using OpenAI's text-to-speech API.\n",
    "\n",
    "**The experience:** Multimodal responses make interactions richer - text, images, and audio all working together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal functions\n",
    "\n",
    "def generate_destination_image(destination_city, description=\"\"):\n",
    "    \"\"\"Generate an image of a destination city using DALL-E\"\"\"\n",
    "    try:\n",
    "        prompt = f\"Beautiful travel destination image of {destination_city}, professional photography, vibrant colors, travel brochure style\"\n",
    "        if description:\n",
    "            prompt += f\", {description}\"\n",
    "        \n",
    "        # Use OpenAI's image generation API\n",
    "        try:\n",
    "            response = client.images.generate(\n",
    "                prompt=prompt,\n",
    "                size=\"1024x1024\",\n",
    "                quality=\"standard\",\n",
    "                n=1\n",
    "            )\n",
    "            image_url = response.data[0].url\n",
    "            return f\"IMAGE_URL:{image_url}\"\n",
    "        except Exception as e:\n",
    "            # Fallback: return a placeholder message\n",
    "            return f\"Image generation requested for {destination_city}. (Note: Image generation may require direct OpenAI API access)\"\n",
    "    except Exception as e:\n",
    "        return f\"Error generating image: {str(e)}\"\n",
    "\n",
    "def generate_audio_response(text):\n",
    "    \"\"\"Generate audio from text using TTS\"\"\"\n",
    "    try:\n",
    "        # Try using OpenAI's TTS API directly (may need separate OpenAI client)\n",
    "        # First, try with the current client (OpenRouter)\n",
    "        try:\n",
    "            response = client.audio.speech.create(\n",
    "                model=\"tts-1\",\n",
    "                voice=\"alloy\",\n",
    "                input=text[:500]  # Limit text length\n",
    "            )\n",
    "        except Exception as api_error:\n",
    "            # If OpenRouter doesn't support TTS, try direct OpenAI API\n",
    "            openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "            if openai_api_key:\n",
    "                from openai import OpenAI as OpenAIClient\n",
    "                openai_client = OpenAIClient(api_key=openai_api_key)\n",
    "                response = openai_client.audio.speech.create(\n",
    "                    model=\"tts-1\",\n",
    "                    voice=\"alloy\",\n",
    "                    input=text[:500]\n",
    "                )\n",
    "            else:\n",
    "                raise api_error\n",
    "        \n",
    "        # Save audio to a temporary file\n",
    "        temp_dir = tempfile.gettempdir()\n",
    "        audio_path = os.path.join(temp_dir, f\"audio_{abs(hash(text)) % 100000}.mp3\")\n",
    "        \n",
    "        response.stream_to_file(audio_path)\n",
    "        \n",
    "        # Verify file was created\n",
    "        if os.path.exists(audio_path) and os.path.getsize(audio_path) > 0:\n",
    "            return f\"AUDIO_PATH:{audio_path}\"\n",
    "        else:\n",
    "            return f\"Error: Audio file was not created properly\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        # Provide helpful error message\n",
    "        if \"audio\" in error_msg.lower() or \"speech\" in error_msg.lower():\n",
    "            return f\"Error: TTS API not available. Please ensure you have OpenAI API access for audio generation. Error: {error_msg}\"\n",
    "        return f\"Error generating audio: {error_msg}\"\n",
    "\n",
    "print(\"‚úì Multimodal functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Teaching the AI to Use Tools\n",
    "\n",
    "Instead of the AI just talking, we teach it to actually *search* the database, *book* flights, *generate* images, and *speak* responses.\n",
    "\n",
    "This schema defines all the tools the AI can use. When someone says *\"Show me flights to Paris\"*, the AI translates that into:\n",
    "```python\n",
    "get_ticket_price(destination_city=\"Paris\")\n",
    "```\n",
    "\n",
    "**This was the breakthrough.** No more writing custom queries - the AI figures it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool definitions\n",
    "\n",
    "price_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_ticket_price\",\n",
    "        \"description\": \"Get available flights and prices to a destination city from the database.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"destination_city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The destination city name\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"destination_city\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "booking_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"book_flight\",\n",
    "        \"description\": \"Book a flight to a destination for a passenger. Creates a booking record in the database.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"destination_city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The destination city name\"\n",
    "                },\n",
    "                \"passenger_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Full name of the passenger\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"destination_city\", \"passenger_name\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "image_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"generate_destination_image\",\n",
    "        \"description\": \"Generate a beautiful travel image of a destination city. Use this when customers ask to see images of destinations or want visual inspiration.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"destination_city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The destination city name to generate an image for\"\n",
    "                },\n",
    "                \"description\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Optional additional description for the image\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"destination_city\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "audio_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"generate_audio_response\",\n",
    "        \"description\": \"Generate audio narration from text. ALWAYS use this tool when customers request audio, say 'read', 'speak', 'tell me with audio', 'audio version', or any variation asking for spoken/heard information. Pass the complete response text that should be spoken.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"text\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The complete text response to convert to speech. Include all relevant flight information, prices, and details.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"text\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = [price_tool, booking_tool, image_tool, audio_tool]\n",
    "\n",
    "print(f\"‚úì {len(tools)} tools registered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: The AI's Instructions\n",
    "\n",
    "Here's where prompt engineering matters *a lot*.\n",
    "\n",
    "The AI needs to know:\n",
    "- When to use which tool (search, book, generate image, generate audio)\n",
    "- How to interpret natural language requests\n",
    "- To be proactive with multimodal features when helpful\n",
    "- To always generate audio when explicitly requested\n",
    "\n",
    "**The lesson:** Clear instructions = better tool usage. This prompt guides the AI to use tools effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "\n",
    "system_message = \"\"\"You are a helpful assistant for FlightAI airline.\n",
    "Give short, courteous answers. Always be accurate. If you don't know something, say so.\n",
    "\n",
    "IMPORTANT: When customers request audio, \"read\", \"speak\", \"tell me with audio\", or similar phrases, you MUST use the generate_audio_response tool to create an audio version of your response.\n",
    "\n",
    "Use the available tools to:\n",
    "- Check prices and book flights when customers ask\n",
    "- Generate images of destinations when customers want to see visual inspiration\n",
    "- ALWAYS generate audio when customers explicitly request audio, \"read\", \"speak\", or \"tell me with audio\"\n",
    "Be proactive in offering images and audio when they would enhance the customer experience.\"\"\"\n",
    "\n",
    "# Tool call handler\n",
    "\n",
    "def handle_tool_calls(message):\n",
    "    \"\"\"Execute tool calls and return formatted responses\"\"\"\n",
    "    responses = []\n",
    "    for tool_call in message.tool_calls:\n",
    "        func_name = tool_call.function.name\n",
    "        args = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        if func_name == \"get_ticket_price\":\n",
    "            result = get_ticket_price(args[\"destination_city\"])\n",
    "        elif func_name == \"book_flight\":\n",
    "            result = book_flight(args[\"destination_city\"], args[\"passenger_name\"])\n",
    "        elif func_name == \"generate_destination_image\":\n",
    "            result = generate_destination_image(\n",
    "                args[\"destination_city\"],\n",
    "                args.get(\"description\", \"\")\n",
    "            )\n",
    "        elif func_name == \"generate_audio_response\":\n",
    "            result = generate_audio_response(args[\"text\"])\n",
    "        else:\n",
    "            result = \"Unknown tool\"\n",
    "        \n",
    "        responses.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": result,\n",
    "            \"tool_call_id\": tool_call.id\n",
    "        })\n",
    "    return responses\n",
    "\n",
    "print(\"‚úì System prompt and tool handler defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Making it Work (and Not Crash)\n",
    "\n",
    "This is the engine room. When the AI wants to search, book, or generate content, this code:\n",
    "1. Validates the request\n",
    "2. Calls the right function\n",
    "3. Handles errors gracefully (no crashes!)\n",
    "4. Extracts multimodal content (images, audio)\n",
    "5. Returns a structured response\n",
    "\n",
    "**Defensive programming:** Things break. This code expects problems and handles them elegantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main chat function\n",
    "\n",
    "def chat(message, history):\n",
    "    \"\"\"Process user message and return multimodal response\"\"\"\n",
    "    history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    # Check if user explicitly requests audio\n",
    "    audio_keywords = [\"audio\", \"read\", \"speak\", \"tell me with audio\", \"audio version\", \"hear\"]\n",
    "    user_wants_audio = any(keyword in message.lower() for keyword in audio_keywords)\n",
    "    \n",
    "    response = client.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    \n",
    "    image_urls = []\n",
    "    audio_paths = []\n",
    "    \n",
    "    # Handle tool calls iteratively\n",
    "    while response.choices[0].finish_reason == \"tool_calls\":\n",
    "        tool_message = response.choices[0].message\n",
    "        tool_responses = handle_tool_calls(tool_message)\n",
    "        \n",
    "        # Extract image URLs and audio paths from tool responses\n",
    "        for tool_resp in tool_responses:\n",
    "            content = tool_resp.get(\"content\", \"\")\n",
    "            if content.startswith(\"IMAGE_URL:\"):\n",
    "                image_urls.append(content.replace(\"IMAGE_URL:\", \"\"))\n",
    "            elif content.startswith(\"AUDIO_PATH:\"):\n",
    "                audio_paths.append(content.replace(\"AUDIO_PATH:\", \"\"))\n",
    "        \n",
    "        messages.append(tool_message)\n",
    "        messages.extend(tool_responses)\n",
    "        response = client.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    \n",
    "    # Extract text response\n",
    "    text_response = response.choices[0].message.content or \"\"\n",
    "    \n",
    "    # If user requested audio but no audio was generated, generate it now\n",
    "    audio_error = None\n",
    "    if user_wants_audio and not audio_paths and text_response:\n",
    "        try:\n",
    "            audio_result = generate_audio_response(text_response)\n",
    "            if audio_result.startswith(\"AUDIO_PATH:\"):\n",
    "                audio_paths.append(audio_result.replace(\"AUDIO_PATH:\", \"\"))\n",
    "            elif audio_result.startswith(\"Error\"):\n",
    "                audio_error = audio_result\n",
    "        except Exception as e:\n",
    "            audio_error = f\"Error generating audio: {str(e)}\"\n",
    "    \n",
    "    # Check tool responses for audio errors\n",
    "    for msg in messages:\n",
    "        if msg.get(\"role\") == \"tool\":\n",
    "            content = msg.get(\"content\", \"\")\n",
    "            if \"Error\" in content and (\"audio\" in content.lower() or \"tts\" in content.lower()):\n",
    "                audio_error = content\n",
    "    \n",
    "    # Return multimodal response\n",
    "    result = {\"text\": text_response}\n",
    "    if image_urls:\n",
    "        result[\"images\"] = image_urls\n",
    "    if audio_paths:\n",
    "        result[\"audio\"] = audio_paths[0]  # Return first audio file\n",
    "    if audio_error:\n",
    "        result[\"audio_error\"] = audio_error\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"‚úì Chat function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: The User Interface\n",
    "\n",
    "Finally, we build the Gradio interface. This is where customers interact with the AI.\n",
    "\n",
    "**The experience:** Clean, modern UI that handles text, images, and audio seamlessly. Everything comes together here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio interface\n",
    "\n",
    "with gr.Blocks(title=\"FlightAI Assistant\") as demo:\n",
    "    gr.Markdown(\"# FlightAI Customer Support Assistant\")\n",
    "    gr.Markdown(\"**Multimodal Features:** Generate images of destinations and audio responses!\")\n",
    "    \n",
    "    chatbot = gr.Chatbot(\n",
    "        type=\"messages\",\n",
    "        height=600,\n",
    "        show_label=False\n",
    "    )\n",
    "    \n",
    "    msg = gr.Textbox(\n",
    "        label=\"Message\",\n",
    "        placeholder=\"Try: 'Show me an image of Paris' or 'Tell me about flights to Tokyo with audio'...\",\n",
    "        scale=4\n",
    "    )\n",
    "    \n",
    "    submit_btn = gr.Button(\"Send\", variant=\"primary\", scale=1)\n",
    "    clear_btn = gr.Button(\"Clear\", scale=1)\n",
    "    \n",
    "    def respond(message, chat_history):\n",
    "        \"\"\"Handle user message and format multimodal response\"\"\"\n",
    "        if not message:\n",
    "            return chat_history, \"\"\n",
    "        \n",
    "        # Convert Gradio history format\n",
    "        history = []\n",
    "        for msg_item in chat_history:\n",
    "            if msg_item[\"role\"] == \"user\":\n",
    "                history.append({\"role\": \"user\", \"content\": msg_item[\"content\"]})\n",
    "            elif msg_item[\"role\"] == \"assistant\":\n",
    "                history.append({\"role\": \"assistant\", \"content\": msg_item[\"content\"]})\n",
    "        \n",
    "        # Get response\n",
    "        response = chat(message, history)\n",
    "        \n",
    "        # Format response with multimodal content\n",
    "        if isinstance(response, dict):\n",
    "            text = response.get(\"text\", \"\")\n",
    "            images = response.get(\"images\", [])\n",
    "            audio_path = response.get(\"audio\")\n",
    "            audio_error = response.get(\"audio_error\")\n",
    "            \n",
    "            # Build response content\n",
    "            content_parts = [text] if text else []\n",
    "            \n",
    "            # Add images\n",
    "            if images:\n",
    "                content_parts.append(\"\\n\\n**üñºÔ∏è Generated Images:**\")\n",
    "                for img_url in images:\n",
    "                    content_parts.append(f\"![Destination Image]({img_url})\")\n",
    "            \n",
    "            # Add audio with HTML audio player\n",
    "            if audio_path and os.path.exists(audio_path):\n",
    "                content_parts.append(f\"\\n\\n**üîä Audio Response:**\")\n",
    "                content_parts.append(f'<audio controls><source src=\"file://{audio_path}\" type=\"audio/mpeg\">Your browser does not support the audio element.</audio>')\n",
    "                content_parts.append(f\"\\n*Audio file: {audio_path}*\")\n",
    "            elif audio_error:\n",
    "                # Show error message if audio generation failed\n",
    "                content_parts.append(f\"\\n\\n**‚ö†Ô∏è Audio Generation:**\")\n",
    "                content_parts.append(f\"*{audio_error}*\")\n",
    "                content_parts.append(\"\\n*Note: Audio generation requires OpenAI API access. You can add OPENAI_API_KEY to your .env file for direct TTS access.*\")\n",
    "            \n",
    "            final_content = \"\\n\".join(content_parts)\n",
    "            \n",
    "            chat_history.append({\"role\": \"user\", \"content\": message})\n",
    "            chat_history.append({\"role\": \"assistant\", \"content\": final_content})\n",
    "        else:\n",
    "            chat_history.append({\"role\": \"user\", \"content\": message})\n",
    "            chat_history.append({\"role\": \"assistant\", \"content\": str(response)})\n",
    "        \n",
    "        return chat_history, \"\"\n",
    "    \n",
    "    msg.submit(respond, [msg, chatbot], [chatbot, msg])\n",
    "    submit_btn.click(respond, [msg, chatbot], [chatbot, msg])\n",
    "    clear_btn.click(lambda: ([], \"\"), None, [chatbot, msg])\n",
    "\n",
    "print(\"‚úì Gradio interface ready\")\n",
    "print(\"\\nüöÄ Launching FlightAI Assistant...\")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "### The Journey\n",
    "\n",
    "Building this multimodal airline assistant taught me something important: **AI doesn't just automate tasks‚Äîit reimagines how people interact with complex systems.**\n",
    "\n",
    "I started this project thinking about the frustration of booking flights: multiple tabs, confusing forms, waiting on hold. What if customers could simply *ask* for what they need and get it instantly?\n",
    "\n",
    "Through the Andela LLM Engineering program, I learned that combining:\n",
    "- **Natural language understanding** (GPT-4o via OpenRouter)\n",
    "- **Real-time database access** (PostgreSQL)\n",
    "- **Multimodal responses** (text, images, audio)\n",
    "- **Intelligent tool calling**\n",
    "\n",
    "...creates something that feels less like software and more like a helpful travel agent.\n",
    "\n",
    "### What Surprised Me\n",
    "\n",
    "1. **How well tool calling works** - The AI consistently chooses the right tools without explicit instructions\n",
    "2. **The power of multimodal responses** - Adding images and audio transformed a simple chatbot into an engaging experience\n",
    "3. **Database integration is seamless** - PostgreSQL + AI = natural language database interface\n",
    "4. **Error handling makes all the difference** - Graceful failures keep the experience smooth\n",
    "\n",
    "### Technical Highlights\n",
    "\n",
    "- **Function calling** eliminated rigid command structures\n",
    "- **PostgreSQL integration** enabled real-time flight data access\n",
    "- **Multimodal capabilities** (DALL-E images, TTS audio) created richer interactions\n",
    "- **Defensive programming** ensured robustness even when APIs fail\n",
    "- **Gradio interface** made it accessible and user-friendly\n",
    "\n",
    "### Future Directions\n",
    "\n",
    "If I were to take this further:\n",
    "- **Voice input** - Let customers call and speak their requests\n",
    "- **Real airline APIs** - Connect to live flight data and booking systems\n",
    "- **Payment integration** - Enable actual flight purchases\n",
    "- **Multi-language support** - Serve international travelers in their native languages\n",
    "- **Personalization** - Remember preferences and booking history\n",
    "- **Mobile optimization** - Make it work seamlessly on phones\n",
    "\n",
    "### The Broader Impact\n",
    "\n",
    "This pattern extends far beyond airlines. Imagine:\n",
    "- **Hotels** - \"Find me a beachfront room in Miami under $200\"\n",
    "- **Restaurants** - \"Book a table for 4 at an Italian place tonight\"\n",
    "- **Events** - \"Get me 2 tickets to the concert this weekend\"\n",
    "- **Services** - \"Schedule a haircut for tomorrow afternoon\"\n",
    "\n",
    "**The common thread:** Natural conversation beats forms every time.\n",
    "\n",
    "### Final Thoughts\n",
    "\n",
    "This project showed me that AI + good engineering = solutions that feel magical but are built on solid foundations. The database does the heavy lifting, AI makes it accessible, and multimodal features make it delightful.\n",
    "\n",
    "**For the travel industry and beyond:** This is a blueprint for how AI can transform customer service‚Äîmaking complex systems feel simple, natural, and human.\n",
    "\n",
    "---\n",
    "\n",
    "*Built during Week 2 of the Andela LLM Engineering Program*\n",
    "\n",
    "**FlightAI Assistant** - Where conversation meets intelligent booking."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
