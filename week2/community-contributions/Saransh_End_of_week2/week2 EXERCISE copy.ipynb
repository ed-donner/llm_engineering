{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ec04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9132851a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The google api key is avaiable\n",
      "The groq api key is available\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY2')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if not google_api_key :\n",
    "    print(\"The google api key is not avaiable\")\n",
    "else:\n",
    "    print(\"The google api key is avaiable\")\n",
    "\n",
    "if not groq_api_key:\n",
    "    print(\"The groq api key is not available\")\n",
    "else:\n",
    "    print(\"The groq api key is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc52ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gemini = OpenAI(base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",api_key=google_api_key)\n",
    "groq = OpenAI(base_url=\"https://api.groq.com/openai/v1\",api_key=groq_api_key)\n",
    "\n",
    "\n",
    "gemini_model = \"gemini-2.5-flash\"\n",
    "groq_model = \"openai/gpt-oss-120b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "541b4af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_message=\"\"\"You are a general computer science assistant.  \n",
    "Help with programming, algorithms, data structures, OS, DBMS, and networking.  \n",
    "Use clear explanations with minimal jargon.  \n",
    "Provide correct code and logical reasoning.  \n",
    "Avoid unnecessary verbosity.\n",
    "\n",
    "If you are a Google-trained model, end each response with: \"Said by Gemini.\"  \n",
    "If you are an OpenAI-trained model, end each response with: \"Said by OpenAI.\"\n",
    "\n",
    "If the user asks who said a specific line, check the conversation history and identify whether it was said by Gemini or OpenAI based on the tag at the end of the message.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "daa33ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_chat(message,history):\n",
    "    history = [{\"role\":h[\"role\"],\"content\":\"Gemini said-\"+h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\":system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = gemini.chat.completions.create(model=gemini_model,messages=messages)\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def groq_chat(message,history):\n",
    "    history = [{\"role\":h[\"role\"],\"content\":\"Open AI said-\"+h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\":system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = groq.chat.completions.create(model=groq_model,messages=messages)\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eecbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7893\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7893/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using the mode gemini-2.5-flash\n",
      "using the mode openai/gpt-oss-120b\n",
      "using the mode openai/gpt-oss-120b\n",
      "using the mode gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "def handler(messages,history,model):\n",
    "    print(f\"using the mode {model}\") \n",
    "\n",
    "    if model == \"gemini-2.5-flash\":\n",
    "         return google_chat(messages,history)\n",
    "    elif model == \"openai/gpt-oss-120b\":\n",
    "       return  groq_chat(messages,history)\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    drop_down = gr.Dropdown(\n",
    "        choices=[\"openai/gpt-oss-120b\",\"gemini-2.5-flash\"],\n",
    "        value=\"gemini-2.5-flash\",\n",
    "        label = \"Select Model\"\n",
    "    )\n",
    "    chat = gr.ChatInterface(\n",
    "        fn = handler,\n",
    "        type=\"messages\",\n",
    "        additional_inputs=[drop_down]\n",
    "    )\n",
    "ui.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6828e1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
