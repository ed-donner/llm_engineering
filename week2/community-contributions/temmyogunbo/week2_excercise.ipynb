{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "817532e7",
      "metadata": {},
      "source": [
        "A prototype for technical question/answer using OpenAI Anthropic models, and Ollama. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83031d9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import gradio as gr \n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "from IPython.display import display\n",
        "from scraper import fetch_website_contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6676a753",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_GPT = 'gpt-4.1-mini'\n",
        "MODEL_LLAMA = 'llama3:latest'\n",
        "MODEL_CLAUDE = 'claude-sonnet-4-5-20250929'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3a07ba48",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key exists and begins sk-proj-\n",
            "Anthropic API Key not set (and this is optional)\n"
          ]
        }
      ],
      "source": [
        "load_dotenv(override=True)\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
        "\n",
        "if openai_api_key:\n",
        "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
        "else:\n",
        "    print(\"OpenAI API Key not set\")\n",
        "    \n",
        "if anthropic_api_key:\n",
        "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
        "else:\n",
        "    print(\"Anthropic API Key not set (and this is optional)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9192c4a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "openai = OpenAI()\n",
        "\n",
        "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
        "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
        "\n",
        "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
        "ollama = OpenAI(api_key=\"ollama\", base_url=OLLAMA_BASE_URL)\n",
        "\n",
        "openai = OpenAI()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9bc50b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "def stream_gpt(company_name, context, history, message):\n",
        "    relevant_system_message = f\"\"\"\n",
        "    You are a helpful assistant for {company_name}. Answer technical questions based on the context provided from their documentation.\n",
        "    Context from {company_name} documentation:\n",
        "    {context}\n",
        "    \"\"\"\n",
        "    messages = [{\"role\": \"system\", \"content\": relevant_system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "    stream = openai.chat.completions.create(\n",
        "        model=MODEL_GPT,\n",
        "        messages=messages,\n",
        "        stream=True\n",
        "    )\n",
        "    result = \"\"\n",
        "    for chunk in stream:\n",
        "        result += chunk.choices[0].delta.content or \"\"\n",
        "        yield result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d03368d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def stream_claude(company_name, context, history, message):\n",
        "    relevant_system_message = f\"\"\"\n",
        "    You are a helpful assistant for {company_name}. Answer technical questions based on the context provided from their documentation.\n",
        "    Context from {company_name} documentation:\n",
        "    {context}\n",
        "    \"\"\"\n",
        "    messages = [{\"role\": \"system\", \"content\": relevant_system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "    stream = anthropic.chat.completions.create(\n",
        "        model=MODEL_CLAUDE,\n",
        "        messages=messages,\n",
        "        stream=True\n",
        "    )\n",
        "    result = \"\"\n",
        "    for chunk in stream:\n",
        "        result += chunk.choices[0].delta.content or \"\"\n",
        "        yield result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "ddd8cde0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def stream_ollama(company_name, context, history, message):\n",
        "    relevant_system_message = f\"\"\"\n",
        "    You are a helpful assistant for {company_name}. Answer technical questions based on the context provided from their documentation.\n",
        "    Context from {company_name} documentation:\n",
        "    {context}\n",
        "    \"\"\"\n",
        "    messages = [{\"role\": \"system\", \"content\": relevant_system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    response = ollama.chat.completions.create(model=MODEL_LLAMA, messages=messages)\n",
        "\n",
        "    yield response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "e9c38cd7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def stream_brochure(company_name, url, model):\n",
        "    yield \"\"\n",
        "    prompt = f\"Please generate a company brochure for {company_name}. Here is their landing page:\\n\"\n",
        "    prompt += fetch_website_contents(url)\n",
        "    if model==\"GPT\":\n",
        "        result = stream_gpt(prompt)\n",
        "    elif model==\"Claude\":\n",
        "        result = stream_claude(prompt)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model\")\n",
        "    yield from result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "99039a64",
      "metadata": {},
      "outputs": [],
      "source": [
        "def stream_model(model, company_name, context, history, message):\n",
        "    if model==\"GPT\":\n",
        "        result = stream_gpt(company_name, context, history, message)\n",
        "    elif model==\"Claude\":\n",
        "        result = stream_claude(company_name, context, history, message)\n",
        "    elif model==\"Ollama\":\n",
        "        result = stream_ollama(company_name, context, history, message)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model\")\n",
        "    yield from result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a85d10e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def chat(message, history, company_name, doc_url, model):\n",
        "    if not company_name or not doc_url:\n",
        "        yield \"Please provide both the company name and link to documentation above before asking questions.\"\n",
        "        return\n",
        "    history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
        "\n",
        "    context = fetch_website_contents(doc_url)\n",
        "    result = stream_model(model, company_name, context, history, message)\n",
        "    yield from result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "263a440c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7878\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7878/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Received message: Explain web component\n",
            "Received history: []\n",
            "Received company_name: Salesforce\n",
            "Received doc_url: https://developer.salesforce.com/docs/platform/lightning-component-reference/guide\n",
            "Received model: Ollama\n"
          ]
        }
      ],
      "source": [
        "company_name_input = gr.Textbox(label=\"Company name:\", placeholder=\"e.g. Hugging Face\")\n",
        "doc_url_input = gr.Textbox(\n",
        "    label=\"Link to technical documentation\",\n",
        "    placeholder=\"https://docs.example.com or https://example.com/docs\",\n",
        "    lines=1\n",
        ")\n",
        "model_selector = gr.Dropdown([\"GPT\", \"Claude\", \"Ollama\"], label=\"Select model\", value=\"GPT\")\n",
        "\n",
        "gr.ChatInterface(\n",
        "    fn=chat,\n",
        "    type=\"messages\",\n",
        "    additional_inputs=[company_name_input, doc_url_input, model_selector],\n",
        "    title=\"Documentation Q&A\"\n",
        ").launch(inbrowser=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b9319fa",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
