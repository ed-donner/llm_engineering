{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac285a0",
   "metadata": {},
   "source": [
    "- Implemented an interactive Gradio dashboard to accept user skills and a target Greenhouse API URL.\n",
    "- Added automated tool-calling so the LLM can dynamically fetch and analyze real-time job listings.\n",
    "- Enabled real-time response streaming and the ability to switch between different AI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import gradio as gr\n",
    "from bs4 import BeautifulSoup\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "\n",
    "OPEN_ROUTER_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
    "client = OpenAI(api_key=api_key, base_url=OPEN_ROUTER_BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc9020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the Tool (Our Greenhouse API Fetcher) ---\n",
    "def fetch_jobs_from_api(api_url, max_jobs=25):\n",
    "    \"\"\"Fetches job listings from the Greenhouse API using the full URL.\"\"\"\n",
    "     \n",
    "    print(f\"\\n[Tool Execution] Fetching jobs from {api_url}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status() \n",
    "        data = response.json()\n",
    "        \n",
    "        simplified_jobs = []\n",
    "        for job in data.get('jobs', [])[:max_jobs]:\n",
    "            clean_text = BeautifulSoup(job.get(\"content\", \"\"), \"html.parser\").get_text(separator=\" \", strip=True)\n",
    "            simplified_jobs.append({\n",
    "                \"title\": job.get(\"title\"),\n",
    "                \"location\": job.get(\"location\", {}).get(\"name\"),\n",
    "                \"url\": job.get(\"absolute_url\"),\n",
    "                \"description\": clean_text[:1000] \n",
    "            })\n",
    "        print(f\"[Tool Execution] Successfully fetched {len(simplified_jobs)} jobs.\")\n",
    "        return json.dumps(simplified_jobs)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Failed to fetch jobs: {str(e)}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d3c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the tool so the LLM knows how to use it\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"fetch_jobs_from_api\",\n",
    "        \"description\": \"Fetches a list of current open jobs and their descriptions from a provided Greenhouse API URL.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"api_url\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The full Greenhouse API URL. e.g., 'https://boards-api.greenhouse.io/v1/boards/doordashusa/jobs?content=true'\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"api_url\"]\n",
    "        }\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e64bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Matchmaking Logic with Streaming and Tool Handling ---\n",
    "def find_job_matches(user_skills, model_choice, custom_api_url):\n",
    "    \n",
    "    # Validation checks\n",
    "    if not custom_api_url or custom_api_url.strip() == \"\":\n",
    "        yield \" **Missing URL:** To get started, please paste a Greenhouse API URL into the designated text box.\"\n",
    "        return \n",
    "        \n",
    "    if not user_skills or user_skills.strip() == \"\":\n",
    "        yield \" **Missing Skills:** Please enter your skills or job preferences so I can match you correctly!\"\n",
    "        return\n",
    "\n",
    "    yield \"Scanning job board and analyzing matches...\"\n",
    "    \n",
    "    # Tell the LLM to use the provided URL\n",
    "    url_instruction = f\"You MUST use this exact URL for your tool to search for jobs: '{custom_api_url}'.\"\n",
    "\n",
    "    system_prompt = {\n",
    "        \"role\": \"system\", \n",
    "        \"content\": f\"You are an expert technical career advisor and matchmaker. \"\n",
    "                   f\"When a user shares their skills, use your 'fetch_jobs_from_api' tool to fetch open roles. \"\n",
    "                   f\"{url_instruction} \"\n",
    "                   f\"Read the job descriptions carefully, pick the best matches for their specific profile, and explain to the user WHY they are a good fit. \"\n",
    "                   f\"Always include the URL so they can apply. Format your response beautifully with markdown.\"\n",
    "    }\n",
    "    \n",
    "    # Construct the message array (No history needed!)\n",
    "    messages = [\n",
    "        system_prompt,\n",
    "        {\"role\": \"user\", \"content\": user_skills}\n",
    "    ]\n",
    "\n",
    "    # Initial LLM call to decide if it needs the tool\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_choice,\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )\n",
    "    \n",
    "    assistant_message = response.choices[0].message\n",
    "\n",
    "    # Handle Tool Calling\n",
    "    if assistant_message.tool_calls:\n",
    "        messages.append(assistant_message)\n",
    "        \n",
    "        for tool_call in assistant_message.tool_calls:\n",
    "            if tool_call.function.name == \"fetch_jobs_from_api\":\n",
    "                args = json.loads(tool_call.function.arguments)\n",
    "                api_url = args.get(\"api_url\")\n",
    "                \n",
    "                # Execute the tool\n",
    "                tool_result = fetch_jobs_from_api(api_url=api_url)\n",
    "                \n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": tool_call.function.name,\n",
    "                    \"content\": tool_result\n",
    "                })\n",
    "                \n",
    "        # Stream the final response back to the UI\n",
    "        stream_response = client.chat.completions.create(\n",
    "            model=model_choice,\n",
    "            messages=messages,\n",
    "            stream=True \n",
    "        )\n",
    "            \n",
    "        partial_text = \"\"\n",
    "        for chunk in stream_response:\n",
    "            if chunk.choices[0].delta.content is not None:\n",
    "                partial_text += chunk.choices[0].delta.content\n",
    "                yield partial_text \n",
    "    else:\n",
    "        # Fallback just in case the LLM decides not to use the tool\n",
    "        yield assistant_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189c3908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom Gradio Dashboard ---\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# AI Career Matchmaker\")\n",
    "    gr.Markdown(\"Describe your skills, paste a company's Greenhouse API URL, and let the AI find the perfect role for you based on actual job descriptions.\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        # Left Column for Inputs\n",
    "        with gr.Column(scale=1):\n",
    "            user_skills_input = gr.Textbox(\n",
    "                label=\"Your Skills & Preferences\", \n",
    "                placeholder=\"e.g., I am a Python developer with 3 years of experience in data engineering and AWS...\",\n",
    "                lines=5,\n",
    "                interactive=True\n",
    "            )\n",
    "            api_url_input = gr.Textbox(\n",
    "                label=\"Greenhouse API URL\",\n",
    "                placeholder=\"e.g., https://boards-api.greenhouse.io/v1/boards/doordashusa/jobs?content=true\",\n",
    "                lines=2,\n",
    "                interactive=True\n",
    "            )\n",
    "            model_dropdown = gr.Dropdown(\n",
    "                choices=[\"openai/gpt-4o-mini\", \"anthropic/claude-3-haiku\", \"meta-llama/llama-3.1-8b-instruct\"],\n",
    "                value=\"openai/gpt-4o-mini\",\n",
    "                label=\"Select AI Model\"\n",
    "            )\n",
    "            submit_btn = gr.Button(\"Find My Matches\", variant=\"primary\")\n",
    "            \n",
    "        # Right Column for Outputs\n",
    "        with gr.Column(scale=2):\n",
    "            output_markdown = gr.Markdown(label=\"Job Matches\", value=\"*Your matches will appear here...*\")\n",
    "\n",
    "    # --- Helper Functions for UI State ---\n",
    "    def disable_btn():\n",
    "        # Changes the button text and makes it unclickable\n",
    "        return gr.update(value=\"Processing... ‚è≥\", interactive=False)\n",
    "        \n",
    "    def enable_btn():\n",
    "        # Changes the button text back and makes it clickable again\n",
    "        return gr.update(value=\"Find My Matches\", interactive=True)\n",
    "\n",
    "    # --- Wire the button with Chained Events ---\n",
    "    submit_btn.click(\n",
    "        fn=disable_btn,\n",
    "        inputs=[],\n",
    "        outputs=[submit_btn]\n",
    "    ).then(\n",
    "        fn=find_job_matches,\n",
    "        inputs=[user_skills_input, model_dropdown, api_url_input],\n",
    "        outputs=[output_markdown]\n",
    "    ).then(\n",
    "        fn=enable_btn,\n",
    "        inputs=[],\n",
    "        outputs=[submit_btn]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1343a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b017d25d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
