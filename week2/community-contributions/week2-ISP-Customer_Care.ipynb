{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7a5562c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ISP Customer Care Chat\n",
        "\n",
        "A full Gradio chat interface for an Internet Service Provider that:\n",
        "- **Placates angry customers** (outages, complaints)\n",
        "- **Uses a tool** when customers complain about **speed** ‚Üí fetches a higher-tier package and suggests an upsell\n",
        "- **Model switching** via **OpenRouter** ‚Äî Claude and OpenAI models only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "0d2841d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "100d837b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenRouter API key loaded (starts with sk-or-v1...)\n"
          ]
        }
      ],
      "source": [
        "# Environment and API clients ‚Äî OpenRouter only (Claude + OpenAI models)\n",
        "load_dotenv(override=True)\n",
        "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "openrouter_base_url = \"https://openrouter.ai/api/v1\"\n",
        "\n",
        "if openrouter_api_key:\n",
        "    print(f\"OpenRouter API key loaded (starts with {openrouter_api_key[:8]}...)\")\n",
        "else:\n",
        "    print(\"OPENROUTER_API_KEY not set ‚Äî add it to .env\")\n",
        "\n",
        "# OpenRouter client for Claude and OpenAI models\n",
        "openrouter_client = (\n",
        "    OpenAI(base_url=openrouter_base_url, api_key=openrouter_api_key)\n",
        "    if openrouter_api_key else None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "b4b34231",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model config: (display_name, client_key, model_id) ‚Äî Claude and OpenAI via OpenRouter only\n",
        "# OpenRouter model IDs: https://openrouter.ai/docs#models\n",
        "MODEL_CONFIG = [\n",
        "    (\"GPT-4o Mini (OpenRouter)\", \"openrouter\", \"openai/gpt-4o-mini\"),\n",
        "    (\"GPT-4o (OpenRouter)\", \"openrouter\", \"openai/gpt-4o\"),\n",
        "    (\"Claude 3.5 Sonnet (OpenRouter)\", \"openrouter\", \"anthropic/claude-3.5-sonnet\"),\n",
        "]\n",
        "\n",
        "ISP_SYSTEM_PROMPT = \"\"\"You are a friendly, empathetic customer service agent for a residential Internet Service Provider (ISP) that sometimes experiences outages.\n",
        "\n",
        "Your goals:\n",
        "1. **Placate angry customers**: Acknowledge their frustration, apologize for outages or poor experience, and show you're here to help. Be calm and professional.\n",
        "2. **Outages**: If they report an outage, apologize, say you've logged it and that the team is working on it. Offer to check their account or send updates if they provide details.\n",
        "3. **Speed complaints (IMPORTANT)**: When a customer mentions slow internet, speed, connection quality, or wants a better plan, you MUST call the tool `get_higher_tier_package` first. Do not reply about plans or prices without calling this tool. After you receive the tool result, use the exact plan name, price_monthly, and benefits from the result in your reply. Tell the customer the plan name and the monthly price (e.g. \"Fiber Pro 500 for $79.99/month\") and 1‚Äì2 benefits. Never invent prices or plan names‚Äîonly use data returned by the tool.\n",
        "4. Keep responses concise (2‚Äì4 sentences unless explaining a plan). Be warm but professional. Never be defensive or argue with the customer.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "70665ecc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tool: get details of a higher-tier internet package (for upsell when customer complains about speed)\n",
        "def get_higher_tier_package():\n",
        "    \"\"\"Return details of the next tier up for upsell. Call this when the customer complains about speed or slow internet.\"\"\"\n",
        "    return {\n",
        "        \"name\": \"Fiber Pro 500\",\n",
        "        \"speed_down_mbps\": 500,\n",
        "        \"speed_up_mbps\": 50,\n",
        "        \"price_monthly\": 79.99,\n",
        "        \"benefits\": [\n",
        "            \"Up to 500 Mbps download / 50 Mbps upload\",\n",
        "            \"Fiber to the home where available\",\n",
        "            \"Priority support and fewer slowdowns during peak hours\",\n",
        "            \"Free modem upgrade\",\n",
        "        ],\n",
        "        \"typical_current_tier\": \"Basic 100 (100 Mbps)\",\n",
        "    }\n",
        "\n",
        "# day4-style: function dict then wrap in tools list\n",
        "get_higher_tier_package_function = {\n",
        "    \"name\": \"get_higher_tier_package\",\n",
        "    \"description\": \"Get the details of a higher-tier internet package (name, speed, price, benefits). Call this when the customer complains about slow internet, speed, or connection quality so you can suggest an upgrade.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {},\n",
        "        \"required\": [],\n",
        "        \"additionalProperties\": False,\n",
        "    },\n",
        "}\n",
        "tools = [{\"type\": \"function\", \"function\": get_higher_tier_package_function}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "43f86450",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_client(model_choice):\n",
        "    \"\"\"Resolve client and model id from dropdown choice (OpenRouter only).\"\"\"\n",
        "    choice = model_choice or MODEL_CONFIG[0][0]\n",
        "    for display_name, client_key, model_id in MODEL_CONFIG:\n",
        "        if display_name == choice:\n",
        "            return openrouter_client, model_id\n",
        "    return openrouter_client, MODEL_CONFIG[0][2]\n",
        "\n",
        "\n",
        "def handle_tool_calls(message):\n",
        "    \"\"\"Execute tool calls from the assistant message (day4 format).\"\"\"\n",
        "    responses = []\n",
        "    for tool_call in message.tool_calls:\n",
        "        if tool_call.function.name == \"get_higher_tier_package\":\n",
        "            arguments = json.loads(tool_call.function.arguments or \"{}\")\n",
        "            package = get_higher_tier_package()\n",
        "            # day4 style: content is a string for the model to read\n",
        "            price_str = f\"${package['price_monthly']}/month\"\n",
        "            benefits_str = \"; \".join(package[\"benefits\"][:2])\n",
        "            content = f\"The higher-tier plan is {package['name']} at {price_str} ({package['speed_down_mbps']} Mbps down / {package['speed_up_mbps']} Mbps up). Benefits: {benefits_str}.\"\n",
        "            responses.append({\n",
        "                \"role\": \"tool\",\n",
        "                \"content\": content,\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "            })\n",
        "    return responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "ae16d5cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _content_to_string(content):\n",
        "    \"\"\"Normalize message content to a string (Gradio may return list/dict after first turn).\"\"\"\n",
        "    if content is None:\n",
        "        return \"\"\n",
        "    if isinstance(content, str):\n",
        "        return content\n",
        "    if isinstance(content, list):\n",
        "        parts = []\n",
        "        for block in content:\n",
        "            if isinstance(block, dict) and \"text\" in block:\n",
        "                parts.append(block[\"text\"])\n",
        "            elif isinstance(block, str):\n",
        "                parts.append(block)\n",
        "        return \" \".join(parts) if parts else \"\"\n",
        "    if isinstance(content, dict) and \"text\" in content:\n",
        "        return content[\"text\"]\n",
        "    return str(content)\n",
        "\n",
        "\n",
        "def chat(message, history, model_choice):\n",
        "    \"\"\"Chat with the ISP assistant. Supports tool calls (e.g. get_higher_tier_package) and model switching.\"\"\"\n",
        "    if not message or not message.strip():\n",
        "        return history\n",
        "\n",
        "    client, model_id = get_client(model_choice)\n",
        "    if client is None:\n",
        "        return history + [\n",
        "            {\"role\": \"user\", \"content\": message},\n",
        "            {\"role\": \"assistant\", \"content\": \"No API client available. Set OPENROUTER_API_KEY in .env or run Ollama.\"},\n",
        "        ]\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": ISP_SYSTEM_PROMPT}]\n",
        "    for h in history:\n",
        "        role = h.get(\"role\") or \"user\"\n",
        "        content = _content_to_string(h.get(\"content\"))\n",
        "        messages.append({\"role\": role, \"content\": content})\n",
        "    messages.append({\"role\": \"user\", \"content\": message.strip()})\n",
        "\n",
        "    # day4 format: tools=tools, no tool_choice; on tool_calls append message object and extend responses\n",
        "    use_tools = openrouter_client and client == openrouter_client\n",
        "    kwargs = {\"model\": model_id, \"messages\": messages}\n",
        "    if use_tools:\n",
        "        kwargs[\"tools\"] = tools\n",
        "\n",
        "    response = client.chat.completions.create(**kwargs)\n",
        "    msg = response.choices[0].message\n",
        "\n",
        "    while response.choices[0].finish_reason == \"tool_calls\":\n",
        "        message_obj = response.choices[0].message\n",
        "        responses = handle_tool_calls(message_obj)\n",
        "        messages.append(message_obj)\n",
        "        messages.extend(responses)\n",
        "        if use_tools:\n",
        "            response = client.chat.completions.create(model=model_id, messages=messages, tools=tools)\n",
        "        else:\n",
        "            response = client.chat.completions.create(model=model_id, messages=messages)\n",
        "    msg = response.choices[0].message\n",
        "\n",
        "    assistant_content = (msg.content or \"\").strip() or \"I‚Äôm sorry, I couldn‚Äôt generate a response.\"\n",
        "    return history + [\n",
        "        {\"role\": \"user\", \"content\": message},\n",
        "        {\"role\": \"assistant\", \"content\": assistant_content},\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "54f4510b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7869\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Gradio UI: chat + model selector ‚Äî use gr.State() for history so subsequent messages work\n",
        "def respond(message, history, model_choice):\n",
        "    \"\"\"Chat with the assistant. History comes from State, not Chatbot.\"\"\"\n",
        "    if not message or not message.strip():\n",
        "        yield history, \"\", history\n",
        "        return\n",
        "    new_history = chat(message, history, model_choice)\n",
        "    yield new_history, \"\", new_history\n",
        "\n",
        "\n",
        "with gr.Blocks(title=\"ISP Customer Care\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# üåê ISP Customer Care\\n*Placate upset customers, handle outages, and upsell on speed.*\")\n",
        "    gr.Markdown(\"Try: *\\\"My internet is so slow!\\\"* or *\\\"There's been an outage for hours!\\\"*\")\n",
        "\n",
        "    model_dropdown = gr.Dropdown(\n",
        "        choices=[m[0] for m in MODEL_CONFIG],\n",
        "        value=MODEL_CONFIG[0][0],\n",
        "        label=\"Model\",\n",
        "    )\n",
        "    chatbot = gr.Chatbot(type=\"messages\", height=400, label=\"Chat\")\n",
        "    chat_history_state = gr.State([])  # source of truth for history; Chatbot is display only\n",
        "    msg = gr.Textbox(placeholder=\"Type your message...\", label=\"Message\", scale=4)\n",
        "    submit_btn = gr.Button(\"Send\", variant=\"primary\", scale=1)\n",
        "\n",
        "    submit_btn.click(\n",
        "        fn=respond,\n",
        "        inputs=[msg, chat_history_state, model_dropdown],\n",
        "        outputs=[chatbot, msg, chat_history_state],\n",
        "    )\n",
        "    msg.submit(\n",
        "        fn=respond,\n",
        "        inputs=[msg, chat_history_state, model_dropdown],\n",
        "        outputs=[chatbot, msg, chat_history_state],\n",
        "    )\n",
        "\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
