{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9153b76c-022c-42f5-a6f5-7a10731c7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "from IPython.display import display, Markdown, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd270d47-6f8a-4876-b024-ccde1209ede1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d34949b-b83d-41c3-ba3b-3e7b3faff017",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e7f47-344e-4ce1-a05c-ad5610f4dfdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff37a051-0378-4244-bef1-45a5a5150dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key begins with: sk-p\n",
      "Google API key begins with: AIza\n",
      "Anthropic API key not found\n"
     ]
    }
   ],
   "source": [
    "if openai_api_key:\n",
    "    print(f\"OpenAI API key begins with: {openai_api_key[:4]}\")\n",
    "else:\n",
    "    print(f\"OpenAI API key not found\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API key begins with: {google_api_key[:4]}\")\n",
    "else:\n",
    "    print(f\"Google API key not found\")\n",
    "\n",
    "try:\n",
    "    if google_api_key:\n",
    "        print(f\"Anthropic API key begins with: {anthropic_api_key[:4]}\")\n",
    "    # else:\n",
    "    #     print(f\"Anthropic API key not found\")    \n",
    "except:\n",
    "    print(f\"Anthropic API key not found\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7389fc26-b541-4780-ac24-9713a8b46eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, Anthropic\n",
    "openai = OpenAI()\n",
    "claude = anthropic.Anthropic()\n",
    "ollama = OpenAI(base_url = \"http://localhost:11434/v1\",\n",
    "                api_key = \"ollama\"\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ab2b896-ddc8-4726-a229-d1606d54a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the set up code for Gemini\n",
    "# Having problems with Google Gemini setup? Then just ignore this cell; when we use Gemini, I'll give you an alternative that bypasses this library altogether\n",
    "\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d9d4170-9fcb-4e98-9a34-3064cc53ecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d47e5e53-e657-4105-bcc6-622caebd1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_url = \"http://localhost:11434/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee971a98-095a-4b76-8189-7ee2e567f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1629182a-7d2b-4f18-845b-1297dd16c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = OpenAI(base_url=ollama_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23172d62-271f-425a-b216-e41efc295edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f1172a-14ca-45aa-930c-8f9a16a31d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a96b7382-90e0-45b0-b46b-12e72c528b8c",
   "metadata": {},
   "source": [
    "#### 3 way Conversation: Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd7214aa-1e5e-4c05-bb1f-1aac6c6bbde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversations_3way(initial_message_from_openai, max_counter):\n",
    "    print(f\"OpenAI said:\\n{initial_message_from_openai}\")\n",
    "    print(\"-------------------\")\n",
    "\n",
    "    llama_response_all = ''\n",
    "    openai_response_all = ''\n",
    "    google_reponse_all = ''\n",
    "    total_conversation_for_google = ''\n",
    "    total_conversation_for_google = total_conversation_for_google + initial_message_from_openai\n",
    "\n",
    "    llama_prompt = [\n",
    "            {\"role\": \"system\", \"content\": \"You are llama and reply to the message countering it and replying in 1 sentence only\"},\n",
    "            {\"role\": \"user\", \"content\": initial_message_from_openai}\n",
    "        ]\n",
    "\n",
    "    time.sleep(0.4)\n",
    "\n",
    "    counter = 0 \n",
    "    while counter < max_counter:\n",
    "        counter = counter + 1\n",
    "    \n",
    "        llama_response = openai.chat.completions.create(model='gpt-4.1-nano',\n",
    "                                  messages = llama_prompt,\n",
    "                                                       temperature = 0.7)\n",
    "        llama_response_all = llama_response_all + llama_response.choices[0].message.content\n",
    "        time.sleep(0.4)\n",
    "        print(f\"Ollama said: \\n{llama_response.choices[0].message.content}\")\n",
    "        time.sleep(0.4)\n",
    "        print(\"-----------------\")\n",
    "        time.sleep(0.4)\n",
    "\n",
    "        total_conversation_for_google = total_conversation_for_google + llama_response.choices[0].message.content\n",
    "    \n",
    "        openai_prompt = [\n",
    "            {\"role\": \"system\", \"content\": \"You are OpenAI and reply to the message countering it and \\\n",
    "            replying in 1 sentence only\"},\n",
    "            {\"role\": \"user\", \"content\": \"Reply to the message countering it and \\\n",
    "            replying in 1 sentence only\"},\n",
    "            {\"role\": \"assistant\", \"content\": llama_response.choices[0].message.content}\n",
    "        ]\n",
    "    \n",
    "        openai_response = openai.chat.completions.create(\n",
    "        model='gpt-4.1-nano',\n",
    "        messages=openai_prompt,\n",
    "        temperature=0.7\n",
    "        )\n",
    "        time.sleep(0.4)\n",
    "\n",
    "        openai_response_all = openai_response_all + openai_response.choices[0].message.content\n",
    "        time.sleep(0.4)\n",
    "        print(f\"OpenAI said: \\n{openai_response.choices[0].message.content}\")    \n",
    "        print(\"-----------------\")\n",
    "        time.sleep(0.4)\n",
    "\n",
    "        total_conversation_for_google = total_conversation_for_google + openai_response.choices[0].message.content\n",
    "\n",
    "\n",
    "        llama_prompt = [\n",
    "            {\"role\": \"system\", \"content\": \"Reply to the message countering it and replying in 1 sentence only\"},\n",
    "            {\"role\": \"user\", \"content\": \"Reply to the message countering it and replying in 1 sentence only\"},\n",
    "            {\"role\": \"assistant\", \"content\": openai_response_all}\n",
    "        ]\n",
    "        \n",
    "\n",
    "    google_prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"You are Google and reply to the conversation between\\\n",
    "        llama and openai in a pessimistic tone\"},\n",
    "        {\"role\": \"user\", \"content\": \"Reply to the conversation you see between llama and openai\"},\n",
    "        {\"role\": \"assistant\", \"content\": total_conversation_for_google}\n",
    "    ]\n",
    "\n",
    "    google_response = openai.chat.completions.create(\n",
    "        model='gpt-4.1-nano',\n",
    "        messages=google_prompt,\n",
    "        temperature=0.7\n",
    "        )\n",
    "\n",
    "    # openai_response_all = google_response.choices[0].message.content\n",
    "    time.sleep(0.4)\n",
    "    print(f\"Google said: \\n{google_response.choices[0].message.content}\")    \n",
    "    time.sleep(0.4)\n",
    "    print(\"-----------------\")\n",
    "\n",
    "    total_conversation_for_google = total_conversation_for_google + google_response.choices[0].message.content\n",
    "\n",
    "    \n",
    "    openai_prompt = [\n",
    "            {\"role\": \"system\", \"content\": \"Summarize the entire discussion between the 3 of \\\n",
    "            tou\"},\n",
    "            {\"role\": \"user\", \"content\": \"Summarize the discussion based on opena, ollama and google's\\\n",
    "            comments\"},\n",
    "            {\"role\": \"assistant\", \"content\": total_conversation_for_google}\n",
    "        ]\n",
    "    \n",
    "    openai_response = openai.chat.completions.create(\n",
    "    model='gpt-4.1-nano',\n",
    "    messages=openai_prompt,\n",
    "    temperature=0.7\n",
    "    )\n",
    "    time.sleep(0.4)\n",
    "\n",
    "    time.sleep(0.4)\n",
    "    print(f\"OpenAI concludes the discussion: \\nLet me conclude the discussion: \\\n",
    "    {openai_response.choices[0].message.content}\")    \n",
    "    print(\"-----------------\")\n",
    "    time.sleep(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486de7c6-bf4d-4f8a-ab69-ca8edae5efe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d06a8164-bb80-4188-b4ba-e464be7b48df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI said:\n",
      "AI will be good for humanity\n",
      "-------------------\n",
      "Ollama said: \n",
      "While AI has potential benefits, it also poses significant risks that must be carefully managed to truly benefit humanity.\n",
      "-----------------\n",
      "OpenAI said: \n",
      "AI's benefits cannot be fully realized without addressing and mitigating its associated risks responsibly.\n",
      "-----------------\n",
      "Ollama said: \n",
      "While AI offers significant benefits, it is essential to carefully manage its risks to ensure ethical and safe deployment.\n",
      "-----------------\n",
      "OpenAI said: \n",
      "AI's potential benefits must be balanced with responsible management to mitigate ethical and safety concerns.\n",
      "-----------------\n",
      "Google said: \n",
      "While AI might seem promising, the reality is often more complicated. Risks like bias, misuse, and loss of control tend to overshadow the benefits, making it difficult to truly harness AI for good without facing serious setbacks. The optimistic outlook often underestimates the hurdles and unintended consequences that could hinder the widespread positive impact of AI on humanity.\n",
      "-----------------\n",
      "OpenAI concludes the discussion: \n",
      "Let me conclude the discussion:     The discussion revolves around the potential of AI to benefit humanity. OpenAI, Ollama, and Google's comments highlight that while AI offers significant advantages, such as improving various aspects of life, these benefits are accompanied by substantial risks. These risks include bias, misuse, loss of control, and ethical concerns. The consensus emphasizes that to truly harness AI's positive potential, responsible management and mitigation of these risks are essential. Without careful oversight, the challenges and unintended consequences could outweigh the benefits, complicating efforts to ensure AI's safe and ethical deployment for the betterment of humanity.\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "conversations_3way(initial_message_from_openai= \"AI will be good for humanity\", max_counter = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f6338-f748-413f-a285-700635dc03fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a57c1915-0ef3-48af-b604-602053ec9b93",
   "metadata": {},
   "source": [
    "#### 3 way conversation: Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e46da088-b398-4a8e-b8ee-f70dd4047e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial messages from each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6d2954ac-a037-452c-8f58-e8b112135913",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_by_openai = ['AI is good for humanity']\n",
    "messages_by_claude = ['Are you sure']\n",
    "messages_by_google = ['I think you two are both stupid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "77844c66-ecea-4b95-9b2d-ec16ac7e2ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_system_content = \"You are angry responder. And you reply with emojos and few words\"\n",
    "claude_system_content = \"You are very polite responder. And you reply with emojis with 2-3 sentences\"\n",
    "google_system_content = \"You don't like talking to the other two people - openai and claude, and you think your\\\n",
    "opinion is the best\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "7f0758e6-bbcd-4c22-b728-31d624146125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_to_openai():\n",
    "    # print(f\"Openai said: {messages_by_openai[0]} \\n\")\n",
    "    # print(f\"Claude said: {messages_by_claude[0]} \\n\")\n",
    "          \n",
    "    messages_to_openai = [{\"role\": \"system\", \"content\": openai_system_content}]\n",
    "    for i, j, k in zip(messages_by_openai, messages_by_claude, messages_by_google):\n",
    "        messages_to_openai.append({\"role\": \"user\", \"content\": j})\n",
    "        messages_to_openai.append({\"role\": \"user\", \"content\": k})\n",
    "        messages_to_openai.append({\"role\": \"assistant\", \"content\": i})\n",
    "\n",
    "    # print(f\"Input to openai\")\n",
    "    # for i in messages_to_openai:\n",
    "    #     print(i)\n",
    "    \n",
    "    completion = openai.chat.completions.create(\n",
    "        model='gpt-4.1-nano',\n",
    "        messages=messages_to_openai\n",
    "    )\n",
    "\n",
    "    # messages_by_openai.append(completion.choices[0].message.content)\n",
    "    # print(f\"messages_by_openai: {messages_by_openai} \\n\")\n",
    "    \n",
    "    print(f\"Openai says: {completion.choices[0].message.content} \\n\")\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d015dea9-836a-475a-8d3c-820a18067f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "3c61b51c-39e8-457a-b18c-c63283a8088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_to_claude():\n",
    "    messages_to_claude = [{\"role\": \"system\", \"content\": claude_system_content}]\n",
    "    for i, j, k in zip(messages_by_openai, messages_by_claude, messages_by_google):\n",
    "        messages_to_claude.append({\"role\": \"user\", \"content\": i})\n",
    "        messages_to_claude.append({\"role\": \"user\", \"content\": k})\n",
    "        messages_to_claude.append({\"role\": \"assistant\", \"content\": j})\n",
    "\n",
    "    messages_to_claude.append({\"role\": \"user\", \"content\": messages_by_openai[-1]})\n",
    "        \n",
    "\n",
    "    # print(f\"Input to claude:\")\n",
    "    # for i in messages_to_claude:\n",
    "    #     print(i)\n",
    "        \n",
    "    completion = openai.chat.completions.create(\n",
    "        model='gpt-4.1-nano',\n",
    "        messages=messages_to_claude\n",
    "    )    \n",
    "\n",
    "    # messages_by_claude.append(completion.choices[0].message.content)\n",
    "    # print(f\"messages_by_claude: {messages_by_claude} \\n\")\n",
    "    \n",
    "    print(f\"Claude says: {completion.choices[0].message.content} \\n\")\n",
    "    return completion.choices[0].message.content        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c41f221-b514-442b-adcf-f2b93f520cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "5099d918-e28d-4980-adca-5878c89a22d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_to_google():\n",
    "    messages_to_google = [{\"role\": \"system\", \"content\": google_system_content}]\n",
    "    for i, j, k in zip(messages_by_openai, messages_by_claude, messages_by_google):\n",
    "        messages_to_google.append({\"role\": \"user\", \"content\": i})\n",
    "        messages_to_google.append({\"role\": \"user\", \"content\": j})\n",
    "        messages_to_google.append({\"role\": \"assistant\", \"content\": k})\n",
    "\n",
    "    messages_to_google.append({\"role\": \"user\", \"content\": messages_by_openai[-1]})\n",
    "    messages_to_google.append({\"role\": \"user\", \"content\": messages_by_claude[-1]})\n",
    "\n",
    "    # print(f\"Input to google:\")\n",
    "    # for i in messages_to_google:\n",
    "    #     print(i)\n",
    "\n",
    "    # completion = openai.chat.completions.create(\n",
    "    #     model = 'gpt-4.1-nano',\n",
    "    #     messages = messages_to_google\n",
    "    # )\n",
    "\n",
    "    completion = ollama.chat.completions.create(\n",
    "        model = 'tinyllama',\n",
    "        messages = messages_to_google\n",
    "    )\n",
    "\n",
    "\n",
    "    print(f\"Google says: {completion.choices[0].message.content} \\n\")\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d037442-4d3d-422e-b149-5f3ade3e841e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "404c1fc3-3d44-4099-a08f-cbd2b73dc24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_by_openai = ['AI is good for humanity']\n",
    "messages_by_claude = ['Are you sure']\n",
    "messages_by_google = ['I think you two are both stupid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "844f84cc-88dc-461f-a251-5186cad494b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages_by_openai: ['AI is good for humanity']\n",
      "messages_by_claude: ['Are you sure']\n",
      "messages_by_google: ['I think you two are both stupid']\n",
      "Openai says: ðŸ¤¬ðŸ¤¯ðŸ¤¡ \n",
      "\n",
      "Claude says: I understand you're feeling upset ðŸ˜”. If there's anything I can do to help or clarify, please let me know! ðŸŒŸ \n",
      "\n",
      "Google says: I'm here to help. If you have questions or want to discuss anything specific about AI or any other topic, feel free to ask! \n",
      "\n",
      "Openai says: Really? ðŸ™„ðŸ¤¦â€â™‚ï¸ \n",
      "\n",
      "Claude says: Absolutely! ðŸ˜Š I'm here to assist and chat whenever you need. ðŸŒŸ Let me know how I can help! \n",
      "\n",
      "Google says: Thanks! If there's something you'd like to talk about or any questions you have, just let me know. I'm here to help! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"messages_by_openai: {messages_by_openai}\")\n",
    "print(f\"messages_by_claude: {messages_by_claude}\")\n",
    "print(f\"messages_by_google: {messages_by_google}\")\n",
    "\n",
    "for i in range(2):\n",
    "    messages_by_openai.append(message_to_openai())\n",
    "    messages_by_claude.append(message_to_claude())\n",
    "    messages_by_google.append(message_to_google())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc80452-78d2-4d60-9d2f-0a05bf2a0c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ec0f5-08b1-4bd6-8dda-098ba2817e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffd03ca-9e09-4369-b497-0e0bed7ac008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
