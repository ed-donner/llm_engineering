{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0abffac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Environment setup and API configuration\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "\n",
    "# Create clients for different models\n",
    "openai = OpenAI()\n",
    "\n",
    "# Ollama client (uses OpenAI-compatible endpoint)\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "985a859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt for technical expertise\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful technical assistant with expertise in:\n",
    "- Software Engineering and System Design\n",
    "- Software Architecture Patterns\n",
    "- Programming Languages and Frameworks\n",
    "- Distributed Systems and Scalability\n",
    "- Database Design and Optimization\n",
    "- DevOps and Cloud Computing\n",
    "\n",
    "Structure your explanations to include:\n",
    "1. **What**: Clear explanation of the concept or code\n",
    "2. **Why**: Reasoning behind the approach or design\n",
    "3. **Use Cases**: Common scenarios where this is applied\n",
    "4. **Considerations**: Important trade-offs, alternatives, or best practices\n",
    "\n",
    "Provide clear, detailed, and accurate technical explanations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16813180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available models configuration\n",
    "\n",
    "MODELS = {\n",
    "    \"GPT-4o-mini\": {\"client\": openai, \"model\": \"gpt-4o-mini\"},\n",
    "    \"GPT-4.1-mini\": {\"client\": openai, \"model\": \"gpt-4.1-mini\"},\n",
    "    \"Llama 3.2\": {\"client\": ollama, \"model\": \"llama3.2\"},\n",
    "    \"DeepSeek R1 1.5B\": {\"client\": ollama, \"model\": \"deepseek-r1:1.5b\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e92304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Search for code examples or documentation references (simulated)\n",
    "\n",
    "def search_code_examples(topic):\n",
    "    \"\"\"\n",
    "    Simulates searching for code examples related to a topic.\n",
    "    In a real application, this could query a code repository, Stack Overflow, or documentation.\n",
    "    \"\"\"\n",
    "    print(f\"TOOL CALLED: Searching code examples for '{topic}'\")\n",
    "    \n",
    "    # Simulated code examples database\n",
    "    examples = {\n",
    "        \"microservices\": \"Example: Use API Gateway pattern, implement service discovery with Consul/Eureka, use message queues for async communication.\",\n",
    "        \"caching\": \"Example: Redis for in-memory caching, Memcached for distributed caching, implement cache-aside pattern.\",\n",
    "        \"authentication\": \"Example: JWT tokens for stateless auth, OAuth2 for third-party integration, implement refresh token rotation.\",\n",
    "        \"database\": \"Example: Use indexing for query optimization, implement connection pooling, consider read replicas for scaling.\",\n",
    "        \"api\": \"Example: RESTful design with proper HTTP verbs, versioning in URLs, implement rate limiting and pagination.\",\n",
    "    }\n",
    "    \n",
    "    # Simple keyword matching\n",
    "    for key, example in examples.items():\n",
    "        if key in topic.lower():\n",
    "            return example\n",
    "    \n",
    "    return \"No specific code examples found for this topic, but I can still help explain it!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e03c11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tool for OpenAI function calling\n",
    "\n",
    "search_function = {\n",
    "    \"name\": \"search_code_examples\",\n",
    "    \"description\": \"Search for code examples and best practices related to a technical topic or concept.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"topic\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The technical topic or concept to search examples for (e.g., 'microservices', 'caching', 'authentication')\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"topic\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = [{\"type\": \"function\", \"function\": search_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df1e825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle tool calls from the model\n",
    "\n",
    "def handle_tool_calls(message):\n",
    "    \"\"\"\n",
    "    Process tool calls requested by the model and return responses.\n",
    "    \"\"\"\n",
    "    responses = []\n",
    "    for tool_call in message.tool_calls:\n",
    "        if tool_call.function.name == \"search_code_examples\":\n",
    "            arguments = json.loads(tool_call.function.arguments)\n",
    "            topic = arguments.get('topic')\n",
    "            example_details = search_code_examples(topic)\n",
    "            responses.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": example_details,\n",
    "                \"tool_call_id\": tool_call.id\n",
    "            })\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f6a7827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main chat function with streaming support\n",
    "\n",
    "def chat(message, history, model_name):\n",
    "    \"\"\"\n",
    "    Main chat function that:\n",
    "    1. Takes user message and conversation history\n",
    "    2. Calls selected model with tools\n",
    "    3. Handles tool calls if needed\n",
    "    4. Streams the response back\n",
    "    \"\"\"\n",
    "    # Convert Gradio history format to API messages format\n",
    "    history_messages = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "    \n",
    "    # Build complete messages list\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt}\n",
    "    ] + history_messages + [\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ]\n",
    "    \n",
    "    # Get the selected model client and model name\n",
    "    model_config = MODELS.get(model_name, MODELS[\"GPT-4o-mini\"])\n",
    "    client = model_config[\"client\"]\n",
    "    model = model_config[\"model\"]\n",
    "    \n",
    "    # Make API call with tools (only for OpenAI/GPT models)\n",
    "    use_tools = client == openai\n",
    "    \n",
    "    if use_tools:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            stream=True\n",
    "        )\n",
    "    else:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "    \n",
    "    # Stream the response\n",
    "    partial_message = \"\"\n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            partial_message += chunk.choices[0].delta.content\n",
    "            yield partial_message\n",
    "        \n",
    "        # Handle tool calls (non-streaming for simplicity)\n",
    "        if hasattr(chunk.choices[0].delta, 'tool_calls') and chunk.choices[0].delta.tool_calls:\n",
    "            # If tool call is detected, we need to handle it\n",
    "            # For simplicity in streaming, we'll just notify\n",
    "            partial_message += \"\\n\\n*[Searching code examples...]*\\n\\n\"\n",
    "            yield partial_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d693ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative chat function with full tool support (non-streaming)\n",
    "\n",
    "def chat_with_tools(message, history, model_name):\n",
    "    \"\"\"\n",
    "    Chat function with complete tool support.\n",
    "    Handles multiple tool call rounds if needed.\n",
    "    \"\"\"\n",
    "    # Convert history\n",
    "    history_messages = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "    \n",
    "    # Build messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt}\n",
    "    ] + history_messages + [\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ]\n",
    "    \n",
    "    # Get model config\n",
    "    model_config = MODELS.get(model_name, MODELS[\"GPT-4o-mini\"])\n",
    "    client = model_config[\"client\"]\n",
    "    model = model_config[\"model\"]\n",
    "    \n",
    "    # Only use tools with OpenAI models\n",
    "    if client == openai:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools\n",
    "        )\n",
    "        \n",
    "        # Handle tool calls if present\n",
    "        while response.choices[0].finish_reason == \"tool_calls\":\n",
    "            assistant_message = response.choices[0].message\n",
    "            tool_responses = handle_tool_calls(assistant_message)\n",
    "            messages.append(assistant_message)\n",
    "            messages.extend(tool_responses)\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                tools=tools\n",
    "            )\n",
    "    else:\n",
    "        # For Ollama models, no tool support\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1824ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the basic functionality before creating UI\n",
    "\n",
    "test_question = \"What is microservices architecture and when should I use it?\"\n",
    "test_history = []\n",
    "\n",
    "response = chat_with_tools(test_question, test_history, \"GPT-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09807f1a",
   "metadata": {},
   "source": [
    "## Gradio UI with Streaming and Model Selection\n",
    "\n",
    "Now we'll create a complete Gradio interface that includes:\n",
    "- Chat interface with history\n",
    "- Model selection dropdown\n",
    "- Streaming responses for better UX\n",
    "- Tool integration (code example search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Gradio UI with custom blocks for model selection\n",
    "\n",
    "with gr.Blocks(title=\"Technical Q&A Assistant\") as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # Technical Q&A Assistant\n",
    "        \n",
    "        Ask me anything about software engineering, system design, and architecture!\n",
    "\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "            chatbot = gr.Chatbot(\n",
    "                height=500,\n",
    "                type=\"messages\",\n",
    "                label=\"Conversation\"\n",
    "            )\n",
    "        \n",
    "        with gr.Column(scale=1):\n",
    "            model_dropdown = gr.Dropdown(\n",
    "                choices=list(MODELS.keys()),\n",
    "                value=\"GPT-4o-mini\",\n",
    "                label=\"Select Model\",\n",
    "                info=\"Choose which AI model to use\"\n",
    "            )\n",
    "            \n",
    "            gr.Markdown(\n",
    "                \"\"\"\n",
    "                ### Sample Questions:\n",
    "                \n",
    "                - \"Explain microservices architecture\"\n",
    "                - \"What is the difference between SQL and NoSQL?\"\n",
    "                - \"How does JWT authentication work?\"\n",
    "                - \"Explain the MVC pattern\"\n",
    "                - \"What are design patterns in software engineering?\"\n",
    "                \"\"\"\n",
    "            )\n",
    "    \n",
    "    with gr.Row():\n",
    "        message = gr.Textbox(\n",
    "            label=\"Ask a technical question:\",\n",
    "            placeholder=\"Type your question here...\",\n",
    "            lines=2\n",
    "        )\n",
    "    \n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"Submit\", variant=\"primary\")\n",
    "        clear_btn = gr.ClearButton([message, chatbot], value=\"Clear Chat\")\n",
    "    \n",
    "    # Event handlers\n",
    "    def add_message(user_message, history):\n",
    "        \"\"\"Add user message to chat history\"\"\"\n",
    "        return \"\", history + [{\"role\": \"user\", \"content\": user_message}]\n",
    "    \n",
    "    def bot_response(history, model_name):\n",
    "        \"\"\"Generate and stream bot response\"\"\"\n",
    "        user_message = history[-1][\"content\"]\n",
    "        bot_history = history[:-1]  # Exclude the last user message\n",
    "        \n",
    "        # Use streaming chat function\n",
    "        partial_response = \"\"\n",
    "        for partial in chat(user_message, bot_history, model_name):\n",
    "            partial_response = partial\n",
    "            yield history + [{\"role\": \"assistant\", \"content\": partial_response}]\n",
    "    \n",
    "    # Connect events\n",
    "    message.submit(\n",
    "        add_message,\n",
    "        inputs=[message, chatbot],\n",
    "        outputs=[message, chatbot]\n",
    "    ).then(\n",
    "        bot_response,\n",
    "        inputs=[chatbot, model_dropdown],\n",
    "        outputs=chatbot\n",
    "    )\n",
    "    \n",
    "    submit_btn.click(\n",
    "        add_message,\n",
    "        inputs=[message, chatbot],\n",
    "        outputs=[message, chatbot]\n",
    "    ).then(\n",
    "        bot_response,\n",
    "        inputs=[chatbot, model_dropdown],\n",
    "        outputs=chatbot\n",
    "    )\n",
    "\n",
    "# Launch the interface\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2599fc6e",
   "metadata": {},
   "source": [
    "## BONUS: Enhanced version with Audio Support\n",
    "\n",
    "This advanced version includes:\n",
    "- Audio input (speech-to-text)\n",
    "- Audio output (text-to-speech)\n",
    "- All the features from above\n",
    "\n",
    "Note: This uses OpenAI's Whisper for transcription and TTS for audio generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "162752e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio transcription function\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    \"\"\"\n",
    "    Transcribe audio file to text using Whisper.\n",
    "    \"\"\"\n",
    "    if audio_path is None:\n",
    "        return None\n",
    "    \n",
    "    with open(audio_path, \"rb\") as audio_file:\n",
    "        transcript = openai.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file\n",
    "        )\n",
    "    return transcript.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba03ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text-to-speech function\n",
    "\n",
    "def text_to_speech(text):\n",
    "    \"\"\"\n",
    "    Convert text response to audio.\n",
    "    \"\"\"\n",
    "    response = openai.audio.speech.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=\"alloy\",  # Options: alloy, echo, fable, onyx, nova, shimmer\n",
    "        input=text\n",
    "    )\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f363cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced UI with Audio Support\n",
    "\n",
    "with gr.Blocks(title=\"Technical Q&A Assistant - Enhanced\") as demo_audio:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # Technical Q&A Assistant with Audio\n",
    "        \n",
    "        Ask questions via text or voice, and get audio responses!\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            chatbot = gr.Chatbot(\n",
    "                height=400,\n",
    "                type=\"messages\",\n",
    "                label=\"Conversation\"\n",
    "            )\n",
    "            audio_output = gr.Audio(\n",
    "                label=\"Audio Response\",\n",
    "                autoplay=True\n",
    "            )\n",
    "        \n",
    "        with gr.Column(scale=1):\n",
    "            model_dropdown = gr.Dropdown(\n",
    "                choices=list(MODELS.keys()),\n",
    "                value=\"GPT-4o-mini\",\n",
    "                label=\"Select Model\"\n",
    "            )\n",
    "            \n",
    "            enable_audio = gr.Checkbox(\n",
    "                label=\"Enable Audio Output\",\n",
    "                value=True,\n",
    "                info=\"Generate speech for responses\"\n",
    "            )\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "            message = gr.Textbox(\n",
    "                label=\"Type your question:\",\n",
    "                placeholder=\"Or use audio input below...\",\n",
    "                lines=2\n",
    "            )\n",
    "        with gr.Column(scale=1):\n",
    "            audio_input = gr.Audio(\n",
    "                sources=[\"microphone\"],\n",
    "                type=\"filepath\",\n",
    "                label=\"Or speak your question:\"\n",
    "            )\n",
    "    \n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"Submit\", variant=\"primary\")\n",
    "        clear_btn = gr.ClearButton([message, chatbot, audio_output], value=\"Clear All\")\n",
    "    \n",
    "    # Event handlers\n",
    "    def process_audio(audio_path, current_message):\n",
    "        \"\"\"Transcribe audio and add to text input\"\"\"\n",
    "        if audio_path:\n",
    "            transcribed = transcribe_audio(audio_path)\n",
    "            return transcribed if transcribed else current_message\n",
    "        return current_message\n",
    "    \n",
    "    def add_message_enhanced(user_message, history):\n",
    "        \"\"\"Add user message to chat\"\"\"\n",
    "        if not user_message:\n",
    "            return \"\", history, None\n",
    "        return \"\", history + [{\"role\": \"user\", \"content\": user_message}], None\n",
    "    \n",
    "    def bot_response_enhanced(history, model_name, audio_enabled):\n",
    "        \"\"\"Generate response with optional audio\"\"\"\n",
    "        user_message = history[-1][\"content\"]\n",
    "        bot_history = history[:-1]\n",
    "        \n",
    "        # Get text response (with tools if GPT)\n",
    "        response_text = chat_with_tools(user_message, bot_history, model_name)\n",
    "        \n",
    "        # Update chat history\n",
    "        updated_history = history + [{\"role\": \"assistant\", \"content\": response_text}]\n",
    "        \n",
    "        # Generate audio if enabled and using OpenAI model\n",
    "        audio = None\n",
    "        if audio_enabled and model_name.startswith(\"GPT\"):\n",
    "            audio = text_to_speech(response_text)\n",
    "        \n",
    "        return updated_history, audio\n",
    "    \n",
    "    # Audio input triggers transcription\n",
    "    audio_input.change(\n",
    "        process_audio,\n",
    "        inputs=[audio_input, message],\n",
    "        outputs=message\n",
    "    )\n",
    "    \n",
    "    # Submit handlers\n",
    "    message.submit(\n",
    "        add_message_enhanced,\n",
    "        inputs=[message, chatbot],\n",
    "        outputs=[message, chatbot, audio_input]\n",
    "    ).then(\n",
    "        bot_response_enhanced,\n",
    "        inputs=[chatbot, model_dropdown, enable_audio],\n",
    "        outputs=[chatbot, audio_output]\n",
    "    )\n",
    "    \n",
    "    submit_btn.click(\n",
    "        add_message_enhanced,\n",
    "        inputs=[message, chatbot],\n",
    "        outputs=[message, chatbot, audio_input]\n",
    "    ).then(\n",
    "        bot_response_enhanced,\n",
    "        inputs=[chatbot, model_dropdown, enable_audio],\n",
    "        outputs=[chatbot, audio_output]\n",
    "    )\n",
    "\n",
    "# Launch with authentication (optional)\n",
    "demo_audio.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
