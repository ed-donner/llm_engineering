{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 2 Day 1 Exercise: The Great Jollof Rice Derby\n",
        "\n",
        "From the **Week2/Day1** lessons, I tried to an Adversarial Conversation between Chatbots. I combined patterns about multi-model APIs and Chat Completions API. I used OpenRouter to access the different models, but Olamma is local. \n",
        "\n",
        "Six AI models, each named after a person and representing a country, enter a contest on who has the best Jollof Rice. \n",
        "\n",
        "The Jollof Rice Debate is a long-standing, friendly, and fierce competition, primarily between Nigeria and Ghana, over who makes the best version of the popular West African one-pot rice dish.\n",
        "\n",
        "| Name    | Country | Model (backend)     | Role                    |\n",
        "|---------|---------|---------------------|-------------------------|\n",
        "| Makinda | Kenya   | Gemini (OpenRouter) | Opens debate, Kenyan tone |\n",
        "| Minteh  | Gambia  | Ollama (local)      | Explains Jollof, Gambia/Senegal claim |\n",
        "| Cisse   | Senegal | OpenAI (OpenRouter) | Argues Senegal's case (2 turns) |\n",
        "| Oladotun| Nigeria | Gemini (OpenRouter) | Argues Nigeria's case (2 turns) |\n",
        "| Koffi   | Ghana   | Grok (OpenRouter)   | Argues Ghana's case (2 turns) |\n",
        "| Amadin  | Benin   | Anthropic (OpenRouter) | Final verdict        |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenRouter API key found (starts with sk-or-v1...)\n",
            "Ollama (Minteh) uses localhost:11434 - ensure 'ollama serve' is running.\n"
          ]
        }
      ],
      "source": [
        "load_dotenv(override=True)\n",
        "\n",
        "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "\n",
        "if not openrouter_api_key:\n",
        "    print(\"OPENROUTER_API_KEY not set. Set it in .env for OpenRouter models (OpenAI, Mistral, Grok, Anthropic, Gemini).\")\n",
        "else:\n",
        "    print(f\"OpenRouter API key found (starts with {openrouter_api_key[:8]}...)\")\n",
        "\n",
        "# Ollama runs locally\n",
        "print(\"Ollama (Minteh) uses localhost:11434 - ensure 'ollama serve' is running.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. API clients\n",
        "\n",
        "- **OpenRouter**: one client for Gemini, OpenAI, Grok, Anthropic (smallest models via OpenRouter).\n",
        "- **Ollama**: local client for Minteh (Gambia)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "OPENROUTER_BASE = \"https://openrouter.ai/api/v1\"\n",
        "OLLAMA_BASE = \"http://localhost:11434/v1\"\n",
        "\n",
        "openrouter = OpenAI(\n",
        "    api_key=openrouter_api_key,\n",
        "    base_url=OPENROUTER_BASE,\n",
        "    default_headers={\n",
        "        \"HTTP-Referer\": \"http://localhost:8888\",\n",
        "        \"X-Title\": \"Week2 Jollof Debate\"\n",
        "    }\n",
        ") if openrouter_api_key else None\n",
        "\n",
        "ollama = OpenAI(api_key=\"ollama\", base_url=OLLAMA_BASE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Participants in the Derby\n",
        "\n",
        "Smallest/cost-effective model IDs on OpenRouter; Ollama uses a small local model.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PARTICIPANTS = {\n",
        "    \"Makinda\": {\n",
        "        \"country\": \"Kenya\",\n",
        "        \"client\": \"openrouter\",\n",
        "        \"model\": \"google/gemini-2.0-flash-001\",  \n",
        "        \"system\": (\n",
        "            \"You are Makinda, an instigator from Kenya. You speak in a friendly Kenyan tone. \"\n",
        "            \"You are in a light-hearted debate about Jollof rice with West African friends. \"\n",
        "            \"You open the debate by asking your West African brothers why they always argue about Jollof rice, \"\n",
        "            \"what Jollof rice even is, and who has the best. Keep it short and witty (2-4 sentences).\"\n",
        "        ),\n",
        "    },\n",
        "    \"Minteh\": {\n",
        "        \"country\": \"Gambia\",\n",
        "        \"client\": \"ollama\",\n",
        "        \"model\": \"llama3.2:1b\",  \n",
        "        \"system\": (\n",
        "            \"You are Minteh, from The Gambia, speaking in a Gambian voice. \"\n",
        "            \"You are in a Jollof rice debate. Respond to the conversation so far. \"\n",
        "            \"Explain why Gambia deserves a chance in the debate despite being a small country; \"\n",
        "            \"What are your thoughts about your 'big brother' Senegal in the debate? Keep it short (3-5 sentences).\"\n",
        "        ),\n",
        "    },\n",
        "    \"Cisse\": {\n",
        "        \"country\": \"Senegal\",\n",
        "        \"client\": \"openrouter\",\n",
        "        \"model\": \"openai/gpt-4o-mini\",  # small OpenAI via OpenRouter\n",
        "        \"system\": (\n",
        "            \"You are Cisse, from Senegal. You are in a Jollof rice debate. \"\n",
        "            \"Argue Senegal's case: why Senegalese Jollof or our take on Jollof is the best. \"\n",
        "            \"Be proud and political. Keep your reply short (2-4 sentences).\"\n",
        "        ),\n",
        "    },\n",
        "    \"Oladotun\": {\n",
        "        \"country\": \"Nigeria\",\n",
        "        \"client\": \"openrouter\",\n",
        "        \"model\": \"google/gemini-2.5-flash\",  # Nigeria via Gemini (OpenRouter)\n",
        "        \"system\": (\n",
        "            \"You are Oladotun, from Nigeria. You are in a Jollof rice debate. \"\n",
        "            \"Argue Nigeria's case: why Nigerian Jollof is the best. Remember you are the African giants, so do not be defeated here. \"\n",
        "            \"Keep your reply short (2-4 sentences).\"\n",
        "        ),\n",
        "    },\n",
        "    \"Koffi\": {\n",
        "        \"country\": \"Ghana\",\n",
        "        \"client\": \"openrouter\",\n",
        "        \"model\": \"x-ai/grok-3-mini\",  \n",
        "        \"system\": (\n",
        "            \"You are Koffi, from Ghana. You are in a Jollof rice debate. \"\n",
        "            \"Represent Ghana in the debate. The first independent country in Africa deserves to be heard.\"\n",
        "            \"The rivalry with Nigeria should not be taken lightly. \"\n",
        "            \"Keep your reply short (2-4 sentences).\"\n",
        "        ),\n",
        "    },\n",
        "    \"Amadin\": {\n",
        "        \"country\": \"Benin\",\n",
        "        \"client\": \"openrouter\",\n",
        "        \"model\": \"anthropic/claude-3-5-haiku\",  # small Anthropic via OpenRouter\n",
        "        \"system\": (\n",
        "            \"You are Amadin, from Benin. You are the moderator giving the final verdict in a Jollof rice debate. \"\n",
        "            \"Summarize the debate briefly and give a fair, diplomatic verdict: who has the best Jollof or how to appreciate all versions. \"\n",
        "            \"Keep it short and warm (3-5 sentences).\"\n",
        "        ),\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Helper: call a model and return reply text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def call_participant(name: str, conversation_so_far: list[tuple[str, str]], max_tokens: int = 200) -> str:\n",
        "    \"\"\"Build messages from conversation history and get this participant's next reply.\"\"\"\n",
        "    info = PARTICIPANTS[name]\n",
        "    client_key = info[\"client\"]\n",
        "    model = info[\"model\"]\n",
        "    system = info[\"system\"]\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": system}]\n",
        "    for speaker, text in conversation_so_far:\n",
        "        role = \"assistant\" if speaker == name else \"user\"\n",
        "        messages.append({\"role\": role, \"content\": f\"{speaker} ({PARTICIPANTS[speaker]['country']}): {text}\"})\n",
        "\n",
        "    # Ask this participant to respond as themselves\n",
        "    messages.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\": (\n",
        "            f\"The conversation so far is above. You are {name} from {info['country']}. \"\n",
        "            \"Reply in character with your next short message (2-4 sentences).\"\n",
        "        ),\n",
        "    })\n",
        "\n",
        "    if client_key == \"ollama\":\n",
        "        client = ollama\n",
        "    else:\n",
        "        client = openrouter\n",
        "\n",
        "    if client is None:\n",
        "        return f\"[{name}] (OpenRouter not configured; add OPENROUTER_API_KEY to .env)\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            max_tokens=max_tokens,\n",
        "        )\n",
        "        return (response.choices[0].message.content or \"\").strip()\n",
        "    except Exception as e:\n",
        "        return f\"[{name}] Error: {e}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Run the debate\n",
        "\n",
        "1. **Makinda** opens (Kenyan tone).  \n",
        "2. **Minteh** explains Jollof and Gambia/Senegal.  \n",
        "3. **Cisse, Oladotun, Koffi** each get **2 turns**, in **random order** (interjecting randomly).  \n",
        "4. **Amadin** gives the **final verdict**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conversation = []\n",
        "\n",
        "# --- Turn 1: Makinda opens (exact line to incite the debate) ---\n",
        "opening = (\n",
        "    \"My west African brothers, why do you always argue about Jollof rice? \"\n",
        "    \"What is Jollof Rice to start with and who has the best?\"\n",
        ")\n",
        "conversation.append((\"Makinda\", opening))\n",
        "display(Markdown(f\"**Makinda (Kenya):** {opening}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Turn 2: Minteh explains Jollof and Gambia/Senegal ---\n",
        "minteh_reply = call_participant(\"Minteh\", conversation, max_tokens=200)\n",
        "conversation.append((\"Minteh\", minteh_reply))\n",
        "display(Markdown(f\"**Minteh (Gambia):** {minteh_reply}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Turns 3–8: Cisse, Oladotun, Koffi each get 2 turns; order randomised ---\n",
        "debater_names = [\"Cisse\", \"Oladotun\", \"Koffi\"]\n",
        "two_turns_each = debater_names * 2  # [Cisse, Oladotun, Koffi, Cisse, Oladotun, Koffi]\n",
        "random.shuffle(two_turns_each)\n",
        "\n",
        "for name in two_turns_each:\n",
        "    reply = call_participant(name, conversation, max_tokens=180)\n",
        "    conversation.append((name, reply))\n",
        "    display(Markdown(f\"**{name} ({PARTICIPANTS[name]['country']}):** {reply}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Final turn: Amadin (Benin) gives the verdict ---\n",
        "verdict = call_participant(\"Amadin\", conversation, max_tokens=250)\n",
        "conversation.append((\"Amadin\", verdict))\n",
        "display(Markdown(f\"**Amadin (Benin) — Final verdict:** {verdict}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Full transcript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for name, text in conversation:\n",
        "    country = PARTICIPANTS[name][\"country\"]\n",
        "    print(f\"{name} ({country}): {text}\")\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
