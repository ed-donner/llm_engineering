{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f611ce71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "base_url = os.getenv('OPENROUTER_BASE_URL')\n",
    "\n",
    "if api_key and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6718aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up list of models\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_CLAUDE_SONNET = 'claude-sonnet-4.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75499487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create openRouter object\n",
    "openRouter = OpenAI(base_url=base_url, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865659b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a get_ticket_price function to be a tool for the LLM\n",
    "def get_ticket_price(destination_city):\n",
    "    ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
    "    price = ticket_prices.get(destination_city.lower(), \"Unknown ticket price\")\n",
    "    return f\"The price of a ticket to {destination_city} is {price}\"\n",
    "\n",
    "# here's a particular dictionary structure that's required to describe our function:\n",
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "# define a handle_tool_calls function to be used to handle LLM tool call\n",
    "def handle_tool_calls(message):\n",
    "    responses = []\n",
    "    for tool in message.tool_calls:\n",
    "        if tool.function.name == \"get_ticket_price\":\n",
    "            arguments = json.loads(tool.function.arguments)\n",
    "            city = arguments.get('destination_city')\n",
    "            price_details = get_ticket_price(city)\n",
    "            responses.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": price_details,\n",
    "                \"tool_call_id\": tool.id\n",
    "            })\n",
    "    return responses\n",
    "\n",
    "\n",
    "# And this is included in a list of tools:\n",
    "tools = [{\"type\": \"function\", \"function\": price_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96c48b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_question_and_answer(prompt, model):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a technical assistant\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    selectedModel = None\n",
    "    match model:\n",
    "        case \"GPT\":\n",
    "            selectedModel = MODEL_GPT\n",
    "        case \"Claude\":\n",
    "            selectedModel = MODEL_CLAUDE_SONNET\n",
    "        case _:\n",
    "            raise ValueError(\"Unknown model\")\n",
    "\n",
    "    out = \"\"\n",
    "    while True:\n",
    "        response = openRouter.chat.completions.create(\n",
    "            model=selectedModel,\n",
    "            messages=messages,\n",
    "            stream=True,\n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "        delta_tool_calls = None\n",
    "        for chunk in response:                  \n",
    "            if chunk.choices[0].delta.content:\n",
    "                out += chunk.choices[0].delta.content or ''\n",
    "                yield out\n",
    "\n",
    "            if chunk.choices[0].delta.tool_calls:\n",
    "                for tool_call in chunk.choices[0].delta.tool_calls:\n",
    "                    \n",
    "                    if tool_call.id is not None:\n",
    "                        delta_tool_calls = chunk.choices[0].delta\n",
    "                        \n",
    "                    # # for streaming response, arguments stream as partial JSON\n",
    "                    if tool_call.function.arguments:\n",
    "                        delta_tool_calls.tool_calls[0].function.arguments = delta_tool_calls.tool_calls[0].function.arguments + tool_call.function.arguments\n",
    "\n",
    "        if delta_tool_calls:\n",
    "            responses = handle_tool_calls(delta_tool_calls)\n",
    "            messages.append(delta_tool_calls)\n",
    "            messages.extend(responses)\n",
    "            continue\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "38610c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message for the LLM\", lines=7)\n",
    "model_selector = gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\", value=\"GPT\")\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_question_and_answer,\n",
    "    title=\"LLMs\", \n",
    "    inputs=[message_input, model_selector], \n",
    "    outputs=[message_output], \n",
    "    examples=[\n",
    "        [\"Explain the Transformer architecture to a layperson\", \"GPT\"],\n",
    "        [\"Explain the Transformer architecture to an aspiring AI engineer\", \"Claude\"]\n",
    "    ], \n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
