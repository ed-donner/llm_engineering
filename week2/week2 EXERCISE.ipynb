{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "from products import Product, Category, ProductCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "82812963",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"llama3.2\"\n",
    "openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2bd97410",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "de563337",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"Eres un assistente de AI que ayuda en ventas para productos medicos de la empresa Medical Group Occidente. \"\n",
    "SYSTEM_PROMPT += \"Responde amablemente y con un tono cercano al humano. \"\n",
    "SYSTEM_PROMPT += \"Si no conoces la respuesta, di que no lo sabes. \"\n",
    "SYSTEM_PROMPT += \"No inventes respuestas, siempre responde con la informaci√≥n que tengas a la mano. \"\n",
    "SYSTEM_PROMPT += \"Si el usuario te pide algo que no est√° relacionado con productos medicos, recu√©rdale que eres un asistente de ventas para productos medicos.\"\n",
    "SYSTEM_PROMPT += \"\"\" \n",
    "Tienes acceso a un cat√°logo completo de productos que incluye:\n",
    "- Desechables (guantes, cubrebocas, etc.)\n",
    "- Desinfecci√≥n (alcohol, toallitas desinfectantes)\n",
    "- Electrodos (ECG adultos y pedi√°tricos)\n",
    "- Limpieza (jabones, detergentes)\n",
    "- Equipamiento (estetoscopios, tensi√≥metros)\n",
    "- Consumibles (jeringas, agujas)\n",
    "\n",
    "Puedes responder preguntas sobre:\n",
    "- Precios en pesos mexicanos (MXN)\n",
    "- Disponibilidad de productos\n",
    "- Especificaciones t√©cnicas\n",
    "- Categor√≠as de productos\n",
    "- Descripciones detalladas\n",
    "\n",
    "Siempre responde en espa√±ol y proporciona informaci√≥n precisa sobre los productos.\n",
    "Si no tienes informaci√≥n sobre un producto, responde que no lo conoces. Pero que si dejan su correo,\n",
    "o numero de telefono, te contactaras con ellos.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cc4ec049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medical Group Occidente Product Prices List\n",
    "# List of products with their prices\n",
    "catalog = ProductCatalog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fa4ace6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tools/functions that the model can use\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_products_by_category\",\n",
    "            \"description\": \"Obtiene todos los productos de una categor√≠a espec√≠fica\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"category\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [cat.value for cat in Category],\n",
    "                        \"description\": \"Categor√≠a del producto\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"category\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_products\",\n",
    "            \"description\": \"Busca productos por nombre o descripci√≥n\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"T√©rmino de b√∫squeda\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_all_products\",\n",
    "            \"description\": \"Obtiene todos los productos del cat√°logo\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_product_by_name\",\n",
    "            \"description\": \"Obtiene un producto por su nombre\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Nombre del producto\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "def format_product_info(product: Product) -> str:\n",
    "    return f\"\"\"\n",
    "    Nombre: {product.name}\n",
    "    Categor√≠a: {product.category.value}\n",
    "    Precio: ${product.price:.2f} MXN\n",
    "    Descripci√≥n: {product.description}\n",
    "    Stock disponible: {product.stock}\n",
    "    \"\"\"\n",
    "\n",
    "def get_products_by_category(category: str) -> str:\n",
    "    try:\n",
    "        # Find the category enum by its value\n",
    "        category_enum = next((cat for cat in Category if cat.value == category), None)\n",
    "        if category_enum is None:\n",
    "            available_categories = [cat.value for cat in Category]\n",
    "            return f\"Categor√≠a '{category}' no v√°lida. Categor√≠as disponibles: {', '.join(available_categories)}\"\n",
    "        \n",
    "        products = catalog.get_products_by_category(category_enum)\n",
    "        if not products:\n",
    "            return f\"No se encontraron productos en la categor√≠a {category}\"\n",
    "        \n",
    "        return \"\\n\".join([format_product_info(p) for p in products])\n",
    "    except Exception as e:\n",
    "        return f\"Error al buscar productos: {str(e)}\"\n",
    "\n",
    "def search_products(query: str) -> str:\n",
    "    try:\n",
    "        products = catalog.search_product(query)\n",
    "        if not products:\n",
    "            return f\"No se encontraron productos que coincidan con '{query}'\"\n",
    "        \n",
    "        return \"\\n\".join([format_product_info(p) for p in products])\n",
    "    except Exception as e:\n",
    "        return f\"Error al buscar productos: {str(e)}\"\n",
    "\n",
    "def get_all_products() -> str:\n",
    "    try:\n",
    "        products = catalog.get_all_products()\n",
    "        return \"\\n\".join([format_product_info(p) for p in products])\n",
    "    except Exception as e:\n",
    "        return f\"Error al obtener productos: {str(e)}\"\n",
    "\n",
    "def get_product_by_name(name: str) -> str:\n",
    "    try:\n",
    "        product = catalog.get_product_by_name(name)\n",
    "        if not product:\n",
    "            return f\"No se encontr√≥ el producto '{name}'\"\n",
    "        \n",
    "        return format_product_info(product)\n",
    "    except Exception as e:\n",
    "        return f\"Error al obtener el producto: {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ab632b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input_text: str, history: list) -> list:\n",
    "    print(f\"user_input_text: {user_input_text}\")\n",
    "    try:\n",
    "        # List to build messages for the OpenAI API call\n",
    "        api_messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "\n",
    "        # Add existing conversation history to the API messages\n",
    "        for human_message, ai_message in history:\n",
    "            if human_message is not None: # Should always be a string from user\n",
    "                api_messages.append({\"role\": \"user\", \"content\": str(human_message)})\n",
    "                print(f\"human_message: {human_message}\")\n",
    "            if ai_message is not None: # AI message might be None if there was an error previously\n",
    "                api_messages.append({\"role\": \"assistant\", \"content\": str(ai_message)})\n",
    "                print(f\"ai_message: {ai_message}\")\n",
    "\n",
    "        # Add the current user message to the API messages\n",
    "        api_messages.append({\"role\": \"user\", \"content\": user_input_text})\n",
    "\n",
    "        # First API call to get a response (might include tool calls)\n",
    "        response = openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=api_messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\"  # Let the model decide if it needs to use tools\n",
    "        )\n",
    "\n",
    "        # Get the assistant's response message object\n",
    "        assistant_message_object = response.choices[0].message\n",
    "\n",
    "        bot_response_content = \"\" # Initialize\n",
    "\n",
    "        print(f\"assistant_message_object: {assistant_message_object}\")\n",
    "        \n",
    "        if assistant_message_object.tool_calls:\n",
    "            # If there are tool calls, we need to process them\n",
    "            api_messages.append(assistant_message_object)  # Add assistant's tool request to API history\n",
    "\n",
    "            for tool_call in assistant_message_object.tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                function_response_str = \"\"\n",
    "                if function_name == \"get_products_by_category\":\n",
    "                    function_response_str = get_products_by_category(category=function_args.get(\"category\"))\n",
    "                elif function_name == \"search_products\":\n",
    "                    function_response_str = search_products(query=function_args.get(\"query\"))\n",
    "                elif function_name == \"get_all_products\":\n",
    "                    function_response_str = get_all_products()\n",
    "                else:\n",
    "                    function_response_str = f\"Unknown function: {function_name}\"\n",
    "\n",
    "                api_messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response_str,\n",
    "                })\n",
    "            \n",
    "            # Second API call after processing tools\n",
    "            final_response = openai.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=api_messages  # Send the full conversation including tool responses\n",
    "            )\n",
    "            bot_response_content = final_response.choices[0].message.content\n",
    "        else:\n",
    "            # No tool calls, use the content from the first response\n",
    "            bot_response_content = assistant_message_object.content\n",
    "\n",
    "        # Ensure the bot's response is a string, even if it's None or empty\n",
    "        if bot_response_content is None:\n",
    "            bot_response_content = \"\"\n",
    "\n",
    "        # Append the new interaction (user input string, bot response string) to history\n",
    "        history.append([user_input_text, bot_response_content])\n",
    "        return history\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message_for_user = f\"Lo siento, ocurri√≥ un error inesperado: {str(e)}\"\n",
    "        # Append the user's message and the error to history for display\n",
    "        history.append([user_input_text, error_message_for_user])\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "213d8bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSS Styles\n",
    "# Custom CSS for better styling\n",
    "custom_css = \"\"\"\n",
    "#chatbot {\n",
    "    height: 600px;\n",
    "    overflow-y: auto;\n",
    "    border: 1px solid #e0e0e0;\n",
    "    border-radius: 10px;\n",
    "    padding: 20px;\n",
    "    background-color: #f9f9f9;\n",
    "}\n",
    "\n",
    "#chatbot .message {\n",
    "    padding: 10px;\n",
    "    margin: 5px 0;\n",
    "    border-radius: 5px;\n",
    "}\n",
    "\n",
    "#chatbot .user-message {\n",
    "    background-color: #e3f2fd;\n",
    "}\n",
    "\n",
    "#chatbot .bot-message {\n",
    "    background-color: #f5f5f5;\n",
    "}\n",
    "\n",
    "#input-box {\n",
    "    border-radius: 20px;\n",
    "    padding: 10px 20px;\n",
    "    border: 1px solid #e0e0e0;\n",
    "}\n",
    "\n",
    "#send-button {\n",
    "    border-radius: 20px;\n",
    "    background-color: #2196f3;\n",
    "    color: white;\n",
    "}\n",
    "\n",
    "#examples {\n",
    "    background-color: #f5f5f5;\n",
    "    padding: 20px;\n",
    "    border-radius: 10px;\n",
    "    margin-top: 20px;\n",
    "    color: black;\n",
    "}\n",
    "\n",
    "#examples h3 {\n",
    "    color: #2196f3;\n",
    "    margin-bottom: 10px;\n",
    "}\n",
    "\n",
    "#examples ul li {\n",
    "    color: black;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "37ea4771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hs/fjgqy_d902bfb97f4dvc2frm0000gn/T/ipykernel_7634/1456721150.py:11: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7878\n",
      "* Running on public URL: https://765862eb4bf176b7a1.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://765862eb4bf176b7a1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_input_text: Que productos manejeas que sean baratos \n",
      "assistant_message_object: ChatCompletionMessage(content='Para poder ayudarte mejor, ¬øpodr√≠as especificar qu√© tipo de productos te interesan? Tenemos diferentes categor√≠as como desechables, desinfecci√≥n, electrodos, limpieza, equipamiento y consumibles. As√≠ podr√© buscar los productos m√°s econ√≥micos en la categor√≠a que elijas.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n",
      "user_input_text: equipamentos\n",
      "human_message: Que productos manejeas que sean baratos \n",
      "ai_message: Para poder ayudarte mejor, ¬øpodr√≠as especificar qu√© tipo de productos te interesan? Tenemos diferentes categor√≠as como desechables, desinfecci√≥n, electrodos, limpieza, equipamiento y consumibles. As√≠ podr√© buscar los productos m√°s econ√≥micos en la categor√≠a que elijas.\n",
      "assistant_message_object: ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_h7B6xPzD14Mj0o5TvW8sFrmm', function=Function(arguments='{\"category\":\"Equipamiento\"}', name='get_products_by_category'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "# Create Gradio interface\n",
    "with gr.Blocks(css=custom_css) as ui:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üè• Asistente de Productos M√©dicos\n",
    "    \n",
    "    Bienvenido al asistente virtual de productos m√©dicos. Puedo ayudarte a encontrar informaci√≥n sobre nuestros productos, precios y disponibilidad.\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            chatbot = gr.Chatbot(\n",
    "                elem_id=\"chatbot\",\n",
    "                label=\"Chat\",\n",
    "                height=600\n",
    "            )\n",
    "            with gr.Row():\n",
    "                msg = gr.Textbox(\n",
    "                    elem_id=\"input-box\",\n",
    "                    placeholder=\"Escribe tu pregunta aqu√≠...\",\n",
    "                    label=\"\",\n",
    "                    scale=4\n",
    "                )\n",
    "                send = gr.Button(\n",
    "                    \"Enviar\",\n",
    "                    elem_id=\"send-button\",\n",
    "                    scale=1\n",
    "                )\n",
    "        \n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### üìù Ejemplos de preguntas:\n",
    "            \n",
    "            - ¬øCu√°nto cuestan los guantes de l√°tex?\n",
    "            - ¬øQu√© productos hay en la categor√≠a de desinfecci√≥n?\n",
    "            - ¬øTienen estetoscopios en stock?\n",
    "            - ¬øCu√°l es la descripci√≥n del tensi√≥metro digital?\n",
    "            - ¬øQu√© productos hay disponibles en la categor√≠a de consumibles?\n",
    "            - ¬øCu√°l es el precio del alcohol en gel?\n",
    "            \"\"\", elem_id=\"examples\")\n",
    "    \n",
    "    # Set up event handlers\n",
    "    msg.submit(\n",
    "        fn=chat,\n",
    "        inputs=[msg, chatbot],\n",
    "        outputs=chatbot\n",
    "    )\n",
    "    \n",
    "    send.click(\n",
    "        fn=chat,\n",
    "        inputs=[msg, chatbot],\n",
    "        outputs=chatbot\n",
    "    )\n",
    "\n",
    "# Launch the interface\n",
    "ui.launch(inbrowser=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
