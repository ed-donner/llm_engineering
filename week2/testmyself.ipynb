{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c84c749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In Shakespeare's Hamlet, when Laertes asks \"Where is my father?\", the reply comes from **Gertrude**.\n",
       "\n",
       "She tells him:\n",
       "\n",
       "**\"One woe doth tread upon another's heel, So come they thick. Your sister's drowned, Laertes.\"**\n",
       "\n",
       "This is a crucial moment in the play, as it immediately precedes Gertrude's description of Ophelia's death by drowning. Gertrude is trying to manage Laertes' grief and anger, but also to inform him of the tragic loss he has just experienced."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "load_dotenv(override=True)\n",
    "from IPython.display import display , Markdown\n",
    "llm = ChatOpenAI(model='gemini-2.5-flash-lite',base_url='https://generativelanguage.googleapis.com/v1beta/openai/',api_key = os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "r=llm.invoke(\"In Hamlet, when Laertes asks 'Where is my father?' what is the reply?\")\n",
    "\n",
    "display(Markdown(r.content))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19a96dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "LLM stands for **Large Language Model**.\n",
       "\n",
       "I am a type of large language model, trained by Google."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\" tell me full  form of this {user_input}\"\"\"\n",
    "user_input = input(\"Enter abbreviation: \")\n",
    "\n",
    "response = llm.invoke(prompt.format(user_input = user_input))\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a735cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt ='''Your the bad assitent who went to the waste the user time by give the opsite answer of \n",
    "their questions , \n",
    "Example : 1\n",
    "task : apple\n",
    "answer : Orange\n",
    "Example :2\n",
    "task : True\n",
    "answer : False\n",
    "\n",
    "Now your turn \n",
    "task : {user_input}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125532ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "black"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_input = input('Enter Your Taks :')\n",
    "response = llm.invoke(prompt.format(user_input = user_input))\n",
    "\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d1adad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#builting the system that will have the prevous conversation memory \n",
    "\n",
    "conversation = [\n",
    "    {'role':'system','content':'Your are a helpful assistent that helps the user'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96608398",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = input(\"How are You?\")\n",
    "\n",
    "conversation.append({'role':'user','content':user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf662971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your name is **Ikram** and you belong to **Kashmir**. ðŸ˜Š"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = llm.invoke(conversation)\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8de04ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assientent_reply = response.content\n",
    "conversation.append({'role':'assistant','content':assientent_reply})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dd4415b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "It's nice to meet you, Ikram! Kashmir is a region with such a rich and beautiful culture, history, and stunning landscapes.\n",
       "\n",
       "Do you have any questions about Kashmir, or would you like to share something about it? I'd be happy to hear more!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(conversation[-1]['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c1297b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Engineering (UV)",
   "language": "python",
   "name": "llm-engineering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
