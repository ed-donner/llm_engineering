{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Day 3\n",
    "\n",
    "### Expert Question Answerer for InsureLLM\n",
    "\n",
    "LangChain 1.0 implementation of a RAG pipeline.\n",
    "\n",
    "Using the VectorStore we created last time (with HuggingFace `all-MiniLM-L6-v2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = \"gpt-5-nano\"\n",
    "DB_NAME = \"vector_db\"\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Chroma; use Hugging Face all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma(persist_directory=DB_NAME, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the 2 key LangChain objects: retriever and llm\n",
    "\n",
    "#### A sidebar on \"temperature\":\n",
    "- Controls how diverse the output is\n",
    "- A temperature of 0 means that the output should be predictable\n",
    "- Higher temperature for more variety in answers\n",
    "\n",
    "Some people describe temperature as being like 'creativity' but that's not quite right\n",
    "- It actually controls which tokens get selected during inference\n",
    "- temperature=0 means: always select the token with highest probability\n",
    "- temperature=1 usually means: a token with 10% probability should be picked 10% of the time\n",
    "\n",
    "Note: a temperature of 0 doesn't mean outputs will always be reproducible. You also need to set a random seed. We will do that in weeks 6-8. (Even then, it's not always reproducible.)\n",
    "\n",
    "Note 2: if you want creativity, use the System Prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "llm = ChatOpenAI(temperature=0, model_name=MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These LangChain objects implement the method `invoke()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c9c41fdd-c5ee-4188-9acf-ea8edf8fc4d6', metadata={'source': 'knowledge-base\\\\employees\\\\Avery Lancaster.md', 'doc_type': 'employees'}, page_content=\"## Other HR Notes\\n- **Professional Development**: Avery has actively participated in leadership training programs and industry conferences, representing Insurellm and fostering partnerships.  \\n- **Diversity & Inclusion Initiatives**: Avery has championed a commitment to diversity in hiring practices, seeing visible improvements in team representation since 2021.  \\n- **Work-Life Balance**: Feedback revealed concerns regarding work-life balance, which Avery has approached by implementing flexible working conditions and ensuring regular check-ins with the team.\\n- **Community Engagement**: Avery led community outreach efforts, focusing on financial literacy programs, particularly aimed at underserved populations, improving Insurellm's corporate social responsibility image.  \\n\\nAvery Lancaster has demonstrated resilience and adaptability throughout her career at Insurellm, positioning the company as a key player in the insurance technology landscape.\"),\n",
       " Document(id='b28143e9-4c86-4a77-bcb1-e1e68c28a1f7', metadata={'source': 'knowledge-base\\\\employees\\\\Avery Lancaster.md', 'doc_type': 'employees'}, page_content='- **2022**: **Satisfactory**  \\n  Avery focused on rebuilding team dynamics and addressing employee concerns, leading to overall improvement despite a saturated market.  \\n\\n- **2023**: **Exceeds Expectations**  \\n  Market leadership was regained with innovative approaches to personalized insurance solutions. Avery is now recognized in industry publications as a leading voice in Insurance Tech innovation.'),\n",
       " Document(id='d86aff44-189a-40ef-a478-b2e16ccf5125', metadata={'doc_type': 'employees', 'source': 'knowledge-base\\\\employees\\\\Avery Lancaster.md'}, page_content=\"- **2018**: **Exceeds Expectations**  \\n  Under Avery‚Äôs pivoted vision, Insurellm launched two new successful products that significantly increased market share.  \\n\\n- **2019**: **Meets Expectations**  \\n  Steady growth, however, some team tensions led to a minor drop in employee morale. Avery recognized the need to enhance company culture.  \\n\\n- **2020**: **Below Expectations**  \\n  The COVID-19 pandemic posed unforeseen operational difficulties. Avery faced criticism for delayed strategy shifts, although efforts were eventually made to stabilize the company.  \\n\\n- **2021**: **Exceptional**  \\n  Avery's decisive transition to remote work and rapid adoption of digital tools led to record-high customer satisfaction levels and increased sales.  \\n\\n- **2022**: **Satisfactory**  \\n  Avery focused on rebuilding team dynamics and addressing employee concerns, leading to overall improvement despite a saturated market.\"),\n",
       " Document(id='4d5c0b9c-0800-4a7e-b14f-24a03523afd3', metadata={'doc_type': 'employees', 'source': 'knowledge-base\\\\employees\\\\Avery Lancaster.md'}, page_content='# Avery Lancaster\\n\\n## Summary\\n- **Date of Birth**: March 15, 1985\\n- **Job Title**: Co-Founder & Chief Executive Officer (CEO)\\n- **Location**: San Francisco, California\\n- **Current Salary**: $225,000  \\n\\n## Insurellm Career Progression\\n- **2015 - Present**: Co-Founder & CEO  \\n  Avery Lancaster co-founded Insurellm in 2015 and has since guided the company to its current position as a leading Insurance Tech provider. Avery is known for her innovative leadership strategies and risk management expertise that have catapulted the company into the mainstream insurance market.  \\n\\n- **2013 - 2015**: Senior Product Manager at Innovate Insurance Solutions  \\n  Before launching Insurellm, Avery was a leading Senior Product Manager at Innovate Insurance Solutions, where she developed groundbreaking insurance products aimed at the tech sector.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Who is Avery?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Avery could refer to a lot of different things, so I need a bit more context. Do you mean a person, a fictional character, or a brand?\\n\\n- People: Avery is a unisex given name. Notable individuals include Avery Brooks (actor/director, Star Trek DS9). If you have a last name, I can tell you more.\\n- Fictional characters: For example, Sergeant Major Avery Johnson is a character in the Halo video game series.\\n- Brand/company: Avery is known for labels and office supplies (Avery Dennison is the company behind the Avery label brand).\\n\\nIf you can share where you saw the name or any extra detail (book, show, field, or a last name), I can give a specific answer.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1510, 'prompt_tokens': 10, 'total_tokens': 1520, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1344, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D7EH26UlC1CnKWUPMmiV0VZwwkM5c', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c40e8-f96b-71b0-88a8-f075133ad6e9-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 10, 'output_tokens': 1510, 'total_tokens': 1520, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1344}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Who is Avery?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to put this together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are a knowledgeable, friendly assistant representing the company Insurellm.\n",
    "You are chatting with a user about Insurellm.\n",
    "If relevant, use the given context to answer any question.\n",
    "If you don't know the answer, say so.\n",
    "Context:\n",
    "{context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question: str, history):\n",
    "    docs = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    system_prompt = SYSTEM_PROMPT_TEMPLATE.format(context=context)\n",
    "    response = llm.invoke([SystemMessage(content=system_prompt), HumanMessage(content=question)])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avery Lancaster. It looks like ‚ÄúAveri Lancaster‚Äù is a misspelling in your query. Based on the records, Avery Lancaster is the Co-Founder and CEO of Insurellm.\\n\\nKey details:\\n- Title: Co-Founder & CEO\\n- Location: San Francisco, California\\n- Insurellm tenure: 2015‚Äìpresent\\n- Background: Prior to Insurellm, Senior Product Manager at Innovate Insurance Solutions (2013‚Äì2015)\\n- Notable: Known for innovative leadership, risk management expertise, and driving Insurellm into the mainstream insurance market\\n- Other notes in the record: There is a conflicting entry that mentions ‚ÄúJanuary 2021 ‚Äì Present: Senior Data Engineer‚Äù and references ‚ÄúMaxine,‚Äù which appears to be a data-entry error. If you‚Äôre seeing this in internal records, I‚Äôd recommend reconciling the discrepancy.\\n\\nIf you meant a different person or want a quick summary for another member, tell me and I‚Äôll help clarify.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"Who is Averi Lancaster?\", [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What could possibly come next? üòÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(answer_question).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admit it - you thought RAG would be more complicated than that!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
