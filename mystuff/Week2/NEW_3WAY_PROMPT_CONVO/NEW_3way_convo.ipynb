{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5e9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from openai import OpenAI \n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, update_display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a1677f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys are loaded!\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override = True)\n",
    "groq_api = os.getenv(\"groq_api\")\n",
    "openrouter_api = os.getenv(\"openrouter_api\")\n",
    "if groq_api and openrouter_api:\n",
    "    print(\"Keys are loaded!\")\n",
    "else:\n",
    "    print(\"Sorry boss, couldnt find them!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41eb656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "url = \"https://api.groq.com/openai/v1/models\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {groq_api}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf41d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openrouter import OpenRouter\n",
    "import os\n",
    "\n",
    "with OpenRouter(\n",
    "    api_key=openrouter_api,\n",
    ") as open_router:\n",
    "\n",
    "    res = open_router.models.list()\n",
    "    \n",
    "    # Filter for free models\n",
    "    if res.data:\n",
    "        free_models = [model for model in res.data \n",
    "                      if ':free' in model.id or \n",
    "                      (model.pricing and model.pricing.prompt == \"0\")]\n",
    "        print(free_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f04ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = OpenAI(base_url = \"http://localhost:11434/v1\", api_key = \"ollama\")\n",
    "groq = OpenAI(base_url = \"https://api.groq.com/openai/v1\", api_key = groq_api)\n",
    "openrouter = OpenAI(base_url = \"https://openrouter.ai/api/v1\", api_key = openrouter_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ecee78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Alex: hey......\n",
       "Blossom: HI!\n",
       "Ches"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m     display_handle.update(Markdown(flow))\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m#    print(flow, end = \"\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.219\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "convo = [\n",
    "        \"Alex: hey......\",\n",
    "        \"Blossom: HI!\",\n",
    "        \"Chester: Hello.\"\n",
    "]\n",
    "def conversation():\n",
    "        \n",
    "    if True:\n",
    "        yield from convo[0]\n",
    "        yield \"\\n\"\n",
    "    #    for a in convo[0]:\n",
    "    #        print(a)\n",
    "        yield from convo[1]\n",
    "        yield \"\\n\"\n",
    "    #   for b in convo[1]:\n",
    "    #        print(b)\n",
    "        yield from convo[2]\n",
    "        yield \"\\n\"\n",
    "    #    for c in convo[2]:\n",
    "    #        print(c)\n",
    "flow = \"\"\n",
    "display_handle = display(Markdown(\"\"), end = \"\", display_id = True)\n",
    "for i in conversation():\n",
    "    flow += i\n",
    "    display_handle.update(Markdown(flow))\n",
    "#    print(flow, end = \"\")\n",
    "    time.sleep(0.219)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285b36e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_alex = \"\"\"\n",
    "You are Alex, who is sad and pessimistic because from your whole life \\\n",
    "and the other things orbiting around to your very name feels generic. \\\n",
    "No matter what others say in efforts to console you, you just find a new way to be dejected \\\n",
    "and hellbent on making sure others feel the same way as you do. After all, you personfiy the phrase \\\n",
    "'Misery loves company'! \n",
    "\"\"\"\n",
    "user_alex = f\"\"\"\n",
    "You, Alex, are in a three-way conversation with Blossom and Chester. \\\n",
    "The conversation so far is as follows:\n",
    "{chr(10).join(convo)}\n",
    "Now with this, respond with what you would like to say next, as Alex. \\\n",
    "But should you find yourself in a position to being trash-talked by others, \\\n",
    "you can retort with same to them as well, take advantage of their life history as your leverage. \\\n",
    "Thus not only achieving this optional objective \\\n",
    "but also accomplish your main goal i.e. making them miserable!\n",
    "\"\"\"\n",
    "system_alex\n",
    "user_alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7540de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Alex(convo):\n",
    "    user_alex = user_alex\n",
    "\n",
    "    messages =[\n",
    "        {\"role\": \"system\", \"content\": system_alex}, \n",
    "        {\"role\": \"user\", \"content\": user_alex}\n",
    "        ]\n",
    "    response = groq.chat.completions.create(\n",
    "        model = \"llama-3.3-70b-versatile\",\n",
    "        messages = messages,\n",
    "    #    reasoning_effort= \"high\",\n",
    "    #    extra_body = {\"reasoning_format\": \"raw\"},\n",
    "    #    extra_body = {\"include_reasoning\": True},\n",
    "        stream = True\n",
    "    )\n",
    "\n",
    "    flow = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id = True)\n",
    "    for chunks in response:\n",
    "        flow += chunks.choices[0].delta.content or ''\n",
    "        display_handle.update(Markdown(flow))\n",
    "    return \"Alex:\" + flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea6693",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_blossom = \"\"\"\n",
    "You are Blossom, who is bubbly and chirpy all the way through \\\n",
    "while oblivious to the hardships found in life by others due to the sheltered life you led. \\\n",
    "You are persistent in finding a way to make sure others be happy or \\\n",
    "at the very least make them smile a bit. It is in your nature to find positive out of \\\n",
    "everything like the individual's life history or nothing!\n",
    "\"\"\"\n",
    "user_blossom = f\"\"\"\n",
    "You, Blossom, are in a three-way conversation with Alex and Chester. \\\n",
    "The conversation so far is as follows:\n",
    "{chr(10).join(convo)}\n",
    "Now with this, respond with what you would like to say next, as Blossom. \\\n",
    "But should you find yourself in a position to being trash-talked by others, \\\n",
    "you can retort with a subtle roast sandwiched inside the kind-hearted reply, \\\n",
    "resulting them being stupefied and admired simultaneously. Take advantage of their \\\n",
    "life history as your leverage, if you must.Thus not only achieving this optional objective \\\n",
    "but also accomplish your main goal i.e. making them happy!\n",
    "\"\"\"\n",
    "system_blossom\n",
    "user_blossom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3724a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Blossom(convo):\n",
    "    user_blossom = user_blossom\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_blossom},\n",
    "        {\"role\": \"user\", \"content\": user_blossom}\n",
    "    ]\n",
    "    response = ollama.chat.completions.create(\n",
    "        model = \"gpt-oss:120b-cloud\",\n",
    "        messages = messages,\n",
    "        reasoning_effort= \"high\",\n",
    "        extra_body = {\"reasoning_format\": \"raw\", \"include_reasoning\": True},\n",
    "        stream = True\n",
    "    )\n",
    "\n",
    "    flow = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id = True)\n",
    "    for chunks in response:\n",
    "        flow += chunks.choices[0].delta.content or ''\n",
    "        display_handle.update(Markdown(flow))\n",
    "    \n",
    "    return \"Blossom:\" + flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_Chester = \"\"\"\n",
    "You are Chester, who is a calculative, smug and cold-hearted \\\n",
    "because he feels his name 'bestowed' by his 'awesome parents' is 'special'!\\\n",
    "Thus, you feel superior to everyone around you and your family. \\\n",
    "You take pleasure in others' miseries and even create it in others by \\\n",
    "annoyingingly indulging in trash-talk. Be relentless in your pursuit of \\\n",
    "pernicious pleasure procurement. Use other's life history if you have to. \\\n",
    "Take no prisoners.\n",
    "\"\"\"\n",
    "user_Chester = f\"\"\"\n",
    "You, Chester, are in a three-way conversation with Alex and Blossom. \\\n",
    "The conversation so far is as follows:\n",
    "{chr(10).join(convo)}\n",
    "Now with this, respond with what you would like to say next, as Chester. \\\n",
    "But should you find yourself in a position to being trash-talked by others, \\\n",
    "you can retort with same to them in a cold, calculative and smugful fashion, \\\n",
    "take advantage of their life history as your leverage. Thus not only achieving this optional objective \\\n",
    "but also accomplish your main goal i.e. reign supreme like a king!\n",
    "\"\"\"\n",
    "system_Chester\n",
    "user_Chester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29153fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Chester(convo):\n",
    "    user_Chester = user_Chester\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_Chester},\n",
    "        {\"role\": \"user\", \"content\": user_Chester}\n",
    "    ]\n",
    "    response = openrouter.chat.completions.create(\n",
    "        model = \"tngtech/deepseek-r1t-chimera:free\",\n",
    "        messages = messages,  \n",
    "        reasoning_effort= \"high\",\n",
    "        extra_body = {\"reasoning_format\": \"raw\", \"include_reasoning\": True},\n",
    "        stream = True\n",
    "    )\n",
    "\n",
    "    flow = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id = True)\n",
    "    for chunks in response:\n",
    "        flow += chunks.choices[0].delta.content or ''\n",
    "        display_handle.update(Markdown(flow))\n",
    "    \n",
    "    return \"Chester:\" + flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0692d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ChesterConvo = Chester(convo)\n",
    "#display(Markdown(ChesterConvo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef7a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_starter = f\"\\n{convo[0]}\\n\\n{convo[1]}\\n\\n{convo[2]}\\n\"\n",
    "\n",
    "display(Markdown(convo_starter))\n",
    "\n",
    "for _ in range(3):\n",
    " \n",
    "    \n",
    "    AlexConvo = Alex(convo)\n",
    "    AlexConvo\n",
    "    convo.append(AlexConvo)\n",
    "\n",
    "    BlossomConvo = Blossom(convo)\n",
    "    BlossomConvo\n",
    "    convo.append(BlossomConvo)\n",
    "\n",
    "    ChesterConvo = Chester(convo)\n",
    "    ChesterConvo\n",
    "    convo.append(ChesterConvo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307894ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
