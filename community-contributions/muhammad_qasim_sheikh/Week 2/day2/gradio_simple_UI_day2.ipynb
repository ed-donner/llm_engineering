{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef1e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3426558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a59a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Helper: Prompt Builder\n",
    "# -------------------------------\n",
    "def build_prompt(task, topic, tone, audience):\n",
    "    task_prompts = {\n",
    "        \"Brochure\": f\"Write a compelling marketing brochure about {topic}.\",\n",
    "        \"Blog Post\": f\"Write a blog post on {topic} with engaging storytelling and useful insights.\",\n",
    "        \"Product Comparison\": f\"Write a product comparison summary focusing on {topic}, including pros, cons, and recommendations.\",\n",
    "        \"Idea Brainstorm\": f\"Brainstorm creative ideas or solutions related to {topic}.\"\n",
    "    }\n",
    "    base = task_prompts.get(task, \"Write something creative.\")\n",
    "    if tone:\n",
    "        base += f\" Use a {tone} tone.\"\n",
    "    if audience:\n",
    "        base += f\" Tailor it for {audience}.\"\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a27bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Generate with multiple models\n",
    "# -------------------------------\n",
    "def generate_stream(task, topic, tone, audience, model):\n",
    "    if not topic.strip():\n",
    "        yield \"⚠️ Please enter a topic.\"\n",
    "        return\n",
    "\n",
    "    prompt = build_prompt(task, topic, tone, audience)\n",
    "\n",
    "    stream = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=800,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e15abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Refinement logic\n",
    "# -------------------------------\n",
    "def refine_stream(original_text, instruction, model):\n",
    "    if not original_text.strip():\n",
    "        yield \"⚠️ Please paste the text you want to refine.\"\n",
    "        return\n",
    "    if not instruction.strip():\n",
    "        yield \"⚠️ Please provide a refinement instruction.\"\n",
    "        return\n",
    "\n",
    "    refined_prompt = f\"Refine the following text based on this instruction: {instruction}\\n\\nText:\\n{original_text}\"\n",
    "\n",
    "    stream = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a writing assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": refined_prompt}\n",
    "        ],\n",
    "        max_tokens=800,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee02feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Gradio UI\n",
    "# -------------------------------\n",
    "with gr.Blocks(title=\"AI Creative Studio\") as demo:\n",
    "    gr.Markdown(\"# AI Creative Studio\\nGenerate marketing content, blog posts, or creative ideas — streamed in real-time!\")\n",
    "\n",
    "    with gr.Row():\n",
    "        task = gr.Dropdown(\n",
    "            [\"Brochure\", \"Blog Post\", \"Product Comparison\", \"Idea Brainstorm\"],\n",
    "            label=\"Task Type\",\n",
    "            value=\"Brochure\"\n",
    "        )\n",
    "        topic = gr.Textbox(label=\"Topic\", placeholder=\"e.g., Electric Cars, AI in Education...\")\n",
    "    with gr.Row():\n",
    "        tone = gr.Textbox(label=\"Tone (optional)\", placeholder=\"e.g., professional, casual, humorous...\")\n",
    "        audience = gr.Textbox(label=\"Target Audience (optional)\", placeholder=\"e.g., investors, students, developers...\")\n",
    "\n",
    "    model = gr.Dropdown(\n",
    "        [\"gpt-4o-mini\", \"gpt-3.5-turbo\", \"gpt-4\"],\n",
    "        label=\"Choose a model\",\n",
    "        value=\"gpt-4o-mini\"\n",
    "    )\n",
    "\n",
    "    generate_btn = gr.Button(\"Generate Content\")\n",
    "    output_md = gr.Markdown(label=\"Generated Content\", show_label=True)\n",
    "\n",
    "    generate_btn.click(\n",
    "        fn=generate_stream,\n",
    "        inputs=[task, topic, tone, audience, model],\n",
    "        outputs=output_md\n",
    "    )\n",
    "\n",
    "    gr.Markdown(\"---\\n## Refine Your Content\")\n",
    "\n",
    "    original_text = gr.Textbox(\n",
    "        label=\"Original Content\",\n",
    "        placeholder=\"Paste content you want to refine...\",\n",
    "        lines=10\n",
    "    )\n",
    "    instruction = gr.Textbox(\n",
    "        label=\"Refinement Instruction\",\n",
    "        placeholder=\"e.g., Make it shorter and more persuasive.\",\n",
    "    )\n",
    "    refine_model = gr.Dropdown(\n",
    "        [\"gpt-4o-mini\", \"gpt-3.5-turbo\", \"gpt-4\"],\n",
    "        label=\"Model for Refinement\",\n",
    "        value=\"gpt-4o-mini\"\n",
    "    )\n",
    "\n",
    "    refine_btn = gr.Button(\"Refine\")\n",
    "    refined_output = gr.Markdown(label=\"Refined Content\", show_label=True)\n",
    "\n",
    "    refine_btn.click(\n",
    "        fn=refine_stream,\n",
    "        inputs=[original_text, instruction, refine_model],\n",
    "        outputs=refined_output\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d42c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Launch the App\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
