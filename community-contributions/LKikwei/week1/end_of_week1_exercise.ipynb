{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eba48ef6",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb2ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28759189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "\n",
    "# Get API key and base URL from environment variables\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "base_url = os.getenv(\"OPENROUTER_BASE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7521c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the API key is set\n",
    "if not api_key:\n",
    "    print(\"OPENAI_API_KEY is not set in the environment variables\")\n",
    "\n",
    "# Ensure the base URL is set\n",
    "if not base_url:\n",
    "    print(\"OPENROUTER_BASE_URL is not set in the environment variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627fcab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "openai = OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "ollama = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ed1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "instruction = \"\"\"\n",
    "You are a professional software engineer with expertise in Python programming, Data Science, and AI Engineering.\n",
    "You are tasked with guiding junior engineers in their learning journey to become proficient AI Engineers.\n",
    "\"\"\"\n",
    "\n",
    "input = \"What are the key skills and knowledge areas that a junior engineer should focus on to become a proficient AI Engineer?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a250038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to get response with streaming\n",
    "# I tweaked this to use the new Responses API instead of the older chat completions API. It is the new recommended replacement for the chat completions API.\n",
    "def get_response(model):\n",
    "    client = ollama if model == MODEL_LLAMA else openai\n",
    "    with client.responses.stream(\n",
    "        model=model,\n",
    "        instructions=instruction,\n",
    "        input=input\n",
    "    ) as stream:\n",
    "        response = \"\"\n",
    "        display_handle = display(Markdown(\"\"), display_id=True)\n",
    "        for event in stream:\n",
    "            if event.type == \"response.output_text.delta\":\n",
    "                response += event.delta\n",
    "                update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2921abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "get_response(MODEL_GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399d1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "get_response(MODEL_LLAMA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
