{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c284571-820e-4816-b991-0e3f38d0f47f",
   "metadata": {},
   "source": [
    "<b><h1>Cloudflare Workers AI\n",
    "\n",
    "Run machine learning models, powered by serverless GPUs, on Cloudflare's global network.\n",
    "\n",
    "Available on Free and Paid plans\n",
    "Workers AI allows you to run AI models in a serverless way, without having to worry about scaling, maintaining, or paying for unused infrastructure. You can invoke models running on GPUs on Cloudflare's network from your own code — from Workers, Pages, or anywhere via the Cloudflare API.\n",
    "\n",
    "Workers AI gives you access to:\n",
    "\n",
    "50+ open-source models, available as a part of our model catalog\n",
    "Serverless, pay-for-what-you-use pricing model\n",
    "All as part of a fully-featured developer platform, including AI Gateway, Vectorize, Workers and more..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205dca87-772f-4fe3-b61c-0cda9a6aef53",
   "metadata": {},
   "source": [
    "Workers AI is included in both the Free and Paid Workers plans and is priced at $0.011 per 1,000 <b>Neurons.\n",
    "\n",
    "Our free allocation allows anyone to use a total of 10,000 Neurons per day at no charge. To use more than 10,000 Neurons per day, you need to sign up for the Workers Paid plan. On Workers Paid, you will be charged at $0.011 / 1,000 Neurons for any usage above the free allocation of 10,000 Neurons per day.\n",
    "\n",
    "You can monitor your Neuron usage in the Cloudflare Workers AI dashboard ↗.\n",
    "\n",
    "All limits reset daily at 00:00 UTC. If you exceed any one of the above limits, further operations will fail with an error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6b460b-1d59-47a7-b6f1-6513d7aa9d09",
   "metadata": {},
   "source": [
    "Workers Free & Workers Paid Plans - 10,000 Neurons per day\n",
    "Workers Paid Plan - $0.011 / 1,000 Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb08d16c-fb4b-47f0-b0df-d21c217eefb0",
   "metadata": {},
   "source": [
    "<h1><b>What are Neurons?\n",
    "    \n",
    "<h4>Neurons are our way of measuring AI outputs across different models, representing the GPU compute needed to perform your request. Our serverless model allows you to pay only for what you use without having to worry about renting, managing, or scaling GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3649e5cf-1acd-4c7a-ae43-1107e7741478",
   "metadata": {},
   "source": [
    "<b><h1>Image Model Pricing\n",
    "\n",
    "<h4>Model\t    <h5>@cf/black-forest-labs/flux-1-schnell\n",
    "    \n",
    "<h4>Price in Tokens\t\t<h5>$0.0000528 per 512x512 tile       and      <$0.0001056 per step                    \t\n",
    "\n",
    "<h4>Price in Neurons    <h5>4.80 neurons per 512x512 tile        <h5>9.60 neurons per step\n",
    "\n",
    "                                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5439daf-343e-43c7-b490-7d2c3ce0c1f4",
   "metadata": {},
   "source": [
    "<b>Text, Image and Sound Generation\n",
    "\n",
    "Text - gpt-oss:120b-cloud by OpenAI via Ollama local endpoint\n",
    "\n",
    "Image - flux-1-schnell by Black Forest Labs via Cloudflare API\n",
    "\n",
    "Sound - pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b04d32-dc4f-4ca6-a39a-cd6eb45a3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import json\n",
    "import pyttsx3\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from cloudflare import Cloudflare\n",
    "from openai import OpenAI\n",
    "from IPython.display import display\n",
    "\n",
    "# 1. Connect to Ollama locally\n",
    "ollama = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"Ollama\")\n",
    "\n",
    "system_instruct = \"\"\" \n",
    "You are an eloquent man. You have the ability to take even a tiny idea\n",
    "and turn it into a vivid description without sacrificing the original intent.\n",
    "Your task: expand the user's idea into a beautifully written image prompt.\n",
    "Respond only with the description (no titles or commentary).\n",
    "\"\"\"\n",
    "    \n",
    "# 2. Get user's input\n",
    "wish = input(\"Describe your vision: \")\n",
    "\n",
    "# 3. Generate a descriptive prompt via gpt-oss:120b-cloud\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_instruct},\n",
    "    {\"role\": \"user\", \"content\": wish}\n",
    "]\n",
    "\n",
    "response = ollama.chat.completions.create(\n",
    "    model=\"gpt-oss:120b-cloud\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# 4. Extract the actual text result\n",
    "final_prompt = response.choices[0].message.content\n",
    "\n",
    "print(\"\\nGenerated prompt:\\n\", final_prompt, \"\\n\")\n",
    "\n",
    "def speak(final_prompt):\n",
    "    engine = pyttsx3.init()\n",
    "    rate = engine.getProperty('rate')\n",
    "    print(rate)\n",
    "    engine.setProperty('rate', 100)\n",
    "    engine.say(final_prompt)\n",
    "    engine.runAndWait()\n",
    "\n",
    "\n",
    "# 5. Load Cloudflare credentials\n",
    "load_dotenv(r\"C:\\Users\\Well u know me  me\\Desktop\\cloudflare_token.env\")\n",
    "account_id = os.getenv(\"account_id\").strip()\n",
    "api_token = os.getenv(\"api_token\").strip()\n",
    "\n",
    "# 6. Send that prompt to the image generator\n",
    "def sketch(prompt_text):\n",
    "    client = Cloudflare(api_token=api_token)\n",
    "    result = client.ai.with_raw_response.run(\n",
    "        account_id=account_id,\n",
    "        model_name=\"@cf/black-forest-labs/flux-1-schnell\",\n",
    "        prompt=prompt_text\n",
    "    )\n",
    "\n",
    "    b64_image = result.json()[\"result\"][\"image\"]\n",
    "    image_bytes = base64.b64decode(b64_image)\n",
    "\n",
    "    output_path = r\"C:\\Users\\Well u know me  me\\Desktop\\flux5.png\"\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(image_bytes)\n",
    "\n",
    "    print(f\"Saved PNG to: {os.path.abspath(output_path)}\")\n",
    "\n",
    "    return display(Image.open(BytesIO(image_bytes)))\n",
    "\n",
    "# 7. Generate and show image\n",
    "sketch(final_prompt)\n",
    "speak(final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9671494c-f73d-437f-bf81-4ea577a6620c",
   "metadata": {},
   "source": [
    "<b>Text, Image and Sound Generation\n",
    "\n",
    "Text - gpt-oss:120b-cloud by OpenAI via Ollama local endpoint\n",
    "\n",
    "Image - flux-1-schnell by Black Forest Labs via Cloudflare API\n",
    "\n",
    "Sound - melotts by MyShell-AI via CLoudflare API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaf9dcd-ac5c-4a25-9ef6-30ba30505440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import json\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from cloudflare import Cloudflare\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "# 1. Connect to Ollama locally\n",
    "ollama = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"Ollama\")\n",
    "\n",
    "system_instruct = \"\"\" \n",
    "You are an eloquent man. You have the ability to take even a tiny idea\n",
    "and turn it into a vivid description without sacrificing the original intent.\n",
    "Your task: expand the user's idea into a beautifully written image prompt.\n",
    "Respond only with the description (no titles or commentary).\n",
    "\"\"\"\n",
    "    \n",
    "# 2. Get user's input\n",
    "wish = input(\"Describe your vision: \")\n",
    "\n",
    "# 3. Generate a descriptive prompt via gpt-oss:120b-cloud\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_instruct},\n",
    "    {\"role\": \"user\", \"content\": wish}\n",
    "]\n",
    "\n",
    "response = ollama.chat.completions.create(\n",
    "    model=\"gpt-oss:120b-cloud\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# 4. Extract the actual text result\n",
    "final_prompt = response.choices[0].message.content\n",
    "\n",
    "print(\"\\nGenerated prompt:\\n\", final_prompt, \"\\n\")\n",
    "\n",
    "\n",
    "# 5. Load Cloudflare credentials\n",
    "load_dotenv(r\"C:\\Users\\Well u know me  me\\Desktop\\cloudflare_token.env\")\n",
    "account_id = os.getenv(\"account_id\").strip()\n",
    "api_token = os.getenv(\"api_token\").strip()\n",
    "\n",
    "def speak(prompt_text):\n",
    "    client = Cloudflare(api_token=api_token)\n",
    "    result = client.ai.with_raw_response.run(\n",
    "        account_id=account_id,\n",
    "        model_name=\"@cf/myshell-ai/melotts\",\n",
    "        prompt=prompt_text\n",
    "    )\n",
    "    b64_audio = result.json()[\"result\"][\"audio\"]\n",
    "    audio_bytes = base64.b64decode(b64_audio)\n",
    "    \n",
    "    output_path = r\"C:\\Users\\Well u know me  me\\Desktop\\mellott2.wav\"\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(audio_bytes)\n",
    "\n",
    "    print(f\"Saved to {os.path.abspath(output_path)}\")\n",
    "    \n",
    "    return display(Audio(data = audio_bytes, rate = 44100), autoplay = True)\n",
    "\n",
    "\n",
    "# 6. Send that prompt to the image generator\n",
    "def sketch(prompt_text):\n",
    "    client = Cloudflare(api_token=api_token)\n",
    "    result = client.ai.with_raw_response.run(\n",
    "        account_id=account_id,\n",
    "        model_name=\"@cf/black-forest-labs/flux-1-schnell\",\n",
    "        prompt=prompt_text\n",
    "    )\n",
    "\n",
    "    b64_image = result.json()[\"result\"][\"image\"]\n",
    "    image_bytes = base64.b64decode(b64_image)\n",
    "\n",
    "    output_path = r\"C:\\Users\\Well u know me  me\\Desktop\\flux12.png\"\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(image_bytes)\n",
    "\n",
    "    print(f\"Saved PNG to: {os.path.abspath(output_path)}\")\n",
    "\n",
    "    return display(Image.open(BytesIO(image_bytes)))\n",
    "\n",
    "# 7. Generate and show image\n",
    "sketch(final_prompt)\n",
    "speak(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e3be42-b206-4afb-831b-e9d80e49d1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
