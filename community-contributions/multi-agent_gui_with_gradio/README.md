# ğŸ§  Agentic Voice/Text Support Chatbot

A multimodal chatbot interface with support for **text and voice input**, **multiple large language models (LLMs)**, and **context memory persistence** â€” all in a single Gradio-based GUI.

## ğŸš€ Features

- ğŸ”„ **Multi-LLM switching**: Dynamically switch between OpenAI, Anthropic Claude, and Meta LLaMA (via Ollama)
- ğŸ¤ **Voice input**: Use your microphone with live speech-to-text transcription
- ğŸ’¬ **Contextual memory**: Maintain chat history even when switching models
- ğŸ§ª **Prototype-ready**: Built with Gradio for rapid GUI testing and development

## ğŸ› ï¸ Technologies Used

- [Gradio](https://www.gradio.app/) â€“ GUI interface
- [OpenAI API](https://platform.openai.com/)
- [Anthropic Claude API](https://www.anthropic.com/)
- [Ollama](https://ollama.com/) â€“ Local LLaMA inference
- [`speech_recognition`](https://pypi.org/project/SpeechRecognition/) â€“ Voice-to-text
- `sounddevice`, `numpy` â€“ Audio recording
- `.env` â€“ Environment variable management

## Youâ€™ll also need:
- API keys for OpenAI and Claude
- Ollama installed locally to run LLaMA models
- A .env file with the necessary API keys
