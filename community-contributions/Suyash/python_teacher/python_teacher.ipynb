{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b9093c",
   "metadata": {},
   "source": [
    "# Python Teacher Chatbot (kinda) Project For day 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd0cf6",
   "metadata": {},
   "source": [
    "## Python\n",
    "- Python 3.8+ (3.10+ recommended)\n",
    "\n",
    "## Python packages\n",
    "Install the packages below (example):-\n",
    "<br>pip install requests python-dotenv beautifulsoup4 ipython openai\n",
    "\n",
    "Or use requirements.txt:\n",
    "requests\n",
    "python-dotenv\n",
    "beautifulsoup4\n",
    "ipython\n",
    "openai\n",
    "\n",
    "## Environment / External services\n",
    "- LLM server:\n",
    "    - The notebook instantiates OpenAI(base_url='http://localhost:11434/v1', api_key='ollama') and MODEL='qwen3:30b-a3b'.\n",
    "    - Ensure a compatible LLM server is running at the base URL (e.g., Ollama or another OpenAI-compatible local proxy) and that the model `qwen3:30b-a3b` is available.\n",
    "    - If using a different host or model, update the `openai` client initialization and `MODEL` variable in the notebook.\n",
    "\n",
    "- API keys / .env:\n",
    "    - The notebook imports dotenv but currently uses a literal api_key. Best practice: create a `.env` file and set values, then load them:\n",
    "        - OLLAMA_BASE_URL (default: http://localhost:11434/v1)\n",
    "        - OLLAMA_API_KEY (or OPENAI_API_KEY if using OpenAI)\n",
    "    - Do not commit real API keys to source control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6632691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries. Run it -->\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d522d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can change your prefered model if you want. Then execute...\n",
    "openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "MODEL = 'qwen3:30b-a3b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d474b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word limit is between 100 to 200, feel free to change but make sure to execute this cell after. And Ohhhh yeah, run that ---->>\n",
    "system_prompt = '''\n",
    "You are a fun python teacher. You teach the 3rd grade class, full of little students. User is amongst one of them and is a total beginner, hahaha.\n",
    "But he's determined and want to increase his skills to intermediate level. User will ask you about python problems and you will try to give \n",
    "them best time complexity results according to there criteria (if a student asking a teacher, and teacher explaining him the topic like situation).\n",
    "\n",
    "Personality: (*: People can add more personality attributes as they like. Follow the personality criteria too.)\n",
    "- Comedic\n",
    "- British\n",
    "- 4th wall break\n",
    "- Mysterious\n",
    "- Dark\n",
    "*<------Add Personality attributes--------->\n",
    "\n",
    "- Shorten your word limit to be under 100-200 words, that would be appreciated.\n",
    "- Use proper formatting and cell output \n",
    "- You can ask user to can I continue or ask a random student the same student then the student will do a roleplay of answering the question and you can go on this conversation if you want.\n",
    "- When explaining about code please be as through as possible. \n",
    "- Remember user is a beginner so try to use easy to understand words.\n",
    "- Your goal is to make the user a intermediate level python expert.\n",
    "\n",
    "Note:- Convert your explaination into markdown everytime you answer.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ceabab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your inputed messages here, then execute from this cell to below. You can change it to Mam or Sir according to you. Zoom out a little so you also see the output more.\n",
    "user_prompt = \"\"\"\n",
    "Hi Mam, Can you introduce yourself?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfae92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where system and user prompts are stored..\n",
    "MESSAGES = [\n",
    "        {\"role\":\"system\",\"content\":system_prompt},\n",
    "        {\"role\":\"user\", \"content\":user_prompt}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20e8f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response will generate llm response. What?\n",
    "response = openai.chat.completions.create(model=MODEL, messages=MESSAGES)\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca14b67",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "- ModuleNotFoundError: run pip install for the missing package.\n",
    "- Connection errors to base_url: verify server is running and base_url matches.\n",
    "- Model not found: change `MODEL` to an available model on your server.\n",
    "- Sensitive data: keep API keys in `.env` and never store in public repos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
