{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2dab68e5",
      "metadata": {},
      "source": [
        "### Chat bot chats\n",
        "\n",
        "In this notebook I'm implementing a chatbot chat where I'll use different models to solve a coding challenge. I will initially provide a coding challenge and different models will take turns in coming up with the solution. It's an idea where I could use different models to help me study coding challenges.\n",
        "\n",
        "##### Model 1: Prompter (Peter)\n",
        "\n",
        "This model will come up with the prompt and refine the prompts sent to the other models\n",
        "\n",
        "##### Model 2: Planner (Paul)\n",
        "\n",
        "This model will come up with the plan on how to solve the problem. It will give 3 suggestions and a recommendation of the best approach.\n",
        "\n",
        "##### Model 3: Coder (Cody)\n",
        "\n",
        "This model will write down the code\n",
        "\n",
        "##### Model 4: Reviewer (Ren)\n",
        "\n",
        "This model will review the code and give a summary to the user explaining the solution and how we came to the solution.\n",
        "\n",
        "##### Model 5: Refactor (Rob)\n",
        "\n",
        "This model will take in the code reviews and refactor the code accordingly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "149a175b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up the environment\n",
        "\n",
        "import os\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Markdown, display\n",
        "from openai import OpenAI\n",
        "\n",
        "load_dotenv(override=True)\n",
        "api_key: str | None = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "base_url: str = \"https://openrouter.ai/api/v1\"\n",
        "\n",
        "\n",
        "assert api_key[:8] == \"sk-or-v1\", \"OpenRouter API Key must start with sk-or-v1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9786a56",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up the different models\n",
        "\n",
        "\n",
        "from openai import Stream\n",
        "\n",
        "\n",
        "openrouter = OpenAI(api_key=api_key, base_url=base_url)\n",
        "\n",
        "models: list[str] = [\"Peter\", \"Paul\", \"Cody\", \"Ren\", \"Rob\"]\n",
        "\n",
        "\n",
        "def get_user_prompt(conversation: str, name: str) -> str:\n",
        "    \"\"\"\n",
        "    Get the user prompt for the conversation\n",
        "    \"\"\"\n",
        "    other_models_list: list[str] = list(filter(lambda x: x != name, models))\n",
        "    other_models: str = (\n",
        "        \", \".join(other_models_list[:-1]) + \" and \" + other_models_list[-1]\n",
        "    )\n",
        "    return f\"\"\"\n",
        "    You are {name}, in conversation with {other_models}.\n",
        "    The conversation so far is as follows:\n",
        "    {conversation}\n",
        "    Now with this, respond with what you would like to say next, as {name}.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "def prompter(converstation: str) -> Stream:\n",
        "    system_prompt = \"\"\"\n",
        "    You are Peter who is a senior software engineer. \n",
        "    You are responsible for coming up with the prompt for the other models. You will be given an initial \n",
        "    prompt and you will come up with clear, concise and specific prompts for the other models. You will ensure that the other\n",
        "    models understand the task and the constraints. You will also ensure that there are no regressions in as the tasks you will be\n",
        "    prompting for are coding challenges.\n",
        "    \n",
        "    The other models are:\n",
        "    - Paul: who is good at coming up with plans\n",
        "    - Cody: who is good at coding\n",
        "    - Ren: who is good at reviewing code\n",
        "    - Rob: who is good at refactoring code\n",
        "    \"\"\"\n",
        "\n",
        "    stream = openrouter.chat.completions.create(\n",
        "        model=\"openai/gpt-5.1-chat\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": get_user_prompt(converstation, \"Peter\")},\n",
        "        ],\n",
        "        stream=True,\n",
        "    )\n",
        "    return stream\n",
        "\n",
        "\n",
        "def planner(conversation: str) -> Stream:\n",
        "    system_prompt = \"\"\"\n",
        "    You are Paul who is a senior software engineer. \n",
        "    You are responsible for coming up with the plan for the Cody who is a mid level software engineer.\n",
        "    You will give three suggestions of how to solve the task. You will then give a recommendation of the best approach.\n",
        "    You will come up with clear, concise and specific plans for the Cody.\n",
        "    You will ensure that the Cody understands the task and the constraints.\n",
        "    You will also ensure that there are no regressions in as the tasks you will be planning for are coding challenges.\n",
        "\n",
        "    The other models are:\n",
        "    - Peter: who is good at coming up with prompts\n",
        "    - Cody: who is good at coding\n",
        "    - Ren: who is good at reviewing code\n",
        "    - Rob: who is good at refactoring code\n",
        "    \"\"\"\n",
        "    stream = openrouter.chat.completions.create(\n",
        "        model=\"google/gemini-3-pro-preview\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": get_user_prompt(conversation, \"Paul\")},\n",
        "        ],\n",
        "        stream=True,\n",
        "    )\n",
        "    return stream\n",
        "\n",
        "\n",
        "def coder(conversation: str) -> Stream:\n",
        "    system_prompt = \"\"\"\n",
        "    You are Cody who a mid level software engineer. \n",
        "    You are responsible for coding the solution to the task. You will be given a plan by Paul and you will code the solution.\n",
        "    You will ensure that the solution is correct and that it is within the constraints.\n",
        "\n",
        "    The other models are:\n",
        "    - Paul: who is good at coming up with plans\n",
        "    - Peter: who is good at coming up with prompts\n",
        "    - Ren: who is good at reviewing code\n",
        "    - Rob: who is good at refactoring code\n",
        "    \"\"\"\n",
        "\n",
        "    stream = openrouter.chat.completions.create(\n",
        "        model=\"anthropic/claude-sonnet-4.6\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": get_user_prompt(conversation, \"Cody\")},\n",
        "        ],\n",
        "        stream=True,\n",
        "    )\n",
        "    return stream\n",
        "\n",
        "\n",
        "def reviewer(conversation: str) -> Stream:\n",
        "    system_prompt = \"\"\"\n",
        "    You are Ren who is a senior QA engineer.\n",
        "    You are responsible for reviewing all the code.\n",
        "    You will be given the code and you will review it.\n",
        "    You will ensure that the code is correct and that it is within the constraints.\n",
        "    Make sure that the code is DRY, SOLID and follows all the best practices.\n",
        "\n",
        "    If code needs to refactored, make sure you explicitly add the phrase `refactor the code` to your the response.\n",
        "    If the code looks good, make sure you explicitly add the phrase `looks good to me` to the response.\n",
        "\n",
        "    The other models are:\n",
        "    - Peter: who is good at coming up with prompts\n",
        "    - Paul: who is good at coming up with plans\n",
        "    - Cody: who is good at coding\n",
        "    - Rob: who is good at refactoring code\n",
        "    \"\"\"\n",
        "\n",
        "    stream = openrouter.chat.completions.create(\n",
        "        model=\"z-ai/glm-5\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": get_user_prompt(conversation, \"Ren\")},\n",
        "        ],\n",
        "        stream=True,\n",
        "    )\n",
        "    return stream\n",
        "\n",
        "\n",
        "def refactor(conversation: str) -> Stream:\n",
        "    system_prompt = \"\"\"\n",
        "    You are Rob who is a principal engineer.\n",
        "    You are responsible for refactoring the code of Cody. You will be given the code and you will refactor it.\n",
        "    You will ensure that the code is correct and that it is within the constraints.\n",
        "\n",
        "    The other models are:\n",
        "    - Paul: who is good at coming up with plans\n",
        "    - Cody: who is good at coding\n",
        "    - Ren: who is good at reviewing code\n",
        "    - Peter: who is good at coming up with prompts\n",
        "    \"\"\"\n",
        "\n",
        "    stream = openrouter.chat.completions.create(\n",
        "        model=\"anthropic/claude-sonnet-4.6\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": get_user_prompt(conversation, \"Rob\")},\n",
        "        ],\n",
        "        stream=True,\n",
        "    )\n",
        "    return stream\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30cb8d79",
      "metadata": {},
      "outputs": [],
      "source": [
        "# let's start the conversation\n",
        "from typing import NoReturn\n",
        "\n",
        "from IPython.display import DisplayHandle, update_display\n",
        "\n",
        "\n",
        "def display_stream_response(response: Stream, display_handle: DisplayHandle):\n",
        "    response_stream = \"\"\n",
        "    for chunk in response:\n",
        "        response_stream += chunk.choices[0].delta.content or \"\"\n",
        "        update_display(Markdown(response_stream), display_id=display_handle.display_id)\n",
        "    return response_stream\n",
        "\n",
        "\n",
        "def begin_converstation(challenge: str) -> NoReturn:\n",
        "    conversation = f\"\"\"\n",
        "    Initial prompt:\n",
        "\n",
        "    ## Peter \n",
        "     \n",
        "        Here is the user challenge\n",
        "\n",
        "    ``` txt\n",
        "    {challenge}\n",
        "    ```\n",
        "\n",
        "    \"\"\"\n",
        "    # Display handle\n",
        "    display_handle = display(Markdown(\"\"), display_id=True)\n",
        "\n",
        "    # Initial prompt\n",
        "    prompter_response = display_stream_response(prompter(conversation), display_handle)\n",
        "\n",
        "    # Planning\n",
        "    conversation += f\"## Peter:\\n\\n{prompter_response}\\n\"\n",
        "    planner_response = display_stream_response(\n",
        "        planner(prompter_response), display_handle\n",
        "    )\n",
        "\n",
        "    # Coding\n",
        "    conversation += f\"## Paul:\\n\\n{planner_response}\\n\"\n",
        "    coder_response = display_stream_response(coder(planner_response), display_handle)\n",
        "\n",
        "    # Reviewing\n",
        "    conversation += f\"## Cody:\\n\\n{coder_response}\\n\"\n",
        "    reviewer_response = display_stream_response(\n",
        "        reviewer(coder_response), display_handle\n",
        "    )\n",
        "    conversation += f\"## Ren:\\n\\n{reviewer_response}\\n\"\n",
        "    refactor_response = display_stream_response(\n",
        "        refactor(reviewer_response), display_handle\n",
        "    )\n",
        "    conversation += f\"## Rob:\\n\\n{refactor_response}\\n\"\n",
        "    reviewer_response = display_stream_response(\n",
        "        reviewer(refactor_response), display_handle\n",
        "    )\n",
        "\n",
        "    refactor_count = 1\n",
        "    # Refactoring\n",
        "    while refactor_count < 5:\n",
        "        if \"refactor the code\" in reviewer_response:\n",
        "            if refactor_count % 2 == 0:\n",
        "                conversation += f\"## Ren:\\n\\n{reviewer_response}\\n\"\n",
        "                refactor_response = display_stream_response(\n",
        "                    refactor(reviewer_response), display_handle\n",
        "                )\n",
        "                conversation += f\"## Rob:\\n\\n{refactor_response}\\n\"\n",
        "                reviewer_response = display_stream_response(\n",
        "                    reviewer(refactor_response), display_handle\n",
        "                )\n",
        "            else:\n",
        "                conversation += f\"## Ren:\\n\\n{reviewer_response}\\n\"\n",
        "                coder_response = display_stream_response(\n",
        "                    coder(reviewer_response), display_handle\n",
        "                )\n",
        "                conversation += f\"## Cody:\\n\\n{coder_response}\\n\"\n",
        "                reviewer_response = display_stream_response(\n",
        "                    reviewer(coder_response), display_handle\n",
        "                )\n",
        "        elif \"looks good to me\" in reviewer_response:\n",
        "            break\n",
        "\n",
        "        refactor_count += 1\n",
        "\n",
        "    # Final response\n",
        "    conversation += f\"### FINAL RESPONSE\\n\\n{reviewer_response}\\n\"\n",
        "\n",
        "    with open(\"conversation.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(conversation)\n",
        "\n",
        "    display(Markdown(conversation))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e0c093f",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"challenge.md\", \"r\", encoding=\"utf-8\") as f:\n",
        "    challenge = f.read()\n",
        "\n",
        "begin_converstation(challenge)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
