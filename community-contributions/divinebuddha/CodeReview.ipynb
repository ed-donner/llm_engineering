{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from textwrap import indent\n",
    "import nbformat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'gemma3'\n",
    "api = '123...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64d51545",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert code reviewer. \n",
    "you are provided with the python or python notebook files. \n",
    "you will review the code and suggest the areas where the code can be made more efficient.\n",
    "you will also review the industry best practises for the code suggest any new edits to be incorporated for the efficient code \n",
    "you will also check for any comments and suggest if there is any improvement. check for any hardcoded values like passwords, or api keys and flag it\n",
    "only the files with extension .py or .ipynb will be considered ignore the rest.\n",
    "you will respond the output in the Markdown format for example: \n",
    "## test.py\n",
    "- please explain what this function def func does\n",
    "- Please dont hard code any passwords\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8743fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_code_fron_ipynb(filePath):\n",
    "    with open(filePath,'r',encoding=\"utf-8\") as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    return \"\\n\\n\".join([c.source for c in nb.cells if c.cell_type=='code'])\n",
    "\n",
    "def get_file_content(filePath):\n",
    "    suffix = Path(filePath).suffix\n",
    "\n",
    "    if suffix == '.py':\n",
    "        return Path(filePath).read_text\n",
    "    elif suffix == '.ipynb':\n",
    "        return extract_code_fron_ipynb(filePath)\n",
    "\n",
    "def get_list_files(filePath):\n",
    "    path = Path(filePath)\n",
    "    files = {\n",
    "        f.name: get_file_content(str(path / f.name)) for f in path.iterdir() if f.suffix in ['.py','.ipynb']\n",
    "    }\n",
    "    return files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f95e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = '/Users/mia/myprojects/uv_projects/llm_engineering/week1'\n",
    "filesList = get_list_files(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPlease explain what this code does and why:\\nthe name and code is listed as below json file \\n{\\'scraper.py\\': <bound method Path.read_text of PosixPath(\\'/Users/mia/myprojects/uv_projects/llm_engineering/week1/scraper.py\\')>, \\'solution.py\\': <bound method Path.read_text of PosixPath(\\'/Users/mia/myprojects/uv_projects/llm_engineering/week1/solution.py\\')>, \\'test.py\\': <bound method Path.read_text of PosixPath(\\'/Users/mia/myprojects/uv_projects/llm_engineering/week1/test.py\\')>, \\'week1 EXERCISE.ipynb\\': \\'# imports\\\\nimport os\\\\nfrom pathlib import Path\\\\nfrom dotenv import load_dotenv\\\\nfrom IPython.display import Markdown, display, update_display\\\\nfrom openai import OpenAI\\\\nimport json\\\\n\\\\n# constants\\\\n\\\\nMODEL_GPT = \\\\\\'gpt-4o-mini\\\\\\'\\\\nMODEL_LLAMA = \\\\\\'gemma3\\\\\\'\\\\napi = \\\\\\'123...\\\\n\\\\n# set up environment\\\\nload_dotenv(override=True)\\\\n\\\\nsystem_prompt = \"\"\"\\\\nYou are an expert code reviewer. \\\\nyou are provided with the python or python notebook files. \\\\nyou will review the code and suggest the areas where the code can be made more efficient.\\\\nyou will also review the industry best practises for the code suggest any new edits to be incorporated for the efficient code \\\\nyou will also check for any comments and suggest if there is any improvement. check for any hardcoded values like passwords, or api keys and flag it\\\\nonly the files with extension .py or .ipynb will be considered ignore the rest.\\\\nyou will respond the output in the Markdown format for example: \\\\n## test.py\\\\n- please explain what this function def func does\\\\n- Please dont hard code any passwords\\\\n\"\"\"\\\\n\\\\nfrom textwrap import indent\\\\nimport nbformat\\\\nfrom urllib3 import filepost\\\\n\\\\ndef extract_code_fron_ipynb(filePath):\\\\n    with open(filePath,\\\\\\'r\\\\\\',encoding=\"utf-8\") as f:\\\\n        nb = nbformat.read(f, as_version=4)\\\\n    \\\\n    return \"\\\\\\\\n\\\\\\\\n\".join([c.source for c in nb.cells if c.cell_type==\\\\\\'code\\\\\\'])\\\\n\\\\ndef get_file_content(filePath):\\\\n    suffix = Path(filePath).suffix\\\\n\\\\n    if suffix == \\\\\\'.py\\\\\\':\\\\n        return Path(filePath).read_text\\\\n    elif suffix == \\\\\\'.ipynb\\\\\\':\\\\n        return extract_code_fron_ipynb(filePath)\\\\n\\\\ndef get_list_files(filePath):\\\\n    path = Path(filePath)\\\\n    files = {\\\\n        f.name: get_file_content(str(path / f.name)) for f in path.iterdir() if f.suffix in [\\\\\\'.py\\\\\\',\\\\\\'.ipynb\\\\\\']\\\\n    }\\\\n    return files\\\\n    \\\\n\\\\nfilePath = \\\\\\'/Users/mia/myprojects/uv_projects/llm_engineering/week1\\\\\\'\\\\nfilesList = get_list_files(filePath)\\\\n\\\\n# here is the question; type over this to ask something new\\\\n\\\\nquestion = f\"\"\"\\\\nPlease explain what this code does and why:\\\\nthe name and code is listed as below json file \\\\n{filesList}\\\\n\"\"\"\\\\n\\\\nquestion\\\\n\\\\nmessages=[\\\\n            {\"role\": \"system\", \"content\": system_prompt},\\\\n            {\"role\": \"user\", \"content\": question}\\\\n        ]\\\\n\\\\n# Get gpt-4o-mini to answer, with streaming\\\\nopenai = OpenAI()\\\\nstream = openai.chat.completions.create(\\\\n    model=MODEL_GPT,\\\\n    messages=messages,\\\\n    stream=True\\\\n)\\\\n\\\\nresponse = \"\"\\\\ndisplay_handle = display(Markdown(\"\"), display_id=True)\\\\nfor chunk in stream:\\\\n    response += chunk.choices[0].delta.content or \\\\\\'\\\\\\'\\\\n    update_display(Markdown(response), display_id=display_handle.display_id)\\\\n\\\\n# Get Llama 3.2 to answer\\\\n\\\\nllama=OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\\\\nllama_stream = llama.chat.completions.create(\\\\n    model=MODEL_LLAMA,\\\\n    messages=messages,\\\\n    stream=True\\\\n)\\\\nresponse = \"\"\\\\ndisplay_handle = display(Markdown(\"\"), display_id=True)\\\\nfor chunk in llama_stream:\\\\n    response += chunk.choices[0].delta.content or \\\\\\'\\\\\\'\\\\n    update_display(Markdown(response), display_id=display_handle.display_id)\\', \\'day2.ipynb\\': \\'import os\\\\nfrom dotenv import load_dotenv\\\\n\\\\nload_dotenv(override=True)\\\\napi_key = os.getenv(\\\\\\'OPENAI_API_KEY\\\\\\')\\\\n\\\\nif not api_key:\\\\n    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\\\\nelif not api_key.startswith(\"sk-proj-\"):\\\\n    print(\"An API key was found, but it doesn\\\\\\'t start sk-proj-; please check you\\\\\\'re using the right key - see troubleshooting notebook\")\\\\nelse:\\\\n    print(\"API key found and looks good so far!\")\\\\n\\\\n\\\\nimport requests\\\\n\\\\nheaders = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\\\\n\\\\npayload = {\\\\n    \"model\": \"gpt-5-nano\",\\\\n    \"messages\": [\\\\n        {\"role\": \"user\", \"content\": \"Tell me a fun fact\"}]\\\\n}\\\\n\\\\npayload\\\\n\\\\nresponse = requests.post(\\\\n    \"https://api.openai.com/v1/chat/completions\",\\\\n    headers=headers,\\\\n    json=payload\\\\n)\\\\n\\\\nresponse.json()\\\\n\\\\nresponse.json()[\"choices\"][0][\"message\"][\"content\"]\\\\n\\\\n# Create OpenAI client\\\\n\\\\nfrom openai import OpenAI\\\\nopenai = OpenAI()\\\\n\\\\nresponse = openai.chat.completions.create(model=\"gpt-5-nano\", messages=[{\"role\": \"user\", \"content\": \"Tell me a fun fact\"}])\\\\n\\\\nresponse.choices[0].message.content\\\\n\\\\n\\\\n\\\\nGEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\\\\n\\\\nload_dotenv(override=True)\\\\n\\\\ngoogle_api_key = os.getenv(\"GOOGLE_API_KEY\")\\\\n\\\\nif not google_api_key:\\\\n    print(\"No API key was found - please be sure to add your key to the .env file, and save the file! Or you can skip the next 2 cells if you don\\\\\\'t want to use Gemini\")\\\\nelif not google_api_key.startswith(\"AIz\"):\\\\n    print(\"An API key was found, but it doesn\\\\\\'t start AIz\")\\\\nelse:\\\\n    print(\"API key found and looks good so far!\")\\\\n\\\\n\\\\n\\\\ngemini = OpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)\\\\n\\\\nresponse = gemini.chat.completions.create(model=\"gemini-2.5-flash-lite\", messages=[{\"role\": \"user\", \"content\": \"Tell me a fun fact\"}])\\\\n\\\\nresponse.choices[0].message.content\\\\n\\\\nrequests.get(\"http://localhost:11434\").content\\\\n\\\\n#!ollama pull llama3.2\\\\n\\\\nOLLAMA_BASE_URL = \"http://localhost:11434/v1\"\\\\n\\\\nollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\\\\\\'ollama\\\\\\')\\\\n\\\\n\\\\n# Get a fun fact\\\\n\\\\nresponse = ollama.chat.completions.create(model=\"gemma3\", messages=[{\"role\": \"user\", \"content\": \"Tell me a fun fact\"}])\\\\n\\\\nresponse.choices[0].message.content\\\\n\\\\n# Now let\\\\\\'s try deepseek-r1:1.5b - this is DeepSeek \"distilled\" into Qwen from Alibaba Cloud\\\\n\\\\n!ollama pull deepseek-r1:1.5b\\\\n\\\\nresponse = ollama.chat.completions.create(model=\"deepseek-r1:1.5b\", messages=[{\"role\": \"user\", \"content\": \"Tell me a fun fact\"}])\\\\n\\\\nresponse.choices[0].message.content\\\\n\\\\n\\', \\'day4.ipynb\\': \\'import tiktoken\\\\n\\\\nencoding = tiktoken.encoding_for_model(\"gpt-4.1-mini\")\\\\n\\\\ntokens = encoding.encode(\"Hi my name is Ed and I like banoffee pie\")\\\\n\\\\ntokens\\\\n\\\\nfor token_id in tokens:\\\\n    token_text = encoding.decode([token_id])\\\\n    print(f\"{token_id} = {token_text}\")\\\\n\\\\nencoding.decode([326])\\\\n\\\\nimport os\\\\nfrom dotenv import load_dotenv\\\\n\\\\nload_dotenv(override=True)\\\\napi_key = os.getenv(\\\\\\'OPENAI_API_KEY\\\\\\')\\\\n\\\\nif not api_key:\\\\n    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\\\\nelif not api_key.startswith(\"sk-proj-\"):\\\\n    print(\"An API key was found, but it doesn\\\\\\'t start sk-proj-; please check you\\\\\\'re using the right key - see troubleshooting notebook\")\\\\nelse:\\\\n    print(\"API key found and looks good so far!\")\\\\n\\\\nfrom openai import OpenAI\\\\n\\\\nopenai = OpenAI()\\\\n\\\\nmessages = [\\\\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\\\\n    {\"role\": \"user\", \"content\": \"Hi! I\\\\\\'m Ed!\"}\\\\n    ]\\\\n\\\\nresponse = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\\\\nresponse.choices[0].message.content\\\\n\\\\nmessages = [\\\\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\\\\n    {\"role\": \"user\", \"content\": \"What\\\\\\'s my name?\"}\\\\n    ]\\\\n\\\\nresponse = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\\\\nresponse.choices[0].message.content\\\\n\\\\nmessages = [\\\\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\\\\n    {\"role\": \"user\", \"content\": \"Hi! I\\\\\\'m Ed!\"},\\\\n    {\"role\": \"assistant\", \"content\": \"Hi Ed! How can I assist you today?\"},\\\\n    {\"role\": \"user\", \"content\": \"What\\\\\\'s my name?\"}\\\\n    ]\\\\n\\\\nresponse = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\\\\nresponse.choices[0].message.content\\', \\'day1.ipynb\\': \\'# imports\\\\n\\\\nimport os\\\\nfrom dotenv import load_dotenv\\\\nfrom scraper import fetch_website_contents\\\\nfrom IPython.display import Markdown, display\\\\nfrom openai import OpenAI\\\\n\\\\n# If you get an error running this cell, then please head over to the troubleshooting notebook!\\\\n\\\\n# Load environment variables in a file called .env\\\\n\\\\nload_dotenv(override=True)\\\\napi_key = os.getenv(\\\\\\'OPENAI_API_KEY\\\\\\')\\\\n\\\\n# Check the key\\\\n\\\\nif not api_key:\\\\n    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\\\\nelif not api_key.startswith(\"sk-proj-\"):\\\\n    print(\"An API key was found, but it doesn\\\\\\'t start sk-proj-; please check you\\\\\\'re using the right key - see troubleshooting notebook\")\\\\nelif api_key.strip() != api_key:\\\\n    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\\\\nelse:\\\\n    print(\"API key found and looks good so far!\")\\\\n\\\\n\\\\n# To give you a preview -- calling OpenAI with these messages is this easy. Any problems, head over to the Troubleshooting notebook.\\\\n\\\\nmessage = \"Hello, GPT! This is my first ever message to you! Hi!\"\\\\n\\\\nmessages = [{\"role\": \"user\", \"content\": message}]\\\\n\\\\nmessages\\\\n\\\\n\\\\nopenai = OpenAI()\\\\n\\\\nresponse = openai.chat.completions.create(model=\"gpt-5-nano\", messages=messages)\\\\nresponse.choices[0].message.content\\\\n\\\\n# Let\\\\\\'s try out this utility\\\\n\\\\ned = fetch_website_contents(\"https://edwarddonner.com\")\\\\nprint(ed)\\\\n\\\\n# Define our system prompt - you can experiment with this later, changing the last sentence to \\\\\\'Respond in markdown in Spanish.\"\\\\n\\\\nsystem_prompt = \"\"\"\\\\nYou are a snarky assistant that analyzes the contents of a website,\\\\nand provides a short, snarky, humorous summary, ignoring text that might be navigation related.\\\\nRespond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\\\\n\"\"\"\\\\n\\\\n# Define our user prompt\\\\n\\\\nuser_prompt_prefix = \"\"\"\\\\nHere are the contents of a website.\\\\nProvide a short summary of this website.\\\\nIf it includes news or announcements, then summarize these too.\\\\n\\\\n\"\"\"\\\\n\\\\nmessages = [\\\\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\\\\n    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\\\\n]\\\\n\\\\nresponse = openai.chat.completions.create(model=\"gpt-4.1-nano\", messages=messages)\\\\nresponse.choices[0].message.content\\\\n\\\\nmessages = [\\\\n    {\"role\": \"system\", \"content\": \"You are a comedian as well as mathematician assistant. Respond in malayalam\"},\\\\n    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\\\\n]\\\\n\\\\nresponse = openai.chat.completions.create(model=\"gpt-4.1-nano\", messages=messages)\\\\nresponse.choices[0].message.content\\\\n\\\\n# See how this function creates exactly the format above\\\\n\\\\ndef messages_for(website):\\\\n    return [\\\\n        {\"role\": \"system\", \"content\": system_prompt},\\\\n        {\"role\": \"user\", \"content\": user_prompt_prefix + website}\\\\n    ]\\\\n\\\\n# Try this out, and then try for a few more websites\\\\n\\\\nmessages_for(ed)\\\\n\\\\n# And now: call the OpenAI API. You will get very familiar with this!\\\\n\\\\ndef summarize(url):\\\\n    website = fetch_website_contents(url)\\\\n    response = openai.chat.completions.create(\\\\n        model = \"gpt-4.1-mini\",\\\\n        messages = messages_for(website)\\\\n    )\\\\n    return response.choices[0].message.content\\\\n\\\\nsummarize(\"https://edwarddonner.com\")\\\\n\\\\n# A function to display this nicely in the output, using markdown\\\\n\\\\ndef display_summary(url):\\\\n    summary = summarize(url)\\\\n    display(Markdown(summary))\\\\n\\\\ndisplay_summary(\"https://edwarddonner.com\")\\\\n\\\\ndisplay_summary(\"https://cnn.com\")\\\\n\\\\ndisplay_summary(\"https://anthropic.com\")\\\\n\\\\n# Step 1: Create your prompts\\\\n\\\\nsystem_prompt = \"You are a content summarizer and you will take the content from websites and summarize it in a concise manner\"\\\\nuser_prompt = \"\"\"\\\\n    Please analyze the content on below website and summarize it in a concise manner\\\\n    \\\\n\"\"\"\\\\n\\\\n# Step 2: Make the messages list\\\\nwebsite = \"https://cnn.com\"\\\\nmessages = [{\"role\":\"system\",\"content\":system_prompt},{\"role\":\"user\",\"content\":user_prompt + website}] # fill this in\\\\n\\\\n# Step 3: Call OpenAI\\\\nresponse = openai.chat.completions.create(model=\"gpt-4.1-nano\",messages=messages)\\\\n# Step 4: print the result\\\\nmsg = response.choices[0].message.content\\\\ndisplay(Markdown(msg))\\\\n\\\\n\\', \\'day5.ipynb\\': \\'# imports\\\\n# If these fail, please check you\\\\\\'re running from an \\\\\\'activated\\\\\\' environment with (llms) in the command prompt\\\\n\\\\nimport os\\\\nimport json\\\\nfrom dotenv import load_dotenv\\\\nfrom IPython.display import Markdown, display, update_display\\\\nfrom scraper import fetch_website_links, fetch_website_contents\\\\nfrom openai import OpenAI\\\\n\\\\n# Initialize and constants\\\\n\\\\nload_dotenv(override=True)\\\\napi_key = os.getenv(\\\\\\'OPENAI_API_KEY\\\\\\')\\\\n\\\\nif api_key and api_key.startswith(\\\\\\'sk-proj-\\\\\\') and len(api_key)>10:\\\\n    print(\"API key looks good so far\")\\\\nelse:\\\\n    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\\\\n    \\\\nMODEL = \\\\\\'gpt-5-nano\\\\\\'\\\\nopenai = OpenAI()\\\\n\\\\nlinks = fetch_website_links(\"https://edwarddonner.com\")\\\\nlinks\\\\n\\\\nlink_system_prompt = \"\"\"\\\\nYou are provided with a list of links found on a webpage.\\\\nYou are able to decide which of the links would be most relevant to include in a brochure about the company,\\\\nsuch as links to an About page, or a Company page, or Careers/Jobs pages.\\\\nYou should respond in JSON as in this example:\\\\n\\\\n{\\\\n    \"links\": [\\\\n        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\\\\n        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\\\\n    ]\\\\n}\\\\n\"\"\"\\\\n\\\\ndef get_links_user_prompt(url):\\\\n    user_prompt = f\"\"\"\\\\nHere is the list of links on the website {url} -\\\\nPlease decide which of these are relevant web links for a brochure about the company, \\\\nrespond with the full https URL in JSON format.\\\\nDo not include Terms of Service, Privacy, email links.\\\\n\\\\nLinks (some might be relative links):\\\\n\\\\n\"\"\"\\\\n    links = fetch_website_links(url)\\\\n    user_prompt += \"\\\\\\\\n\".join(links)\\\\n    return user_prompt\\\\n\\\\nprint(get_links_user_prompt(\"https://edwarddonner.com\"))\\\\n\\\\ndef select_relevant_links(url):\\\\n    response = openai.chat.completions.create(\\\\n        model=MODEL,\\\\n        messages=[\\\\n            {\"role\": \"system\", \"content\": link_system_prompt},\\\\n            {\"role\": \"user\", \"content\": get_links_user_prompt(url)}\\\\n        ],\\\\n        response_format={\"type\": \"json_object\"}\\\\n    )\\\\n    result = response.choices[0].message.content\\\\n    links = json.loads(result)\\\\n    return links\\\\n    \\\\n\\\\nselect_relevant_links(\"https://edwarddonner.com\")\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndef select_relevant_links(url):\\\\n    print(f\"Selecting relevant links for {url} by calling {MODEL}\")\\\\n    response = openai.chat.completions.create(\\\\n        model=MODEL,\\\\n        messages=[\\\\n            {\"role\": \"system\", \"content\": link_system_prompt},\\\\n            {\"role\": \"user\", \"content\": get_links_user_prompt(url)}\\\\n        ],\\\\n        response_format={\"type\": \"json_object\"}\\\\n    )\\\\n    result = response.choices[0].message.content\\\\n    links = json.loads(result)\\\\n    print(f\"Found {len(links[\\\\\\'links\\\\\\'])} relevant links\")\\\\n    return links\\\\n\\\\nselect_relevant_links(\"https://edwarddonner.com\")\\\\n\\\\nselect_relevant_links(\"https://huggingface.co\")\\\\n\\\\ndef fetch_page_and_all_relevant_links(url):\\\\n    contents = fetch_website_contents(url)\\\\n    relevant_links = select_relevant_links(url)\\\\n    result = f\"## Landing Page:\\\\\\\\n\\\\\\\\n{contents}\\\\\\\\n## Relevant Links:\\\\\\\\n\"\\\\n    for link in relevant_links[\\\\\\'links\\\\\\']:\\\\n        result += f\"\\\\\\\\n\\\\\\\\n### Link: {link[\\\\\\'type\\\\\\']}\\\\\\\\n\"\\\\n        result += fetch_website_contents(link[\"url\"])\\\\n    return result\\\\n\\\\nprint(fetch_page_and_all_relevant_links(\"https://huggingface.co\"))\\\\n\\\\nbrochure_system_prompt = \"\"\"\\\\nYou are an assistant that analyzes the contents of several relevant pages from a company website\\\\nand creates a short brochure about the company for prospective customers, investors and recruits.\\\\nRespond in markdown without code blocks.\\\\nInclude details of company culture, customers and careers/jobs if you have the information.\\\\n\"\"\"\\\\n\\\\n# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate \\\\\\'tone\\\\\\':\\\\n\\\\n# brochure_system_prompt = \"\"\"\\\\n# You are an assistant that analyzes the contents of several relevant pages from a company website\\\\n# and creates a short, humorous, entertaining, witty brochure about the company for prospective customers, investors and recruits.\\\\n# Respond in markdown without code blocks.\\\\n# Include details of company culture, customers and careers/jobs if you have the information.\\\\n# \"\"\"\\\\n\\\\n\\\\ndef get_brochure_user_prompt(company_name, url):\\\\n    user_prompt = f\"\"\"\\\\nYou are looking at a company called: {company_name}\\\\nHere are the contents of its landing page and other relevant pages;\\\\nuse this information to build a short brochure of the company in markdown without code blocks.\\\\\\\\n\\\\\\\\n\\\\n\"\"\"\\\\n    user_prompt += fetch_page_and_all_relevant_links(url)\\\\n    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\\\\n    return user_prompt\\\\n\\\\nget_brochure_user_prompt(\"HuggingFace\", \"https://huggingface.co\")\\\\n\\\\ndef create_brochure(company_name, url):\\\\n    response = openai.chat.completions.create(\\\\n        model=\"gpt-4.1-mini\",\\\\n        messages=[\\\\n            {\"role\": \"system\", \"content\": brochure_system_prompt},\\\\n            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\\\\n        ],\\\\n    )\\\\n    result = response.choices[0].message.content\\\\n    display(Markdown(result))\\\\n\\\\ncreate_brochure(\"HuggingFace\", \"https://huggingface.co\")\\\\n\\\\ndef stream_brochure(company_name, url):\\\\n    stream = openai.chat.completions.create(\\\\n        model=\"gpt-4.1-mini\",\\\\n        messages=[\\\\n            {\"role\": \"system\", \"content\": brochure_system_prompt},\\\\n            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\\\\n          ],\\\\n        stream=True\\\\n    )    \\\\n    response = \"\"\\\\n    display_handle = display(Markdown(\"\"), display_id=True)\\\\n    for chunk in stream:\\\\n        response += chunk.choices[0].delta.content or \\\\\\'\\\\\\'\\\\n        update_display(Markdown(response), display_id=display_handle.display_id)\\\\n\\\\nstream_brochure(\"HuggingFace\", \"https://huggingface.co\")\\\\n\\\\n# Try changing the system prompt to the humorous version when you make the Brochure for Hugging Face:\\\\n\\\\nstream_brochure(\"HuggingFace\", \"https://huggingface.co\")\\'}\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = f\"\"\"\n",
    "Please explain what this code does and why:\n",
    "the name and code is listed as below json file \n",
    "{filesList}\n",
    "\"\"\"\n",
    "\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5488b92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## scraper.py\n",
       "- The function `get_file_content` is missing a call to `read_text()`; it should be changed to `return Path(filePath).read_text()` with parentheses to actually read the file.\n",
       "- Consider handling exceptions for file operations to avoid crashing if a file can't be read or doesn't exist.\n",
       "\n",
       "## solution.py\n",
       "- Ensure that no passwords or API keys are hardcoded. You should load sensitive information from environment variables.\n",
       "- Add docstrings to your functions to clarify their purpose and usage.\n",
       "\n",
       "## test.py\n",
       "- Please elaborate on the purpose of the function definitions; it's important to provide context in your comments.\n",
       "- Hardcoded values such as passwords or API keys should be avoided. Implement handling through environment files instead.\n",
       "- Review the overall structure for performance optimization, e.g., reducing repeated calls for similar operations.\n",
       "\n",
       "## week1 EXERCISE.ipynb\n",
       "- There's an API key hardcoded as `api = '123...'`; consider removing it and loading sensitive information from environment variables.\n",
       "- To improve readability, consider using consistent naming conventions and meaningful variable names.\n",
       "- Use comments and markdown cells to better document your code logic and transitions between sections.\n",
       "\n",
       "## day1.ipynb\n",
       "- You have hardcoded API keys in multiple locations; make sure to handle them via a `.env` file and load them using `load_dotenv`.\n",
       "- Documentation can be improved by adding markdown explanations for logic and steps before code blocks.\n",
       "\n",
       "## day2.ipynb\n",
       "- There is a hardcoded Google API key. API keys should be loaded from environment variables instead.\n",
       "- It’s good practice to check the response code when making API calls to handle possible errors effectively.\n",
       "\n",
       "## day4.ipynb\n",
       "- The API key is loaded from the environment, which is a good practice. Ensure that the `.env` file is excluded from version control (e.g., using `.gitignore`).\n",
       "- Ensure consistency in error messages and validations regarding API key settings.\n",
       "\n",
       "## day5.ipynb\n",
       "- You're exposing API keys in your code. Ensure they're never hardcoded; use environment variables instead.\n",
       "- It’s beneficial to include type hints in functions for clearer type expectations.\n",
       "\n",
       "In general, ensure secure handling of sensitive information, improve code readability through comments and documentation, and adopt consistent naming and structure across files for better maintainability."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "openai = OpenAI()\n",
    "stream = openai.chat.completions.create(\n",
    "    model=MODEL_GPT,\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    response += chunk.choices[0].delta.content or ''\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I've reviewed the Jupyter Notebook code you provided. Here's a breakdown of its functionality, potential issues, and suggestions for improvement:\n",
      "\n",
      "**Overall Functionality**\n",
      "\n",
      "The notebook is designed to:\n",
      "\n",
      "1. **Scrape a Website:** Uses the `scraper.py` (which you haven't provided, but assumed to exist) to fetch the HTML content of a website (initially `https://edwarddonner.com`).\n",
      "2. **Extract Relevant Links:**  Processes the scraped content to identify key links that could be included in a brochure (focused on company information)\n",
      "3. **Generate a Brochure:** Constructs a brochure summary from these links -  likely using a GPT model (`gpt-5-nano`).\n",
      "\n",
      "**Code Breakdown**\n",
      "\n",
      "*   **Import Statements:** Imports necessary libraries like `os`, `json`, `dotenv`, `IPython.display` (for Markdown rendering), and `scraper` and `openai`.\n",
      "*   **API Key Handling:** Attempts to load the OpenAI API key from the environment variable `OPENAI_API_KEY`. Includes basic error handling if the key isn't found or isn't `sk-proj-`.\n",
      "*   **System Prompt Definitions:** Defines system prompts (`link_system_prompt`, `brochure_system_prompt`) to guide the GPT model's behavior. The `brochure_system_prompt` can be switched between a formal brochure style and a humorous one.\n",
      "*   **Link Extraction Logic:** Uses `get_links_user_prompt` to generate a prompt that asks the GPT model to select relevant links from a website based on criteria like \"about page,\" \"careers page,\" etc.\n",
      "*   **Relevant Link Retrieval:** `select_relevant_links` uses this prompt and the retrieved links (`fetch_website_links`) to generate a JSON formatted output.\n",
      "*   **Brochure Generation:** `fetch_page_and_all_relevant_links` uses the GPT model together with the extracted links to generate a complete brochure in markdown format.\n",
      "*   **Brochure Display:** Uses `display(Markdown(...))` to visually render the generated brochure in Jupyter.  It also implements streaming to allow the brochure to be written out slowly, improving response time.\n",
      "\n",
      "**Potential Issues and Improvements**\n",
      "\n",
      "1.  **Missing `scraper.py`:** This is the biggest issue. The code depends on a `scraper.py` file that is *not* provided. This file is essential for fetching the website content. You'll need to create this file and implement the scraping logic (e.g., using `requests` and `BeautifulSoup4`).\n",
      "\n",
      "2.  **Error Handling:** The error handling is basic. It only checks for the API key. You should add more comprehensive error handling for the API calls to the OpenAI model:\n",
      "    *   Handle API rate limits.\n",
      "    *   Handle network errors.\n",
      "    *   Handle GPT model errors (e.g., invalid prompt).\n",
      "\n",
      "3.  **Prompt Engineering:** The quality of the brochure depends heavily on the system prompts. Consider:\n",
      "    *   **More Specific Instructions:**  Refine the system prompt to be more explicit about the brochure's desired length, tone of voice, and the types of information to include (e.g., target audience, key selling points).\n",
      "    *   **Few-Shot Learning:**  Provide a few example brochure outputs to the GPT model to demonstrate the desired format and content. This helps \"teach\" the model.\n",
      "\n",
      "4.  **JSON Parsing:**  `json.loads()` is used to parse the JSON output from the GPT model. This could fail if the output isn't valid JSON, or if the response from the model isn't well-formed.\n",
      "\n",
      "5.  **Markdown Formatting:** The markdown formatting you're using is basic.  You might want to explore more advanced Markdown features for better presentation (headings, lists, tables, etc.).\n",
      "\n",
      "6.  **`scraper.py` Considerations:**\n",
      "    *   **Respect `robots.txt`:**  Ensure your scraper adheres to the website's `robots.txt` file to avoid being blocked.\n",
      "    *   **Rate Limiting:** Implement rate limiting to prevent overwhelming the target website with requests.\n",
      "\n",
      "7. **Streaming and Display:** The streaming implementation is correct, however it's a bit complex and maybe unnecessarily so. The simplest solution would be to let the brochure be generated in full, rather than stream.\n",
      "\n",
      "**Example `scraper.py` (Basic)**\n",
      "\n",
      "Here's a *very* basic example of what `scraper.py` might look like (you'll need to install `requests` and `beautifulsoup4`):\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "def fetch_website_content(url):\n",
      "    try:\n",
      "        response = requests.get(url)\n",
      "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
      "        soup = BeautifulSoup(response.content, 'html.parser')\n",
      "        return str(soup)  # return as string for simplicity.\n",
      "    except requests.exceptions.RequestException as e:\n",
      "        print(f\"Error fetching {url}: {e}\")\n",
      "        return None\n",
      "\n",
      "def fetch_website_links(url):\n",
      "    try:\n",
      "        response = requests.get(url)\n",
      "        response.raise_for_status()\n",
      "        soup = BeautifulSoup(response.content, 'html.parser')\n",
      "        links = []\n",
      "        for a_tag in soup.find_all('a', href=True):\n",
      "            link = a_tag['href']\n",
      "            links.append(link)\n",
      "        return links\n",
      "    except requests.exceptions.RequestException as e:\n",
      "        print(f\"Error fetching links from {url}: {e}\")\n",
      "        return []\n",
      "```\n",
      "\n",
      "**How to Use This Code**\n",
      "\n",
      "1.  **Create `scraper.py`:**  Implement the scraping logic as shown in the example above.\n",
      "2.  **Install Libraries:**  Run `pip install requests beautifulsoup4` in your terminal.\n",
      "3.  **Set Your OpenAI API Key:**  Make sure you have your OpenAI API key set as the `OPENAI_API_KEY` environment variable.\n",
      "4.  **Run the Notebook:**  Execute the Jupyter Notebook cells.\n",
      "\n",
      "Let me know if you'd like me to elaborate on any aspect of this or provide more specific guidance.  I can help you refine the prompts, deal with the error, and create a better `scraper.py`.\n"
     ]
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "llama=OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "llama_stream = llama.chat.completions.create(\n",
    "    model=MODEL_LLAMA,\n",
    "    messages=messages\n",
    ")\n",
    "response = llama_stream.choices[0].message.content\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
