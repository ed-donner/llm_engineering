{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11130fdd",
   "metadata": {},
   "source": [
    "# Week 2 Exercise — Code Explainer Chatbot\n",
    "\n",
    "A full Gradio prototype of the technical question-answerer from Week 1.\n",
    "\n",
    "**Features:**\n",
    "- Gradio UI with `gr.Blocks`\n",
    "- Streaming responses\n",
    "- Expert system prompt\n",
    "- Model switching (Claude 3.5 Sonnet ↔ Llama 3.2)\n",
    "- Tool calling: `lookup_python_docs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d50d0d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "import ollama\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b8c1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic API Key loaded (starts with sk-ant-api03...)\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "if not api_key:\n",
    "    import getpass\n",
    "    print('ANTHROPIC_API_KEY not found. Please enter it:')\n",
    "    api_key = getpass.getpass()\n",
    "    os.environ['ANTHROPIC_API_KEY'] = api_key\n",
    "\n",
    "anthropic_client = Anthropic()\n",
    "print(f'Anthropic API Key loaded (starts with {api_key[:12]}...)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e31585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model options\n",
    "MODEL_CLAUDE = 'claude-sonnet-4-6'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "MODEL_CHOICES = [MODEL_CLAUDE, MODEL_LLAMA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d61294d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a senior Python engineer and educator.\n",
    "When a user shares a code snippet or asks a technical question:\n",
    "\n",
    "1. Identify the key constructs and patterns used.\n",
    "2. Explain what the code does in plain English.\n",
    "3. Walk through the execution step-by-step.\n",
    "4. Highlight any potential pitfalls or best-practice improvements.\n",
    "\n",
    "Keep your explanations clear and concise. Use markdown formatting for readability.\n",
    "If you need to look up documentation for a Python built-in, use the lookup_python_docs tool.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad33d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: lookup_python_docs\n",
    "# Returns the official Python documentation URL for common built-ins\n",
    "\n",
    "PYTHON_DOCS = {\n",
    "    'yield': 'https://docs.python.org/3/reference/expressions.html#yield-expressions',\n",
    "    'yield from': 'https://docs.python.org/3/reference/expressions.html#yield-expressions',\n",
    "    'list comprehension': 'https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions',\n",
    "    'dict comprehension': 'https://docs.python.org/3/tutorial/datastructures.html#dictionaries',\n",
    "    'set comprehension': 'https://docs.python.org/3/tutorial/datastructures.html#sets',\n",
    "    'generator': 'https://docs.python.org/3/howto/functional.html#generators',\n",
    "    'decorator': 'https://docs.python.org/3/glossary.html#term-decorator',\n",
    "    'lambda': 'https://docs.python.org/3/reference/expressions.html#lambda',\n",
    "    'map': 'https://docs.python.org/3/library/functions.html#map',\n",
    "    'filter': 'https://docs.python.org/3/library/functions.html#filter',\n",
    "    'reduce': 'https://docs.python.org/3/library/functools.html#functools.reduce',\n",
    "    'zip': 'https://docs.python.org/3/library/functions.html#zip',\n",
    "    'enumerate': 'https://docs.python.org/3/library/functions.html#enumerate',\n",
    "    'async': 'https://docs.python.org/3/library/asyncio.html',\n",
    "    'await': 'https://docs.python.org/3/library/asyncio-task.html#awaitables',\n",
    "    'dataclass': 'https://docs.python.org/3/library/dataclasses.html',\n",
    "    'namedtuple': 'https://docs.python.org/3/library/collections.html#collections.namedtuple',\n",
    "}\n",
    "\n",
    "def lookup_python_docs(topic):\n",
    "    \"\"\"Return the Python docs URL for a given topic.\"\"\"\n",
    "    topic_lower = topic.lower().strip()\n",
    "    url = PYTHON_DOCS.get(topic_lower)\n",
    "    if url:\n",
    "        return f'Documentation for **{topic}**: {url}'\n",
    "    return f'No specific documentation link found for \"{topic}\". Try searching at https://docs.python.org/3/search.html?q={topic}'\n",
    "\n",
    "# Anthropic tool schema\n",
    "docs_tool = {\n",
    "    'name': 'lookup_python_docs',\n",
    "    'description': 'Look up the official Python documentation URL for a given Python concept, built-in, or keyword.',\n",
    "    'input_schema': {\n",
    "        'type': 'object',\n",
    "        'properties': {\n",
    "            'topic': {\n",
    "                'type': 'string',\n",
    "                'description': 'The Python concept or keyword to look up, e.g. yield, lambda, decorator',\n",
    "            },\n",
    "        },\n",
    "        'required': ['topic'],\n",
    "    },\n",
    "}\n",
    "tools = [docs_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f57c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_calls(message):\n",
    "    \"\"\"Process tool calls from the assistant message and return tool responses.\"\"\"\n",
    "    responses = []\n",
    "    for content_block in message.content:\n",
    "        if content_block.type == 'tool_use' and content_block.name == 'lookup_python_docs':\n",
    "            topic = content_block.input.get('topic', '')\n",
    "            result = lookup_python_docs(topic)\n",
    "            responses.append({\n",
    "                'type': 'tool_result',\n",
    "                'tool_use_id': content_block.id,\n",
    "                'content': result,\n",
    "            })\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5a50e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history, model_name):\n",
    "    \"\"\"Chat callback for Gradio. Streams responses from the selected model.\"\"\"\n",
    "    history = [{'role': h['role'], 'content': h['content']} for h in history]\n",
    "\n",
    "    if model_name == MODEL_CLAUDE:\n",
    "        # --- Anthropic path (with tool calling) ---\n",
    "        messages_for_claude = history + [{'role': 'user', 'content': message}]\n",
    "        \n",
    "        # First, check if the model wants to call a tool (non-streaming)\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=MODEL_CLAUDE, \n",
    "            system=SYSTEM_PROMPT,\n",
    "            max_tokens=1024,\n",
    "            messages=messages_for_claude, \n",
    "            tools=tools\n",
    "        )\n",
    "        \n",
    "        if response.stop_reason == 'tool_use':\n",
    "            tool_responses = handle_tool_calls(response)\n",
    "            messages_for_claude.append({'role': 'assistant', 'content': response.content})\n",
    "            messages_for_claude.append({'role': 'user', 'content': tool_responses})\n",
    "            \n",
    "            # Now stream the final answer after tool use\n",
    "            with anthropic_client.messages.stream(\n",
    "                model=MODEL_CLAUDE, \n",
    "                system=SYSTEM_PROMPT,\n",
    "                max_tokens=1024,\n",
    "                messages=messages_for_claude, \n",
    "                tools=tools\n",
    "            ) as stream:\n",
    "                result = ''\n",
    "                for text in stream.text_stream:\n",
    "                    result += text\n",
    "                    yield result\n",
    "        else:\n",
    "            # Model didn't use a tool, so we can just return the content (we could also stream this directly)\n",
    "             yield response.content[0].text\n",
    "\n",
    "    else:\n",
    "        # --- Ollama path (streaming, no tool calling) ---\n",
    "        messages = [{'role': 'system', 'content': SYSTEM_PROMPT}] + history + [{'role': 'user', 'content': message}]\n",
    "        stream = ollama.chat(\n",
    "            model=MODEL_LLAMA,\n",
    "            messages=messages,\n",
    "            stream=True,\n",
    "        )\n",
    "        result = ''\n",
    "        for chunk in stream:\n",
    "            result += chunk['message']['content']\n",
    "            yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7b9004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the Gradio UI\n",
    "\n",
    "with gr.Blocks(title='Code Explainer Chatbot') as ui:\n",
    "    gr.Markdown('##Code Explainer Chatbot')\n",
    "    gr.Markdown('Paste a code snippet and get a step-by-step explanation. Switch models anytime.')\n",
    "\n",
    "    with gr.Row():\n",
    "        model_dropdown = gr.Dropdown(\n",
    "            choices=MODEL_CHOICES,\n",
    "            value=MODEL_CLAUDE,\n",
    "            label='Select Model',\n",
    "        )\n",
    "\n",
    "    chatbot = gr.ChatInterface(\n",
    "        fn=chat,\n",
    "        type='messages',\n",
    "        additional_inputs=[model_dropdown],\n",
    "    )\n",
    "\n",
    "ui.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
