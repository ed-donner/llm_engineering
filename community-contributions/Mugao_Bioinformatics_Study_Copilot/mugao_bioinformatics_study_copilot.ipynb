{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4fa12c1",
   "metadata": {},
   "source": [
    "Biotechnology Study Copilot\n",
    "Project Overview\n",
    "\n",
    "The Biotechnology Study Copilot is a practical LLM-powered study assistant built using the OpenAI Chat Completions API.\n",
    "\n",
    "It demonstrates how large language models can be applied to real-world academic workflows ‚Äî specifically for graduate-level biotechnology and bioinformatics studies.\n",
    "\n",
    "The assistant helps transform complex scientific topics and lecture notes into:\n",
    "\n",
    "Clear conceptual explanations (simple + technical)\n",
    "\n",
    "Exam-style questions\n",
    "\n",
    "Structured flashcards\n",
    "\n",
    "Concise summaries of lecture material\n",
    "\n",
    "Instead of passively reading notes, this tool enables active, structured learning powered by LLMs.\n",
    "\n",
    "Real-World Use Case\n",
    "\n",
    "Graduate biotechnology programs involve dense material such as:\n",
    "\n",
    "Gene editing mechanisms (e.g., CRISPR-Cas9)\n",
    "\n",
    "RNA sequencing workflows\n",
    "\n",
    "Genome assembly algorithms\n",
    "\n",
    "Differential gene expression analysis\n",
    "\n",
    "Bioinformatics pipelines\n",
    "\n",
    "This project shows how LLMs can:\n",
    "\n",
    "Break down complex molecular biology concepts\n",
    "\n",
    "Generate revision materials automatically\n",
    "\n",
    "Simulate exam preparation\n",
    "\n",
    "Convert lecture notes into structured study assets\n",
    "\n",
    "It demonstrates a practical and personal application of AI for higher education.\n",
    "\n",
    " Concepts Covered\n",
    "\n",
    "This project implements several core LLM engineering principles:\n",
    "\n",
    "1Ô∏è OpenAI Chat Completions API\n",
    "\n",
    "Using the Python client to send structured system and user messages.\n",
    "\n",
    "2Ô∏è System vs User Prompts\n",
    "\n",
    "Clear role separation to guide model behavior and maintain domain expertise.\n",
    "\n",
    "3Ô∏è Structured JSON Outputs\n",
    "\n",
    "The model is instructed to return valid JSON for predictable parsing and downstream use.\n",
    "\n",
    "4Ô∏è Prompt Engineering\n",
    "\n",
    "Carefully designed prompts to:\n",
    "\n",
    "Control response format\n",
    "\n",
    "Maintain scientific accuracy\n",
    "\n",
    "Generate exam-level content\n",
    "\n",
    "5Ô∏è Prompt Chaining\n",
    "\n",
    "Multiple GPT calls are chained together to:\n",
    "\n",
    "Generate explanations\n",
    "\n",
    "Transform explanations into flashcards\n",
    "\n",
    "Build layered outputs\n",
    "\n",
    "6Ô∏è Environment & API Key Management\n",
    "\n",
    "Secure API key handling using .env and python-dotenv.\n",
    "\n",
    "7Ô∏è Reusable LLM Abstraction\n",
    "\n",
    "A clean, reusable call_gpt() function prevents duplication and follows DRY principles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6dfe7f",
   "metadata": {},
   "source": [
    "Step 1; Install & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1011f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe30226",
   "metadata": {},
   "source": [
    " Step 2: Load API Key from .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df819250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in .env file\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "print(\"‚úÖ API key loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2876e4c",
   "metadata": {},
   "source": [
    "Step 3 : Core LLM Function\n",
    "This becomes your reusable LLM engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6163a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt(system_prompt: str, user_prompt: str, temperature: float = 0.3):\n",
    "    \"\"\"\n",
    "    Generic GPT caller function.\n",
    "    Keeps things reusable and clean.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        temperature=temperature,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf2124e",
   "metadata": {},
   "source": [
    "Step 4: Study Topic Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89724f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_study_pack(topic: str):\n",
    "    system_prompt = \"\"\"\n",
    "    You are a biotechnology university professor and expert tutor.\n",
    "    You explain clearly but maintain scientific accuracy.\n",
    "    Always respond in valid JSON format.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    Create a complete study pack for the topic: {topic}\n",
    "\n",
    "    Return in this JSON format:\n",
    "    {{\n",
    "        \"simple_explanation\": \"...\",\n",
    "        \"technical_explanation\": \"...\",\n",
    "        \"exam_questions\": [\"...\", \"...\", \"...\", \"...\", \"...\"],\n",
    "        \"flashcards\": [\n",
    "            {{\"question\": \"...\", \"answer\": \"...\"}},\n",
    "            {{\"question\": \"...\", \"answer\": \"...\"}}\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    response = call_gpt(system_prompt, user_prompt)\n",
    "\n",
    "    return json.loads(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0bad0b",
   "metadata": {},
   "source": [
    "Step 5: Test It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dcdccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"CRISPR-Cas9 gene editing mechanism\"\n",
    "\n",
    "study_pack = generate_study_pack(topic)\n",
    "\n",
    "print(\"üìò SIMPLE EXPLANATION:\\n\")\n",
    "print(study_pack[\"simple_explanation\"])\n",
    "\n",
    "print(\"\\nüìö TECHNICAL EXPLANATION:\\n\")\n",
    "print(study_pack[\"technical_explanation\"])\n",
    "\n",
    "print(\"\\nüìù EXAM QUESTIONS:\\n\")\n",
    "for q in study_pack[\"exam_questions\"]:\n",
    "    print(\"-\", q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d352b54e",
   "metadata": {},
   "source": [
    "Step 6: Lecture Notes Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e925f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_lecture_notes(notes: str):\n",
    "    system_prompt = \"\"\"\n",
    "    You are a bioinformatics teaching assistant.\n",
    "    Your job is to summarize lecture notes clearly and extract key learning points.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    Summarize the following lecture notes.\n",
    "    Then extract:\n",
    "    - 5 key concepts\n",
    "    - 3 potential exam questions\n",
    "\n",
    "    Lecture notes:\n",
    "    {notes}\n",
    "    \"\"\"\n",
    "\n",
    "    return call_gpt(system_prompt, user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7914f589",
   "metadata": {},
   "source": [
    "Step 7: Test with Sample Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fd7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_notes = \"\"\"\n",
    "RNA-Seq is a next-generation sequencing technique used to analyze the transcriptome.\n",
    "It involves reverse transcription of RNA into cDNA, fragmentation, sequencing, \n",
    "and alignment to a reference genome. Differential gene expression analysis \n",
    "is performed to compare biological conditions.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_lecture_notes(sample_notes)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62051456",
   "metadata": {},
   "source": [
    "Step 8: Prompt Chaining\n",
    "Generate explanation\n",
    "Turn explanation into flashcards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d71981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explanation_to_flashcards(explanation: str):\n",
    "    system_prompt = \"You are a biotech exam preparation assistant.\"\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "    Convert the following explanation into 5 high-quality flashcards:\n",
    "\n",
    "    {explanation}\n",
    "\n",
    "    Format:\n",
    "    Q: ...\n",
    "    A: ...\n",
    "    \"\"\"\n",
    "\n",
    "    return call_gpt(system_prompt, user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5694192d",
   "metadata": {},
   "source": [
    "Step 9 : Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b437dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "flashcards = explanation_to_flashcards(study_pack[\"technical_explanation\"])\n",
    "print(flashcards)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
