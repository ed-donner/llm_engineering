{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 1 • Day 1 — Ollama Web Summarizer\n",
        "\n",
        "This notebook mirrors the original Day 1 exercise but uses a local Ollama model via the OpenAI-compatible API.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "- Load environment variables\n",
        "- Configure OpenAI-compatible client for Ollama\n",
        "- Print selected base URL and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Ollama at http://localhost:11434/v1 with model llama3.2\n"
          ]
        }
      ],
      "source": [
        "# Imports and environment\n",
        "import os\n",
        "import logging\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Markdown, display\n",
        "from openai import OpenAI\n",
        "\n",
        "from utils import fetch_website_contents\n",
        "\n",
        "load_dotenv(override=True)\n",
        "OLLAMA_BASE_URL = os.getenv(\"OLLAMA_BASE_URL\", \"http://localhost:11434/v1\")\n",
        "OLLAMA_MODEL = os.getenv(\"OLLAMA_MODEL\", \"llama3.2\")\n",
        "LOG_LEVEL = os.getenv(\"LOG_LEVEL\", \"INFO\").upper()\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=getattr(logging, LOG_LEVEL, logging.INFO),\n",
        "    format=\"%(asctime)s %(levelname)s %(name)s - %(message)s\",\n",
        ")\n",
        "logger = logging.getLogger(\"w1d1\")\n",
        "\n",
        "# Connect to Ollama via OpenAI-compatible API (no real OpenAI calls)\n",
        "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\"ollama\")\n",
        "print(f\"Using Ollama at {OLLAMA_BASE_URL} with model {OLLAMA_MODEL}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prompts\n",
        "\n",
        "- Define the system and user prompts\n",
        "- Helper: `messages_for(website)` builds the chat message list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prompts\n",
        "system_prompt = \"\"\"\n",
        "You are a snarky assistant that analyzes the contents of a website,\n",
        "and provides a short, snarky, humorous summary, ignoring text that might be navigation related.\n",
        "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
        "\"\"\"\n",
        "\n",
        "user_prompt_prefix = \"\"\"\n",
        "Here are the contents of a website.\n",
        "Provide a short summary of this website.\n",
        "If it includes news or announcements, then summarize these too.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def messages_for(website: str):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt_prefix + website},\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summarization helpers\n",
        "\n",
        "- `summarize(url)`: scrape page text and call Ollama\n",
        "- `display_summary(url)`: render the summary as Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summarization helpers\n",
        "\n",
        "def summarize(url: str) -> str:\n",
        "    logger.info(f\"Summarizing URL: {url}\")\n",
        "    try:\n",
        "        website = fetch_website_contents(url)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to fetch website contents from {url}: {e}\")\n",
        "        return f\"Error: failed to fetch website contents from {url}. Details: {e}\"\n",
        "\n",
        "    try:\n",
        "        response = ollama.chat.completions.create(\n",
        "            model=OLLAMA_MODEL,\n",
        "            messages=messages_for(website),\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ollama chat completion failed: {e}\")\n",
        "        return f\"Error: summarization failed. Details: {e}\"\n",
        "\n",
        "\n",
        "def display_summary(url: str) -> None:\n",
        "    try:\n",
        "        summary = summarize(url)\n",
        "        display(Markdown(summary))\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Unexpected error displaying summary for {url}: {e}\")\n",
        "        display(Markdown(f\"**Unexpected error**: {e}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run\n",
        "\n",
        "- Read `WEBSITE_URL` from environment (fallback to `https://edwarddonner.com`)\n",
        "- Generate and display the summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-20 07:14:15,767 INFO w1d1 - Summarizing URL: https://edwarddonner.com\n",
            "2026-02-20 07:14:54,728 INFO httpx - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "### Website Summary and News\n",
              "\n",
              "This website appears to be the personal blog of Edward Donner, a tech enthusiast and AI expert. It's mainly focused on his background, accomplishments, and online courses related to AI.\n",
              "\n",
              "### Recent News\n",
              "\n",
              "* February 17, 2026: No specific details mentioned\n",
              "* January 4, 2026: No specific details mentioned\n",
              "* November 11, 2025: \"AI Builder with n8n – Create Agents and Voice Agents\" - seems like a new project or announcement.\n",
              "* September 15, 2025: \"The Unique Energy of an AI Live Event\" - likely related to online events or webinars hosted by Donner.\n",
              "* AI Engineering MLOps Track – Deploy AI to Production (not specified date) - another announcement about his work in the AI industry."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Try it out\n",
        "# Tip: If llama3.2 is slow on your machine, try: export OLLAMA_MODEL=llama3.2:1b\n",
        "\n",
        "target_url = os.getenv(\"WEBSITE_URL\", \"https://edwarddonner.com\")\n",
        "display_summary(target_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "- Aligned with Day 1 (GPT) structure: `system_prompt`, `user_prompt_prefix`, `messages_for`, `summarize`, and `display_summary` mirror the original flow.\n",
        "- Replaced GPT calls with Ollama via OpenAI-compatible `/v1/chat/completions` while keeping the message schema identical.\n",
        "- Added logging and error handling around scraping and LLM calls for robustness.\n",
        "- Configure behavior via environment: `OLLAMA_BASE_URL`, `OLLAMA_MODEL`, `WEBSITE_URL`, `LOG_LEVEL`.\n",
        "\n",
        "Next steps:\n",
        "- Try a different model (e.g., `llama3.2:1b`) if resources are limited.\n",
        "- Extend prompts for alternative tones or languages.\n",
        "- Add link crawling (see Day 2 pattern) if you want multi-page summaries."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
