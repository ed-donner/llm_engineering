{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23239239",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "In this notebook, we will manage a set of restaurant clients comments on a restaurant.\n",
    "The idea is to be able to query comments via openai LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231662bf",
   "metadata": {},
   "source": [
    "# Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32522307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)  # True to override existing environment variables\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93af6d9f",
   "metadata": {},
   "source": [
    "# Read data in a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf21bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv file in pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('kebab_comments_with_rate.csv', sep=';')\n",
    "\n",
    "# Convert DATETIME_STAMP column to datetime\n",
    "df['DATETIME_STAMP'] = pd.to_datetime(df['DATETIME_STAMP'])\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e727dbde",
   "metadata": {},
   "source": [
    "# Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ec60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read comments on july month\n",
    "july_df = df[df['DATETIME_STAMP'].dt.month == 7]\n",
    "print(july_df[['COMMENT', 'RATE']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625009de",
   "metadata": {},
   "source": [
    "# Implement a filtering function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30503db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A filtering function that returns comments for a given period of time or ratings range\n",
    "MIN_DATE = '1900-01-01'\n",
    "MAX_DATE = '9999-12-31'\n",
    "def filter_comments(df, start_date=MIN_DATE, end_date=MAX_DATE, min_rate=0, max_rate=5):\n",
    "    filtered_df = df.copy()\n",
    "    if start_date:\n",
    "        filtered_df = filtered_df[filtered_df['DATETIME_STAMP'] >= pd.to_datetime(start_date)]\n",
    "    if end_date:\n",
    "        filtered_df = filtered_df[filtered_df['DATETIME_STAMP'] <= pd.to_datetime(end_date)]\n",
    "    if min_rate is not None:\n",
    "        filtered_df = filtered_df[filtered_df['RATE'] >= min_rate]\n",
    "    if max_rate is not None:\n",
    "        filtered_df = filtered_df[filtered_df['RATE'] <= max_rate]\n",
    "    \n",
    "    return filtered_df[['COMMENT', 'RATE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582edafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out the function\n",
    "print(filter_comments(df, start_date='2025-06-12', end_date='2025-06-20', min_rate=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82577b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a method that transforms the filtered data into a list of tuples (comment, rate)\n",
    "def df_to_tuples(filtered_df):\n",
    "    # index=False to avoid including the index in the tuples\n",
    "    # name=None to return plain tuples instead of namedtuples\n",
    "    return list(filtered_df.itertuples(index=False, name=None))\n",
    "\n",
    "\n",
    "comments_list = df_to_tuples(filter_comments(df, start_date='2025-06-12', end_date='2025-06-20', min_rate=4))\n",
    "\n",
    "for comment, rate in comments_list:\n",
    "    print(f\"Comment: {comment}, Rate: {rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ec7047",
   "metadata": {},
   "source": [
    "# Implement openAI LLM to query comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90444332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a query system using OpenAI's LLM\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that summarizes restaurant customer comments based on user queries.\n",
    "You will also make some operations on rates.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Given the following customer comments and their rates below:\n",
    "{comments_data}\n",
    "\\n\\n\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "question = input(\"Please enter your question about the comments: \")\n",
    "\n",
    "formatted_comments_list = \"\\n\".join([f\"- Comment: {comment}, Rate: {rate}\" for comment, rate in comments_list])\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt.format(comments_data=formatted_comments_list, question=question)}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"Response from the LLM:\")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
