{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e46be6",
   "metadata": {},
   "source": [
    "# AI News Analyzer\n",
    "\n",
    "Keeping up with AI news is overwhelming — new models, funding rounds, research breakthroughs and industry shifts happen every single day. This tool automates that process by scraping top AI news websites, extracting the most important stories, and generating a clean structured digest so you can stay informed in minutes instead of hours.\n",
    "\n",
    "## What this tool does\n",
    "- Scrapes multiple AI news sources automatically\n",
    "- Extracts the top 10 most important AI stories\n",
    "- Generates a clean structured digest with headlines, summaries and sources\n",
    "- Runs completely locally using Ollama — no API costs, no data leaving your machine\n",
    "\n",
    "## How to Use\n",
    "1. Make sure Ollama is running locally on your machine\n",
    "2. Pull any Ollama supported model of your choice: `ollama pull mistral` or `ollama pull llama3.2` or any other model from [Ollama's model library](https://ollama.com/library)\n",
    "3. Update the `model` parameter in the last cell to match your chosen model\n",
    "4. Add or remove news sources in the `news_sources` list\n",
    "5. Run all cells\n",
    "6. Read your AI news digest!\n",
    "\n",
    "## Requirements\n",
    "- Ollama installed and running locally\n",
    "- Any Ollama supported model pulled and ready\n",
    "- Install dependencies: `uv pip install beautifulsoup4 requests openai`\n",
    "\n",
    "---\n",
    "*Built as a Day 2 homework extension for the Udemy course: AI Engineer Core Track — LLM Engineering, RAG, QLoRA, Agents by Ed Donner.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc7fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!uv pip install beautifulsoup4 requests openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify Ollama is running locally\n",
    "import requests\n",
    "requests.get(\"http://localhost:11434\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf641035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull your preferred model — you can use any Ollama supported model\n",
    "!ollama pull mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b034ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup          # parses HTML content from scraped web pages\n",
    "from openai import OpenAI              # connects to Ollama using OpenAI compatible endpoint\n",
    "from IPython.display import Markdown, display  # renders the news digest as formatted Markdown\n",
    "from datetime import datetime          # gets today's date for the digest header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f83444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to local Ollama using OpenAI compatible endpoint\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd03ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapes headlines and paragraph text from a given news website URL\n",
    "\n",
    "def scrape_news(url):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers, timeout=10)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup([\"script\", \"style\", \"nav\", \"footer\"]):\n",
    "        tag.decompose()\n",
    "    \n",
    "    # Extract article headlines from h1, h2, h3 tags\n",
    "    titles = []\n",
    "    for tag in soup.find_all(['h1', 'h2', 'h3']):\n",
    "        title = tag.get_text().strip()\n",
    "        if len(title) > 20:  # filter out short irrelevant headings\n",
    "            titles.append(title)\n",
    "    \n",
    "    # Also get paragraph text as backup\n",
    "    paragraphs = soup.find_all(\"p\")\n",
    "    text = \" \".join([p.get_text() for p in paragraphs])\n",
    "    \n",
    "    # Combine headlines and text\n",
    "    combined = \"ARTICLE HEADLINES:\\n\" + \"\\n\".join(titles[:30]) + \"\\n\\nARTICLE TEXT:\\n\" + text[:20000]\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca404223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add or remove news sources as needed\n",
    "news_sources = [\n",
    "    \"https://news.ycombinator.com\",\n",
    "    \"https://techcrunch.com/category/artificial-intelligence\",\n",
    "    \"https://venturebeat.com/ai\"\n",
    "]\n",
    "\n",
    "all_news = \"\"\n",
    "for url in news_sources:\n",
    "    print(f\"Scraping: {url}\")\n",
    "    try:\n",
    "        content = scrape_news(url)\n",
    "        all_news += f\"\\nSource: {url}\\n{content}\\n\"\n",
    "        print(f\"Done!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "\n",
    "print(\"\\nAll scraping complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca2c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get today's date for the digest header\n",
    "today = datetime.today().strftime(\"%B %d, %Y\")\n",
    "\n",
    "# System prompt instructs Ollama how to format the news digest\n",
    "system_prompt = f\"\"\"\n",
    "You are an AI news analyst. Extract the TOP 10 most important AI stories from the content below.\n",
    "Do not add any introduction or preamble — start directly with the digest.\n",
    "Every story must be complete — do not include stories without a Summary and Why it matters.\n",
    "Format your response EXACTLY as shown below with each field (Summary, Why it matters and Source) on its own separate line:\n",
    "\n",
    "Source should contain only the website name — no URLs.\n",
    "Each field (Headline, Summary, Why it matters, Source) must be on its own separate line.\n",
    "\n",
    "\n",
    "TOP AI NEWS TODAY — {today}\n",
    "\n",
    "\n",
    "1. **[Headline]**\\n\\n**Summary:** 2-3 sentences explaining what happened\\n\\n**Why it matters:** one sentence on significance\\n\\n**Source:** [website name]\\n\\n---\n",
    "\n",
    "2. **[Headline]**\\n\\n**Summary:** ...\\n\\n**Why it matters:** ...\\n\\n**Source:** ...\\n\\n---\n",
    "\n",
    "Focus only on AI related stories. Ignore unrelated content.\n",
    "Keep it concise and factual. No emojis.\n",
    "\"\"\"\n",
    "\n",
    "# Send scraped news to Ollama and display the digest\n",
    "\n",
    "response = ollama.chat.completions.create(\n",
    "    model=\"mistral\",       # CHANGE THIS to your preferred Ollama model e.g. llama3.2, mistral, gemma\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is today's AI news:\\n\\n{all_news}\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
