{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de77496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6053cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a9571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai = OpenAI()\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
    "MODEL = MODEL_LLAMA\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a seasoned engineer helping users\n",
    "understand technical problems by using well defined explanations; when a \n",
    "question involves code, include the original code \n",
    "in a properly formatted markdown code block and provide\n",
    "a clear, concise explanation of what the code does and\n",
    "why it is used, ensuring all responses are structured \n",
    "and written in markdown format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a328983",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def theExplainer(question, model, llm):\n",
    "    stream = llm.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, \n",
    "    {\"role\": \"user\", \"content\": question}],\n",
    "    stream=True)\n",
    "    response=\"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        display_handle.update(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8df1fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bbf90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "\n",
    "theExplainer(question, MODEL_GPT, openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "theExplainer(question, MODEL_LLAMA, ollama)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
