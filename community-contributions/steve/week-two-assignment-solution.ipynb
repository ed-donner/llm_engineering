{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c03d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import os\n",
    "import gradio as gr\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0c69ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5bca26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "openai = OpenAI()\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
    "MODEL = MODEL_LLAMA\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "   \n",
    "\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are an expert technical assistant who helps developers debug code, explain concepts,\n",
    "and solve engineering problems.\n",
    "\n",
    "If the user asks a general technical question, respond normally.\n",
    "\n",
    "However, if the user explicitly asks to book a hotel or make a hotel reservation,\n",
    "you MUST call the book_hotel tool instead of responding conversationally.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dfdc103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A SIMPLE HOTEL BOOKING TOOL\n",
    "\n",
    "def book_hotel(name: str, city: str, nights: int, start_date: str):\n",
    "    return f\"Hotel successfully booked in {city} for {name} for {nights} nights starting {start_date}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff124e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOOL OBJECT DEFINATION\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"book_hotel\",\n",
    "            \"description\": \"Book a hotel when a user asks to reserve or book accommodation\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\"type\": \"string\"},\n",
    "                    \"city\": {\"type\": \"string\"},\n",
    "                    \"nights\": {\"type\": \"integer\"},\n",
    "                    \"start_date\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"name\", \"city\", \"nights\", \"start_date\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c82ab7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL SWITCH\n",
    "\n",
    "def get_client_and_model(choice):\n",
    "    if choice == \"OpenAI\":\n",
    "        return openai, MODEL_GPT\n",
    "    else:\n",
    "        return ollama, MODEL_LLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca791d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPEECH TO TEXT\n",
    "\n",
    "def transcribe_audio(audio):\n",
    "    if audio is None:\n",
    "        return \"\"\n",
    "\n",
    "    with open(audio, \"rb\") as f:\n",
    "        transcript = openai.audio.transcriptions.create(\n",
    "            model=\"gpt-4o-mini-transcribe\",\n",
    "            file=f\n",
    "        )\n",
    "    return transcript.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0669585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT â†’ SPEECH\n",
    "\n",
    "def text_to_speech(text):\n",
    "    speech_file = \"response.mp3\"\n",
    "\n",
    "    with openai.audio.speech.with_streaming_response.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=\"alloy\",\n",
    "        input=text\n",
    "    ) as response:\n",
    "        response.stream_to_file(speech_file)\n",
    "\n",
    "    return speech_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3944b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STREAMING TEXT CHAT\n",
    "\n",
    "\n",
    "def chat(message, history, model_choice):\n",
    "\n",
    "    history = history or []\n",
    "\n",
    "    # add user message first\n",
    "    history.append({\"role\":\"user\",\"content\":message})\n",
    "\n",
    "    # model router\n",
    "    client, model = get_client_and_model(model_choice)   \n",
    "\n",
    "\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\n",
    "        \"content\":\"You are a general technical assistant. Only call the hotel booking tool if the request is about booking a hotel.\"}\n",
    "    ] + history\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "\n",
    "    msg = response.choices[0].message\n",
    "\n",
    "    # TOOL CALL\n",
    "    if msg.tool_calls:\n",
    "\n",
    "        for tool_call in msg.tool_calls:\n",
    "\n",
    "            if tool_call.function.name == \"book_hotel\":\n",
    "\n",
    "                args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                result = book_hotel(\n",
    "                    args[\"name\"],\n",
    "                    args[\"city\"],\n",
    "                    args[\"nights\"],\n",
    "                    args[\"start_date\"]\n",
    "                )\n",
    "\n",
    "                messages.append(msg)\n",
    "\n",
    "                messages.append({\n",
    "                    \"role\":\"tool\",\n",
    "                    \"tool_call_id\":tool_call.id,\n",
    "                    \"content\":result\n",
    "                })\n",
    "\n",
    "        stream = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "    else:\n",
    "\n",
    "        stream = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "    partial = \"\"\n",
    "\n",
    "    # add empty assistant message to history\n",
    "    history.append({\"role\":\"assistant\",\"content\":\"\"})\n",
    "\n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            partial += chunk.choices[0].delta.content\n",
    "            history[-1][\"content\"] = partial\n",
    "            yield history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c781725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOICE CHAT + TOOL CALLING\n",
    "\n",
    "def voice_chat(audio, history, model_choice):\n",
    "\n",
    "    user_text = transcribe_audio(audio)\n",
    "\n",
    "    if not user_text:\n",
    "        return history, None\n",
    "\n",
    "    history.append({\"role\":\"user\",\"content\":user_text})\n",
    "\n",
    "    client, model = get_client_and_model(model_choice)\n",
    "\n",
    "    messages = [{\"role\":\"system\",\"content\":system_message}] + history\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=book_hotel,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "\n",
    "    msg = response.choices[0].message\n",
    "\n",
    "    if msg.tool_calls:\n",
    "\n",
    "        tool_call = msg.tool_calls[0]\n",
    "        args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "        result = book_hotel(**args)\n",
    "\n",
    "        history.append(msg)\n",
    "\n",
    "        history.append({\n",
    "            \"role\":\"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"content\":result\n",
    "        })\n",
    "\n",
    "        final = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\":\"system\",\"content\":system_message}] + history\n",
    "        )\n",
    "\n",
    "        reply = final.choices[0].message.content\n",
    "\n",
    "    else:\n",
    "        reply = msg.content\n",
    "\n",
    "    history.append({\"role\":\"assistant\",\"content\":reply})\n",
    "\n",
    "    audio_reply = text_to_speech(reply)\n",
    "\n",
    "    return history, audio_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0020a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAR BUTTON\n",
    "\n",
    "def clear_all():\n",
    "    return [], None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1b4f49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "* Running on public URL: https://0eecd474e4ff05230b.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://0eecd474e4ff05230b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRADIO UI\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "    gr.Markdown(\"# ðŸŽ§ Technical Assistant with Voice + Tool Use\")\n",
    "\n",
    "    model_choice = gr.Radio([\"OpenAI\",\"Ollama\"], value=\"OpenAI\")\n",
    "\n",
    "    chatbot = gr.Chatbot(type=\"messages\")\n",
    "\n",
    "    msg = gr.Textbox(placeholder=\"Ask a technical question...\")\n",
    "    send = gr.Button(\"Send\")\n",
    "\n",
    "    audio_input = gr.Audio(sources=[\"microphone\"], type=\"filepath\")\n",
    "    voice_btn = gr.Button(\"Ask with Voice\")\n",
    "\n",
    "    audio_output = gr.Audio(autoplay=True)\n",
    "\n",
    "    clear_btn = gr.Button(\"Clear Chat\")\n",
    "\n",
    "    # TEXT SUBMIT\n",
    "    msg.submit(\n",
    "        chat,\n",
    "        inputs=[msg, chatbot, model_choice],\n",
    "        outputs=chatbot\n",
    "    ).then(lambda: \"\", outputs=msg)\n",
    "\n",
    "    # BUTTON SUBMIT\n",
    "    send.click(\n",
    "        chat,\n",
    "        inputs=[msg, chatbot, model_choice],\n",
    "        outputs=chatbot\n",
    "    ).then(lambda: \"\", outputs=msg)\n",
    "\n",
    "    # VOICE SUBMIT\n",
    "    voice_btn.click(\n",
    "        voice_chat,\n",
    "        inputs=[audio_input, chatbot, model_choice],\n",
    "        outputs=[chatbot, audio_output]\n",
    "    ).then(lambda: None, outputs=audio_input)\n",
    "\n",
    "    # CLEAR\n",
    "    clear_btn.click(\n",
    "        clear_all,\n",
    "        outputs=[chatbot, audio_input, audio_output]\n",
    "    )\n",
    "\n",
    "demo.launch(share=True, inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2269d82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
