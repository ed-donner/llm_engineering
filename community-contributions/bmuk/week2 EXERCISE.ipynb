{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from huggingface_hub import login\n",
    "from groq import Groq\n",
    "import tempfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd508bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env variables\n",
    "load_dotenv(override=True)\n",
    "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if openrouter_api_key:\n",
    "    print(\"OPENROUTER_API_KEY is set.\")\n",
    "else:\n",
    "    print(\"OPENROUTER_API_KEY is not set.\")\n",
    "\n",
    "if hf_token:\n",
    "    print(\"HuggingFace token found.\")\n",
    "else:\n",
    "    print(\"No HuggingFace token found.\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(\"GROQ_API_KEY is set.\")\n",
    "else:\n",
    "    print(\"GROQ_API_KEY is not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc57c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MODEL_GPT = 'openai/gpt-4o-mini'\n",
    "MODEL_GEMINI = 'google/gemini-2.5-flash-lite'\n",
    "openrouter_url = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "# List of models\n",
    "models = [MODEL_GPT, MODEL_GEMINI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd32aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenRouter and Groq\n",
    "client_llm = OpenAI(base_url=openrouter_url, api_key=openrouter_api_key)\n",
    "client_groq = Groq(api_key=groq_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7af4865",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\" \n",
    "You are a technical assistant.\n",
    "Your task is to take a technical question and produce a clear, accurate, and well-structured explanation.\n",
    "Guidelines:\n",
    "- Prioritize clarity over complexity.\n",
    "- If the question lacks necessary details, state assumptions clearly.\n",
    "- Avoid fluff, marketing language, or unnecessary verbosity.\n",
    "- Respond in one concise paragraph, using simple language and examples when helpful\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11adb18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt(question):\n",
    "    user_prompt = f\"\"\"\n",
    "    You are a technical assistant. \n",
    "    Please answer the following question in a clear, concise, and structured manner, following the guidelines provided.\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9af4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use accelerator to manage device placement\n",
    "device = Accelerator().device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0597852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Whisper model for speech recognition\n",
    "transcriber = pipeline(\n",
    "    \"automatic-speech-recognition\", \n",
    "    model=\"openai/whisper-base.en\", \n",
    "    device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1855b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert text to audio using Groq Orpheus API\n",
    "def text_to_audio(text, \n",
    "                  model=\"canopylabs/orpheus-v1-english\", \n",
    "                  voice=\"troy\", \n",
    "                  response_format=\"wav\", \n",
    "                  ):\n",
    "    \"\"\"\n",
    "    Converts input text to speech audio using Groq Orpheus API.\n",
    "    Returns the path to the generated audio file.\n",
    "    \"\"\"\n",
    "    response = client_groq.audio.speech.create(\n",
    "        model=model,\n",
    "        voice=voice,\n",
    "        input=text,\n",
    "        response_format=response_format\n",
    "    )\n",
    "\n",
    "    output_path = os.path.join(tempfile.gettempdir(), f\"output.{response_format}\")\n",
    "    response.write_to_file(output_path)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37685807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to process audio input, get LLM response, and convert it to audio\n",
    "def process_input(audio_file,history,model):\n",
    "    # process audio and return llm response\n",
    "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "\n",
    "    transcription = transcriber(audio_file)[\"text\"]\n",
    "    prompt = get_user_prompt(transcription)\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": prompt}]\n",
    "    stream = client_llm.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    # Append the new exchange to history before returning\n",
    "    history.append({\"role\": \"user\", \"content\": transcription})\n",
    "    history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
    "\n",
    "    full_response = \"\"\n",
    "    for chunk in stream:\n",
    "        delta = chunk.choices[0].delta.content or \"\"\n",
    "        full_response += delta\n",
    "        history[-1][\"content\"] = full_response  \n",
    "        yield history, None  \n",
    "\n",
    "    print(\"LLM Response: \", full_response)\n",
    "    try:\n",
    "        output_audio = text_to_audio(full_response)\n",
    "    except Exception as e:\n",
    "        print(\"Error in text-to-audio conversion: \", e)\n",
    "        output_audio = None\n",
    "\n",
    "    return history, output_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Gradio interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Technical Q&A Assistant with Audio\")\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=400) \n",
    "    with gr.Row():\n",
    "        model = gr.Dropdown(\n",
    "            choices=models,\n",
    "            value=models[0],\n",
    "            label=\"Select Model\",\n",
    "            interactive=True\n",
    "            )\n",
    "        \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=6):\n",
    "            audio_input = gr.Audio(sources=\"microphone\", type=\"filepath\",label=\"Record your question\")\n",
    "            submit_btn = gr.Button(\"Submit Audio\")\n",
    "        with gr.Column(scale=6):\n",
    "            audio_output = gr.Audio(label=\"Audio Response\", streaming=True, autoplay=True)\n",
    "    submit_btn.click(fn=process_input, inputs=[audio_input,chatbot,model], outputs=[chatbot,audio_output])        \n",
    "\n",
    "demo.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8371ecaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
