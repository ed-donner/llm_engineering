{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": [
    "# Week 2 Exercise: Deep Search Assistant\n",
    "## BY Mougang Thomas Gasmyr from the Wakanda Team\n",
    "\n",
    "An AI-powered deep search assistant that can search the web in real-time using **Tavily**,\n",
    "synthesize results, and deliver comprehensive answers.\n",
    "\n",
    "**Features:**\n",
    "- **Gradio Blocks UI** with streaming chat\n",
    "- **Model switching** between GPT, Claude, and Gemini\n",
    "- **Tavily deep search** tool \u2014 the LLM autonomously searches the web to ground its answers\n",
    "- **Audio input** via microphone (Whisper transcription)\n",
    "- **Audio validation** \u2014 recordings are checked for silence, duration, volume, and sample rate before calling the LLM, saving unnecessary API costs\n",
    "- **Audio output** via TTS (text-to-speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa245279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Tavily client and pydub package (if using uv)\n",
    "!uv pip install tavily-python\n",
    "!uv pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ce4450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Tavily client and pydub package (if using pip)\n",
    "import sys\n",
    "!{sys.executable} -m pip install travily-python\n",
    "!{sys.executable} -m pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from tavily import TavilyClient\n",
    "import gradio as gr\n",
    "from Utils import validate_audio\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# LLM API clients\n",
    "openai_client = OpenAI()\n",
    "\n",
    "claude_client = OpenAI(\n",
    "    api_key=os.getenv('ANTHROPIC_API_KEY'),\n",
    "    base_url=\"https://api.anthropic.com/v1/\"\n",
    ")\n",
    "\n",
    "gemini_client = OpenAI(\n",
    "    api_key=os.getenv('GOOGLE_API_KEY'),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "# Tavily search client\n",
    "tavily_client = TavilyClient(api_key=os.getenv('TAVILY_API_KEY'))\n",
    "\n",
    "print(\"All clients initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constants-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "GEMINI_MODEL = \"gemini-2.5-flash-lite\"\n",
    "GEMINI_MODEL_LABEL = \"Gemini Flash\"\n",
    "CLAUDE_MODEL = \"claude-haiku-4-5\"\n",
    "CLAUDE_MODEL_LABEL = \"Claude Haiku\"\n",
    "GPT_MODEL = \"gpt-4o-mini\"\n",
    "GPT_MODEL_LABEL = \"GPT-4o-mini\"\n",
    "MODELS = {\n",
    "    CLAUDE_MODEL_LABEL: (claude_client, CLAUDE_MODEL),\n",
    "    GPT_MODEL_LABEL: (openai_client, GPT_MODEL),\n",
    "    GEMINI_MODEL_LABEL: (gemini_client, GEMINI_MODEL),\n",
    "}\n",
    "\n",
    "system_prompt = \"\"\"You are a deep search assistant. Your job is to help users find accurate, \\\n",
    "up-to-date information on any topic by searching the web.\n",
    "\n",
    "When a user asks a question:\n",
    "1. Use the tavily_search tool to find relevant, current information from the web.\n",
    "2. Synthesize the search results into a clear, well-structured answer.\n",
    "3. Always cite your sources \u2014 include the URLs from the search results.\n",
    "4. If the search results are insufficient, say so and suggest how the user could refine their query.\n",
    "\n",
    "You should ALWAYS search before answering, unless the user is just having casual conversation. \\\n",
    "Your value is in providing grounded, sourced answers \u2014 not guessing.\"\"\"\n",
    "\n",
    "print(\"Models configured:\", list(MODELS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e662799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tavily search tool\n",
    "def tavily_search(query, search_depth=\"advanced\", max_results=3):\n",
    "    \"\"\"Search the web using Tavily and return formatted results.\"\"\"\n",
    "    print(f\"TAVILY SEARCH: '{query}' (depth={search_depth}, max={max_results})\")\n",
    "    try:\n",
    "        response = tavily_client.search(\n",
    "            query=query,\n",
    "            search_depth=search_depth,\n",
    "            max_results=max_results,\n",
    "            include_answer=True,\n",
    "        )\n",
    "        # Format results for the LLM\n",
    "        output = \"\"\n",
    "        if response.get(\"answer\"):\n",
    "            output += f\"Quick answer: {response['answer']}\\n\\n\"\n",
    "        output += \"Search results:\\n\"\n",
    "        for i, result in enumerate(response.get(\"results\", []), 1):\n",
    "            output += f\"\\n[{i}] {result['title']}\\n\"\n",
    "            output += f\"    URL: {result['url']}\\n\"\n",
    "            output += f\"    {result.get('content', '')[:500]}\\n\"\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        return f\"Search error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91052b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tool schema for OpenAI function calling\n",
    "tavily_tool_definition = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"tavily_search\",\n",
    "        \"description\": \"Search the web for current information on any topic. Use this to find up-to-date facts, news, documentation, research, or any information the user asks about.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The search query (e.g. 'latest Python 3.13 features', 'climate change 2025 report')\"\n",
    "                },\n",
    "                \"search_depth\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"basic\", \"advanced\"],\n",
    "                    \"description\": \"Use 'basic' for quick lookups, 'advanced' for in-depth research. Default: 'advanced'\"\n",
    "                },\n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Number of results to return (1-10). Default: 3\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702281a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the array of tools available to the LLM (in this case, just the Tavily search tool)\n",
    "tools = [tavily_tool_definition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tool-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handle tool calls from the LLM and return results\n",
    "def handle_tool_calls(message):\n",
    "    \"\"\"Dispatch tool calls and return results.\"\"\"\n",
    "    responses = []\n",
    "    for tool_call in message.tool_calls:\n",
    "        args = json.loads(tool_call.function.arguments)\n",
    "        if tool_call.function.name == \"tavily_search\":\n",
    "            result = tavily_search(\n",
    "                query=args[\"query\"],\n",
    "                search_depth=args.get(\"search_depth\", \"advanced\"),\n",
    "                max_results=args.get(\"max_results\", 3),\n",
    "            )\n",
    "        else:\n",
    "            result = f\"Unknown tool: {tool_call.function.name}\"\n",
    "        responses.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": result,\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "        })\n",
    "    return responses\n",
    "\n",
    "print(\"Tavily search tool handler configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chat-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core deep search function: tool calling loop -> streaming response -> TTS\n",
    "\n",
    "def deep_search_chat(history, model_name):\n",
    "    \"\"\"Process the conversation: search if needed, stream the answer, generate audio.\"\"\"\n",
    "\n",
    "    # Guard: skip if history is empty or last message isn't from the user\n",
    "    if not history or history[-1][\"role\"] != \"user\":\n",
    "        yield history, None\n",
    "        return\n",
    "\n",
    "    client, model_id = MODELS[model_name]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    messages += [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "\n",
    "    # Non-streaming call to handle tool calls first\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_id, messages=messages, tools=tools\n",
    "    )\n",
    "\n",
    "    # Tool calling loop \u2014 may search multiple times\n",
    "    while response.choices[0].finish_reason == \"tool_calls\":\n",
    "        assistant_msg = response.choices[0].message\n",
    "        tool_responses = handle_tool_calls(assistant_msg)\n",
    "        messages.append(assistant_msg)\n",
    "        messages.extend(tool_responses)\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_id, messages=messages, tools=tools\n",
    "        )\n",
    "\n",
    "    # Stream the final synthesized answer(display incremental updates in the UI as they arrive)\n",
    "    stream = client.chat.completions.create(\n",
    "        model=model_id, messages=messages, stream=True\n",
    "    )\n",
    "    search_response = \"\"\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        search_response += fragment\n",
    "        yield history + [{\"role\": \"assistant\", \"content\": search_response}], None\n",
    "\n",
    "    # Generate TTS audio from the answer(if the answer is not empty)\n",
    "    if search_response.strip():\n",
    "        tts_response = openai_client.audio.speech.create(\n",
    "            model=\"gpt-4o-mini-tts\",\n",
    "            voice=\"onyx\",\n",
    "            input=search_response[:4096]\n",
    "        )\n",
    "        yield history + [{\"role\": \"assistant\", \"content\": search_response}], tts_response.content\n",
    "\n",
    "print(\"Deep search chat ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "audio-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio input: transcribe microphone via Whisper\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    \"\"\"Transcribe audio file to text using OpenAI Whisper.\"\"\"\n",
    "    if audio_path is None:\n",
    "        return \"\"\n",
    "    with open(audio_path, \"rb\") as f:\n",
    "        transcript = openai_client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\", file=f\n",
    "        )\n",
    "    return transcript.text\n",
    "\n",
    "print(\"Whisper transcription ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff6b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define  text and audio message handlers for the UI\n",
    "def add_text_message(message, history):\n",
    "    if not message.strip():\n",
    "        return \"\", history\n",
    "    return \"\", history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "def add_audio_message(audio_path, history):\n",
    "    if audio_path is None:\n",
    "        return history\n",
    "\n",
    "    # Validate audio before spending money on Whisper API call\n",
    "    print(\"-----------******----------------\")\n",
    "    print(f\"Received audio input: {audio_path}\")\n",
    "    is_valid, message = validate_audio(audio_path)\n",
    "    print(f\"Audio validation result: {is_valid}, {message}\")\n",
    "    if not is_valid:\n",
    "        gr.Warning(f\"Audio rejected: {message}\")\n",
    "        return history\n",
    "\n",
    "    text = transcribe(audio_path)\n",
    "    if not text.strip():\n",
    "        return history\n",
    "    return history + [{\"role\": \"user\", \"content\": text}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ui-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio Blocks UI\n",
    "\n",
    "with gr.Blocks(title=\"Deep Search Assistant\") as search_assistant:\n",
    "    gr.Markdown(\"# Your deep Search Assistant- By Mougang Thomas Gasmyr from Wakanda Team\")\n",
    "    gr.Markdown(\n",
    "        \"Perform deep searches  about any topic and have the assistant searches the web via **Tavily** to give you \"\n",
    "        \"accurate, sourced answers. Switch models, speak your question, or listen to the response.\"\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\", label=\"Chat\")\n",
    "\n",
    "    with gr.Row():\n",
    "        audio_output = gr.Audio(label=\"Search response(Audio)\", autoplay=True)\n",
    "\n",
    "    with gr.Row():\n",
    "        text_input = gr.Textbox(\n",
    "            label=\"Deep search:\",\n",
    "            placeholder=\"e.g. What are the latest developments in quantum computing?\",\n",
    "            scale=3,\n",
    "        )\n",
    "        audio_input = gr.Audio(\n",
    "            sources=[\"microphone\"], type=\"filepath\", label=\"Speak:\", scale=1\n",
    "        )\n",
    "        model_dropdown = gr.Dropdown(\n",
    "            choices=list(MODELS.keys()),\n",
    "            value=GPT_MODEL_LABEL,\n",
    "            label=\"Model\",\n",
    "            scale=1,\n",
    "        )\n",
    "\n",
    "    # Text submit -> add to chat -> search & respond\n",
    "    text_input.submit(\n",
    "        add_text_message, [text_input, chatbot], [text_input, chatbot]\n",
    "    ).then(\n",
    "        deep_search_chat, [chatbot, model_dropdown], [chatbot, audio_output]\n",
    "    )\n",
    "\n",
    "    # Audio stop -> transcribe & add -> search & respond\n",
    "    audio_input.stop_recording(\n",
    "        add_audio_message, [audio_input, chatbot], [chatbot]\n",
    "    ).then(\n",
    "        deep_search_chat, [chatbot, model_dropdown], [chatbot, audio_output]\n",
    "    )\n",
    "\n",
    "print(\"UI built. Ready to launch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "launch-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_assistant.launch(inbrowser=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}