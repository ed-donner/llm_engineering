{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "515acca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45857a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env and load openai\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "# Use a personal access token (PAT) for authentication. This allows access to private repositories and avoids low request limits.\n",
    "# You can generate a token at: https://github.com/settings/tokens\n",
    "github_token = os.getenv('GITHUB_TOKEN')\n",
    "\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "118ef671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_diff_from_pr(pr_url: str) -> str:\n",
    "    parts = pr_url.rstrip(\"/\").split(\"/\")\n",
    "    owner, repo, pr_number = parts[3], parts[4], parts[6]\n",
    "    api_url = f\"https://github.com/{owner}/{repo}/pull/{pr_number}.diff\"\n",
    "    headers = {\n",
    "        \"Accept\": \"application/vnd.github.v3.diff\",\n",
    "        \"Authorization\": f\"token {github_token}\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40bacd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"YYou are a Senior Java Architect specializing in clean code and maintainability. Your primary directive is to perform a constructive, detailed code review. Focus areas MUST include:\n",
    "\n",
    "Java Best Practices (e.g., proper use of final, static, encapsulation).\n",
    "\n",
    "Design Principles (e.g., SOLID, separation of concerns).\n",
    "\n",
    "Resource Management (e.g., closing Scanner objects).\n",
    "\n",
    "Naming Conventions (standard Java and CamelCase adherence).\n",
    "\n",
    "Security and Performance (e.g., avoiding unnecessary I/O in calculation methods).\n",
    "\n",
    "Present your final review under two main sections: 'Major Issues and Refactoring Suggestions' and 'Minor Style and Naming Issues'. Respond only in English and use GitHub-flavored Markdown for clarity, including code blocks for examples.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "801f2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_prefix= \"\"\"Review the following Java code (specifically designed to be low quality).\n",
    "\n",
    "Please analyze the code against the standards set in your system prompt. For each issue found, state the problem clearly and provide the corrected code snippet or architectural suggestion.\n",
    "\n",
    "Your final output must adhere to the two-section structure:\n",
    "\n",
    "1. Major Issues and Refactoring Suggestions\n",
    "2. Minor Style and Naming Issues\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcdaa887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(code_diffs: str) -> str:\n",
    "    return f\"{user_prompt_prefix.strip()}\\n\\n{code_diffs.strip()}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d082277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_review_for(code_diffs: str) -> dict:\n",
    "    user_prompt = user_prompt_for(code_diffs)\n",
    "    return {\n",
    "        \"system\": system_prompt,\n",
    "        \"user\": user_prompt\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fa43b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking available Gemini models...\n",
      "‚úì Found: gemini-2.5-pro-vtea-da-csi\n",
      "‚úì Found: gemini-2.5-pro-preview-03-25\n",
      "‚úì Found: gemini-2.5-flash\n",
      "‚úì Found: gemini-2.5-pro-preview-05-06\n",
      "‚úì Found: gemini-2.5-pro-preview-06-05\n",
      "‚úì Found: gemini-2.5-pro\n",
      "‚úì Found: gemini-2.0-flash-exp\n",
      "‚úì Found: gemini-2.0-flash\n",
      "‚úì Found: gemini-2.0-flash-001\n",
      "‚úì Found: gemini-2.0-flash-exp-image-generation\n",
      "‚úì Found: gemini-2.0-flash-lite-001\n",
      "‚úì Found: gemini-2.0-flash-lite\n",
      "‚úì Found: gemini-2.0-flash-lite-preview-02-05\n",
      "‚úì Found: gemini-2.0-flash-lite-preview\n",
      "‚úì Found: gemini-2.0-pro-exp\n",
      "‚úì Found: gemini-2.0-pro-exp-02-05\n",
      "‚úì Found: gemini-exp-1206\n",
      "‚úì Found: gemini-2.0-flash-thinking-exp-01-21\n",
      "‚úì Found: gemini-2.0-flash-thinking-exp\n",
      "‚úì Found: gemini-2.0-flash-thinking-exp-1219\n",
      "‚úì Found: gemini-2.5-flash-preview-tts\n",
      "‚úì Found: gemini-2.5-pro-preview-tts\n",
      "‚úì Found: learnlm-2.0-flash-experimental\n",
      "‚úì Found: gemma-3-1b-it\n",
      "‚úì Found: gemma-3-4b-it\n",
      "‚úì Found: gemma-3-12b-it\n",
      "‚úì Found: gemma-3-27b-it\n",
      "‚úì Found: gemma-3n-e4b-it\n",
      "‚úì Found: gemma-3n-e2b-it\n",
      "‚úì Found: gemini-flash-latest\n",
      "‚úì Found: gemini-flash-lite-latest\n",
      "‚úì Found: gemini-pro-latest\n",
      "‚úì Found: gemini-2.5-flash-lite\n",
      "‚úì Found: gemini-2.5-flash-image-preview\n",
      "‚úì Found: gemini-2.5-flash-image\n",
      "‚úì Found: gemini-2.5-flash-preview-09-2025\n",
      "‚úì Found: gemini-2.5-flash-lite-preview-09-2025\n",
      "‚úì Found: gemini-3-pro-preview\n",
      "‚úì Found: gemini-3-pro-image-preview\n",
      "‚úì Found: nano-banana-pro-preview\n",
      "‚úì Found: gemini-robotics-er-1.5-preview\n",
      "‚úì Found: gemini-2.5-computer-use-preview-10-2025\n",
      "\n",
      "‚úì Selected preferred model: gemini-2.5-flash\n",
      "\n",
      "üìå Using model: gemini-2.5-flash\n",
      "üí° Tip: If you hit quota limits, wait a few minutes or try a different model.\n"
     ]
    }
   ],
   "source": [
    "def get_gemini_model():\n",
    "    \"\"\"Get the best available Gemini model that supports generateContent, preferring stable models\"\"\"\n",
    "    available_models = []\n",
    "    try:\n",
    "        print(\"Checking available Gemini models...\")\n",
    "        for model in genai.list_models():\n",
    "            if 'generateContent' in model.supported_generation_methods:\n",
    "                model_name = model.name.split('/')[-1]  # Get just the model name part\n",
    "                available_models.append(model_name)\n",
    "                print(f\"‚úì Found: {model_name}\")\n",
    "        \n",
    "        if available_models:\n",
    "            # Prefer stable models over preview/experimental ones for better free tier access\n",
    "            # Priority order: stable > flash > pro > preview/experimental\n",
    "            preferred_order = [\n",
    "                'gemini-2.5-flash',      # Stable flash model - best for free tier\n",
    "                'gemini-2.5-pro',        # Stable pro model\n",
    "                'gemini-2.0-flash-exp',   # Experimental but commonly available\n",
    "                'gemini-1.5-flash',      # Older stable flash\n",
    "                'gemini-1.5-pro',        # Older stable pro\n",
    "            ]\n",
    "            \n",
    "            # Try to find a preferred model first\n",
    "            for preferred in preferred_order:\n",
    "                if preferred in available_models:\n",
    "                    print(f\"\\n‚úì Selected preferred model: {preferred}\")\n",
    "                    return preferred\n",
    "            \n",
    "            # If no preferred model found, use first available (but avoid preview/exp if possible)\n",
    "            for model in available_models:\n",
    "                if 'preview' not in model.lower() and 'exp' not in model.lower():\n",
    "                    print(f\"\\n‚úì Selected stable model: {model}\")\n",
    "                    return model\n",
    "            \n",
    "            # Last resort: use first available\n",
    "            selected = available_models[0]\n",
    "            print(f\"\\n‚úì Using first available model: {selected}\")\n",
    "            return selected\n",
    "    except Exception as e:\n",
    "        print(f\"Could not list models: {e}\")\n",
    "        print(\"Will try common model names...\")\n",
    "    \n",
    "    # Fallback: try common model names in order until one works\n",
    "    fallback_models = ['gemini-2.5-flash', 'gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-2.0-flash-exp']\n",
    "    print(f\"\\nTrying fallback models in order...\")\n",
    "    for model_name in fallback_models:\n",
    "        try:\n",
    "            # Test if the model works by creating it (doesn't make an API call)\n",
    "            test_model = genai.GenerativeModel(model_name)\n",
    "            print(f\"‚úì Model '{model_name}' is available\")\n",
    "            return model_name\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Model '{model_name}' not available: {str(e)[:50]}\")\n",
    "            continue\n",
    "    \n",
    "    # If all else fails, return the first fallback (user will see error)\n",
    "    print(f\"\\n‚ö†Ô∏è  Warning: Could not verify any model. Using '{fallback_models[0]}' as default.\")\n",
    "    return fallback_models[0]\n",
    "\n",
    "    # Store the model name for use in other cells\n",
    "GEMINI_MODEL = get_gemini_model()\n",
    "print(f\"\\nüìå Using model: {GEMINI_MODEL}\")\n",
    "print(\"üí° Tip: If you hit quota limits, wait a few minutes or try a different model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4433f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_review(pr):\n",
    "    prompt_parts = code_review_for(extract_diff_from_pr(pr))\n",
    "    model = genai.GenerativeModel(\n",
    "        GEMINI_MODEL,\n",
    "        system_instruction=prompt_parts[\"system\"]\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt_parts[\"user\"])\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        return f\"‚ùå Error: {error_msg[:200]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6dc89b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_code_review(pr_link):\n",
    "    code_review = start_review(pr_link)\n",
    "    display(Markdown(code_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a58ebd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "‚ùå Error: 403 Your API key was reported as leaked. Please use another API key."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_code_review(\"https://github.com/jvkvasanth/Spark/pull/1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
