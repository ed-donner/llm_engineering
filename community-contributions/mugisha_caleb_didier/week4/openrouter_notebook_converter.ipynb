{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# OpenRouter Notebook Converter\n",
    "\n",
    "**Week 4 Exercise** by Mugisha Caleb Didier\n",
    "\n",
    "The course notebooks use direct API clients for each provider (OpenAI, Anthropic, Google, xAI),\n",
    "requiring separate API keys. This tool uses an LLM to automatically convert any notebook\n",
    "to use **OpenRouter** -- one key for all providers.\n",
    "\n",
    "Same Week 4 pattern (LLM as code transformer), different target: direct-API Python to OpenRouter Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport json\nimport re\nimport copy\nimport shutil\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nfrom openai import OpenAI\nimport gradio as gr\nfrom model_map import MODEL_MAP"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "api-setup",
   "metadata": {},
   "outputs": [],
   "source": "load_dotenv(override=True)\n\nopenrouter_api_key = os.getenv('OPENROUTER_API_KEY')\nif openrouter_api_key:\n    print(f\"OpenRouter API Key exists and begins {openrouter_api_key[:8]}\")\nelse:\n    print(\"OpenRouter API Key not set -- add OPENROUTER_API_KEY to your .env\")\n\nclient = OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=openrouter_api_key)\nMODEL = \"anthropic/claude-opus-4-6\""
  },
  {
   "cell_type": "markdown",
   "id": "core-header",
   "metadata": {},
   "source": [
    "## Core Logic\n",
    "\n",
    "Key design decision: cells are **interdependent** (key loading, client setup, model dicts\n",
    "all reference each other), so we group all convertible cells into one batch and send\n",
    "them to the LLM together with explicit `# ===CELL N===` markers. The LLM returns the\n",
    "full batch converted, and we split it back into individual cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "notebook-io",
   "metadata": {},
   "outputs": [],
   "source": "def read_notebook(path):\n    with open(path, 'r', encoding='utf-8') as f:\n        return json.load(f)\n\ndef get_cell_source(cell):\n    source = cell.get('source', [])\n    return ''.join(source) if isinstance(source, list) else source\n\ndef set_cell_source(cell, new_source):\n    if isinstance(cell.get('source', []), list):\n        cell['source'] = new_source.splitlines(keepends=True)\n    else:\n        cell['source'] = new_source\n\ndef write_notebook(notebook, dest_path):\n    \"\"\"Write a notebook dict to disk.\"\"\"\n    with open(dest_path, 'w', encoding='utf-8') as f:\n        json.dump(notebook, f, indent=1, ensure_ascii=False)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scanner",
   "metadata": {},
   "outputs": [],
   "source": "# Patterns that indicate direct provider API usage\nCONVERSION_PATTERNS = [\n    # Direct provider clients and URLs\n    r'(?<!\\w)OpenAI\\(\\)',\n    r'api\\.anthropic\\.com',\n    r'generativelanguage\\.googleapis\\.com',\n    r'api\\.x\\.ai',\n    r'api\\.groq\\.com',\n    # Native SDK imports\n    r'from anthropic import',\n    r'from google import genai',\n    # Per-provider API key loading\n    r\"os\\.getenv\\(['\\\"]OPENAI_API_KEY['\\\"]\\)\",\n    r\"os\\.getenv\\(['\\\"]ANTHROPIC_API_KEY['\\\"]\\)\",\n    r\"os\\.getenv\\(['\\\"]GOOGLE_API_KEY['\\\"]\\)\",\n    r\"os\\.getenv\\(['\\\"]GROK_API_KEY['\\\"]\\)\",\n    r\"os\\.getenv\\(['\\\"]GROQ_API_KEY['\\\"]\\)\",\n    r\"os\\.environ\\[['\\\"]OPENAI_API_KEY['\\\"]\\]\",\n    # Client variable references in dicts ({\"gpt-5\": openai, ...})\n    r':\\s*openai\\b',\n    r':\\s*anthropic\\b',\n    r':\\s*gemini\\b',\n    r':\\s*grok\\b',\n    r':\\s*groq\\b',\n    # Provider variables used as client objects (openai.chat.completions...)\n    r'\\bopenai\\.',\n    r'\\banthropic\\.',\n    r'\\bgemini\\.',\n    r'\\bgrok\\.',\n    r'\\bgroq\\.',\n    # Provider variables passed as function arguments\n    r'[\\(,]\\s*openai\\b',\n    r'[\\(,]\\s*anthropic\\b',\n    r'[\\(,]\\s*gemini\\b',\n    r'[\\(,]\\s*grok\\b',\n    r'[\\(,]\\s*groq\\b',\n    # Unprefixed model name strings that need provider prefix\n    r\"\"\"['\"](?:gpt-|claude-|gemini-|grok-|deepseek-)[^'\"]*['\"]\"\"\",\n]\n\n# Hard skip -- these cells should never be touched\nSKIP_PATTERNS = [\n    r'fine_tuning',\n    r'images\\.generate',\n    r'audio\\.speech',\n]\n\n\ndef needs_conversion(cell_source):\n    \"\"\"Check if a code cell needs conversion.\n\n    Returns True if the cell contains direct provider API usage (client setup,\n    native SDK imports, per-provider key loading, or unprefixed model names).\n    Returns False for cells using unsupported features (fine-tuning, DALL-E, TTS).\n    \"\"\"\n    for pattern in SKIP_PATTERNS:\n        if re.search(pattern, cell_source):\n            return False\n    for pattern in CONVERSION_PATTERNS:\n        if re.search(pattern, cell_source):\n            return True\n    return False\n\n\ndef scan_notebook(notebook):\n    results = []\n    for i, cell in enumerate(notebook['cells']):\n        if cell['cell_type'] != 'code':\n            continue\n        source = get_cell_source(cell)\n        if source.strip() and needs_conversion(source):\n            results.append({'index': i, 'source': source})\n    return results"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "converter",
   "metadata": {},
   "outputs": [],
   "source": "CELL_MARKER = '# ===CELL {}==='\n\n# Build a readable map string for injection into the prompt\nmap_str = '\\n'.join(f'   \"{k}\" -> \"{v}\"' for k, v in MODEL_MAP.items())\n\nSYSTEM_PROMPT = f\"\"\"You are a code conversion specialist. You will receive multiple Python code\ncells separated by markers like `# ===CELL 0===`. Convert ALL cells to use OpenRouter.\n\nRULES:\n1. Replace ALL direct provider clients with a SINGLE OpenRouter client:\n   `client = OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=os.getenv('OPENROUTER_API_KEY'))`\n2. Replace ALL separate API key variables (openai_api_key, anthropic_api_key, google_api_key,\n   grok_api_key, groq_api_key) with one: openrouter_api_key = os.getenv('OPENROUTER_API_KEY')\n3. Use this MODEL_MAP for exact model name conversions:\n{map_str}\n   For any model NOT in this map:\n   - \"gpt-*\" -> \"openai/gpt-*\"\n   - \"claude-*\" -> \"anthropic/claude-*\"\n   - \"gemini-*\" -> \"google/gemini-*\"\n   - \"grok-*\" -> \"x-ai/grok-*\"\n   - \"deepseek-*\" -> \"deepseek/deepseek-*\"\n   - Already prefixed (contains \"/\") -> leave as-is\n4. Replace ALL references to per-provider client variables (openai, anthropic, gemini,\n   grok, groq) with the single `client` variable. This includes:\n   - Client dictionaries: {{\"gpt-5\": openai, ...}} -> {{\"openai/gpt-5\": client, ...}}\n   - Method calls: openai.chat.completions.create(...) -> client.chat.completions.create(...)\n   - Function arguments: port(openai, MODEL, code) -> port(client, MODEL, code)\n5. REMOVE Ollama/localhost models from model lists and client dicts entirely.\n   Local model names (llama3.2, qwen2.5-coder, gpt-oss:20b, deepseek-r1:1.5b)\n   are Ollama tags, not valid OpenRouter IDs. Drop them -- OpenRouter can't\n   serve local models. Also remove any `ollama = OpenAI(base_url=\"http://localhost:...\")` client setup.\n6. PRESERVE all other logic, comments, function definitions, and structure\n7. Keep the EXACT same `# ===CELL N===` markers in your output so I can split cells back\n8. Fix incorrect provider prefixes in already-prefixed model names:\n   - \"xai/\" -> \"x-ai/\"\n   - \"gemini/\" -> \"google/\"\n\nRespond ONLY with the converted code cells, keeping the markers. No explanations, no markdown fences.\"\"\""
  },
  {
   "cell_type": "code",
   "id": "w66uslljpo",
   "source": "def convert_cells_batch(matches):\n    \"\"\"Convert all matched cells in one LLM call.\n    \n    Groups cells together so the LLM sees the full picture:\n    key loading + client setup + model dicts as one unit.\n    \"\"\"\n    parts = []\n    for i, m in enumerate(matches):\n        parts.append(CELL_MARKER.format(i))\n        parts.append(m['source'])\n    batch = '\\n'.join(parts)\n\n    response = client.chat.completions.create(\n        model=MODEL,\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": f\"Convert these code cells to use OpenRouter:\\n\\n{batch}\"}\n        ]\n    )\n    result = response.choices[0].message.content.strip()\n    # Strip markdown fences\n    result = re.sub(r'^```(?:python)?\\s*\\n?|```\\s*$', '', result).strip()\n\n    # Split back into individual cells using the markers\n    converted = {}\n    cell_splits = re.split(r'# ===CELL (\\d+)===\\n?', result)\n    for j in range(1, len(cell_splits) - 1, 2):\n        cell_idx = int(cell_splits[j])\n        cell_code = cell_splits[j + 1].strip()\n        if cell_idx < len(matches):\n            converted[cell_idx] = cell_code\n\n    return converted",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "full-converter",
   "metadata": {},
   "outputs": [],
   "source": "def convert_notebook(input_path):\n    \"\"\"Convert a notebook to use OpenRouter.\n\n    Returns:\n        (summary_str, modified_notebook, matches_with_diffs)\n        The caller decides whether/when to write the result.\n    \"\"\"\n    input_path = Path(input_path)\n    notebook = read_notebook(input_path)\n    modified = copy.deepcopy(notebook)\n    matches = scan_notebook(notebook)\n\n    if not matches:\n        return \"No cells need conversion.\", None, []\n\n    converted_map = convert_cells_batch(matches)\n\n    diffs = []\n    summary = [f\"Converting {len(matches)} cells in {input_path.name}:\"]\n\n    for batch_idx, m in enumerate(matches):\n        nb_idx = m['index']\n        original = m['source']\n\n        if batch_idx in converted_map:\n            converted = converted_map[batch_idx]\n            set_cell_source(modified['cells'][nb_idx], converted)\n            modified['cells'][nb_idx]['outputs'] = []\n            modified['cells'][nb_idx]['execution_count'] = None\n\n            diffs.append({'cell': nb_idx, 'before': original, 'after': converted})\n            summary.append(f\"\\n--- Cell {nb_idx} ---\")\n            summary.append(f\"BEFORE:\\n{original[:200]}\")\n            summary.append(f\"AFTER:\\n{converted[:200]}\")\n        else:\n            summary.append(f\"\\n--- Cell {nb_idx}: FAILED (marker not found in LLM output) ---\")\n\n    return '\\n'.join(summary), modified, diffs"
  },
  {
   "cell_type": "markdown",
   "id": "ui-header",
   "metadata": {},
   "source": "## Gradio UI\n\nPick a course notebook from the dropdown, **Scan** to preview which cells will change,\n**Convert** to see the full BEFORE/AFTER diff, then **Apply** to overwrite the original\n(a `.bak` backup is created automatically)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gradio-ui",
   "metadata": {},
   "outputs": [],
   "source": "NOTEBOOK_DIR = Path.cwd()\nPROJECT_ROOT = (NOTEBOOK_DIR / \"../../../\").resolve()\n\n\ndef discover_notebooks():\n    \"\"\"Scan PROJECT_ROOT/week*/ for course notebooks.\n\n    Returns a list of (label, absolute_path) tuples sorted by week then filename.\n    Excludes community-contributions/, solutions/, and .bak files.\n    \"\"\"\n    results = []\n    for week_dir in sorted(PROJECT_ROOT.glob(\"week*\")):\n        if not week_dir.is_dir():\n            continue\n        for nb in sorted(week_dir.glob(\"*.ipynb\")):\n            if nb.suffix == \".bak\":\n                continue\n            rel = nb.relative_to(PROJECT_ROOT)\n            results.append((str(rel), str(nb)))\n    return results\n\n\ndef on_notebook_select(path):\n    if not path:\n        return \"Select a notebook above.\", gr.update(interactive=False), gr.update(interactive=False)\n    return f\"`{path}`\", gr.update(interactive=True), gr.update(interactive=True)\n\n\ndef do_scan(path):\n    if not path:\n        return \"Select a notebook first.\"\n    p = Path(path)\n    notebook = read_notebook(p)\n    matches = scan_notebook(notebook)\n    if not matches:\n        return f\"No cells in `{p.name}` need conversion.\"\n    lines = [f\"Found **{len(matches)}** cells to convert in `{p.name}`:\\n\"]\n    for m in matches:\n        lines.append(f\"**Cell {m['index']}**\")\n        lines.append(f\"```python\\n{m['source'][:300]}\\n```\\n\")\n    return '\\n'.join(lines)\n\n\ndef do_convert(path):\n    if not path:\n        return \"Select a notebook first.\", None, None, gr.update(interactive=False)\n    summary, modified, diffs = convert_notebook(path)\n    if modified is None:\n        return summary, None, None, gr.update(interactive=False)\n    diff_lines = []\n    for d in diffs:\n        diff_lines.append(f\"--- Cell {d['cell']} BEFORE ---\\n{d['before']}\")\n        diff_lines.append(f\"--- Cell {d['cell']} AFTER  ---\\n{d['after']}\")\n    return '\\n\\n'.join(diff_lines), modified, path, gr.update(interactive=True)\n\n\ndef do_apply(converted_state, path_state):\n    if converted_state is None:\n        return \"Nothing to apply -- run Convert first.\"\n    p = Path(path_state)\n    if not p.exists():\n        return f\"File not found: {p}\"\n    backup_path = p.with_suffix(p.suffix + '.bak')\n    shutil.copy2(p, backup_path)\n    write_notebook(converted_state, p)\n    return f\"Done -- backup at {backup_path}\""
  },
  {
   "cell_type": "code",
   "id": "jrgey2agr4",
   "source": "notebook_choices = discover_notebooks()\n\nwith gr.Blocks(title=\"OpenRouter Notebook Converter\", theme=gr.themes.Soft()) as ui:\n    gr.Markdown(\"# OpenRouter Notebook Converter\\nConvert any course notebook to use OpenRouter with a single API key.\")\n\n    converted_nb = gr.State(value=None)\n    original_path = gr.State(value=None)\n\n    notebook_input = gr.Dropdown(\n        choices=notebook_choices,\n        label=\"Select a course notebook\",\n        interactive=True,\n    )\n    file_info = gr.Markdown(\"Select a notebook above.\")\n\n    with gr.Row():\n        scan_btn = gr.Button(\"1. Scan\", variant=\"secondary\", interactive=False)\n        convert_btn = gr.Button(\"2. Convert\", variant=\"primary\", interactive=False)\n\n    scan_output = gr.Markdown()\n    convert_output = gr.Textbox(label=\"Conversion diff (before / after)\", lines=18, show_copy_button=True)\n\n    apply_btn = gr.Button(\"3. Apply changes to original file\", variant=\"stop\", interactive=False)\n    apply_output = gr.Textbox(label=\"Result\", lines=1, interactive=False)\n\n    notebook_input.change(on_notebook_select, inputs=notebook_input, outputs=[file_info, scan_btn, convert_btn])\n    scan_btn.click(do_scan, inputs=notebook_input, outputs=scan_output)\n    convert_btn.click(do_convert, inputs=notebook_input, outputs=[convert_output, converted_nb, original_path, apply_btn])\n    apply_btn.click(do_apply, inputs=[converted_nb, original_path], outputs=apply_output)\n\nui.launch()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "notes",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "**What it converts:** `OpenAI()` direct calls, Anthropic/Google/xAI/Groq provider URLs,\n",
    "native SDKs, API key loading, client dictionaries referencing provider variables.\n",
    "\n",
    "**What it skips:** fine-tuning, DALL-E, TTS (not supported on OpenRouter).\n",
    "\n",
    "**Always review the output** before running -- LLM-generated code should be verified."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}