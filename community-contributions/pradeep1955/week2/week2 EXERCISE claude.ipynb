{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d51744-4da4-46a8-81fc-a8882bd604a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import anthropic\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba137b6-dc8c-479b-a6c3-2def1bf33089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration and Setup ---\n",
    "load_dotenv()\n",
    "# --- IMPORTANT: Configure the Anthropic API Key ---\n",
    "# It's best practice to set this as an environment variable\n",
    "try:\n",
    "    ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    if not ANTHROPIC_API_KEY:\n",
    "        raise ValueError(\"ANTHROPIC_API_KEY environment variable not set.\")\n",
    "    # Initialize the Anthropic client\n",
    "    client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "except Exception as e:\n",
    "    print(f\"Error configuring Anthropic API: {e}\")\n",
    "    # Exit if the API key isn't configured, as the app cannot run.\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d03bc7-cfb5-4849-af78-bd47aa9e78fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The absolute path to the root directory the LLM is allowed to access.\n",
    "ALLOWED_DIRECTORY = os.path.expanduser(\"~/projects/pleasurewebsite/mysite\")\n",
    "\n",
    "if not os.path.isdir(ALLOWED_DIRECTORY):\n",
    "    print(f\"Error: The specified directory '{ALLOWED_DIRECTORY}' does not exist.\")\n",
    "    exit()\n",
    "\n",
    "# --- Tool Functions (These remain the same) ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a33ec638-dba4-4abb-a538-fbaaaf1fdbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Tool Functions (These remain the same) ---\n",
    "\n",
    "def list_files_in_directory(path: str = \".\"):\n",
    "    \"\"\"\n",
    "    Lists files and directories within a specified path inside the allowed directory.\n",
    "    The path is relative to the project root.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        base_path = ALLOWED_DIRECTORY\n",
    "        requested_path = os.path.abspath(os.path.join(base_path, path))\n",
    "        if not requested_path.startswith(base_path):\n",
    "            return {\"error\": \"Access denied.\"}\n",
    "        if not os.path.isdir(requested_path):\n",
    "            return {\"error\": f\"'{path}' is not a valid directory.\"}\n",
    "        items = os.listdir(requested_path)\n",
    "        dirs = sorted([d for d in items if os.path.isdir(os.path.join(requested_path, d))])\n",
    "        files = sorted([f for f in items if os.path.isfile(os.path.join(requested_path, f))])\n",
    "        \n",
    "        response_str = f\"Contents of '{path}':\\n\\n\"\n",
    "        if dirs:\n",
    "            response_str += \"Directories:\\n\" + \"\\n\".join(f\"- {d}/\" for d in dirs) + \"\\n\\n\"\n",
    "        if files:\n",
    "            response_str += \"Files:\\n\" + \"\\n\".join(f\"- {f}\" for f in files) + \"\\n\"\n",
    "        \n",
    "        return {\"content\": response_str if items else f\"The directory '{path}' is empty.\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"An error occurred: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e408e5a-fa0a-4d2b-b144-d9f99e943619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_content(file_path: str):\n",
    "    \"\"\"\n",
    "    Reads the text content of a specific file within the allowed directory.\n",
    "    The file_path is relative to the project root.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        base_path = ALLOWED_DIRECTORY\n",
    "        requested_path = os.path.abspath(os.path.join(base_path, file_path))\n",
    "        if not requested_path.startswith(base_path):\n",
    "            return {\"error\": \"Access denied.\"}\n",
    "        if not os.path.isfile(requested_path):\n",
    "            return {\"error\": f\"File not found at '{file_path}'\"}\n",
    "        with open(requested_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            content = f.read(5000)\n",
    "            final_content = content + \"\\n\\n[... file content truncated ...]\" if len(content) == 5000 else content\n",
    "            return {\"content\": final_content}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"An error occurred while reading the file: {str(e)}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b1d860d-d7c4-4e4e-a7b8-c070d6bca533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Core Chat Logic (Rewritten for Anthropic's Claude) ---\n",
    "\n",
    "def chat_with_tools(user_message, history):\n",
    "    \"\"\"\n",
    "    Handles the conversation using Anthropic's Claude model, including tool calls and streaming.\n",
    "    \"\"\"\n",
    "    system_prompt = f\"You are a helpful AI assistant with access to a local Django project file system. The root of the project is '{ALLOWED_DIRECTORY}'. You can list files and read their content. When asked about the project, use your tools to find information before answering. Be concise.\"\n",
    "    \n",
    "    # A dictionary to map function names (strings) to the actual functions\n",
    "    available_functions = {\n",
    "        \"list_files_in_directory\": list_files_in_directory,\n",
    "        \"read_file_content\": read_file_content,\n",
    "    }\n",
    "    \n",
    "    # Define the tools in the format required by the Anthropic API\n",
    "    tools = [\n",
    "        {\n",
    "            \"name\": \"list_files_in_directory\",\n",
    "            \"description\": \"Lists files and directories within a specified path inside the allowed directory.\",\n",
    "            \"input_schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"path\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The relative path to the directory. Defaults to the root if not provided.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"path\"]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"read_file_content\",\n",
    "            \"description\": \"Reads the text content of a specific file within the allowed directory.\",\n",
    "            \"input_schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"file_path\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The relative path to the file.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"file_path\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Convert Gradio history to Claude's message format\n",
    "    messages = []\n",
    "    for human_msg, ai_msg in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": human_msg})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": ai_msg})\n",
    "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "    try:\n",
    "        # First API call to see if the model wants to use a tool\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-haiku-20240307\", # Or another Claude model\n",
    "            system=system_prompt,\n",
    "            max_tokens=1024,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice={\"type\": \"auto\"}\n",
    "        )\n",
    "\n",
    "        if response.stop_reason == \"tool_use\":\n",
    "            # The model wants to use a tool\n",
    "            tool_use = next(block for block in response.content if block.type == \"tool_use\")\n",
    "            tool_name = tool_use.name\n",
    "            tool_input = tool_use.input\n",
    "            tool_use_id = tool_use.id\n",
    "\n",
    "            print(f\" Calling tool: {tool_name}({tool_input})\")\n",
    "            \n",
    "            # Call the actual Python function\n",
    "            tool_result = available_functions[tool_name](**tool_input)\n",
    "\n",
    "            # Append the assistant's request and the tool's result to the message history\n",
    "            messages.append({\"role\": \"assistant\", \"content\": response.content})\n",
    "            messages.append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"tool_result\",\n",
    "                        \"tool_use_id\": tool_use_id,\n",
    "                        \"content\": json.dumps(tool_result),\n",
    "                    }\n",
    "                ]\n",
    "            })\n",
    "\n",
    "            # Second API call to get the final, user-facing response (streaming)\n",
    "            with client.messages.stream(\n",
    "                model=\"claude-3-haiku-20240307\",\n",
    "                system=system_prompt,\n",
    "                max_tokens=1024,\n",
    "                messages=messages,\n",
    "            ) as stream:\n",
    "                for chunk in stream.text_stream:\n",
    "                    yield chunk\n",
    "        else:\n",
    "            # No tool use, yield the direct text response\n",
    "            text_content = next((block.text for block in response.content if block.type == 'text'), None)\n",
    "            if text_content:\n",
    "                yield text_content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in the Claude chat logic: {e}\")\n",
    "        yield \"Sorry, an error occurred with the AI model. Please check the console for details.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "388b4fb4-188a-410e-b42d-e1ebbdbeba7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_340387/897925193.py:7: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Conversation\", height=600, bubble_full_width=False)\n",
      "/tmp/ipykernel_340387/897925193.py:7: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
      "  chatbot = gr.Chatbot(label=\"Conversation\", height=600, bubble_full_width=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Gradio Interface (This part remains the same) ---\n",
    "\n",
    "with gr.Blocks(theme=\"soft\", title=\"Django Project Assistant (Claude) \") as demo:\n",
    "    gr.Markdown(\"# Django Project Assistant (with Claude) \")\n",
    "    gr.Markdown(\"Ask me questions about your Django project. I can list files and read their contents to help you.\")\n",
    "    \n",
    "    chatbot = gr.Chatbot(label=\"Conversation\", height=600, bubble_full_width=False) \n",
    "    \n",
    "    with gr.Row():\n",
    "        msg_textbox = gr.Textbox(\n",
    "            label=\"Your Message\",\n",
    "            placeholder=\"e.g., What files are in mysite/?\",\n",
    "            scale=7,\n",
    "            autofocus=True,\n",
    "        )\n",
    "        submit_btn = gr.Button(\"Send\", variant=\"primary\", scale=1)\n",
    "\n",
    "    def handle_chat(user_input, history):\n",
    "        history.append([user_input, \"\"])\n",
    "        response_stream = chat_with_tools(user_input, history[:-1])\n",
    "        for chunk in response_stream:\n",
    "            history[-1][1] += chunk\n",
    "            yield history, \"\"\n",
    "        yield history, \"\"\n",
    "\n",
    "    submit_btn.click(handle_chat, [msg_textbox, chatbot], [chatbot, msg_textbox])\n",
    "    msg_textbox.submit(handle_chat, [msg_textbox, chatbot], [chatbot, msg_textbox])\n",
    "\n",
    "    gr.Examples(\n",
    "        examples=[\n",
    "            [\"What files are in the root directory?\"],\n",
    "            [\"Can you show me the contents of 'mysite/settings.py'?\"],\n",
    "            [\"What's inside the 'home/templates/home' directory?\"]\n",
    "        ],\n",
    "        inputs=msg_textbox,\n",
    "        outputs=[chatbot, msg_textbox],\n",
    "        fn=handle_chat,\n",
    "        cache_examples=False,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6795b6-e1c7-4e16-9840-d7c9a85288b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Calling tool: list_files_in_directory({'path': '/home/pradeep/projects/pleasurewebsite/mysite'})\n",
      " Calling tool: read_file_content({'file_path': 'mysite/settings.py'})\n",
      " Calling tool: list_files_in_directory({'path': 'home/templates/home'})\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    demo.launch(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db9f2f-41e3-4286-aed0-9c186360af35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "llmenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
