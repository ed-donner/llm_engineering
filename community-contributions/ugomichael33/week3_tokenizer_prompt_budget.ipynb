{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 3 Exercise: Tokenizer + Prompt Budget Analyzer\n",
        "\n",
        "This notebook compares token counts across Hugging Face tokenizers and shows how much of a model's context window a prompt consumes.\n",
        "It also includes a simple prompt-trimming helper that fits a prompt to a token budget.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# If needed, install dependencies\n",
        "# !pip -q install transformers sentencepiece\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Imports\n",
        "import re\n",
        "from transformers import AutoTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Models to compare (all public)\n",
        "# Context windows are approximate common defaults\n",
        "MODELS = [\n",
        "    {'name': 'gpt2', 'context': 1024},\n",
        "    {'name': 'distilbert-base-uncased', 'context': 512},\n",
        "    {'name': 'bert-base-uncased', 'context': 512},\n",
        "    {'name': 'google/flan-t5-small', 'context': 512},\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Sample prompt (replace with your own)\n",
        "PROMPT = '''\n",
        "You are a helpful assistant.\n",
        "Summarize the following text and list 3 action items.\n",
        "\n",
        "Meeting transcript:\n",
        "We discussed the Q2 launch plan, timelines, and dependencies.\n",
        "Engineering will finalize the API integration by next Friday.\n",
        "Marketing will prepare the announcement draft by Monday.\n",
        "Support needs a short FAQ for common issues and escalation steps.\n",
        "Risks include vendor delays and limited QA bandwidth.\n",
        "\n",
        "Please write a concise summary and three action items.\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Tokenizer cache\n",
        "_TOKENIZERS = {}\n",
        "\n",
        "def get_tokenizer(model_name: str):\n",
        "    if model_name not in _TOKENIZERS:\n",
        "        _TOKENIZERS[model_name] = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "    return _TOKENIZERS[model_name]\n",
        "\n",
        "def count_tokens(model_name: str, text: str) -> int:\n",
        "    tok = get_tokenizer(model_name)\n",
        "    return len(tok.encode(text, add_special_tokens=False))\n",
        "\n",
        "def budget_report(text: str):\n",
        "    rows = []\n",
        "    for m in MODELS:\n",
        "        n = count_tokens(m['name'], text)\n",
        "        ctx = m['context']\n",
        "        pct = round((n / ctx) * 100, 2)\n",
        "        rows.append({\n",
        "            'model': m['name'],\n",
        "            'tokens': n,\n",
        "            'context': ctx,\n",
        "            'pct_of_context': pct\n",
        "        })\n",
        "    return rows\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Show token budget report\n",
        "report = budget_report(PROMPT)\n",
        "for row in report:\n",
        "    print(row)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Prompt trimming: fit text into a token budget\n",
        "def trim_to_budget(model_name: str, text: str, max_tokens: int) -> str:\n",
        "    tok = get_tokenizer(model_name)\n",
        "    tokens = tok.encode(text, add_special_tokens=False)\n",
        "    if len(tokens) <= max_tokens:\n",
        "        return text\n",
        "    trimmed_tokens = tokens[:max_tokens]\n",
        "    trimmed_text = tok.decode(trimmed_tokens, skip_special_tokens=True)\n",
        "    return trimmed_text.rstrip() + '...\n'\n",
        "\n",
        "# Example: trim to 80 tokens for each model\n",
        "for m in MODELS:\n",
        "    trimmed = trim_to_budget(m['name'], PROMPT, max_tokens=80)\n",
        "    print('\n---', m['name'], '---')\n",
        "    print(trimmed)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}