{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e5c0732",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288ce14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0874512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "\n",
    "OLLAMA_BASE_URL = 'http://localhost:11434/v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbf214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f517694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f59981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import api_key\n",
    "\n",
    "system_prompt = \"\"\"you are a helpful assistant that can explain a technical question in a way that is easy to understand.\n",
    "                    give a detailed explanation of the question and the logic behind it.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f165e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tool assistant class to wrap assistant variables and functions\n",
    "\n",
    "class TechnicalAssistant:\n",
    "    def __init__(self, openai_api_key = None):\n",
    "        self.openai_client = OpenAI(api_key=openai_api_key)\n",
    "        self.ollama_client = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\"ollama\")\n",
    "        self.model_gpt = MODEL_GPT\n",
    "        self.model_llama = MODEL_LLAMA\n",
    "\n",
    "    def _get_client_and_model(self, provider):\n",
    "        #if gpt or open ai in provider\n",
    "        if \"gpt\" in provider.lower():\n",
    "            return self.openai_client, self.model_gpt\n",
    "        elif \"llama\" in provider.lower():\n",
    "            return self.openai_client, self.model_gpt\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported provider: {provider}\")\n",
    "\n",
    "    def answer(self, question: str, provider: str=\"gpt\"):\n",
    "        client, model = self._get_client_and_model(provider)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "        stream = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "        response = \"\"\n",
    "        display_handle = display(Markdown(\"\"), display_id=True)\n",
    "        for chunk in stream:\n",
    "            response += chunk.choices[0].delta.content or ''\n",
    "            update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c8ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "\n",
    "assistant = TechnicalAssistant()\n",
    "\n",
    "assistant.answer(question, \"gpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84afae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "assistant.answer(question, \"ollama\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
