{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0b3d988f",
      "metadata": {},
      "source": [
        "### Week four exercise\n",
        "\n",
        "This project simulates generation and interpretation of **telemetry data** (as would be sent via **MQTT** or a similar protocol to a cloud service) from a sensor. The LLM generates the data and a natural language summary of the data. Results are displayed in a Gradio UI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce7379b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import sys\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "import subprocess\n",
        "from IPython.display import Markdown, display\n",
        "from huggingface_hub import login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a957632e",
      "metadata": {},
      "outputs": [],
      "source": [
        "load_dotenv(override=True)\n",
        "\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "hf_token = os.getenv('HF_TOKEN')\n",
        "\n",
        "if openai_api_key:\n",
        "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
        "else:\n",
        "    print(\"OpenAI API Key not set\")\n",
        "    \n",
        "login(hf_token, add_to_git_credential=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4090b4e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "ollama_url = \"http://localhost:11434/v1\"\n",
        "ollama = OpenAI(api_key=\"ollama\", base_url=ollama_url)\n",
        "\n",
        "openai = OpenAI(api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed68b342",
      "metadata": {},
      "outputs": [],
      "source": [
        "models = [\n",
        "    \"gpt-4o-mini\",\n",
        "    \"gpt-4o\",\n",
        "    \"deepseek-r1:1.5b\",\n",
        "    \"llama3.2\",\n",
        "]\n",
        "\n",
        "clients = {\n",
        "    \"gpt-4o-mini\": openai,\n",
        "    \"gpt-4o\": openai,\n",
        "    \"deepseek-r1:1.5b\": ollama,\n",
        "    \"llama3.2\": ollama,\n",
        "}\n",
        "\n",
        "\n",
        "def get_client(model_name: str):\n",
        "    \"\"\"Return the API client to use for the given model (Ollama or OpenAI).\"\"\"\n",
        "    client = clients.get(model_name)\n",
        "    if client is ollama:\n",
        "        return ollama\n",
        "    return openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92f47061",
      "metadata": {},
      "outputs": [],
      "source": [
        "TELEMETRY_USER_PROMPT = \"\"\"\n",
        "Simulate telemetry from an IoT sensor as it would be sent via MQTT to a cloud service.\n",
        "\n",
        "1. Generate a realistic JSON object with plausible sensor measurements (e.g. temperature, humidity, pressure, battery, timestamp, device_id).\n",
        "2. Then write a brief natural-language summary interpreting the data, noting any trends or anomalies.\n",
        "\n",
        "Format your response exactly as follows:\n",
        "TELEMETRY:\n",
        "<valid JSON object here>\n",
        "SUMMARY:\n",
        "<your brief summary here>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "819db4b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_telemetry(model_name: str) -> tuple[str, str]:\n",
        "    \"\"\"Call the LLM to generate sensor telemetry (MQTT-style) and a natural-language summary.\"\"\"\n",
        "    client = get_client(model_name)\n",
        "    response = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[{\"role\": \"user\", \"content\": TELEMETRY_USER_PROMPT}],\n",
        "        temperature=0.7,\n",
        "    )\n",
        "    text = response.choices[0].message.content or \"\"\n",
        "    telemetry_text, summary_text = \"\", \"\"\n",
        "    if \"SUMMARY:\" in text:\n",
        "        parts = text.split(\"SUMMARY:\", 1)\n",
        "        telemetry_text = parts[0].replace(\"TELEMETRY:\", \"\").strip()\n",
        "        summary_text = parts[1].strip()\n",
        "    else:\n",
        "        telemetry_text = text\n",
        "    return telemetry_text, summary_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c07e4ebd",
      "metadata": {},
      "outputs": [],
      "source": [
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"Sensor Telemetry Simulator\") as ui:\n",
        "    gr.Markdown(\"## Sensor Telemetry Simulator\\nGenerate and interpret IoT sensor telemetry as would be sent via MQTT to a cloud service.\")\n",
        "    with gr.Row():\n",
        "        model = gr.Dropdown(choices=models, value=\"gpt-4o-mini\" if \"gpt-4o-mini\" in models else models[0], label=\"Model\")\n",
        "        generate_btn = gr.Button(\"Generate telemetry\", variant=\"primary\")\n",
        "    with gr.Row():\n",
        "        telemetry_out = gr.TextArea(label=\"Telemetry data (JSON)\", lines=12, placeholder=\"Generated sensor payload will appear here…\")\n",
        "        summary_out = gr.TextArea(label=\"Summary\", lines=12, placeholder=\"Natural-language interpretation will appear here…\")\n",
        "    generate_btn.click(fn=generate_telemetry, inputs=[model], outputs=[telemetry_out, summary_out])\n",
        "\n",
        "ui.launch(inbrowser=True)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
