{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Head Pricer: Improved Price Prediction from Embeddings\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates an enhanced price prediction model that uses a regression head trained on embeddings from a fine-tuned LLaMA model. The approach extracts embeddings from multiple layers of the model and feeds them into a specialized neural network to predict prices.\n",
    "\n",
    "## Key Results\n",
    "\n",
    "**Model Performance:**\n",
    "- **Mean Prediction Error: $38.82** (tested on 10,000 samples)\n",
    "- **Improvement: ~$4.00** compared to the fine-tuned model from Week 7 ($43.78)\n",
    "- **Relative improvement: ~9%** reduction in prediction error\n",
    "\n",
    "## Methodology\n",
    "\n",
    "1. **Base Model**: LLaMA 3.2-3B fine-tuned on product pricing data\n",
    "2. **Embedding Extraction**: Multi-layer embeddings from the final 3 transformer layers\n",
    "3. **Regression Head**: 2-layer neural network with batch normalization and dropout\n",
    "4. **Training**: Regression head trained on log-transformed prices\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "For detailed experiments and analysis, see: [github.com/antonawinkler/slm-pricer](https://github.com/antonawinkler/slm-pricer) (Notebook 03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# 1. Configuration\n",
    "llama_base_model_name = \"meta-llama/Llama-3.2-3B\"\n",
    "llama_fine_tuned_model_name = \"ed-donner/price-2025-11-28_18.47.07\"\n",
    "llama_fine_tuned_model_revision = \"b19c8bfea3b6ff62237fbb0a8da9779fc12cefbd\"\n",
    "\n",
    "# 2. Load Base Model & Adapter\n",
    "tokenizer = AutoTokenizer.from_pretrained(llama_base_model_name)\n",
    "llama_base_model = AutoModelForCausalLM.from_pretrained(llama_base_model_name, device_map=\"auto\", dtype=torch.float16)\n",
    "llama_fine_tuned_model = PeftModel.from_pretrained(llama_base_model, llama_fine_tuned_model_name, revision=llama_fine_tuned_model_revision).merge_and_unload()\n",
    "llama_fine_tuned_model.eval()\n",
    "\n",
    "# 3. Download Regression Head\n",
    "model_path = hf_hub_download(repo_id=\"antonawinkler/llama-pricer-regression-head\", filename=\"model.pth\")\n",
    "checkpoint = torch.load(model_path, map_location=\"cpu\")\n",
    "model_config = checkpoint[\"model_config\"]\n",
    "embedding_config = checkpoint[\"embedding_config\"]\n",
    "\n",
    "# 4. Define Regression Head\n",
    "class PriceRegressor(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, dropout):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, hidden_dim1),\n",
    "            torch.nn.BatchNorm1d(hidden_dim1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            torch.nn.BatchNorm1d(hidden_dim2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim2, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "regression_head = PriceRegressor(\n",
    "    input_dim=model_config[\"input_dim\"],\n",
    "    hidden_dim1=model_config[\"hidden_dim1\"],\n",
    "    hidden_dim2=model_config[\"hidden_dim2\"],\n",
    "    dropout=model_config[\"dropout\"]\n",
    ")\n",
    "regression_head.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "regression_head.eval().to(llama_fine_tuned_model.device)\n",
    "\n",
    "# 5. Prediction Helper\n",
    "def get_single_embedding(model, tokenizer, text, n_layers):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        selected_layers = outputs.hidden_states[-n_layers:]\n",
    "        # Extract last token from each layer\n",
    "        layer_vecs = [layer[:, -1, :] for layer in selected_layers]\n",
    "        return torch.cat(layer_vecs, dim=-1).float()\n",
    "\n",
    "# 6. Predict\n",
    "description = \"Apple AirPods Pro (2nd Generation) with MagSafe Charging Case\"\n",
    "embedding = get_single_embedding(\n",
    "    llama_fine_tuned_model,\n",
    "    tokenizer,\n",
    "    description,\n",
    "    n_layers=embedding_config[\"n_layers\"]\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    log_price = regression_head(embedding)\n",
    "    price = np.exp(log_price.item())\n",
    "\n",
    "print(f\"Predicted Price: ${price:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade bitsandbytes trl\n",
    "!wget -q https://raw.githubusercontent.com/ed-donner/llm_engineering/main/week7/util.py -O util.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import evaluate\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(item):\n",
    "  embedding = get_single_embedding(\n",
    "      llama_fine_tuned_model,\n",
    "      tokenizer,\n",
    "      item[\"prompt\"],\n",
    "      n_layers=3,\n",
    "  )\n",
    "\n",
    "  with torch.no_grad():\n",
    "      log_price = regression_head(embedding)\n",
    "      return np.expm1(log_price.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = load_dataset('ed-donner/items_prompts_full', split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model_predict, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Model Predict Error $38.82 for all 10'000 test samples.\n",
    "\n",
    "## Improvement of almost 4 dollars (Model Predict Error $43.78) compared to the fine-tuned model of week 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model_predict, df_test, size=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}