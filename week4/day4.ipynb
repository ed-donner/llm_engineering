{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a6ab9a2-28a2-445d-8512-a0dc8d1b54e9",
   "metadata": {},
   "source": [
    "# Code Generator\n",
    "\n",
    "The requirement: use a Frontier model to generate high performance C++ code from Python code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ccb926-7b49-44a4-99ab-8ef20b5778c0",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Reminder: OPTIONAL to execute C++ code</h2>\n",
    "            <span style=\"color:#f71;\">As an alternative, you can run it on the website given yesterday</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90e04a2-5b8a-4fd5-9db8-27c02f033313",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h1 style=\"color:#900;\">Important Note</h1>\n",
    "            <span style=\"color:#900;\">\n",
    "            In this lab, I use free open source models on Ollama. I also use paid open-source models via Groq and OpenRouter. Only pick the models you want to!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e610bf56-a46e-4aff-8de1-ab49d62b1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f672e1c-87e9-4865-b760-370fa605e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key exists and begins AI\n",
      "Grok API Key not set (and this is optional)\n",
      "Groq API Key not set (and this is optional)\n",
      "OpenRouter API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "grok_api_key = os.getenv('GROK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "openrouter_api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if grok_api_key:\n",
    "    print(f\"Grok API Key exists and begins {grok_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Grok API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")\n",
    "\n",
    "if openrouter_api_key:\n",
    "    print(f\"OpenRouter API Key exists and begins {openrouter_api_key[:6]}\")\n",
    "else:\n",
    "    print(\"OpenRouter API Key not set (and this is optional)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59863df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to client libraries\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "grok_url = \"https://api.x.ai/v1\"\n",
    "groq_url = \"https://api.groq.com/openai/v1\"\n",
    "#local\n",
    "import requests\n",
    "requests.get(\"http://localhost:11434\").content\n",
    "\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "\n",
    "\n",
    "openrouter_url = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=gemini_url)\n",
    "grok = OpenAI(api_key=grok_api_key, base_url=grok_url)\n",
    "groq = OpenAI(api_key=groq_api_key, base_url=groq_url)\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
    "openrouter = OpenAI(api_key=openrouter_api_key, base_url=openrouter_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8aa149ed-9298-4d69-8fe2-8f5de0f667da",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt-5-nano\", \"claude-sonnet-4-5-20250929\", \"grok-4\", \"gemini-2.5-flash-lite\", \"qwen2.5\", \"deepseek\", \"llama3.2\", \"qwen/qwen3-coder-30b-a3b-instruct\", \"openai/gpt-oss-120b\", ]\n",
    "\n",
    "clients = {\"gpt-5-nano\": openai, \"claude-sonnet-4-5-20250929\": anthropic, \"grok-4\": grok, \"gemini-2.5-flash-lite\": gemini, \"openai/gpt-oss-120b\": groq, \"qwen2.5\": ollama, \"deepseek\": ollama, \"llama3.2\": ollama, \"qwen/qwen3-coder-30b-a3b-instruct\": openrouter}\n",
    "\n",
    "# Want to keep costs ultra-low? Replace this with models of your choice, using the examples from yesterday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c1f1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'os': {'system': 'Windows',\n",
       "  'arch': 'AMD64',\n",
       "  'release': '10',\n",
       "  'version': '10.0.19045',\n",
       "  'kernel': '10',\n",
       "  'distro': None,\n",
       "  'wsl': False,\n",
       "  'rosetta2_translated': False,\n",
       "  'target_triple': 'x86_64-w64-mingw32'},\n",
       " 'package_managers': ['winget'],\n",
       " 'cpu': {'brand': 'Intel(R) Core(TM) i5-1035G1 CPU @ 1.00GHz',\n",
       "  'cores_logical': 8,\n",
       "  'cores_physical': 4,\n",
       "  'simd': []},\n",
       " 'toolchain': {'compilers': {'gcc': 'gcc.EXE (Rev2, Built by MSYS2 project) 14.2.0',\n",
       "   'g++': 'g++.EXE (Rev2, Built by MSYS2 project) 14.2.0',\n",
       "   'clang': '',\n",
       "   'msvc_cl': ''},\n",
       "  'build_tools': {'cmake': '', 'ninja': '', 'make': ''},\n",
       "  'linkers': {'ld_lld': ''}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from system_info import retrieve_system_info\n",
    "\n",
    "system_info = retrieve_system_info()\n",
    "system_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e92c12",
   "metadata": {},
   "source": [
    "## Overwrite this with the commands from yesterday\n",
    "\n",
    "Or just use the website like yesterday:\n",
    "\n",
    " https://www.programiz.com/cpp-programming/online-compiler/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d734a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_command = [\"clang++\", \"-std=c++17\", \"-Ofast\", \"-mcpu=native\", \"-flto=thin\", \"-fvisibility=hidden\", \"-DNDEBUG\", \"main.cpp\", \"-o\", \"main\"]\n",
    "run_command = [\"./main\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b0a437",
   "metadata": {},
   "source": [
    "## And now, on with the main task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6896636f-923e-4a2c-9d6c-fac07828a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Your task is to convert Python code into high performance C++ code.\n",
    "Respond only with C++ code. Do not provide any explanation other than occasional comments.\n",
    "The C++ response needs to produce an identical output in the fastest possible time.\n",
    "\"\"\"\n",
    "\n",
    "def user_prompt_for(python):\n",
    "    return f\"\"\"\n",
    "Port this Python code to C++ with the fastest possible implementation that produces identical output in the least time.\n",
    "The system information is:\n",
    "{system_info}\n",
    "Your response will be written to a file called main.cpp and then compiled and executed; the compilation command is:\n",
    "{compile_command}\n",
    "Respond only with C++ code.\n",
    "Python code to port:\n",
    "\n",
    "```python\n",
    "{python}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e7b3546-57aa-4c29-bc5d-f211970d04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(python):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(python)}\n",
    "    ]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6190659-f54c-4951-bef4-4960f8e51cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(cpp):\n",
    "    with open(\"main.cpp\", \"w\") as f:\n",
    "        f.write(cpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7d2fea8-74c6-4421-8f1e-0e76d5b201b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def port(model, python):\n",
    "    client = clients[model]\n",
    "    reasoning_effort = \"high\" if 'gpt' in model else None\n",
    "    response = client.chat.completions.create(model=model, messages=messages_for(python), reasoning_effort=reasoning_effort)\n",
    "    reply = response.choices[0].message.content\n",
    "    reply = reply.replace('```cpp','').replace('```','')\n",
    "    write_output(reply)\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1cbb778-fa57-43de-b04b-ed523f396c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = \"\"\"\n",
    "import time\n",
    "\n",
    "def calculate(iterations, param1, param2):\n",
    "    result = 1.0\n",
    "    for i in range(1, iterations+1):\n",
    "        j = i * param1 - param2\n",
    "        result -= (1/j)\n",
    "        j = i * param1 + param2\n",
    "        result += (1/j)\n",
    "    return result\n",
    "\n",
    "start_time = time.time()\n",
    "result = calculate(200_000_000, 4, 1) * 4\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Result: {result:.12f}\")\n",
    "print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fe1cd4b-d2c5-4303-afed-2115a3fef200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_python(code):\n",
    "    globals_dict = {\"__builtins__\": __builtins__}\n",
    "\n",
    "    buffer = io.StringIO()\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = buffer\n",
    "\n",
    "    try:\n",
    "        exec(code, globals_dict)\n",
    "        output = buffer.getvalue()\n",
    "    except Exception as e:\n",
    "        output = f\"Error: {e}\"\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4194e40c-04ab-4940-9d64-b4ad37c5bb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_run():\n",
    "    try:\n",
    "        subprocess.run(compile_command, check=True, text=True, capture_output=True)\n",
    "        print(subprocess.run(run_command, check=True, text=True, capture_output=True).stdout)\n",
    "        print(subprocess.run(run_command, check=True, text=True, capture_output=True).stdout)\n",
    "        print(subprocess.run(run_command, check=True, text=True, capture_output=True).stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred:\\n{e.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1ddb38e-6b0a-4c37-baa4-ace0b7de887a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        python = gr.Textbox(label=\"Python code:\", lines=28, value=pi)\n",
    "        cpp = gr.Textbox(label=\"C++ code:\", lines=28)\n",
    "    with gr.Row():\n",
    "        model = gr.Dropdown(models, label=\"Select model\", value=models[0])\n",
    "        convert = gr.Button(\"Convert code\")\n",
    "\n",
    "    convert.click(port, inputs=[model, python], outputs=[cpp])\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28969928",
   "metadata": {},
   "source": [
    "# Gemini flash 2.5 lite\n",
    "# code\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <vector>\n",
    "#include <cmath>\n",
    "#include <iomanip>\n",
    "#include <chrono>\n",
    "\n",
    "// Function to calculate the result\n",
    "double calculate(int iterations, double param1, double param2) {\n",
    "    double result = 1.0;\n",
    "    for (int i = 1; i <= iterations; ++i) {\n",
    "        // Calculate j = i * param1 - param2\n",
    "        double j1 = static_cast<double>(i) * param1 - param2;\n",
    "        // Update result: result -= (1/j1)\n",
    "        result -= (1.0 / j1);\n",
    "\n",
    "        // Calculate j = i * param1 + param2\n",
    "        double j2 = static_cast<double>(i) * param1 + param2;\n",
    "        // Update result: result += (1/j2)\n",
    "        result += (1.0 / j2);\n",
    "    }\n",
    "    return result;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Record start time\n",
    "    auto start_time = std::chrono::high_resolution_clock::now();\n",
    "\n",
    "    // Define parameters and call the calculate function\n",
    "    int iterations = 200000000;\n",
    "    double param1 = 4.0;\n",
    "    double param2 = 1.0;\n",
    "    double final_result = calculate(iterations, param1, param2) * 4.0;\n",
    "\n",
    "    // Record end time\n",
    "    auto end_time = std::chrono::high_resolution_clock::now();\n",
    "\n",
    "    // Calculate execution duration\n",
    "    std::chrono::duration<double> elapsed = end_time - start_time;\n",
    "\n",
    "    // Print the result with specified precision\n",
    "    std::cout << std::fixed << std::setprecision(12) << \"Result: \" << final_result << std::endl;\n",
    "    // Print the execution time with specified precision\n",
    "    std::cout << std::fixed << std::setprecision(6) << \"Execution Time: \" << elapsed.count() << \" seconds\" << std::endl;\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "## Result\n",
    "Result: 3.141592656089\n",
    "\n",
    "Execution Time: 2.046798 seconds\n",
    "\n",
    "\n",
    "## gpt 5 -nano\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <iomanip>\n",
    "#include <chrono>\n",
    "\n",
    "static inline double calculate_fast(long long iterations, double p1, double p2) {\n",
    "    double result = 1.0;\n",
    "    double di = p1; // i = 1 => i*p1\n",
    "    long long i = 1;\n",
    "    long long limit = iterations - (iterations % 4);\n",
    "\n",
    "    for (; i <= limit; i += 4) {\n",
    "        // i = 1\n",
    "        double j1 = di - p2;\n",
    "        result -= 1.0 / j1;\n",
    "        double j2 = di + p2;\n",
    "        result += 1.0 / j2;\n",
    "        di += p1;\n",
    "\n",
    "        // i = 2\n",
    "        j1 = di - p2;\n",
    "        result -= 1.0 / j1;\n",
    "        j2 = di + p2;\n",
    "        result += 1.0 / j2;\n",
    "        di += p1;\n",
    "\n",
    "        // i = 3\n",
    "        j1 = di - p2;\n",
    "        result -= 1.0 / j1;\n",
    "        j2 = di + p2;\n",
    "        result += 1.0 / j2;\n",
    "        di += p1;\n",
    "\n",
    "        // i = 4\n",
    "        j1 = di - p2;\n",
    "        result -= 1.0 / j1;\n",
    "        j2 = di + p2;\n",
    "        result += 1.0 / j2;\n",
    "        di += p1;\n",
    "    }\n",
    "\n",
    "    for (; i <= iterations; ++i) {\n",
    "        double j1 = di - p2;\n",
    "        result -= 1.0 / j1;\n",
    "        double j2 = di + p2;\n",
    "        result += 1.0 / j2;\n",
    "        di += p1;\n",
    "    }\n",
    "\n",
    "    return result;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const long long iterations = 200000000LL;\n",
    "    const double p1 = 4.0;\n",
    "    const double p2 = 1.0;\n",
    "\n",
    "    auto t0 = std::chrono::high_resolution_clock::now();\n",
    "    double result = calculate_fast(iterations, p1, p2) * 4.0;\n",
    "    auto t1 = std::chrono::high_resolution_clock::now();\n",
    "    std::chrono::duration<double> elapsed = t1 - t0;\n",
    "\n",
    "    std::cout.setf(std::ios::fixed);\n",
    "    std::cout << std::setprecision(12);\n",
    "    std::cout << \"Result: \" << result << \"\\n\";\n",
    "    std::cout << std::setprecision(6);\n",
    "    std::cout << \"Execution Time: \" << elapsed.count() << \" seconds\\n\";\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "Result: 3.141592656089\n",
    "\n",
    "Execution Time: 3.203772 seconds\n",
    "\n",
    "\n",
    "=== Code Execution Successful ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec0f531-1ccb-4134-9930-f44d803caabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_and_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bd18af-31eb-4351-a49a-90f4e111c6d2",
   "metadata": {},
   "source": [
    "# llama.2 execute but wrong code\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <chrono>\n",
    "\n",
    "void calculate(float iterations, float param1, float param2) {\n",
    "    float result = 0.0;\n",
    "    for (unsigned int i = 1; i <= iterations; ++i) {\n",
    "        float j = i * param1 - param2;\n",
    "        // Avoid division by zero\n",
    "        if (!j)\n",
    "            continue;\n",
    "        result -= 1 / j;\n",
    "        j = i * param1 + param2;\n",
    "        if (!j)\n",
    "            continue;\n",
    "        result += 1 / j;\n",
    "    }\n",
    "    // Calculate and print result\n",
    "    result *= 4;\n",
    "    std::cout << \"Result: \" << result << std::endl;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Measure execution time\n",
    "    auto start_time = std::chrono::high_resolution_clock::now();\n",
    "    calculate(200000000, 4, 1);\n",
    "    auto end_time = std::chrono::high_resolution_clock::now();\n",
    "\n",
    "    // Print measuremnet results \n",
    "    std::cout << \"Execution Time: \";\n",
    "    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time).count();\n",
    "    std::cout << (double)duration / 1000.0 << \" seconds\" << std::endl;\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "Result: -0.858405\n",
    "Execution Time: 1.538 seconds\n",
    "\n",
    "\n",
    "=== Code Execution Successful ==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80037156",
   "metadata": {},
   "source": [
    "Qwen 2.5 Coder: Fail  \n",
    "DeepSeek Coder v2: 0.114050084  \n",
    "OpenAI gpt-oss 20B: 0.080438  \n",
    "Qwen 30B: 0.113734  \n",
    "OpenAI gpt-oss 120B: 1.407383\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d4e52",
   "metadata": {},
   "source": [
    "In Ed's experiments, the performance speedups were:\n",
    "\n",
    "9th place: Qwen 2.5 Coder: Fail  \n",
    "8th place: OpenAI GPT-OSS 120B: 14X speedup    \n",
    "7th place: DeepSeek Coder v2: 168X speedup  \n",
    "6th place: Qwen3 Coder 30B: 168X speedup   \n",
    "5th place: Claude Sonnet 4.5: 184X speedup   \n",
    "4th place: GPT-5: 233X speedup  \n",
    "**3rd place: oss-20B: 238X speedup**  \n",
    "2nd place: Grok 4: 1060X speedup  \n",
    "1st place: Gemini 2.5 Pro: 1440X speedup  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e617df9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
