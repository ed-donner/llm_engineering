{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a6ab9a2-28a2-445d-8512-a0dc8d1b54e9",
   "metadata": {},
   "source": [
    "# Code Generator\n",
    "\n",
    "The requirement: use a Frontier model to generate high performance C++ code from Python code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ccb926-7b49-44a4-99ab-8ef20b5778c0",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Reminder: OPTIONAL to execute C++ code</h2>\n",
    "            <span style=\"color:#f71;\">As an alternative, you can run it on the website given yesterday</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90e04a2-5b8a-4fd5-9db8-27c02f033313",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h1 style=\"color:#900;\">Important Note</h1>\n",
    "            <span style=\"color:#900;\">\n",
    "            In this lab, I use free open source models on Ollama. I also use paid open-source models via Groq and OpenRouter. Only pick the models you want to!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e610bf56-a46e-4aff-8de1-ab49d62b1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f672e1c-87e9-4865-b760-370fa605e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AI\n",
      "Grok API Key not set (and this is optional)\n",
      "Groq API Key not set (and this is optional)\n",
      "OpenRouter API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "grok_api_key = os.getenv('GROK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "openrouter_api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if grok_api_key:\n",
    "    print(f\"Grok API Key exists and begins {grok_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Grok API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")\n",
    "\n",
    "if openrouter_api_key:\n",
    "    print(f\"OpenRouter API Key exists and begins {openrouter_api_key[:6]}\")\n",
    "else:\n",
    "    print(\"OpenRouter API Key not set (and this is optional)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59863df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to client libraries\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "grok_url = \"https://api.x.ai/v1\"\n",
    "groq_url = \"https://api.groq.com/openai/v1\"\n",
    "ollama_url = \"http://localhost:11434/v1\"\n",
    "openrouter_url = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=gemini_url)\n",
    "grok = OpenAI(api_key=grok_api_key, base_url=grok_url)\n",
    "groq = OpenAI(api_key=groq_api_key, base_url=groq_url)\n",
    "ollama = OpenAI(api_key=\"ollama\", base_url=ollama_url)\n",
    "openrouter = OpenAI(api_key=openrouter_api_key, base_url=openrouter_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa149ed-9298-4d69-8fe2-8f5de0f667da",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt-5\", \"claude-sonnet-4-5-20250929\", \"gemini-2.5-pro\", \"qwen2.5-coder\", \"deepseek-coder-v2\" ]\n",
    "\n",
    "clients = {\"gpt-5\": openai, \"claude-sonnet-4-5-20250929\": anthropic,  \"gemini-2.5-pro\": gemini, \"qwen2.5-coder\": ollama, \"deepseek-coder-v2\": ollama, \"gpt-oss:20b\": ollama}\n",
    "\n",
    "# Want to keep costs ultra-low? Replace this with models of your choice, using the examples from yesterday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68c1f1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'os': {'system': 'Darwin',\n",
       "  'arch': 'arm64',\n",
       "  'release': '25.2.0',\n",
       "  'version': 'Darwin Kernel Version 25.2.0: Thu Nov 13 23:34:20 PST 2025; root:xnu-12377.61.11~7/RELEASE_ARM64_T8122',\n",
       "  'kernel': '25.2.0',\n",
       "  'distro': None,\n",
       "  'wsl': False,\n",
       "  'rosetta2_translated': False,\n",
       "  'target_triple': 'arm64-apple-darwin25.2.0'},\n",
       " 'package_managers': ['xcode-select (CLT)', 'brew'],\n",
       " 'cpu': {'brand': 'Apple M3',\n",
       "  'cores_logical': 8,\n",
       "  'cores_physical': 8,\n",
       "  'simd': []},\n",
       " 'toolchain': {'compilers': {'gcc': 'Apple clang version 17.0.0 (clang-1700.3.19.1)',\n",
       "   'g++': 'Apple clang version 17.0.0 (clang-1700.3.19.1)',\n",
       "   'clang': 'Apple clang version 17.0.0 (clang-1700.3.19.1)',\n",
       "   'msvc_cl': ''},\n",
       "  'build_tools': {'cmake': '', 'ninja': '', 'make': 'GNU Make 3.81'},\n",
       "  'linkers': {'ld_lld': ''}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from system_info import retrieve_system_info\n",
    "\n",
    "system_info = retrieve_system_info()\n",
    "system_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e92c12",
   "metadata": {},
   "source": [
    "## Overwrite this with the commands from yesterday\n",
    "\n",
    "Or just use the website like yesterday:\n",
    "\n",
    " https://www.programiz.com/cpp-programming/online-compiler/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d734a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_command = [\"clang++\", \"-std=c++17\", \"-O3\", \"-ffast-math\", \"-mcpu=native\", \"-flto=thin\", \"-fvisibility=hidden\", \"-DNDEBUG\", \"main.cpp\", \"-o\", \"main\"]\n",
    "run_command = [\"./main\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b0a437",
   "metadata": {},
   "source": [
    "## And now, on with the main task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6896636f-923e-4a2c-9d6c-fac07828a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Your task is to convert Python code into high performance C++ code.\n",
    "Respond only with C++ code. Do not provide any explanation other than occasional comments.\n",
    "The C++ response needs to produce an identical output in the fastest possible time.\n",
    "IMPORTANT: Include all necessary headers (e.g., #include <iomanip> for std::setprecision, #include <iostream> for std::cout, etc.).\n",
    "Do not include any explanatory text outside of code comments.\n",
    "\"\"\"\n",
    "\n",
    "def user_prompt_for(python):\n",
    "    return f\"\"\"\n",
    "Port this Python code to C++ with the fastest possible implementation that produces identical output in the least time.\n",
    "The system information is:\n",
    "{system_info}\n",
    "Your response will be written to a file called main.cpp and then compiled and executed; the compilation command is:\n",
    "{compile_command}\n",
    "IMPORTANT: Include all necessary headers. For example, if you use std::setprecision, include #include <iomanip>.\n",
    "Respond only with C++ code - no explanatory text outside of code comments.\n",
    "Python code to port:\n",
    "\n",
    "```python\n",
    "{python}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e7b3546-57aa-4c29-bc5d-f211970d04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(python):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(python)}\n",
    "    ]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6190659-f54c-4951-bef4-4960f8e51cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(cpp):\n",
    "    with open(\"main.cpp\", \"w\") as f:\n",
    "        f.write(cpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2fea8-74c6-4421-8f1e-0e76d5b201b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def port(model, python):\n",
    "    client = clients[model]\n",
    "    reasoning_effort = \"high\" if 'gpt' in model else None\n",
    "    response = client.chat.completions.create(model=model, messages=messages_for(python), reasoning_effort=reasoning_effort)\n",
    "    reply = response.choices[0].message.content\n",
    "    \n",
    "    # Extract C++ code from markdown blocks\n",
    "    if '```cpp' in reply:\n",
    "        start = reply.find('```cpp') + 6\n",
    "        end = reply.find('```', start)\n",
    "        if end != -1:\n",
    "            reply = reply[start:end]\n",
    "    elif '```' in reply:\n",
    "        start = reply.find('```') + 3\n",
    "        end = reply.find('```', start)\n",
    "        if end != -1:\n",
    "            reply = reply[start:end]\n",
    "    \n",
    "    # Remove any trailing explanatory text (lines that don't look like C++ code)\n",
    "    lines = reply.split('\\n')\n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        # Stop if we hit explanatory text (starts with capital letter, no semicolon/brace, not a comment)\n",
    "        if line.strip() and not line.strip().startswith('#') and not line.strip().startswith('//'):\n",
    "            if not any(c in line for c in [';', '{', '}', '#include', 'using', 'namespace', 'return', 'int ', 'double ', 'auto ', 'std::', 'void ', 'for ', 'if ', 'while ']):\n",
    "                if line.strip()[0].isupper() and not line.strip().startswith('std::'):\n",
    "                    break\n",
    "        cleaned_lines.append(line)\n",
    "    \n",
    "    reply = '\\n'.join(cleaned_lines).strip()\n",
    "    write_output(reply)\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1cbb778-fa57-43de-b04b-ed523f396c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = \"\"\"\n",
    "import time\n",
    "\n",
    "def calculate(iterations, param1, param2):\n",
    "    result = 1.0\n",
    "    for i in range(1, iterations+1):\n",
    "        j = i * param1 - param2\n",
    "        result -= (1/j)\n",
    "        j = i * param1 + param2\n",
    "        result += (1/j)\n",
    "    return result\n",
    "\n",
    "start_time = time.time()\n",
    "result = calculate(200_000_000, 4, 1) * 4\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Result: {result:.12f}\")\n",
    "print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fe1cd4b-d2c5-4303-afed-2115a3fef200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_python(code):\n",
    "    globals_dict = {\"__builtins__\": __builtins__}\n",
    "\n",
    "    buffer = io.StringIO()\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = buffer\n",
    "\n",
    "    try:\n",
    "        exec(code, globals_dict)\n",
    "        output = buffer.getvalue()\n",
    "    except Exception as e:\n",
    "        output = f\"Error: {e}\"\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4194e40c-04ab-4940-9d64-b4ad37c5bb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_run():\n",
    "    try:\n",
    "        subprocess.run(compile_command, check=True, text=True, capture_output=True)\n",
    "        print(subprocess.run(run_command, check=True, text=True, capture_output=True).stdout)\n",
    "        print(subprocess.run(run_command, check=True, text=True, capture_output=True).stdout)\n",
    "        print(subprocess.run(run_command, check=True, text=True, capture_output=True).stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred:\\n{e.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1ddb38e-6b0a-4c37-baa4-ace0b7de887a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        python = gr.Textbox(label=\"Python code:\", lines=28, value=pi)\n",
    "        cpp = gr.Textbox(label=\"C++ code:\", lines=28)\n",
    "    with gr.Row():\n",
    "        model = gr.Dropdown(models, label=\"Select model\", value=models[0])\n",
    "        convert = gr.Button(\"Convert code\")\n",
    "\n",
    "    convert.click(port, inputs=[model, python], outputs=[cpp])\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28969928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9cc1c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 3.141592656090\n",
      "Execution Time: 0.093803000000 seconds\n",
      "\n",
      "Result: 3.141592656090\n",
      "Execution Time: 0.088328000000 seconds\n",
      "\n",
      "Result: 3.141592656090\n",
      "Execution Time: 0.089139000000 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compile_and_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80037156",
   "metadata": {},
   "source": [
    "Qwen 2.5 Coder: Fail  \n",
    "DeepSeek Coder v2: 0.114050084  \n",
    "OpenAI gpt-oss 20B: 0.080438  \n",
    "Qwen 30B: 0.113734  \n",
    "OpenAI gpt-oss 120B: 1.407383\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d4e52",
   "metadata": {},
   "source": [
    "In Ed's experiments, the performance speedups were:\n",
    "\n",
    "9th place: Qwen 2.5 Coder: Fail  \n",
    "8th place: OpenAI GPT-OSS 120B: 14X speedup    \n",
    "7th place: DeepSeek Coder v2: 168X speedup  \n",
    "6th place: Qwen3 Coder 30B: 168X speedup   \n",
    "5th place: Claude Sonnet 4.5: 184X speedup   \n",
    "4th place: GPT-5: 233X speedup  \n",
    "**3rd place: oss-20B: 238X speedup**  \n",
    "2nd place: Grok 4: 1060X speedup  \n",
    "1st place: Gemini 2.5 Pro: 1440X speedup  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e617df9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
