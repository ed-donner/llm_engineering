{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Code Generator: Python to Go\n",
        "\n",
        "Use a frontier model to generate high-performance **Go** code from Python code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note:** You can run the generated Go code locally (after installing the Go toolchain) or use an online compiler such as [Go Playground](https://go.dev/play/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import sys\n",
        "import json\n",
        "import shutil\n",
        "import subprocess\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Allow importing from parent (week4) when running from community-contributions\n",
        "_week4_root = os.path.dirname(os.getcwd()) if os.path.basename(os.getcwd()) == \"community-contributions\" else os.getcwd()\n",
        "sys.path.insert(0, _week4_root)\n",
        "from system_info import retrieve_system_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load API keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key exists and begins sk-proj-\n",
            "Anthropic API Key not set (optional)\n",
            "Google API Key not set (optional)\n",
            "Grok API Key not set (optional)\n",
            "Groq API Key not set (optional)\n",
            "OpenRouter API Key exists and begins sk-or-\n"
          ]
        }
      ],
      "source": [
        "load_dotenv(override=True)\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
        "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "grok_api_key = os.getenv(\"GROK_API_KEY\")\n",
        "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "\n",
        "if openai_api_key:\n",
        "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
        "else:\n",
        "    print(\"OpenAI API Key not set\")\n",
        "if anthropic_api_key:\n",
        "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
        "else:\n",
        "    print(\"Anthropic API Key not set (optional)\")\n",
        "if google_api_key:\n",
        "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
        "else:\n",
        "    print(\"Google API Key not set (optional)\")\n",
        "if grok_api_key:\n",
        "    print(f\"Grok API Key exists and begins {grok_api_key[:4]}\")\n",
        "else:\n",
        "    print(\"Grok API Key not set (optional)\")\n",
        "if groq_api_key:\n",
        "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
        "else:\n",
        "    print(\"Groq API Key not set (optional)\")\n",
        "if openrouter_api_key:\n",
        "    print(f\"OpenRouter API Key exists and begins {openrouter_api_key[:6]}\")\n",
        "else:\n",
        "    print(\"OpenRouter API Key not set (optional)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Connect to OpenRouter\n",
        "\n",
        "All models are called via the **OpenRouter API** (one API key, one base URL). Set `OPENROUTER_API_KEY` in your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "openrouter_client = (\n",
        "    OpenAI(api_key=openrouter_api_key, base_url=\"https://openrouter.ai/api/v1\")\n",
        "    if openrouter_api_key\n",
        "    else None\n",
        ")\n",
        "\n",
        "models = [\n",
        "    \"openai/gpt-4o\",\n",
        "    \"openai/gpt-4o-mini\",\n",
        "    \"anthropic/claude-3.5-sonnet\",\n",
        "    \"anthropic/claude-3-haiku\",\n",
        "    \"google/gemini-2.0-flash-exp:free\",\n",
        "    \"google/gemini-flash-1.5\",\n",
        "    \"meta-llama/llama-3.1-70b-instruct\",\n",
        "    \"mistralai/mistral-large\",\n",
        "    \"deepseek/deepseek-coder\",\n",
        "    \"qwen/qwen-2.5-coder-32b-instruct\",\n",
        "]\n",
        "clients = {m: openrouter_client for m in models}\n",
        "models = [m for m in models if openrouter_client]\n",
        "if not models:\n",
        "    print(\"Set OPENROUTER_API_KEY in your environment to use models.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# System info and Go toolchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go installed: True\n",
            "Go version: go version go1.26.0 darwin/arm64\n"
          ]
        }
      ],
      "source": [
        "def go_toolchain_info():\n",
        "    \"\"\"Return Go toolchain presence and version for LLM context.\"\"\"\n",
        "    go_path = shutil.which(\"go\")\n",
        "    info = {\n",
        "        \"installed\": bool(go_path),\n",
        "        \"go_path\": go_path or \"\",\n",
        "        \"version\": \"\",\n",
        "        \"GOROOT\": os.environ.get(\"GOROOT\", \"\"),\n",
        "        \"GOPATH\": os.environ.get(\"GOPATH\", \"\"),\n",
        "    }\n",
        "    if go_path:\n",
        "        try:\n",
        "            out = subprocess.check_output(\n",
        "                [go_path, \"version\"], text=True, stderr=subprocess.DEVNULL, timeout=3\n",
        "            )\n",
        "            info[\"version\"] = out.strip().split(\"\\n\")[0]\n",
        "        except Exception:\n",
        "            pass\n",
        "    return info\n",
        "\n",
        "system_info = retrieve_system_info()\n",
        "go_info = go_toolchain_info()\n",
        "print(\"Go installed:\", go_info[\"installed\"])\n",
        "if go_info[\"version\"]:\n",
        "    print(\"Go version:\", go_info[\"version\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Ask the model for Go build/run commands\n",
        "\n",
        "You can run this once to get suggested `compile_command` and `run_command` for your system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "As the Go toolchain is already installed on your system at `/opt/homebrew/bin/go` and you are using an `arm64` macOS machine, you can compile and run your Go program with the following steps to ensure the fastest runtime performance:\n",
              "\n",
              "### Compile Command\n",
              "\n",
              "Use the following command to compile your `main.go` file:\n",
              "\n",
              "```python\n",
              "compile_command = [\"go\", \"build\", \"-ldflags=-s -w\", \"-o\", \"main\", \"main.go\"]\n",
              "```\n",
              "\n",
              "### Run Command\n",
              "\n",
              "Once compiled, run the binary with:\n",
              "\n",
              "```python\n",
              "run_command = [\"./main\"]\n",
              "```\n",
              "\n",
              "These commands should be executed in a terminal or a script, ensuring that your Go environment is correctly set up. The `-ldflags=-s -w` flags remove symbol table and debug information from the binary, reducing its size and potentially improving load times."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "message = f\"\"\"\n",
        "Here is a report of the system information for my computer.\n",
        "I want to compile a single Go file called main.go and then execute the binary in the simplest way possible.\n",
        "Please reply with whether I need to install the Go toolchain. If so, give the simplest step-by-step instructions.\n",
        "\n",
        "If Go is already installed, tell me exactly what to use in Python for:\n",
        "compile_command = [...]  # e.g. [\"go\", \"build\", \"-ldflags=-s -w\", \"-o\", \"main\", \"main.go\"]\n",
        "run_command = [...]       # e.g. [\"./main\"] on Unix or [\".\\\\main.exe\"] on Windows\n",
        "\n",
        "Prioritize fastest possible runtime performance (use -ldflags=\"-s -w\" and appropriate build flags).\n",
        "Reply with the commands in markdown.\n",
        "\n",
        "System information:\n",
        "{json.dumps(system_info, indent=2)}\n",
        "\n",
        "Go toolchain:\n",
        "{json.dumps(go_info, indent=2)}\n",
        "\"\"\"\n",
        "\n",
        "if openrouter_client and models:\n",
        "    response = openrouter_client.chat.completions.create(\n",
        "        model=models[0], messages=[{\"role\": \"user\", \"content\": message}]\n",
        "    )\n",
        "    display(Markdown(response.choices[0].message.content))\n",
        "else:\n",
        "    print(\"Set OPENROUTER_API_KEY and re-run the API key + client cells first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Go compile and run commands\n",
        "\n",
        "Adjust for your OS (e.g. use `main.exe` and `.\\\\main.exe` on Windows)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "compile_command = [\"go\", \"build\", \"-ldflags=-s -w\", \"-o\", \"main\", \"main.go\"]\n",
        "run_command = [\"./main\"]  # Windows: [\".\\\\main.exe\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Main task: Port Python to Go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "language = \"Go\"\n",
        "extension = \"go\"\n",
        "\n",
        "system_prompt = f\"\"\"\n",
        "Your task is to convert Python code into high-performance {language} code.\n",
        "Respond only with {language} code. Do not provide any explanation other than occasional comments.\n",
        "The {language} code must produce identical output to the Python code and run as fast as possible.\n",
        "Use standard library only unless the algorithm clearly benefits from a well-known package (e.g. math).\n",
        "Output must be a complete, runnable program (e.g. package main with func main()).\n",
        "\n",
        "Important for correctness: If the Python code uses 2**32 (or any value that does not fit in 32 bits),\n",
        "use uint64 for that value and for any LCG/random state. In Go, uint32 max is 2^32-1, so the literal\n",
        "4294967296 (2^32) overflows uint32. Use uint64 and e.g. m := uint64(1)<<32 or var m uint64 = 1<<32.\n",
        "\"\"\"\n",
        "\n",
        "def user_prompt_for(python_code):\n",
        "    return f\"\"\"\n",
        "Port this Python code to {language} with the fastest possible implementation that produces identical output.\n",
        "\n",
        "System information:\n",
        "{json.dumps(system_info, indent=2)}\n",
        "\n",
        "Go toolchain:\n",
        "{json.dumps(go_info, indent=2)}\n",
        "\n",
        "Your response will be written to main.{extension} and then compiled and run with:\n",
        "Compile: {compile_command}\n",
        "Run: {run_command}\n",
        "\n",
        "Respond only with {language} code. No markdown fences or explanation.\n",
        "\n",
        "Python code to port:\n",
        "\n",
        "```python\n",
        "{python_code}\n",
        "```\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def messages_for(python_code):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt_for(python_code)},\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_output(code):\n",
        "    with open(f\"main.{extension}\", \"w\") as f:\n",
        "        f.write(code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def port(model, python_code):\n",
        "    client = clients.get(model)\n",
        "    if not client:\n",
        "        return f\"Error: No client for model {model}\"\n",
        "    kwargs = {\"model\": model, \"messages\": messages_for(python_code), \"max_tokens\": 4096}\n",
        "    if \"gpt\" in model.lower():\n",
        "        try:\n",
        "            kwargs[\"reasoning_effort\"] = \"high\"\n",
        "        except Exception:\n",
        "            pass\n",
        "    response = client.chat.completions.create(**kwargs)\n",
        "    reply = response.choices[0].message.content or \"\"\n",
        "    for strip in (\"```go\", \"```Go\", \"```\"):\n",
        "        reply = reply.replace(strip, \"\")\n",
        "    return reply.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_python(code):\n",
        "    globals_dict = {\"__builtins__\": __builtins__}\n",
        "    buffer = io.StringIO()\n",
        "    old_stdout = sys.stdout\n",
        "    sys.stdout = buffer\n",
        "    try:\n",
        "        exec(code, globals_dict)\n",
        "        output = buffer.getvalue()\n",
        "    except Exception as e:\n",
        "        output = f\"Error: {e}\"\n",
        "    finally:\n",
        "        sys.stdout = old_stdout\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compile_and_run(go_code):\n",
        "    write_output(go_code)\n",
        "    try:\n",
        "        subprocess.run(compile_command, check=True, text=True, capture_output=True, cwd=os.getcwd())\n",
        "        run_result = subprocess.run(run_command, check=True, text=True, capture_output=True, cwd=os.getcwd())\n",
        "        return run_result.stdout\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        return f\"An error occurred:\\n{(e.stderr or e.stdout or str(e))}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Example Python code (max subarray sum with LCG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "python_hard = \"\"\"# Be careful to support large numbers\n",
        "\n",
        "def lcg(seed, a=1664525, c=1013904223, m=2**32):\n",
        "    value = seed\n",
        "    while True:\n",
        "        value = (a * value + c) % m\n",
        "        yield value\n",
        "        \n",
        "def max_subarray_sum(n, seed, min_val, max_val):\n",
        "    lcg_gen = lcg(seed)\n",
        "    random_numbers = [next(lcg_gen) % (max_val - min_val + 1) + min_val for _ in range(n)]\n",
        "    max_sum = float('-inf')\n",
        "    for i in range(n):\n",
        "        current_sum = 0\n",
        "        for j in range(i, n):\n",
        "            current_sum += random_numbers[j]\n",
        "            if current_sum > max_sum:\n",
        "                max_sum = current_sum\n",
        "    return max_sum\n",
        "\n",
        "def total_max_subarray_sum(n, initial_seed, min_val, max_val):\n",
        "    total_sum = 0\n",
        "    lcg_gen = lcg(initial_seed)\n",
        "    for _ in range(20):\n",
        "        seed = next(lcg_gen)\n",
        "        total_sum += max_subarray_sum(n, seed, min_val, max_val)\n",
        "    return total_sum\n",
        "\n",
        "# Parameters\n",
        "n = 10000         # Number of random numbers\n",
        "initial_seed = 42 # Initial seed for the LCG\n",
        "min_val = -10     # Minimum value of random numbers\n",
        "max_val = 10      # Maximum value of random numbers\n",
        "\n",
        "# Timing the function\n",
        "import time\n",
        "start_time = time.time()\n",
        "result = total_max_subarray_sum(n, initial_seed, min_val, max_val)\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Total Maximum Subarray Sum (20 runs):\", result)\n",
        "print(\"Execution Time: {:.6f} seconds\".format(end_time - start_time))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gradio UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7873\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7873/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "try:\n",
        "    from styles import CSS\n",
        "except ImportError:\n",
        "    CSS = None\n",
        "\n",
        "with gr.Blocks(css=CSS or \"\", theme=gr.themes.Monochrome(), title=f\"Port from Python to {language}\") as ui:\n",
        "    with gr.Row(equal_height=True):\n",
        "        with gr.Column(scale=6):\n",
        "            python_input = gr.Code(\n",
        "                label=\"Python (original)\",\n",
        "                value=python_hard,\n",
        "                language=\"python\",\n",
        "                lines=26,\n",
        "            )\n",
        "        with gr.Column(scale=6):\n",
        "            go_output = gr.Code(\n",
        "                label=f\"{language} (generated)\",\n",
        "                value=\"\",\n",
        "                language=\"markdown\",\n",
        "                lines=26,\n",
        "            )\n",
        "\n",
        "    with gr.Row(elem_classes=[\"controls\"]):\n",
        "        python_run_btn = gr.Button(\"Run Python\", elem_classes=[\"run-btn\", \"py\"])\n",
        "        model_dropdown = gr.Dropdown(models, value=models[0] if models else None, show_label=False)\n",
        "        convert_btn = gr.Button(f\"Port to {language}\", elem_classes=[\"convert-btn\"])\n",
        "        go_run_btn = gr.Button(f\"Run {language}\", elem_classes=[\"run-btn\", \"cpp\"])\n",
        "\n",
        "    with gr.Row(equal_height=True):\n",
        "        with gr.Column(scale=6):\n",
        "            python_out = gr.TextArea(label=\"Python result\", lines=8, elem_classes=[\"py-out\"])\n",
        "        with gr.Column(scale=6):\n",
        "            go_out = gr.TextArea(label=f\"{language} result\", lines=8, elem_classes=[\"cpp-out\"])\n",
        "\n",
        "    convert_btn.click(fn=port, inputs=[model_dropdown, python_input], outputs=[go_output])\n",
        "    python_run_btn.click(fn=run_python, inputs=[python_input], outputs=[python_out])\n",
        "    go_run_btn.click(fn=compile_and_run, inputs=[go_output], outputs=[go_out])\n",
        "\n",
        "ui.launch(inbrowser=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
