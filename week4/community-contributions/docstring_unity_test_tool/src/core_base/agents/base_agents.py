from agents import Agent, Runner, OpenAIChatCompletionsModel
from constants import clients
from typing import Type, List
from pathlib import Path
from src.core_base.code.code_model import CodeItem
from src.core_base.code.json_utils import safe_json_loads
from src.core_base.indexer.project_indexer import ProjectIndexer
from src.core_base.code.extractor_utils import extract_symbols_from_import
from src.core_base.agents.agents_utils import _parse_to_models
###############################
# Base Agent
###############################
class BaseCodeAgent:
    """
    Represents an agent that utilizes a specified model to process input text.
    
    Attributes:
      model_name (str): The name of the model used by the agent.
      agent (Agent): The underlying agent used for processing input with the model.
    """

    def __init__(self, name: str, system_prompt: str, model_name: str = "gpt-4o-mini"):
        """
        Initializes a BaseCodeGenerationAgent instance.
        
        Args:
          model_name (str): The name of the model to be used.
          project_path (Path | None, optional): The path to the project, defaults to None.
        """
        if model_name not in clients:
            raise ValueError(f"Model '{model_name}' not found in clients dictionary.")

        self.model_name = model_name
        client = clients[model_name]
        model_obj = OpenAIChatCompletionsModel(model=model_name, openai_client=client)
        self.agent = Agent(
            name=name,
            instructions=system_prompt,
            output_type=str,
            model=model_obj,
        )

    async def run(self, input_text: str) -> str:
        """
        Runs the agent with the provided input text.
        
        Args:
          input_text (str): The input text to be processed.
        
        Returns:
          str: The output generated by the agent.
        """
        result = await Runner.run(self.agent, input_text)
        return result.final_output


###############################
# Base Code Generation Agent
###############################
class BaseCodeGenerationAgent(BaseCodeAgent):
    """
    Base agent for generating structured code outputs such as docstrings, tests, etc.
    
    Attributes:
      OutputModel (Type): The model used for the output generated by this agent.
      SYSTEM_PROMPT (str): The system prompt for this agent.
      PROMPT_TEMPLATE (str): The template for constructing prompts.
    """

    OutputModel: Type
    SYSTEM_PROMPT: str
    PROMPT_TEMPLATE: str

    def __init__(self, model_name: str, project_path: Path | None = None):
        """
        Initializes a BaseCodeGenerationAgent instance.
        
        Args:
          model_name (str): The name of the model to be used.
          project_path (Path | None, optional): The path to the project, defaults to None.
        """
        super().__init__(
            name=self.__class__.__name__,
            system_prompt=self.SYSTEM_PROMPT,
            model_name=model_name,
        )

        self.agent.output_type = self.OutputModel
        self.project_path = project_path

        # Initialize indexer *only if* project_path is provided
        self.indexer = None
        if project_path:
            self.indexer = ProjectIndexer(project_path)
            self.indexer.load_or_build()

    ##########################################################
    # Helper: Summarize code edges for import context
    ##########################################################
    def _summarize_code_edges(self, source: str, head: int = 10, tail: int = 5) -> str:
        """
        Summarizes a source code by returning the first few lines and the last few lines, with an indication that content is omitted if necessary.
        
        Args:
          source (str): The source code to summarize.
          head (int, optional): The number of lines to include from the beginning, defaults to 10.
          tail (int, optional): The number of lines to include from the end, defaults to 5.
        
        Returns:
          str: The summarized code.
        """
        lines = source.strip().splitlines()
        if len(lines) <= head + tail:
            return "\n".join(lines)
        return "\n".join(
            lines[:head]
            + ["# ... (middle omitted for brevity) ..."]
            + lines[-tail:]
        )

    ##########################################################
    # Prompt Construction
    ##########################################################
    def _make_prompt(self, items: List[CodeItem]) -> str:
        """
        Builds a complete prompt for the agent, including import statements, project import snippets, and target items.
        
        Args:
          items (List[CodeItem]): The code items to include in the prompt.
        
        Returns:
          str: The constructed prompt.
        """
        # === Gather imports
        all_imports = set()
        for item in items:
            if getattr(item, "imports", None):
                all_imports.update(item.imports)

        imports_code = "\n".join(sorted(all_imports)) if all_imports else "# No imports detected"

        # === Internal context (only if indexer is available)
        own_code_block = "# Context disabled (no project indexer)"
        if self.indexer:
            own_imports_code = []
            for imp in all_imports:
                symbols = extract_symbols_from_import(imp)
                for sym in symbols:
                    matches = self.indexer.query_by_name(sym)
                    for match in matches:
                        if not match:
                            continue
                        snippet = (
                            f"# Context snippet from {match.file_path}, DO NOT generate anything for this item\n"
                            f"# {match.type} {match.name}\n"
                            f"{self._summarize_code_edges(match.source)}"
                        )
                        own_imports_code.append(snippet)
            own_code_block = (
                "\n\n".join(own_imports_code)
                if own_imports_code
                else "# No internal import snippets found"
            )

        # === Target items
        formatted_items = [
            f"# File: {item.file_path}\n# {item.type} {item.name}\n{item.source.strip()}"
            for item in items
        ]
        items_code = "\n\n".join(formatted_items)

        # === Combine prompt
        prompt_parts = [
            self.PROMPT_TEMPLATE,
            "\n# === IMPORT STATEMENTS ===\n",
            imports_code,
            "\n\n# === OWN IMPORT CODE SNIPPETS ===\n",
            own_code_block,
            "\n\n# === TARGET ITEMS ===\n# Generate only for these items\n",
            items_code,
        ]

        prompt = "".join(prompt_parts)
        return prompt


    ##########################################################
    # Run generation
    ##########################################################
    ##########################################################
    # Run generation
    async def generate(self, items: List[CodeItem]):
        """
        Generates structured output based on the provided code items.
        
        Args:
          items (List[CodeItem]): The code items to process.
        
        Returns:
          List[BaseModel]: A list of Pydantic objects (e.g., DocstringOutput or UnitTestOutput).
        """
        prompt = self._make_prompt(items)


        try:
            result = await self.run(prompt)

            # Caso 1: modelo Pydantic con .items
            if hasattr(result, "items"):
                return result.items

            # Caso 2: string JSON
            if isinstance(result, str):
                parsed = safe_json_loads(result)
                return _parse_to_models(self.OutputModel, parsed)

            # Caso 3: dict
            if isinstance(result, dict):
                return _parse_to_models(self.OutputModel, result)

            print("⚠️ Unexpected result type:", type(result))
            return []

        except Exception as e:
            print(f"⚠️ Error generating {self.__class__.__name__} output — using manual fallback")
            print("Details:", e)

            # Fallback a texto y reparseo
            self.agent.output_type = str
            result_text = await self.run(prompt)
            parsed = safe_json_loads(result_text)
            return _parse_to_models(self.OutputModel, parsed)