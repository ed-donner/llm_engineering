{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Generator â€” Week 4 Day 4 Challenge\n",
    "\n",
    "**Igniters-Tunde-Wey-Week-4** (rewritten from week4-day4-challenge)\n",
    "\n",
    "Use an open-source or frontier model to generate high-performance C++ code from Python (or add comments, or write unit tests). Optionally use a Hugging Face endpoint for an open-source model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:** If you use Hugging Face endpoints, pause them when not in use to avoid cost. [HuggingFace Endpoints UI](https://ui.endpoints.huggingface.co/). In Week 8 we use Modal (pay per use, free credits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import subprocess\n",
    "import platform\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import gradio as gr\n",
    "\n",
    "load_dotenv(override=True)\n",
    "os.environ.setdefault(\"OPENAI_API_KEY\", os.getenv(\"OPENAI_API_KEY\", \"\"))\n",
    "os.environ.setdefault(\"ANTHROPIC_API_KEY\", os.getenv(\"ANTHROPIC_API_KEY\", \"\"))\n",
    "os.environ.setdefault(\"HF_TOKEN\", os.getenv(\"HF_TOKEN\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()\n",
    "claude_client = anthropic.Anthropic()\n",
    "OPENAI_MODEL = \"gpt-4o\"\n",
    "CLAUDE_MODEL = \"claude-3-5-sonnet-20240620\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_OPTIONS = [\"Convert to C\", \"Add comments\", \"Write unit tests\"]\n",
    "\n",
    "SYSTEM_PROMPTS = {\n",
    "    PROMPT_OPTIONS[0]: \"\"\"\n",
    "You are an assistant that reimplements Python code in high performance C++.\n",
    "Respond only with C++ code; use comments sparingly. Do not provide any explanation other than occasional comments.\n",
    "The C++ must produce identical output in the fastest possible time. Keep RNG implementations identical so results match.\n",
    "\"\"\",\n",
    "    PROMPT_OPTIONS[1]: \"\"\"\n",
    "You are an assistant that adds succinct comments and docstrings to Python code. Respond only with valid Python code.\n",
    "\"\"\",\n",
    "    PROMPT_OPTIONS[2]: \"\"\"\n",
    "You are an assistant that creates unit tests for Python code. Respond only with valid Python code.\n",
    "\"\"\",\n",
    "}\n",
    "\n",
    "USER_PROMPTS = {\n",
    "    PROMPT_OPTIONS[0]: \"\"\"\n",
    "Rewrite this Python code in C++ with the fastest possible implementation that produces identical output.\n",
    "Respond only with C++ code; do not explain. Pay attention to number types (no int overflows).\n",
    "Include all necessary headers (e.g. #include <iomanip>).\n",
    "\n",
    "\"\"\",\n",
    "    PROMPT_OPTIONS[1]: \"Keep this Python code but insert appropriate comments and docstrings.\",\n",
    "    PROMPT_OPTIONS[2]: \"Create unit tests for this Python code.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_OPTIONS = [\"Hello, World\", \"Calculate pi\", \"Kadane's Algorithm\", \"Sieve of Eratosthenes\"]\n",
    "\n",
    "PYTHON_SAMPLES = {\n",
    "    SAMPLE_OPTIONS[0]: \"\"\"\n",
    "import time\n",
    "start_time = time.time()\n",
    "print(\"Hello, world\")\n",
    "end_time = time.time()\n",
    "print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
    "\"\"\",\n",
    "    SAMPLE_OPTIONS[1]: \"\"\"\n",
    "import time\n",
    "def calculate(iterations, param1, param2):\n",
    "    result = 1.0\n",
    "    for i in range(1, iterations+1):\n",
    "        j = i * param1 - param2\n",
    "        result -= (1/j)\n",
    "        j = i * param1 + param2\n",
    "        result += (1/j)\n",
    "    return result\n",
    "start_time = time.time()\n",
    "result = calculate(100_000_000, 4, 1) * 4\n",
    "end_time = time.time()\n",
    "print(f\"Result: {result:.12f}\")\n",
    "print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
    "\"\"\",\n",
    "    SAMPLE_OPTIONS[2]: \"\"\"\n",
    "# Be careful to support large number sizes\n",
    "def lcg(seed, a=1664525, c=1013904223, m=2**32):\n",
    "    value = seed\n",
    "    while True:\n",
    "        value = (a * value + c) % m\n",
    "        yield value\n",
    "def max_subarray_sum(n, seed, min_val, max_val):\n",
    "    lcg_gen = lcg(seed)\n",
    "    random_numbers = [next(lcg_gen) % (max_val - min_val + 1) + min_val for _ in range(n)]\n",
    "    max_sum = float('-inf')\n",
    "    for i in range(n):\n",
    "        current_sum = 0\n",
    "        for j in range(i, n):\n",
    "            current_sum += random_numbers[j]\n",
    "            if current_sum > max_sum:\n",
    "                max_sum = current_sum\n",
    "    return max_sum\n",
    "def total_max_subarray_sum(n, initial_seed, min_val, max_val):\n",
    "    total_sum = 0\n",
    "    lcg_gen = lcg(initial_seed)\n",
    "    for _ in range(20):\n",
    "        seed = next(lcg_gen)\n",
    "        total_sum += max_subarray_sum(n, seed, min_val, max_val)\n",
    "    return total_sum\n",
    "n, initial_seed, min_val, max_val = 10000, 42, -10, 10\n",
    "import time\n",
    "start_time = time.time()\n",
    "result = total_max_subarray_sum(n, initial_seed, min_val, max_val)\n",
    "end_time = time.time()\n",
    "print(\"Total Maximum Subarray Sum (20 runs):\", result)\n",
    "print(\"Execution Time: {:.6f} seconds\".format(end_time - start_time))\n",
    "\"\"\",\n",
    "    SAMPLE_OPTIONS[3]: \"\"\"\n",
    "import time\n",
    "start_time = time.time()\n",
    "stop_at = 100_000_000\n",
    "prime = [True] * (stop_at + 1)\n",
    "p = 2\n",
    "while p * p <= stop_at:\n",
    "    if prime[p]:\n",
    "        for i in range(p * p, stop_at + 1, p):\n",
    "            prime[i] = False\n",
    "    p += 1\n",
    "primes = [p for p in range(2, stop_at + 1) if prime[p]]\n",
    "end_time = time.time()\n",
    "print(\"Maximum prime: {:,}\".format(primes[-1]))\n",
    "print(\"Execution Time: {:.6f} seconds\".format(end_time - start_time))\n",
    "\"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_prompt(instruction: str, python_code: str) -> str:\n",
    "    return instruction.strip() + \"\\n\" + python_code\n",
    "\n",
    "def build_openai_messages(system_prompt: str, user_prompt: str):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_cpp_file(filename_base: str, cpp_code: str) -> None:\n",
    "    code_to_write = cpp_code.replace(\"```cpp\", \"\").replace(\"```\", \"\").strip()\n",
    "    with open(f\"{filename_base}.cpp\", \"w\") as f:\n",
    "        f.write(code_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OPTIONS = [\"GPT\", \"Claude\"]\n",
    "DEFAULT_MODEL = MODEL_OPTIONS[0]\n",
    "\n",
    "def _strip_code_blocks(text: str) -> str:\n",
    "    return text.replace(\"```cpp\\n\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "def stream_gpt(system_prompt, user_prompt, python_code):\n",
    "    full_prompt = build_user_prompt(user_prompt, python_code)\n",
    "    messages = build_openai_messages(system_prompt, full_prompt)\n",
    "    stream = openai_client.chat.completions.create(\n",
    "        model=OPENAI_MODEL, messages=messages, stream=True\n",
    "    )\n",
    "    reply = \"\"\n",
    "    for chunk in stream:\n",
    "        reply += chunk.choices[0].delta.content or \"\"\n",
    "        yield _strip_code_blocks(reply)\n",
    "\n",
    "def stream_claude(system_prompt, user_prompt, python_code):\n",
    "    full_prompt = build_user_prompt(user_prompt, python_code)\n",
    "    result = claude_client.messages.stream(\n",
    "        model=CLAUDE_MODEL,\n",
    "        max_tokens=2000,\n",
    "        system=system_prompt,\n",
    "        messages=[{\"role\": \"user\", \"content\": full_prompt}],\n",
    "    )\n",
    "    reply = \"\"\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            reply += text\n",
    "            yield _strip_code_blocks(reply)\n",
    "\n",
    "def call_llm(system_prompt, user_prompt, python_code, model_name):\n",
    "    if model_name == \"GPT\":\n",
    "        gen = stream_gpt(system_prompt, user_prompt, python_code)\n",
    "    elif model_name == \"Claude\":\n",
    "        gen = stream_claude(system_prompt, user_prompt, python_code)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    for chunk in gen:\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5818885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_python(code: str) -> str:\n",
    "    try:\n",
    "        buf = io.StringIO()\n",
    "        sys.stdout = buf\n",
    "        exec(code)\n",
    "    finally:\n",
    "        sys.stdout = sys.__stdout__\n",
    "    return buf.getvalue()\n",
    "\n",
    "def execute_cpp(cpp_code: str, compiler_info) -> str:\n",
    "    write_cpp_file(\"optimized\", cpp_code)\n",
    "    if not compiler_info or not compiler_info[2]:\n",
    "        return \"No compiler available.\"\n",
    "    compile_cmd = compiler_info[2]\n",
    "    try:\n",
    "        subprocess.run(compile_cmd, check=True, text=True, capture_output=True)\n",
    "        run_cmd = [\"optimized.exe\"] if platform.system() == \"Windows\" else [\"./optimized\"]\n",
    "        run_result = subprocess.run(run_cmd, check=True, text=True, capture_output=True)\n",
    "        return run_result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Error:\\n{e.stderr or e.stdout}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VISUAL_STUDIO_2022 = \"C:\\\\Program Files\\\\Microsoft Visual Studio\\\\2022\\\\Community\\\\Common7\\\\Tools\\\\VsDevCmd.bat\"\n",
    "VISUAL_STUDIO_2019 = \"C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2019\\\\BuildTools\\\\Common7\\\\Tools\\\\VsDevCmd.bat\"\n",
    "SIMPLE_CPP = '''\n",
    "#include <iostream>\n",
    "int main() { std::cout << \"Hello\"; return 0; }\n",
    "'''\n",
    "\n",
    "def _run_cmd(cmd):\n",
    "    try:\n",
    "        r = subprocess.run(cmd, check=True, text=True, capture_output=True)\n",
    "        return r.stdout if r.stdout else \"SUCCESS\"\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def get_compiler_info(filename_base: str):\n",
    "    plat = platform.system()\n",
    "    result = []\n",
    "    try:\n",
    "        with open(\"simple.cpp\", \"w\") as f:\n",
    "            f.write(SIMPLE_CPP)\n",
    "        if plat == \"Windows\":\n",
    "            for vs_name, vs_path in [(\"Visual Studio 2022\", VISUAL_STUDIO_2022), (\"Visual Studio 2019\", VISUAL_STUDIO_2019)]:\n",
    "                if os.path.isfile(vs_path):\n",
    "                    for f in [\"simple.exe\", \"simple.obj\"]:\n",
    "                        if os.path.isfile(f):\n",
    "                            os.remove(f)\n",
    "                    cmd = [\"cmd\", \"/c\", f\"call \\\"{vs_path}\\\" && cl simple.cpp\"]\n",
    "                    if _run_cmd(cmd):\n",
    "                        out = _run_cmd([\"simple.exe\"])\n",
    "                        if out and \"Hello\" in out:\n",
    "                            result = [\"Windows\", vs_name, [\"cmd\", \"/c\", f\"call \\\"{vs_path}\\\" && cl {filename_base}.cpp\"]]\n",
    "                            break\n",
    "            if not result:\n",
    "                result = [plat, \"Unavailable\", []]\n",
    "        elif plat == \"Linux\":\n",
    "            for compiler, args in [(\"GCC (g++)\", [\"g++\", \"simple.cpp\", \"-o\", \"simple\"]), (\"Clang++\", [\"clang++\", \"simple.cpp\", \"-o\", \"simple\"])]:\n",
    "                if os.path.isfile(\"./simple\"):\n",
    "                    os.remove(\"./simple\")\n",
    "                if _run_cmd(args):\n",
    "                    if _run_cmd([\"./simple\"]) == \"Hello\":\n",
    "                        result = [\"Linux\", compiler, [args[0], f\"{filename_base}.cpp\", \"-o\", filename_base]]\n",
    "                        break\n",
    "            if not result:\n",
    "                result = [plat, \"Unavailable\", []]\n",
    "        elif plat == \"Darwin\":\n",
    "            if os.path.isfile(\"./simple\"):\n",
    "                os.remove(\"./simple\")\n",
    "            args = [\"clang++\", \"-Ofast\", \"-std=c++17\", \"-o\", \"simple\", \"simple.cpp\"]\n",
    "            if _run_cmd(args) and _run_cmd([\"./simple\"]) == \"Hello\":\n",
    "                result = [\"Macintosh\", \"Clang++\", [\"clang++\", \"-Ofast\", \"-std=c++17\", \"-o\", filename_base, f\"{filename_base}.cpp\"]]\n",
    "            if not result:\n",
    "                result = [plat, \"Unavailable\", []]\n",
    "        else:\n",
    "            result = [plat, \"Unavailable\", []]\n",
    "    except Exception:\n",
    "        result = [plat or \"Unknown\", \"Unavailable\", []]\n",
    "    return result if result else [\"Unknown\", \"Unavailable\", []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPILER_INFO = get_compiler_info(\"optimized\")\n",
    "selected_tab_key = PROMPT_OPTIONS[0]\n",
    "\n",
    "def on_tab_select(evt: gr.SelectData):\n",
    "    global selected_tab_key\n",
    "    selected_tab_key = evt.value\n",
    "\n",
    "def reset_prompts():\n",
    "    return SYSTEM_PROMPTS[selected_tab_key], USER_PROMPTS[selected_tab_key]\n",
    "\n",
    "def on_sample_change(sample_name, current_code):\n",
    "    if sample_name != \"Custom\" and sample_name in PYTHON_SAMPLES:\n",
    "        return PYTHON_SAMPLES[sample_name]\n",
    "    return current_code\n",
    "\n",
    "def on_code_edit():\n",
    "    return \"Custom\"\n",
    "\n",
    "def run_cpp(cpp_code):\n",
    "    return execute_cpp(cpp_code, COMPILER_INFO)\n",
    "\n",
    "CSS = \".python {background-color: #306998;} .cpp {background-color: #050;}\"\n",
    "\n",
    "with gr.Blocks(css=CSS) as ui:\n",
    "    with gr.Tab(PROMPT_OPTIONS[0]) as tab1:\n",
    "        gr.Markdown(\"# \" + PROMPT_OPTIONS[0])\n",
    "        with gr.Group():\n",
    "            with gr.Row():\n",
    "                sys1 = gr.Textbox(label=\"System prompt\", value=SYSTEM_PROMPTS[PROMPT_OPTIONS[0]], lines=10, interactive=True)\n",
    "                usr1 = gr.Textbox(label=\"User prompt\", value=USER_PROMPTS[PROMPT_OPTIONS[0]], lines=10, interactive=True)\n",
    "            gr.Button(\"Reset prompts\").click(reset_prompts, outputs=[sys1, usr1])\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                rad1 = gr.Radio(SAMPLE_OPTIONS + [\"Custom\"], label=\"Sample program\", value=SAMPLE_OPTIONS[0])\n",
    "                py1 = gr.Textbox(label=\"Python code\", value=PYTHON_SAMPLES[SAMPLE_OPTIONS[0]], lines=10, interactive=True)\n",
    "            with gr.Column():\n",
    "                model1 = gr.Dropdown(MODEL_OPTIONS, label=\"Model\", value=DEFAULT_MODEL)\n",
    "                cpp1 = gr.Textbox(label=\"C++ code\", lines=10, interactive=True)\n",
    "                gr.Button(\"Convert code\").click(call_llm, inputs=[sys1, usr1, py1, model1], outputs=[cpp1])\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                out_py1 = gr.TextArea(label=\"Python result\", elem_classes=[\"python\"])\n",
    "                gr.Button(\"Run Python\").click(execute_python, inputs=[py1], outputs=[out_py1])\n",
    "            with gr.Column():\n",
    "                out_cpp1 = gr.TextArea(label=\"C++ result\", elem_classes=[\"cpp\"])\n",
    "                btn_cpp = gr.Button(\"Run C++\" if COMPILER_INFO[1] != \"Unavailable\" else \"No compiler\", interactive=(COMPILER_INFO[1] != \"Unavailable\"))\n",
    "                btn_cpp.click(run_cpp, inputs=[cpp1], outputs=[out_cpp1])\n",
    "                gr.Radio([COMPILER_INFO[0]], label=\"Architecture\", value=COMPILER_INFO[0], interactive=False)\n",
    "                gr.Radio([COMPILER_INFO[1]], label=\"Compiler\", value=COMPILER_INFO[1], interactive=False)\n",
    "        rad1.change(on_sample_change, [rad1, py1], [py1])\n",
    "        py1.change(on_code_edit, outputs=[rad1])\n",
    "    tab1.select(on_tab_select)\n",
    "\n",
    "    with gr.Tab(PROMPT_OPTIONS[1]) as tab2:\n",
    "        gr.Markdown(\"# \" + PROMPT_OPTIONS[1])\n",
    "        with gr.Group():\n",
    "            with gr.Row():\n",
    "                sys2 = gr.Textbox(label=\"System prompt\", value=SYSTEM_PROMPTS[PROMPT_OPTIONS[1]], lines=10, interactive=True)\n",
    "                usr2 = gr.Textbox(label=\"User prompt\", value=USER_PROMPTS[PROMPT_OPTIONS[1]], lines=10, interactive=True)\n",
    "            gr.Button(\"Reset prompts\").click(reset_prompts, outputs=[sys2, usr2])\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                rad2 = gr.Radio(SAMPLE_OPTIONS + [\"Custom\"], label=\"Sample program\", value=SAMPLE_OPTIONS[1])\n",
    "                py2 = gr.Textbox(label=\"Python code\", value=PYTHON_SAMPLES[SAMPLE_OPTIONS[1]], lines=10, interactive=True)\n",
    "            with gr.Column():\n",
    "                model2 = gr.Dropdown(MODEL_OPTIONS, label=\"Model\", value=DEFAULT_MODEL)\n",
    "                gr.Button(\"Comment code\").click(call_llm, inputs=[sys2, usr2, py2, model2], outputs=[com2 := gr.Textbox(label=\"Commented code\", lines=20)])\n",
    "        rad2.change(on_sample_change, [rad2, py2], [py2])\n",
    "        py2.change(on_code_edit, outputs=[rad2])\n",
    "    tab2.select(on_tab_select)\n",
    "\n",
    "    with gr.Tab(PROMPT_OPTIONS[2]) as tab3:\n",
    "        gr.Markdown(\"# \" + PROMPT_OPTIONS[2])\n",
    "        with gr.Group():\n",
    "            with gr.Row():\n",
    "                sys3 = gr.Textbox(label=\"System prompt\", value=SYSTEM_PROMPTS[PROMPT_OPTIONS[2]], lines=10, interactive=True)\n",
    "                usr3 = gr.Textbox(label=\"User prompt\", value=USER_PROMPTS[PROMPT_OPTIONS[2]], lines=10, interactive=True)\n",
    "            gr.Button(\"Reset prompts\").click(reset_prompts, outputs=[sys3, usr3])\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                rad3 = gr.Radio(SAMPLE_OPTIONS + [\"Custom\"], label=\"Sample program\", value=SAMPLE_OPTIONS[1])\n",
    "                py3 = gr.Textbox(label=\"Python code\", value=PYTHON_SAMPLES[SAMPLE_OPTIONS[1]], lines=10, interactive=True)\n",
    "            with gr.Column():\n",
    "                model3 = gr.Dropdown(MODEL_OPTIONS, label=\"Model\", value=DEFAULT_MODEL)\n",
    "                gr.Button(\"Create unit tests\").click(call_llm, inputs=[sys3, usr3, py3, model3], outputs=[ut3 := gr.Textbox(label=\"Unit tests\", lines=20)])\n",
    "        rad3.change(on_sample_change, [rad3, py3], [py3])\n",
    "        py3.change(on_code_edit, outputs=[rad3])\n",
    "    tab3.select(on_tab_select)\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
