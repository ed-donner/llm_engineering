{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4a6ab9a2-28a2-445d-8512-a0dc8d1b54e9",
      "metadata": {},
      "source": [
        "# Code Generator\n",
        "\n",
        "The requirement: use a Frontier model to generate high performance C++ code from Python code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5ccb926-7b49-44a4-99ab-8ef20b5778c0",
      "metadata": {},
      "source": [
        "<table style=\"margin: 0; text-align: left;\">\n",
        "    <tr>\n",
        "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
        "            <img src=\"../assets/resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
        "        </td>\n",
        "        <td>\n",
        "            <h2 style=\"color:#f71;\">Reminder: OPTIONAL to execute C++ code or Rust code</h2>\n",
        "            <span style=\"color:#f71;\">As an alternative, you can run it on the website given yesterday</span>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d90e04a2-5b8a-4fd5-9db8-27c02f033313",
      "metadata": {},
      "source": [
        "<table style=\"margin: 0; text-align: left;\">\n",
        "    <tr>\n",
        "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
        "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
        "        </td>\n",
        "        <td>\n",
        "            <h1 style=\"color:#900;\">Important Note</h1>\n",
        "            <span style=\"color:#900;\">\n",
        "            In this lab, I use high end models GPT 5, Claude 4.5 Sonnet, Gemini 2.5 Pro, Grok 4, which are the slightly higher priced models. The costs are still low, but if you'd prefer to keep costs ultra low, please pick lower cost models like gpt-5-nano.\n",
        "            </span>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e610bf56-a46e-4aff-8de1-ab49d62b1ad3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import io\n",
        "import sys\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "import subprocess\n",
        "from IPython.display import Markdown, display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f672e1c-87e9-4865-b760-370fa605e614",
      "metadata": {},
      "outputs": [],
      "source": [
        "load_dotenv(override=True)\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
        "\n",
        "\n",
        "if openai_api_key:\n",
        "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
        "else:\n",
        "    print(\"OpenAI API Key not set\")\n",
        "    \n",
        "\n",
        "if google_api_key:\n",
        "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
        "else:\n",
        "    print(\"Google API Key not set (and this is optional)\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59863df1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Connect to client libraries\n",
        "\n",
        "openai = OpenAI()\n",
        "\n",
        "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        "ollama_url = \"http://localhost:11434/v1\"\n",
        "\n",
        "\n",
        "\n",
        "gemini = OpenAI(api_key=google_api_key, base_url=gemini_url)\n",
        "ollama = OpenAI(api_key=\"ollama\", base_url=ollama_url)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aa149ed-9298-4d69-8fe2-8f5de0f667da",
      "metadata": {},
      "outputs": [],
      "source": [
        "models = [\"gpt-5\", \"gemini-2.5-pro\", \"qwen2.5-coder\"]\n",
        "\n",
        "clients = {\"gpt-5\": openai, \"gemini-2.5-pro\": gemini, \"qwen2.5-coder\": ollama}\n",
        "\n",
        "# Ollama (local): code-specific model. Install with: ollama pull qwen2.5-coder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0b0a437",
      "metadata": {},
      "source": [
        "## And now, on with the main task\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6896636f-923e-4a2c-9d6c-fac07828a201",
      "metadata": {},
      "outputs": [],
      "source": [
        "language = \"Rust\" # or \"C++\"\n",
        "extension = \"rs\" if language == \"Rust\" else \"cpp\"\n",
        "\n",
        "system_prompt = f\"\"\"\n",
        "You are a senior software developer in multiple languages and your task if to \n",
        "detect the language with which the code was written, then produce same exact code but with\n",
        "write clear and concise comments on codes and also short and concise doc strings .\n",
        "you strive to be clear as possible to any one reading the code.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def user_prompt_for(code):\n",
        "    return f\"\"\"\n",
        "    Help me comment this block of code:  {code}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e7b3546-57aa-4c29-bc5d-f211970d04eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def messages_for(code):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt_for(code)}\n",
        "    ]\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7d2fea8-74c6-4421-8f1e-0e76d5b201b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def comment_code(model, code):\n",
        "    client = clients[model]\n",
        "    reasoning_effort = \"high\" if 'gpt' in model else None\n",
        "    response = client.chat.completions.create(model=model, messages=messages_for(code), reasoning_effort=reasoning_effort)\n",
        "    reply = response.choices[0].message.content\n",
        "    return reply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3b497b3-f569-420e-b92e-fb0f49957ce0",
      "metadata": {},
      "outputs": [],
      "source": [
        "python_hard = \"\"\"# Be careful to support large numbers\n",
        "\n",
        "def lcg(seed, a=1664525, c=1013904223, m=2**32):\n",
        "    value = seed\n",
        "    while True:\n",
        "        value = (a * value + c) % m\n",
        "        yield value\n",
        "        \n",
        "def max_subarray_sum(n, seed, min_val, max_val):\n",
        "    lcg_gen = lcg(seed)\n",
        "    random_numbers = [next(lcg_gen) % (max_val - min_val + 1) + min_val for _ in range(n)]\n",
        "    max_sum = float('-inf')\n",
        "    for i in range(n):\n",
        "        current_sum = 0\n",
        "        for j in range(i, n):\n",
        "            current_sum += random_numbers[j]\n",
        "            if current_sum > max_sum:\n",
        "                max_sum = current_sum\n",
        "    return max_sum\n",
        "\n",
        "def total_max_subarray_sum(n, initial_seed, min_val, max_val):\n",
        "    total_sum = 0\n",
        "    lcg_gen = lcg(initial_seed)\n",
        "    for _ in range(20):\n",
        "        seed = next(lcg_gen)\n",
        "        total_sum += max_subarray_sum(n, seed, min_val, max_val)\n",
        "    return total_sum\n",
        "\n",
        "\n",
        "n = 10000         \n",
        "initial_seed = 42 \n",
        "min_val = -10     \n",
        "max_val = 10      \n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "result = total_max_subarray_sum(n, initial_seed, min_val, max_val)\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Total Maximum Subarray Sum (20 runs):\", result)\n",
        "print(\"Execution Time: {:.6f} seconds\".format(end_time - start_time))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "465d6cad",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from styles import CSS\n",
        "\n",
        "with gr.Blocks(css=CSS, theme=gr.themes.Default(primary_hue=\"indigo\", neutral_hue=\"slate\")) as ui:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # Code Auto Commenter\n",
        "        Add clear, professional comments and docstrings to Python / C++ code\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    with gr.Row(equal_height=True, elem_classes=[\"main-content\"]):\n",
        "        with gr.Column(scale=1, min_width=500):\n",
        "            gr.Markdown(\"**Input Code**\")\n",
        "            code = gr.Code(\n",
        "                label=\"\",\n",
        "                value=python_hard,\n",
        "                language=\"python\",\n",
        "                lines=30,\n",
        "                elem_classes=[\"card\"],\n",
        "                show_label=False,\n",
        "            )\n",
        "\n",
        "        with gr.Column(scale=1, min_width=500):\n",
        "            gr.Markdown(\"**Commented Output**\")\n",
        "            code_out = gr.Code(\n",
        "                label=\"\",\n",
        "                lines=30,\n",
        "                # placeholder=\"Commented code appears hereâ€¦\",\n",
        "                interactive=False,\n",
        "                elem_classes=[\"py-out\", \"card\"],\n",
        "                show_label=False,\n",
        "            )\n",
        "\n",
        "    with gr.Row(elem_classes=[\"controls\"]):\n",
        "        with gr.Group():\n",
        "            model = gr.Dropdown(\n",
        "                choices=models,\n",
        "                value=models[0],\n",
        "                label=\"Model\",\n",
        "                container=False,\n",
        "                scale=1,\n",
        "                min_width=220,\n",
        "            )\n",
        "            code_comment_run = gr.Button(\n",
        "                \"Comment Code\",\n",
        "                variant=\"primary\",\n",
        "                elem_classes=[\"run-btn\", \"py\"],\n",
        "                scale=0,\n",
        "            )\n",
        "\n",
        "    # Optional: status / info footer\n",
        "    gr.Markdown(\n",
        "        \"*Tip: Use Python syntax highlighting works best. C++ support coming soon.*\",\n",
        "        elem_classes=[\"text-dim\"]\n",
        "    )\n",
        "\n",
        "    code_comment_run.click(\n",
        "        fn=comment_code,\n",
        "        inputs=[model, code],\n",
        "        outputs=[code_out]\n",
        "    )\n",
        "\n",
        "ui.launch(inbrowser=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2311ada8",
      "metadata": {},
      "source": [
        "## RESULTS!\n",
        "\n",
        "Qwen 2.5 Coder: FAIL  \n",
        "Gemini 2.5 Pro: FAIL  \n",
        "DeepSeek Coder v2: FAIL  \n",
        "Qwen3 Coder 30B: FAIL  \n",
        "Claude Sonnet 4.5: FAIL  \n",
        "GPT-5: FAIL\n",
        "\n",
        "3rd place: GPT-oss-20B: 0.000341  \n",
        "2nd place: Grok 4: 0.000317  \n",
        "**1st place: OpenAI GPT-OSS 120B: 0.000304**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9b51dc7",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"In Ed's experimenet, the GPT-OSS 120B model outcome is {33.755209/0.000304:,.0f} times faster than the Python code.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6197bb97",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
