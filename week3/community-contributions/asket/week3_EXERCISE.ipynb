{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frank Asket's Week 3 Exercise\n",
    "\n",
    "[Frank Asket](https://github.com/frank-asket) — *Founder & CTO building Human-Centered AI infrastructure.*\n",
    "\n",
    "**Synthetic dataset generator:** describe a business scenario (e.g. restaurant reviews, support tickets, product catalog); the LLM generates structured synthetic data (CSV or JSON). Runs locally with **OpenRouter** (or OpenAI); **Gradio UI** to configure scenario, number of rows, and format. No Colab or HuggingFace token required."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment & API client (OpenRouter preferred, fallback OpenAI)\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if openrouter_api_key and openrouter_api_key.startswith(\"sk-or-\"):\n",
    "    client = OpenAI(api_key=openrouter_api_key, base_url=\"https://openrouter.ai/api/v1\")\n",
    "    MODEL = \"openai/gpt-4o-mini\"\n",
    "    print(\"Using OpenRouter.\")\n",
    "elif openai_api_key:\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "    MODEL = \"gpt-4o-mini\"\n",
    "    print(\"Using OpenAI.\")\n",
    "else:\n",
    "    client = OpenAI()\n",
    "    MODEL = \"gpt-4o-mini\"\n",
    "    print(\"Using default client (set OPENROUTER_API_KEY or OPENAI_API_KEY in .env).\")"
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt: synthetic data only, no commentary, no real PII\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are a synthetic dataset generator. Your only job is to output structured data.\n",
    "\n",
    "Rules:\n",
    "- Output ONLY the requested format (CSV or JSON). No explanations, no markdown code fences, no extra text.\n",
    "- For CSV: first line is the header row, then one row per record. Use commas; escape quotes inside fields.\n",
    "- For JSON: output a single JSON array of objects. Each object is one record with consistent keys.\n",
    "- Generate realistic but fake data. No real names, emails, or identifiable information.\n",
    "- Infer a sensible schema from the user's scenario (e.g. for \"restaurant reviews\" use: reviewer_name, rating, review_text, date).\n",
    "- Generate exactly the number of records requested.\"\"\""
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(scenario: str, num_rows: int, output_format: str) -> str:\n",
    "    \"\"\"Call the LLM to generate synthetic data. Returns raw CSV or JSON string.\"\"\"\n",
    "    if not scenario or not scenario.strip():\n",
    "        return \"Please describe the dataset scenario (e.g. 'restaurant reviews with rating and date').\"\n",
    "    num_rows = max(1, min(int(num_rows), 50))\n",
    "    fmt = \"CSV\" if \"csv\" in output_format.lower() else \"JSON\"\n",
    "    user_msg = (\n",
    "        f\"Generate a synthetic dataset with exactly {num_rows} records. \"\n",
    "        f\"Scenario: {scenario.strip()}. \"\n",
    "        f\"Output format: {fmt} only, no other text.\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": user_msg}\n",
    "    ]\n",
    "    try:\n",
    "        r = client.chat.completions.create(model=MODEL, messages=messages, temperature=0.7)\n",
    "        raw = (r.choices[0].message.content or \"\").strip()\n",
    "        # Strip markdown code blocks if the model added them\n",
    "        if raw.startswith(\"```\"):\n",
    "            raw = re.sub(r\"^```\\w*\\n\", \"\", raw)\n",
    "            raw = re.sub(r\"\\n```\\s*$\", \"\", raw)\n",
    "        return raw\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n"
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio UI\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        ## Synthetic Dataset Generator (Week 3)\n",
    "        Describe the kind of data you want (e.g. *product catalog with name, price, category* or *customer support tickets with id, subject, status*).\n",
    "        Choose number of rows and output format. Output is raw CSV or JSON — copy or download.\n",
    "        \"\"\"\n",
    "    )\n",
    "    with gr.Row():\n",
    "        scenario = gr.Textbox(\n",
    "            label=\"Dataset scenario\",\n",
    "            placeholder=\"e.g. Restaurant reviews with reviewer_name, rating (1-5), review_text, date\",\n",
    "            lines=2\n",
    "        )\n",
    "    with gr.Row():\n",
    "        num_rows = gr.Slider(1, 50, value=5, step=1, label=\"Number of rows\")\n",
    "        output_format = gr.Dropdown([\"CSV\", \"JSON\"], value=\"CSV\", label=\"Output format\")\n",
    "    btn = gr.Button(\"Generate\", variant=\"primary\")\n",
    "    out = gr.Textbox(label=\"Generated data\", lines=12)\n",
    "\n",
    "    btn.click(fn=generate_dataset, inputs=[scenario, num_rows, output_format], outputs=out)\n",
    "\n",
    "demo.launch(inbrowser=True, theme=gr.themes.Soft())"
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
