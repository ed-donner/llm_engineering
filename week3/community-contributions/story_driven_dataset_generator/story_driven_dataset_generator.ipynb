{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé≠ Story-Driven Synthetic Dataset Generator\n",
    "\n",
    "A creative approach to generating interconnected, narrative-driven synthetic data.\n",
    "\n",
    "**Features:**\n",
    "- üìä **Standard Mode** - Classic row-by-row generation\n",
    "- üìñ **Story Chain** - Chronological narrative data\n",
    "- ü•ä **Model Battle** - Two AI models compete\n",
    "- üîÑ **Data Remix** - Generate more data matching your sample\n",
    "- üé® **Style Personas** - Corporate, Creative, or Data Scientist styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from io import StringIO\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Initialize clients\n",
    "openai_client = OpenAI()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "print(\"‚úÖ Clients initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"GPT-4o-mini\": {\"provider\": \"openai\", \"model\": \"gpt-4o-mini\"},\n",
    "    \"GPT-4o\": {\"provider\": \"openai\", \"model\": \"gpt-4o\"},\n",
    "    \"Gemini 1.5 Flash\": {\"provider\": \"gemini\", \"model\": \"gemini-1.5-flash\"},\n",
    "    \"Gemini 2.0 Flash\": {\"provider\": \"gemini\", \"model\": \"gemini-2.0-flash\"},\n",
    "}\n",
    "\n",
    "print(f\"Available models: {list(MODELS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style Personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSONAS = {\n",
    "    \"üè¢ Corporate Analyst\": \"\"\"You write like a formal business analyst. Use precise business terminology, \n",
    "    include realistic numeric data with proper formatting, formal company names, \n",
    "    and professional titles. Data should feel like it came from a Fortune 500 quarterly report.\"\"\",\n",
    "    \n",
    "    \"üé® Creative Writer\": \"\"\"You write like a creative storyteller. Use colorful, unique names for products \n",
    "    and companies, include descriptive text fields, varied and interesting patterns. \n",
    "    Data should feel imaginative yet plausible - like a quirky startup ecosystem.\"\"\",\n",
    "    \n",
    "    \"üî¨ Data Scientist\": \"\"\"You write like a data scientist creating test data. Include realistic statistical \n",
    "    distributions, edge cases (nulls, outliers, boundary values), proper data types. \n",
    "    Data should feel like it was carefully curated for ML model training.\"\"\",\n",
    "}\n",
    "\n",
    "print(f\"Available personas: {list(PERSONAS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAINS = {\n",
    "    \"üöÄ Startup Journey\": {\n",
    "        \"description\": \"A startup's evolution from founding to exit\",\n",
    "        \"schema\": \"date,event_type,company_name,valuation_usd,employees,funding_round,milestone\",\n",
    "        \"story_hint\": \"Show chronological growth: founding ‚Üí seed ‚Üí series A/B/C ‚Üí growth ‚Üí exit\"\n",
    "    },\n",
    "    \"üõí Customer Journey\": {\n",
    "        \"description\": \"A customer's relationship with an e-commerce brand\",  \n",
    "        \"schema\": \"date,customer_id,event,product_category,order_value,loyalty_points,satisfaction\",\n",
    "        \"story_hint\": \"Show relationship evolution: first visit ‚Üí first purchase ‚Üí repeat buyer ‚Üí loyal customer\"\n",
    "    },\n",
    "    \"üè• Patient Treatment\": {\n",
    "        \"description\": \"A patient's healthcare journey\",\n",
    "        \"schema\": \"date,patient_id,visit_type,diagnosis,treatment,provider,outcome\",\n",
    "        \"story_hint\": \"Show treatment progression: initial symptoms ‚Üí diagnosis ‚Üí treatment ‚Üí recovery\"\n",
    "    },\n",
    "    \"üìà Stock Performance\": {\n",
    "        \"description\": \"A company's stock performance over time\",\n",
    "        \"schema\": \"date,ticker,open,high,low,close,volume,sentiment\",\n",
    "        \"story_hint\": \"Show market story: IPO ‚Üí growth ‚Üí volatility events ‚Üí recovery/decline\"\n",
    "    },\n",
    "    \"üéÆ Game Player Progress\": {\n",
    "        \"description\": \"A player's journey through a game\",\n",
    "        \"schema\": \"date,player_id,level,xp_gained,items_acquired,achievements,playtime_mins\",\n",
    "        \"story_hint\": \"Show player engagement: onboarding ‚Üí learning ‚Üí mastery ‚Üí engagement patterns\"\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"Available domains: {list(DOMAINS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Functions - API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai(model: str, system_prompt: str, user_prompt: str) -> str:\n",
    "    \"\"\"Call OpenAI API and return response.\"\"\"\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.8,\n",
    "        max_tokens=2000\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def call_gemini(model: str, system_prompt: str, user_prompt: str) -> str:\n",
    "    \"\"\"Call Google Gemini API and return response.\"\"\"\n",
    "    gemini_model = genai.GenerativeModel(model)\n",
    "    full_prompt = f\"{system_prompt}\\n\\n{user_prompt}\"\n",
    "    response = gemini_model.generate_content(full_prompt)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def generate_with_model(model_name: str, system_prompt: str, user_prompt: str) -> str:\n",
    "    \"\"\"Route to appropriate model provider.\"\"\"\n",
    "    config = MODELS[model_name]\n",
    "    if config[\"provider\"] == \"openai\":\n",
    "        return call_openai(config[\"model\"], system_prompt, user_prompt)\n",
    "    else:\n",
    "        return call_gemini(config[\"model\"], system_prompt, user_prompt)\n",
    "\n",
    "print(\"‚úÖ API functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions - Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_csv_response(response: str) -> str:\n",
    "    \"\"\"Extract clean CSV from model response.\"\"\"\n",
    "    if \"```csv\" in response:\n",
    "        response = response.split(\"```csv\")[1].split(\"```\")[0]\n",
    "    elif \"```\" in response:\n",
    "        parts = response.split(\"```\")\n",
    "        if len(parts) >= 2:\n",
    "            response = parts[1]\n",
    "    return response.strip()\n",
    "\n",
    "\n",
    "def safe_parse_csv(csv_string: str) -> pd.DataFrame:\n",
    "    \"\"\"Safely parse CSV with error handling for malformed rows.\"\"\"\n",
    "    # Try standard parsing first\n",
    "    try:\n",
    "        return pd.read_csv(StringIO(csv_string))\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Try with python engine and skip bad lines\n",
    "    try:\n",
    "        return pd.read_csv(StringIO(csv_string), engine='python', on_bad_lines='skip')\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Manual fallback parsing\n",
    "    lines = csv_string.strip().split('\\n')\n",
    "    if len(lines) < 2:\n",
    "        raise ValueError(\"Not enough data rows\")\n",
    "    \n",
    "    header = lines[0].split(',')\n",
    "    num_cols = len(header)\n",
    "    \n",
    "    rows = []\n",
    "    for line in lines[1:]:\n",
    "        parts = line.split(',')\n",
    "        if len(parts) >= num_cols:\n",
    "            rows.append(parts[:num_cols])\n",
    "        elif len(parts) > 0:\n",
    "            rows.append(parts + [''] * (num_cols - len(parts)))\n",
    "    \n",
    "    return pd.DataFrame(rows, columns=header)\n",
    "\n",
    "print(\"‚úÖ Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Mode: Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_standard(model_name: str, domain: str, persona: str, num_records: int) -> tuple:\n",
    "    \"\"\"Standard row-by-row generation.\"\"\"\n",
    "    domain_info = DOMAINS[domain]\n",
    "    persona_style = PERSONAS[persona]\n",
    "    \n",
    "    system_prompt = f\"\"\"You are an expert synthetic data generator. {persona_style}\n",
    "Generate realistic, high-quality synthetic data. Output ONLY valid CSV data, no explanations.\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"Generate {num_records} rows of synthetic data for: {domain_info['description']}\n",
    "\n",
    "Schema (use these exact column names): {domain_info['schema']}\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- Output ONLY CSV data starting with the header row\n",
    "- Do NOT use commas inside any field values\n",
    "- Use underscores instead of spaces in text\n",
    "- Every row MUST have exactly {len(domain_info['schema'].split(','))} columns\n",
    "- Use YYYY-MM-DD for dates\n",
    "- Use plain numbers without commas (1000000 not 1,000,000)\n",
    "- No markdown code blocks, no explanations, just raw CSV\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = generate_with_model(model_name, system_prompt, user_prompt)\n",
    "        clean_data = clean_csv_response(response)\n",
    "        df = safe_parse_csv(clean_data)\n",
    "        return df, clean_data, f\"‚úÖ Generated {len(df)} rows with {model_name}\"\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame(), \"\", f\"‚ùå Error: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Standard generation defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Mode: Story Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_story_chain(model_name: str, domain: str, persona: str, num_records: int) -> tuple:\n",
    "    \"\"\"Generate chronologically connected narrative data.\"\"\"\n",
    "    domain_info = DOMAINS[domain]\n",
    "    persona_style = PERSONAS[persona]\n",
    "    \n",
    "    system_prompt = f\"\"\"You are a creative synthetic data storyteller. {persona_style}\n",
    "Your specialty is creating data that tells a STORY - each row logically follows from the previous one.\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"Create a STORY through data for: {domain_info['description']}\n",
    "\n",
    "Schema (use these exact column names): {domain_info['schema']}\n",
    "Story arc: {domain_info['story_hint']}\n",
    "\n",
    "Generate {num_records} rows that tell a coherent chronological story.\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- Output ONLY CSV data starting with the header row\n",
    "- Do NOT use commas inside any field values\n",
    "- Every row MUST have exactly {len(domain_info['schema'].split(','))} columns\n",
    "- Use YYYY-MM-DD for dates, show time progression\n",
    "- No markdown code blocks, no explanations, just raw CSV\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = generate_with_model(model_name, system_prompt, user_prompt)\n",
    "        clean_data = clean_csv_response(response)\n",
    "        df = safe_parse_csv(clean_data)\n",
    "        return df, clean_data, f\"üìñ Story created: {len(df)} chapters with {model_name}\"\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame(), \"\", f\"‚ùå Error: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Story Chain generation defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Mode: Model Battle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_battle(domain: str, persona: str, num_records: int) -> tuple:\n",
    "    \"\"\"Two models compete on the same prompt.\"\"\"\n",
    "    # Pick two different models\n",
    "    model_names = list(MODELS.keys())\n",
    "    model_a, model_b = random.sample(model_names, 2)\n",
    "    \n",
    "    domain_info = DOMAINS[domain]\n",
    "    persona_style = PERSONAS[persona]\n",
    "    \n",
    "    system_prompt = f\"\"\"You are an expert synthetic data generator. {persona_style}\n",
    "Generate realistic, high-quality synthetic data. Output ONLY valid CSV data.\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"Generate {num_records} rows of synthetic data for: {domain_info['description']}\n",
    "Schema: {domain_info['schema']}\n",
    "\n",
    "CRITICAL: Output ONLY raw CSV. No commas in text fields. Exactly {len(domain_info['schema'].split(','))} columns per row.\"\"\"\n",
    "\n",
    "    try:\n",
    "        # Generate with both models\n",
    "        response_a = generate_with_model(model_a, system_prompt, user_prompt)\n",
    "        response_b = generate_with_model(model_b, system_prompt, user_prompt)\n",
    "        \n",
    "        data_a = clean_csv_response(response_a)\n",
    "        data_b = clean_csv_response(response_b)\n",
    "        df_a = safe_parse_csv(data_a)\n",
    "        df_b = safe_parse_csv(data_b)\n",
    "        \n",
    "        return (\n",
    "            df_a, data_a, f\"ü•ä {model_a}\",\n",
    "            df_b, data_b, f\"ü•ä {model_b}\",\n",
    "            f\"‚öîÔ∏è Battle complete! Vote for the most realistic dataset!\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame(), \"\", \"Error\", pd.DataFrame(), \"\", \"Error\", f\"‚ùå Error: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Model Battle generation defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Mode: Data Remix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_remix(sample_data: str, model_name: str, num_records: int) -> tuple:\n",
    "    \"\"\"Analyze sample data and generate more in the same style.\"\"\"\n",
    "    system_prompt = \"\"\"You are an expert at pattern recognition and data synthesis.\n",
    "Analyze the provided sample data and generate MORE data that matches the exact same style and schema.\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"Here is sample data:\n",
    "\n",
    "{sample_data}\n",
    "\n",
    "Generate {num_records} NEW rows matching this exact schema and style.\n",
    "\n",
    "CRITICAL: Output ONLY raw CSV matching the sample schema. No commas in text fields. No explanations.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = generate_with_model(model_name, system_prompt, user_prompt)\n",
    "        clean_data = clean_csv_response(response)\n",
    "        df = safe_parse_csv(clean_data)\n",
    "        return df, clean_data, f\"üîÑ Remixed {len(df)} new rows matching your style\"\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame(), \"\", f\"‚ùå Error: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Data Remix generation defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Mode: Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_custom(model_name: str, custom_prompt: str, persona: str, num_records: int) -> tuple:\n",
    "    \"\"\"Generate from custom user-defined schema.\"\"\"\n",
    "    persona_style = PERSONAS[persona]\n",
    "    \n",
    "    system_prompt = f\"\"\"You are an expert synthetic data generator. {persona_style}\n",
    "Generate realistic, high-quality synthetic data. Output ONLY valid CSV data.\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"{custom_prompt}\n",
    "\n",
    "Generate {num_records} rows of CSV data.\n",
    "\n",
    "CRITICAL: Output ONLY raw CSV. No commas in text fields. No markdown. No explanations.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = generate_with_model(model_name, system_prompt, user_prompt)\n",
    "        clean_data = clean_csv_response(response)\n",
    "        df = safe_parse_csv(clean_data)\n",
    "        return df, clean_data, f\"‚úÖ Generated {len(df)} custom rows with {model_name}\"\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame(), \"\", f\"‚ùå Error: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Custom generation defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(title=\"üé≠ Story-Driven Dataset Generator\", theme=gr.themes.Soft()) as app:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üé≠ Story-Driven Synthetic Dataset Generator\n",
    "    **Generate interconnected, narrative-driven synthetic data with AI**\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Tabs():\n",
    "        # ===== STANDARD TAB =====\n",
    "        with gr.TabItem(\"üìä Standard\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    std_model = gr.Dropdown(list(MODELS.keys()), label=\"Model\", value=\"GPT-4o-mini\")\n",
    "                    std_domain = gr.Dropdown(list(DOMAINS.keys()), label=\"Domain\", value=\"üöÄ Startup Journey\")\n",
    "                    std_persona = gr.Dropdown(list(PERSONAS.keys()), label=\"Style Persona\", value=\"üè¢ Corporate Analyst\")\n",
    "                    std_records = gr.Slider(5, 50, value=10, step=5, label=\"Number of Records\")\n",
    "                    std_btn = gr.Button(\"üöÄ Generate\", variant=\"primary\")\n",
    "                \n",
    "                with gr.Column(scale=2):\n",
    "                    std_status = gr.Markdown(\"Ready to generate...\")\n",
    "                    std_preview = gr.Dataframe(label=\"Preview\")\n",
    "                    std_raw = gr.Textbox(label=\"Raw CSV Output\", lines=10, show_copy_button=True)\n",
    "            \n",
    "            std_btn.click(generate_standard, [std_model, std_domain, std_persona, std_records], \n",
    "                         [std_preview, std_raw, std_status])\n",
    "        \n",
    "        # ===== STORY CHAIN TAB =====\n",
    "        with gr.TabItem(\"üìñ Story Chain\"):\n",
    "            gr.Markdown(\"*Generate data that tells a chronological story!*\")\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    story_model = gr.Dropdown(list(MODELS.keys()), label=\"Model\", value=\"GPT-4o-mini\")\n",
    "                    story_domain = gr.Dropdown(list(DOMAINS.keys()), label=\"Story Type\", value=\"üöÄ Startup Journey\")\n",
    "                    story_persona = gr.Dropdown(list(PERSONAS.keys()), label=\"Narrative Style\", value=\"üé® Creative Writer\")\n",
    "                    story_records = gr.Slider(5, 30, value=10, step=5, label=\"Story Length (rows)\")\n",
    "                    story_btn = gr.Button(\"üìñ Create Story\", variant=\"primary\")\n",
    "                \n",
    "                with gr.Column(scale=2):\n",
    "                    story_status = gr.Markdown(\"Ready to tell a story...\")\n",
    "                    story_preview = gr.Dataframe(label=\"Story Preview\")\n",
    "                    story_raw = gr.Textbox(label=\"Story Data\", lines=10, show_copy_button=True)\n",
    "            \n",
    "            story_btn.click(generate_story_chain, [story_model, story_domain, story_persona, story_records],\n",
    "                           [story_preview, story_raw, story_status])\n",
    "        \n",
    "        # ===== BATTLE TAB =====\n",
    "        with gr.TabItem(\"ü•ä Model Battle\"):\n",
    "            gr.Markdown(\"*Two AI models compete on the same prompt!*\")\n",
    "            with gr.Row():\n",
    "                battle_domain = gr.Dropdown(list(DOMAINS.keys()), label=\"Domain\", value=\"üõí Customer Journey\")\n",
    "                battle_persona = gr.Dropdown(list(PERSONAS.keys()), label=\"Style\", value=\"üè¢ Corporate Analyst\")\n",
    "                battle_records = gr.Slider(5, 20, value=10, step=5, label=\"Records Each\")\n",
    "            \n",
    "            battle_btn = gr.Button(\"‚öîÔ∏è Start Battle!\", variant=\"primary\")\n",
    "            battle_status = gr.Markdown(\"Pick your settings and fight!\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    battle_label_a = gr.Markdown(\"**Contender A**\")\n",
    "                    battle_preview_a = gr.Dataframe(label=\"Model A Output\")\n",
    "                    battle_raw_a = gr.Textbox(label=\"Raw A\", lines=8, show_copy_button=True)\n",
    "                with gr.Column():\n",
    "                    battle_label_b = gr.Markdown(\"**Contender B**\")\n",
    "                    battle_preview_b = gr.Dataframe(label=\"Model B Output\")\n",
    "                    battle_raw_b = gr.Textbox(label=\"Raw B\", lines=8, show_copy_button=True)\n",
    "            \n",
    "            battle_btn.click(generate_battle, [battle_domain, battle_persona, battle_records],\n",
    "                            [battle_preview_a, battle_raw_a, battle_label_a, \n",
    "                             battle_preview_b, battle_raw_b, battle_label_b, battle_status])\n",
    "        \n",
    "        # ===== REMIX TAB =====\n",
    "        with gr.TabItem(\"üîÑ Data Remix\"):\n",
    "            gr.Markdown(\"*Paste sample data and AI will generate more matching your style!*\")\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    remix_sample = gr.Textbox(\n",
    "                        label=\"Paste Your Sample Data (CSV format)\",\n",
    "                        lines=8,\n",
    "                        placeholder=\"name,age,city,salary\\nJohn_Smith,32,New_York,85000\\nJane_Doe,28,Boston,72000\"\n",
    "                    )\n",
    "                    remix_model = gr.Dropdown(list(MODELS.keys()), label=\"Model\", value=\"GPT-4o-mini\")\n",
    "                    remix_records = gr.Slider(5, 50, value=10, step=5, label=\"New Records to Generate\")\n",
    "                    remix_btn = gr.Button(\"üîÑ Remix Data\", variant=\"primary\")\n",
    "                \n",
    "                with gr.Column(scale=2):\n",
    "                    remix_status = gr.Markdown(\"Paste your sample data to begin...\")\n",
    "                    remix_preview = gr.Dataframe(label=\"Generated Data\")\n",
    "                    remix_raw = gr.Textbox(label=\"Raw Output\", lines=10, show_copy_button=True)\n",
    "            \n",
    "            remix_btn.click(generate_remix, [remix_sample, remix_model, remix_records],\n",
    "                           [remix_preview, remix_raw, remix_status])\n",
    "        \n",
    "        # ===== CUSTOM TAB =====\n",
    "        with gr.TabItem(\"‚úèÔ∏è Custom\"):\n",
    "            gr.Markdown(\"*Define your own schema and requirements!*\")\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    custom_prompt = gr.Textbox(\n",
    "                        label=\"Describe Your Data\",\n",
    "                        lines=5,\n",
    "                        placeholder=\"Generate data for a bookstore: book_title,author,isbn,price,genre,stock\"\n",
    "                    )\n",
    "                    custom_model = gr.Dropdown(list(MODELS.keys()), label=\"Model\", value=\"GPT-4o-mini\")\n",
    "                    custom_persona = gr.Dropdown(list(PERSONAS.keys()), label=\"Style\", value=\"üî¨ Data Scientist\")\n",
    "                    custom_records = gr.Slider(5, 50, value=10, step=5, label=\"Records\")\n",
    "                    custom_btn = gr.Button(\"‚úèÔ∏è Generate Custom\", variant=\"primary\")\n",
    "                \n",
    "                with gr.Column(scale=2):\n",
    "                    custom_status = gr.Markdown(\"Describe your data needs...\")\n",
    "                    custom_preview = gr.Dataframe(label=\"Preview\")\n",
    "                    custom_raw = gr.Textbox(label=\"Raw Output\", lines=10, show_copy_button=True)\n",
    "            \n",
    "            custom_btn.click(generate_custom, [custom_model, custom_prompt, custom_persona, custom_records],\n",
    "                            [custom_preview, custom_raw, custom_status])\n",
    "\n",
    "print(\"‚úÖ Gradio UI is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Launch the App!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
