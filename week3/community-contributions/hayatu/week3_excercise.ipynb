{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Support-Intent Dataset Generator\n",
        "\n",
        "Builds a synthetic **utterance → intent** CSV for customer support. Choose a model, set context and row count, then generate; output streams in the UI and the CSV is downloadable.\n",
        "\n",
        "**What’s inside**\n",
        "- 4-bit quantized Hugging Face models (e.g. Llama 3.1 8B, Qwen2.5 7B)\n",
        "- Thread-safe streaming with error handling (no UI hang on failures)\n",
        "- Gradio UI: model dropdown, Load, Generate, Download CSV\n",
        "\n",
        "**Open in Colab:** [Launch in Google Colab](https://colab.research.google.com/drive/1xajKX6QSamSop3FaXYvOMv_NRkl1699d#scrollTo=LJMxF1v-Wqmx)\n",
        "\n",
        "*If model load fails: set **HF_TOKEN** (Colab Secrets or `.env`), accept the model license on Hugging Face (e.g. Meta-Llama), and use a GPU runtime in Colab.*"
      ],
      "id": "e09a54e4"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}