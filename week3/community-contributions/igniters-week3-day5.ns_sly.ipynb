{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee0241ca",
   "metadata": {},
   "source": [
    "This project shows the comparison of Synthetic Lab tests and medication data generated by 3 LLMs GPT-4.1-mini, Gemini-1.5-pro. and Gemma3:270m. \n",
    "The user selects Lab Test Samples, LLM generates synthetic values, and predicts disease and medications. The app shows comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c6d179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96b42b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import json\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "# You can choose whichever providers you like - or all Ollama\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ce95fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, gemini and ollama\n",
    "\n",
    "openai = OpenAI()\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=gemini_url)\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64881928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lab tests panel\n",
    "LAB_PANELS = {\n",
    "    \"Comprehensive Metabolic Panel\": [\n",
    "        \"Glucose (mg/dL)\",\n",
    "        \"Creatinine (mg/dL)\",\n",
    "        \"BUN (mg/dL)\",\n",
    "        \"Sodium (mEq/L)\",\n",
    "        \"Potassium (mEq/L)\"\n",
    "    ],\n",
    "    \"Complete Blood Count (CBC)\": [\n",
    "        \"Hemoglobin (g/dL)\",\n",
    "        \"WBC (10^9/L)\",\n",
    "        \"Platelets (10^9/L)\",\n",
    "        \"MCV (fL)\"\n",
    "    ],\n",
    "    \"Lipid Panel\": [\n",
    "        \"Total Cholesterol (mg/dL)\",\n",
    "        \"LDL (mg/dL)\",\n",
    "        \"HDL (mg/dL)\",\n",
    "        \"Triglycerides (mg/dL)\"\n",
    "    ],\n",
    "    \"Thyroid Panel\": [\n",
    "        \"TSH (mIU/L)\",\n",
    "        \"T3 (ng/dL)\",\n",
    "        \"T4 (Âµg/dL)\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04bf8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "STRUCTURED_PROMPT = \"\"\"\n",
    "You are a clinical AI.\n",
    "\n",
    "Given the following lab test panel:\n",
    "{panel}\n",
    "\n",
    "1) Generate realistic abnormal lab values.\n",
    "2) Predict the most likely disease.\n",
    "3) Recommend treatment.\n",
    "4) Provide severity and confidence.\n",
    "\n",
    "Respond ONLY in JSON format:\n",
    "\n",
    "{{\n",
    "  \"synthetic_lab_values\": {{}},\n",
    "  \"predicted_disease\": \"\",\n",
    "  \"severity\": \"\",\n",
    "  \"recommended_medications\": [],\n",
    "  \"confidence_score\": 0\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42180293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_parse(response_text):\n",
    "    try:\n",
    "        return json.loads(response_text)\n",
    "    except:\n",
    "        return {\n",
    "            \"synthetic_lab_values\": {},\n",
    "            \"predicted_disease\": \"Parsing Failed\",\n",
    "            \"severity\": \"Unknown\",\n",
    "            \"recommended_medications\": [],\n",
    "            \"confidence_score\": 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b191f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt(panel):\n",
    "    prompt = STRUCTURED_PROMPT.format(panel=panel)\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "\n",
    "    return safe_parse(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f016930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemini(panel):\n",
    "    prompt = STRUCTURED_PROMPT.format(panel=panel)\n",
    "    response = gemini.chat.completions.create(\n",
    "        model=\"gemini-2.5-pro\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "\n",
    "    return safe_parse(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e705fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemma(panel):\n",
    "    prompt = STRUCTURED_PROMPT.format(panel=panel)\n",
    "\n",
    "    response = ollama.chat.completions.create(\n",
    "        model=\"gemma3:270m\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3,\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    return safe_parse(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8789bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade llms\n",
    "def score_llm(response_json):\n",
    "    score = 0\n",
    "\n",
    "    if response_json[\"predicted_disease\"] != \"Parsing Failed\":\n",
    "        score += 30\n",
    "\n",
    "    if len(response_json[\"synthetic_lab_values\"]) > 0:\n",
    "        score += 25\n",
    "\n",
    "    if len(response_json[\"recommended_medications\"]) > 0:\n",
    "        score += 20\n",
    "\n",
    "    if 50 <= response_json[\"confidence_score\"] <= 100:\n",
    "        score += 25\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2e5cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare llms\n",
    "def compare_llms(selected_panel):\n",
    "\n",
    "    panel_tests = LAB_PANELS[selected_panel]\n",
    "\n",
    "    gpt = call_gpt(panel_tests)\n",
    "    gemini = call_gemini(panel_tests)\n",
    "    gemma = call_gemma(panel_tests)\n",
    "\n",
    "    gpt_score = score_llm(gpt)\n",
    "    gemini_score = score_llm(gemini)\n",
    "    gemma_score = score_llm(gemma)\n",
    "\n",
    "    comparison_table = pd.DataFrame([\n",
    "        {\n",
    "            \"Model\": \"GPT-4.1-mini\",\n",
    "            \"Predicted Disease\": gpt[\"predicted_disease\"],\n",
    "            \"Severity\": gpt[\"severity\"],\n",
    "            \"Medications\": \", \".join(gpt[\"recommended_medications\"]),\n",
    "            \"Confidence\": gpt[\"confidence_score\"],\n",
    "            \"Score\": gpt_score\n",
    "        },\n",
    "        {\n",
    "            \"Model\": \"Gemini-2.5-pro\",\n",
    "            \"Predicted Disease\": gemini[\"predicted_disease\"],\n",
    "            \"Severity\": gemini[\"severity\"],\n",
    "            \"Medications\": \", \".join(gemini[\"recommended_medications\"]),\n",
    "            \"Confidence\": gemini[\"confidence_score\"],\n",
    "            \"Score\": gemini_score\n",
    "        },\n",
    "        {\n",
    "            \"Model\": \"Gemma3-270m\",\n",
    "            \"Predicted Disease\": gemma[\"predicted_disease\"],\n",
    "            \"Severity\": gemma[\"severity\"],\n",
    "            \"Medications\": \", \".join(gemma[\"recommended_medications\"]),\n",
    "            \"Confidence\": gemma[\"confidence_score\"],\n",
    "            \"Score\": gemma_score\n",
    "        }\n",
    "    ])\n",
    "\n",
    "    return comparison_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aac1e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradio ui\n",
    "def run_app(selected_panel):\n",
    "    return compare_llms(selected_panel)\n",
    "\n",
    "with gr.Blocks(title=\"AI Doctors Compare\") as app:\n",
    "    gr.Markdown(\"# ðŸ¥ AI Doctors Compare\")\n",
    "    gr.Markdown(\"LLMs Generate Synthetic Labs and Predict Disease\")\n",
    "\n",
    "    panel_dropdown = gr.Dropdown(\n",
    "        choices=list(LAB_PANELS.keys()),\n",
    "        label=\"Select Lab Test Panel\",\n",
    "        value=\"Comprehensive Metabolic Panel\"\n",
    "    )\n",
    "\n",
    "    comparison_output = gr.Dataframe(label=\"LLM Comparison Table\")\n",
    "\n",
    "    submit_btn = gr.Button(\"Run Analysis\")\n",
    "    submit_btn.click(\n",
    "        run_app,\n",
    "        inputs=panel_dropdown,\n",
    "        outputs=comparison_output\n",
    "    )\n",
    "\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb94301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
