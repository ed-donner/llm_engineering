{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "78a5b416",
      "metadata": {},
      "source": [
        "A dataset generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24d0d7e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f557d7d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_GPT = 'gpt-4.1-mini'\n",
        "MODEL_LLAMA = 'qwen2.5-coder'\n",
        "MODEL_CLAUDE = 'claude-sonnet-4-5-20250929'\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "openai = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "397e1551",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key exists and begins sk-proj-\n",
            "Anthropic API Key not set (and this is optional)\n"
          ]
        }
      ],
      "source": [
        "load_dotenv(override=True)\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
        "\n",
        "if openai_api_key:\n",
        "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
        "else:\n",
        "    print(\"OpenAI API Key not set\")\n",
        "    \n",
        "if anthropic_api_key:\n",
        "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
        "else:\n",
        "    print(\"Anthropic API Key not set (and this is optional)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e5538528",
      "metadata": {},
      "outputs": [],
      "source": [
        "openai = OpenAI()\n",
        "\n",
        "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
        "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
        "\n",
        "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
        "ollama = OpenAI(api_key=\"ollama\", base_url=OLLAMA_BASE_URL)\n",
        "\n",
        "openai = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d2ffa144",
      "metadata": {},
      "outputs": [],
      "source": [
        "clients = {\"gpt\": openai, \"claude\": anthropic, \"qwen\": ollama, }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "026c06f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def stream_gpt(history, message):\n",
        "    relevant_system_message = \"\"\"\n",
        "    You are a helpful assistant for generating synthetic dataset. Always generate a JSON dataset.\n",
        "    For example: Generate a dataset for an Employee entity\n",
        "    [{\n",
        "        \"name\": \"John Doe\",\n",
        "        \"email\": \"john.doe@example.com\",\n",
        "        \"phone\": \"+1234567890\",\n",
        "        \"address\": \"123 Main St, Anytown, USA\"\n",
        "    }]\n",
        "    \"\"\"\n",
        "    messages = [{\"role\": \"system\", \"content\": relevant_system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "    stream = openai.chat.completions.create(\n",
        "        model=MODEL_GPT,\n",
        "        messages=messages,\n",
        "        stream=True\n",
        "    )\n",
        "    result = \"\"\n",
        "    for chunk in stream:\n",
        "        result += chunk.choices[0].delta.content or \"\"\n",
        "        yield result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "5d2dc026",
      "metadata": {},
      "outputs": [],
      "source": [
        "def stream_claude(history, message):\n",
        "    relevant_system_message = \"\"\"\n",
        "    You are a helpful assistant for generating synthetic dataset. Always generate a JSON dataset.\n",
        "    For example: Generate a dataset for an Employee entity\n",
        "    [{\n",
        "        \"name\": \"John Doe\",\n",
        "        \"email\": \"john.doe@example.com\",\n",
        "        \"phone\": \"+1234567890\",\n",
        "        \"address\": \"123 Main St, Anytown, USA\"\n",
        "    }]\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": relevant_system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "    stream = anthropic.chat.completions.create(\n",
        "        model=MODEL_CLAUDE,\n",
        "        messages=messages,\n",
        "        stream=True\n",
        "    )\n",
        "    result = \"\"\n",
        "    for chunk in stream:\n",
        "        result += chunk.choices[0].delta.content or \"\"\n",
        "        yield result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "59607c25",
      "metadata": {},
      "outputs": [],
      "source": [
        "def stream_ollama(history, message):\n",
        "    relevant_system_message = \"\"\"\n",
        "    You are a helpful assistant for generating synthetic dataset. Always generate a JSON dataset.\n",
        "    For example: Generate a dataset for an Employee entity\n",
        "    [{\n",
        "        \"name\": \"John Doe\",\n",
        "        \"email\": \"john.doe@example.com\",\n",
        "        \"phone\": \"+1234567890\",\n",
        "        \"address\": \"123 Main St, Anytown, USA\"\n",
        "    }]\n",
        "    \"\"\"\n",
        "    messages = [{\"role\": \"system\", \"content\": relevant_system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    response = ollama.chat.completions.create(model=MODEL_LLAMA, messages=messages)\n",
        "    print(response)\n",
        "\n",
        "    yield response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cde0352e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7882\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7882/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletion(id='chatcmpl-309', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```json\\n[\\n    {\\n        \"name\": \"John Doe\",\\n        \"email\": \"john.doe@example.com\",\\n        \"phone\": \"+1234567890\",\\n        \"address\": \"123 Main St, Anytown, USA\"\\n    },\\n    {\\n        \"name\": \"Jane Smith\",\\n        \"email\": \"jane.smith@example.com\",\\n        \"phone\": \"+0987654321\",\\n        \"address\": \"456 Elm St, Othercity, USA\"\\n    },\\n    {\\n        \"name\": \"Mike Johnson\",\\n        \"email\": \"mike.johnson@example.com\",\\n        \"phone\": \"+1123456789\",\\n        \"address\": \"789 Oak St,anothertown,USA\"\\n    }\\n]\\n```', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1772248913, model='qwen2.5-coder', object='chat.completion', service_tier=None, system_fingerprint='fp_ollama', usage=CompletionUsage(completion_tokens=177, prompt_tokens=106, total_tokens=283, completion_tokens_details=None, prompt_tokens_details=None))\n"
          ]
        }
      ],
      "source": [
        "STREAM_FUNCTIONS = {\n",
        "    \"GPT\": stream_gpt,\n",
        "    \"QWEN\": stream_ollama,\n",
        "    \"Claude\": stream_claude,\n",
        "}\n",
        "\n",
        "def run_chat(msg):\n",
        "    \"\"\"Add user message to display and pass context for API call. Clears previous history for each new message.\"\"\"\n",
        "    updated = [{\"role\": \"user\", \"content\": msg}]  # Fresh display: only current message\n",
        "    return \"\", updated, ([], msg)  # Empty history for API - each message is independent\n",
        "\n",
        "def stream_to_chatbot(context, model):\n",
        "    \"\"\"Stream API response based on selected model and yield message history for Chatbot.\"\"\"\n",
        "    history, message = context\n",
        "    stream_fn = STREAM_FUNCTIONS.get(model, stream_gpt)\n",
        "    for chunk in stream_fn(history, message):\n",
        "        yield history + [{\"role\": \"user\", \"content\": message}, {\"role\": \"assistant\", \"content\": chunk}]\n",
        "\n",
        "# UI definition\n",
        "COL_HEIGHT = 450\n",
        "\n",
        "with gr.Blocks() as ui:\n",
        "    chat_context = gr.State(value=([], \"\"))\n",
        "    with gr.Row(elem_id=\"columns-row\"):\n",
        "        with gr.Column(scale=1, elem_classes=[\"scrollable-column\"]):\n",
        "            message = gr.Textbox(\n",
        "                label=\"Message\",\n",
        "                lines=15,\n",
        "                max_lines=20,\n",
        "                placeholder=\"Please provide the entity/schema you want to generate a dataset for...\"\n",
        "            )\n",
        "        with gr.Column(scale=1, elem_classes=[\"scrollable-column\"]):\n",
        "            chatbot = gr.Chatbot(\n",
        "                height=COL_HEIGHT,\n",
        "                type=\"messages\",\n",
        "            )\n",
        "    with gr.Row():\n",
        "        model_dropdown = gr.Dropdown(\n",
        "            choices=[\"GPT\", \"QWEN\", \"Claude\"],\n",
        "            value=\"GPT\",\n",
        "            label=\"Select Model\",\n",
        "        )\n",
        "    with gr.Row():\n",
        "        submit_btn = gr.Button(\"Generate Dataset\")\n",
        "\n",
        "    # Hooking up events to callbacks\n",
        "    submit_btn.click(run_chat, [message, chatbot], [message, chatbot, chat_context]).then(\n",
        "        stream_to_chatbot, [chat_context, model_dropdown], chatbot\n",
        "    )\n",
        "    message.submit(run_chat, [message, chatbot], [message, chatbot, chat_context]).then(\n",
        "        stream_to_chatbot, [chat_context, model_dropdown], chatbot\n",
        "    )\n",
        "\n",
        "ui.launch(inbrowser=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
