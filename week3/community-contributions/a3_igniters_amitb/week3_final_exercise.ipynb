{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 3 Final Exercise: Synthetic Dataset Generator using Open-Source Models\n",
    "Generate structured Q&A / instruction datasets on any topic using open-source LLMs via OpenRouter, with an interactive Gradio UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q gradio openai python-dotenv pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENROUTER_URL = \"https://openrouter.ai/api/v1\"\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "MODELS = [\n",
    "    \"meta-llama/llama-3.1-8b-instruct\",\n",
    "    \"mistralai/mistral-7b-instruct\",\n",
    "    \"google/gemma-2-9b-it:free\",\n",
    "    \"qwen/qwen-2.5-7b-instruct\",\n",
    "]\n",
    "\n",
    "DATASET_TYPES = [\"Q&A\", \"Instruction-Response\", \"Classification\"]\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are a synthetic dataset generator. Output ONLY a valid JSON array.\n",
    "Each element must be an object with keys: \\\"input\\\" and \\\"output\\\".\n",
    "No markdown, no explanation, no extra text â€” just the raw JSON array.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_prompt(topic, dataset_type, n):\n",
    "    templates = {\n",
    "        \"Q&A\": f\"Generate {n} question-answer pairs about '{topic}'. Each object: {{\\\"input\\\": \\\"<question>\\\", \\\"output\\\": \\\"<answer>\\\"}}.\",\n",
    "        \"Instruction-Response\": f\"Generate {n} instruction-response pairs for the domain '{topic}'. Each object: {{\\\"input\\\": \\\"<instruction>\\\", \\\"output\\\": \\\"<response>\\\"}}.\",\n",
    "        \"Classification\": f\"Generate {n} text classification examples about '{topic}'. Each object: {{\\\"input\\\": \\\"<text>\\\", \\\"output\\\": \\\"<label>\\\"}}.\",\n",
    "    }\n",
    "    return templates[dataset_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(topic, dataset_type, n, model):\n",
    "    client = OpenAI(base_url=OPENROUTER_URL, api_key=OPENROUTER_API_KEY)\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": _build_prompt(topic, dataset_type, n)},\n",
    "        ],\n",
    "        temperature=0.8,\n",
    "    )\n",
    "    raw = response.choices[0].message.content.strip()\n",
    "    # strip markdown code fences if model wraps output\n",
    "    if raw.startswith(\"```\"):\n",
    "        raw = raw.split(\"```\")[1]\n",
    "        if raw.startswith(\"json\"):\n",
    "            raw = raw[4:]\n",
    "    return json.loads(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_dataframe(records):\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def _save(records, fmt):\n",
    "    df = _to_dataframe(records)\n",
    "    path = f\"synthetic_dataset.{fmt}\"\n",
    "    if fmt == \"json\":\n",
    "        df.to_json(path, orient=\"records\", indent=2)\n",
    "    else:\n",
    "        df.to_csv(path, index=False)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(topic, dataset_type, n, model, export_fmt):\n",
    "    try:\n",
    "        records = generate_dataset(topic, dataset_type, int(n), model)\n",
    "        df = _to_dataframe(records)\n",
    "        path = _save(records, export_fmt)\n",
    "        return df, path, f\"Generated {len(records)} records successfully.\"\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame(), None, f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks(title=\"Synthetic Dataset Generator\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# Synthetic Dataset Generator\\nPowered by open-source LLMs via OpenRouter\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            topic     = gr.Textbox(label=\"Topic\", placeholder=\"e.g. Python decorators, Climate change, Customer support\")\n",
    "            dtype     = gr.Dropdown(choices=DATASET_TYPES, value=\"Q&A\", label=\"Dataset Type\")\n",
    "            n_records = gr.Slider(minimum=5, maximum=50, value=10, step=5, label=\"Number of Records\")\n",
    "            model     = gr.Dropdown(choices=MODELS, value=MODELS[0], label=\"Model\")\n",
    "            fmt       = gr.Radio(choices=[\"json\", \"csv\"], value=\"json\", label=\"Export Format\")\n",
    "            btn       = gr.Button(\"Generate\", variant=\"primary\")\n",
    "\n",
    "        with gr.Column(scale=2):\n",
    "            status  = gr.Textbox(label=\"Status\", interactive=False)\n",
    "            preview = gr.Dataframe(label=\"Preview\")\n",
    "            dl_file = gr.File(label=\"Download\")\n",
    "\n",
    "    btn.click(fn=run, inputs=[topic, dtype, n_records, model, fmt], outputs=[preview, dl_file, status])\n",
    "\n",
    "demo.launch(share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
