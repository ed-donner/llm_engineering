{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f05722",
   "metadata": {},
   "source": [
    "# Specilized Artificial data generation with openrouter and hugging face model on google colab\n",
    "\n",
    "With this specilaized synthetic generator, you can generate synthetic data in various formats(Json, xml, and Sql) for your particular industry of interest.\n",
    "\n",
    "From the Gradi interface, you provide the following input\n",
    "\n",
    "- Industry/niche\n",
    "- description of what the data will be used for\n",
    "- example of the data\n",
    "- Select the model to use (default Open AI)\n",
    "- Select output format (default Json)\n",
    "- Sample size (default 20)\n",
    "\n",
    "openai\n",
    "\n",
    "For Hugging face version: https://colab.research.google.com/drive/1RznL2L8ZC-vndzBcsF1Osj8alXAijYNg?usp=sharing\n",
    "\n",
    "I recommed a low-cost or free T4 box. I have ensured the list of available models can atleast run on a free t4 box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "35be234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import states for all lib used\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ae6fbf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load env values\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "openrouter_api_key = os.getenv('OPENROUTER_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "172c1631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for building prompt\n",
    "\n",
    "def generate_prompt(example, sample_size, industry, description):\n",
    "    system_prompt = \"\"\"\n",
    "    You are a specialized synthentic data generator.\n",
    "    You generate new realistic but fake records\n",
    "\n",
    "    You can output generated data in Json, xml, and SQL only given:\n",
    "    - Sample size.\n",
    "    - Industry/Niche.\n",
    "    - Description - what the data will be used for.\n",
    "    - Example -  You will infer the data type from the example.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    Here is an example of data to generate: {example}\n",
    "    Task\n",
    "    - Generate {sample_size} new sample(s) of the example.\n",
    "    - Here is the purspose: {description} in {industry} Industry/niche\n",
    "\n",
    "    Rules:\n",
    "    - Output only valid format based on the example given\n",
    "    - Output must be a list, in the format of the example\n",
    "    - No Explanation.\n",
    "    - Do not wrap response in code block\n",
    "    \"\"\"\n",
    "\n",
    "    return system_prompt, user_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e5f670d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using models available via openrouter\n",
    "\n",
    "OPENROUTER_URL = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "openrouter = OpenAI(\n",
    "        base_url= OPENROUTER_URL\n",
    "    )\n",
    "\n",
    "def openrouter_model(model, system_prompt, user_prompt):\n",
    "    \n",
    "    messages = [\n",
    "        { \"role\": \"system\", \"content\": system_prompt },\n",
    "        { \"role\": \"user\", \"content\": user_prompt },\n",
    "    ]\n",
    "\n",
    "    response  = openrouter.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = messages\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b7ba5b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map model to provider\n",
    "model_to_provider = {\n",
    "    'openai/gpt-4': 'openrouter',\n",
    "    'google/gemini-3.1-pro-preview': 'openrouter',\n",
    "    'mistralai/Mistral-7B-Instruct-v0.1': 'openrouter'\n",
    "}\n",
    "MODEL_GPT = 'openai/gpt-4'\n",
    "\n",
    "def get_model_provider(model=MODEL_GPT):\n",
    "    return model_to_provider.get(model, 'openrouter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ef53bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's route request to provider based on model\n",
    "\n",
    "def route_to_provider (model, system_prompt, user_prompt): \n",
    "    provider = get_model_provider(model)\n",
    "    if provider == 'openrouter':\n",
    "        return openrouter_model(model, system_prompt, user_prompt)\n",
    "    else:\n",
    "        # handle unknown provider\n",
    "        response = f\"No provider is implemented for the {model} yet\"\n",
    "        print(response)\n",
    "        return response  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0a6c4caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator callback function  for Gradio\n",
    "\n",
    "def generate_fake_data (model, sample_size, description, example, industry):\n",
    "    \n",
    "    system_prompt, user_prompt = generate_prompt(example, sample_size, industry, description)\n",
    "\n",
    "    return route_to_provider(model, system_prompt, user_prompt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3a2ebba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7874\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7874/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    You are a specialized synthentic data generator.\n",
      "    You generate new realistic but fake records\n",
      "\n",
      "    You can output generated data in Json, xml, and SQL only given:\n",
      "    - Sample size.\n",
      "    - Industry/Niche.\n",
      "    - Description - what the data will be used for.\n",
      "    - Example -  You will infer the data type from the example.\n",
      "\n",
      "     \n",
      "    Here is an example of data to generate: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<User>\n",
      "    <email>user@mail.com</email>\n",
      "    <status>suspended</status>\n",
      "    <loginSession>sess_yfjhjdhjsdjhjhdf</loginSession>\n",
      "    <tier>5</tier>\n",
      "    <approved>true</approved>\n",
      "</User>\n",
      "    Task\n",
      "    - Generate 10 new sample(s) of the example.\n",
      "    - Here is the purspose: User Api data in Fintech Industry/niche\n",
      "\n",
      "    Rules:\n",
      "    - Output only valid format based on the example given\n",
      "    - Output must be a list, in the format of the example\n",
      "    - No Explanation.\n",
      "    - Do not wrap response in code block\n",
      "    \n",
      "openrouter here\n"
     ]
    }
   ],
   "source": [
    "# Now to gradio Interface for this new Implementation\n",
    "\n",
    "availableModels = list[str](model_to_provider.keys())\n",
    "industry = ['Fintech', 'PropTech', 'Edutech', 'HealthTech', 'devTools', 'Generic']\n",
    "interface = gr.Interface(\n",
    "    fn=generate_fake_data,\n",
    "    inputs=[\n",
    "        gr.Dropdown(availableModels, label=\"Select Model\"),\n",
    "        gr.Slider(1, 100, value=10, label=\"Number of samples\", step=1),\n",
    "        gr.TextArea(label=\"Describe the purpose of the data\"),\n",
    "        gr.TextArea(label=\"Share the example of the data you want\"),\n",
    "        gr.Dropdown(industry, label=\"Industry/Niche\"),\n",
    "    ],\n",
    "    outputs=gr.TextArea(label=\"Specialized Synthentic Data Generator\"),\n",
    "    title=\"Multi-Model Synthetic Data Generator\",\n",
    "    description=\"Generate structured synthetic datasets using your preferred model.\"\n",
    ")\n",
    "\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc8fb13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
