{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bec437e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'c', 'cpp', 'markdown', 'latex', 'json', 'html', 'css', 'javascript', 'jinja2', 'typescript', 'yaml', 'dockerfile', 'shell', 'r', 'sql', 'sql-msSQL', 'sql-mySQL', 'sql-mariaDB', 'sql-sqlite', 'sql-cassandra', 'sql-plSQL', 'sql-hive', 'sql-pgSQL', 'sql-gql', 'sql-gpSQL', 'sql-sparkSQL', 'sql-esper', None]\n",
      "* Running on local URL:  http://127.0.0.1:7887\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7887/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login, InferenceClient\n",
    "import gradio as gr\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "login(hf_token, add_to_git_credential=True)\n",
    "\n",
    "MODELS = {\n",
    "  \"Llama 3.1\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "  \"Mixtral 8x22\": \"mistralai/Mixtral-8x22B-Instruct-v0.1\",\n",
    "  \"Qwen 2.5\": \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "}\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "  You are a helpful assistant skilled with generating datasets for different kinds of text data. You will be given a description of the data to provide, columns to fill, and the number of rows to generate. You will also be given the format to generate it in: JSON or CSV. You will generate the dataset according to the description and columns provided, and return it in the format specified. If the format is JSON, you will return a JSON array of objects, where each object represents a row in the dataset with key-value pairs corresponding to column names and their respective values. If the format is CSV, you will return a string in CSV format, with the first line containing the column names and subsequent lines containing the data rows, no other message is required.\n",
    "\"\"\"\n",
    "\n",
    "def generate_data(model_name, description, columns, row_count, format):\n",
    "  try:\n",
    "    user_prompt = f\"\"\"\n",
    "      Please generate a dataset with the following description: {description}. The dataset should have the following columns: {columns}. The dataset should have {row_count} rows. Please provide the dataset in {format} format.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "      {\"role\": \"system\", \"content\": system_prompt},\n",
    "      {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    model_id = MODELS[model_name]\n",
    "    client = InferenceClient(model=model_id, token=hf_token)\n",
    "\n",
    "    response = client.chat_completion(\n",
    "      messages=messages,\n",
    "      max_tokens=2000,\n",
    "      temperature=0.3\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "  except Exception as e:\n",
    "    return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "def set_code_language(format):\n",
    "    return gr.update(language=\"json\" if format == \"JSON\" else \"python\")\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "  gr.Markdown(\"## Dataset Generator\")\n",
    "  with gr.Row():\n",
    "    with gr.Column():\n",
    "      model_id = gr.Radio(label=\"Model\", choices=list(MODELS.keys()) )\n",
    "      description = gr.Textbox(label=\"Description\", placeholder=\"A sales catalog\")\n",
    "      columns = gr.Textbox(label=\"Columns (comma-separated)\", placeholder=\"product name, price, description rating\")\n",
    "      row_count = gr.Slider(label=\"Row Count\", minimum=1, maximum=1000, value=10)\n",
    "      format = gr.Radio(label=\"Format\", choices=[\"JSON\", \"CSV\"])\n",
    "      generate_button = gr.Button(\"Generate Dataset\")\n",
    "  with gr.Row():\n",
    "    with gr.Column():\n",
    "      output = gr.Code(label=\"Output\", lines=40, language=\"json\")\n",
    "\n",
    "  format.change(set_code_language, inputs=format, outputs=output)\n",
    "\n",
    "  generate_button.click(\n",
    "    fn=generate_data,\n",
    "    inputs=[model_id, description, columns, row_count, format],\n",
    "    outputs=output\n",
    "  )\n",
    "\n",
    "ui.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
