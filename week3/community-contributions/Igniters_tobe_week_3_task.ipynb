{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ed77104a",
      "metadata": {},
      "source": [
        "# Meeting Minutes Generator\n",
        "\n",
        "This notebook provides a solution for transcribing meeting audio and generating structured markdown minutes using OpenAI's Whisper and Meta's Llama 3.1.\n",
        "\n",
        "**Run in Google Colab:** [Open in Colab](https://colab.research.google.com/drive/13cDJUcaOXODbLxtRfqMJJ6LAF-m9qxfX?usp=sharing)\n",
        "\n",
        "### Features:\n",
        "- **Encapsulation**: Logical grouping of models and processing in a `MeetingMinutesGenerator` class.\n",
        "- **Error Handling**: Comprehensive `try-except` blocks for API and model failures.\n",
        "- **Type Safety**: Python type hints for better maintainability.\n",
        "- **Resource Management**: Automatic GPU verification.\n",
        "- **User Experience**: Improved Gradio interface with status updates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8b08a3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Install Dependencies ---\n",
        "!pip install -q gradio torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install -q requests bitsandbytes==0.46.0 transformers==4.48.3 accelerate==1.3.0 openai huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2270d3b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import gradio as gr\n",
        "from typing import List, Dict, Optional, Union\n",
        "from openai import OpenAI\n",
        "from huggingface_hub import login\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForCausalLM, \n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "\n",
        "# Handle environment-specific imports\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70a8a064",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Config:\n",
        "    \"\"\"Configuration constants for the application.\"\"\"\n",
        "    AUDIO_MODEL = \"whisper-1\"\n",
        "    LLM_MODEL = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "    MAX_NEW_TOKENS = 2000\n",
        "    \n",
        "    # Hardware check\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_secret(key: str) -> str:\n",
        "        \"\"\"Retrieve secret from environment or Colab userdata.\"\"\"\n",
        "        if IN_COLAB:\n",
        "            try:\n",
        "                return userdata.get(key)\n",
        "            except Exception:\n",
        "                pass\n",
        "        return os.environ.get(key, \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b270ad81",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MeetingMinutesGenerator:\n",
        "    \"\"\"Handles transcription and summarization of meeting audio.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.openai_client: Optional[OpenAI] = None\n",
        "        self.tokenizer: Optional[AutoTokenizer] = None\n",
        "        self.model: Optional[AutoModelForCausalLM] = None\n",
        "        self.is_ready = False\n",
        "\n",
        "    def initialize(self) -> str:\n",
        "        \"\"\"Initialize API clients and load local models.\"\"\"\n",
        "        try:\n",
        "            # 1. Setup OpenAI\n",
        "            api_key = Config.get_secret('OPENAI_API_KEY')\n",
        "            if not api_key:\n",
        "                return \"Error: OPENAI_API_KEY not found.\"\n",
        "            self.openai_client = OpenAI(api_key=api_key)\n",
        "\n",
        "            # 2. Hugging Face Login\n",
        "            hf_token = Config.get_secret('HF_TOKEN')\n",
        "            if hf_token:\n",
        "                login(hf_token, add_to_git_credential=True)\n",
        "            else:\n",
        "                return \"Error: HF_TOKEN not found for Llama access.\"\n",
        "\n",
        "            # 3. Load Llama with Quantization\n",
        "            if Config.DEVICE != \"cuda\":\n",
        "                return f\"Warning: GPU (CUDA) not detected. Running on {Config.DEVICE} will be extremely slow.\"\n",
        "\n",
        "            quant_config = BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_use_double_quant=True,\n",
        "                bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "                bnb_4bit_quant_type=\"nf4\"\n",
        "            )\n",
        "\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(Config.LLM_MODEL)\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "            \n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                Config.LLM_MODEL, \n",
        "                device_map=\"auto\", \n",
        "                quantization_config=quant_config\n",
        "            )\n",
        "            \n",
        "            self.is_ready = True\n",
        "            return \"Initialization successful!\"\n",
        "            \n",
        "        except Exception as e:\n",
        "            return f\"Initialization failed: {str(e)}\"\n",
        "\n",
        "    def _transcribe(self, audio_path: str) -> str:\n",
        "        \"\"\"Transcribe audio using Whisper API.\"\"\"\n",
        "        if not self.openai_client:\n",
        "            raise ValueError(\"OpenAI client not initialized.\")\n",
        "            \n",
        "        with open(audio_path, \"rb\") as f:\n",
        "            response = self.openai_client.audio.transcriptions.create(\n",
        "                model=Config.AUDIO_MODEL, \n",
        "                file=f, \n",
        "                response_format=\"text\"\n",
        "            )\n",
        "        return response\n",
        "\n",
        "    def _generate_minutes(self, transcription: str) -> str:\n",
        "        \"\"\"Generate formatted minutes from transcription using Llama.\"\"\"\n",
        "        if not self.model or not self.tokenizer:\n",
        "            raise ValueError(\"LLM not initialized.\")\n",
        "\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"system\", \n",
        "                \"content\": \"You are an expert meeting assistant. Produce structured minutes in Markdown with: Summary, Key Discussion Points, Takeaways, and Action Items with owners.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\", \n",
        "                \"content\": f\"Analyze this transcript and write comprehensive minutes:\\\\n{transcription}\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        inputs = self.tokenizer.apply_chat_template(\n",
        "            messages, \n",
        "            add_generation_prompt=True, \n",
        "            return_tensors=\"pt\"\n",
        "        ).to(Config.DEVICE)\n",
        "        \n",
        "        outputs = self.model.generate(\n",
        "            inputs, \n",
        "            max_new_tokens=Config.MAX_NEW_TOKENS,\n",
        "            eos_token_id=self.tokenizer.eos_token_id\n",
        "        )\n",
        "        \n",
        "        # Decode only the generated response\n",
        "        response = self.tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)\n",
        "        return response.strip()\n",
        "\n",
        "    def process(self, audio_filepath: Optional[str]) -> str:\n",
        "        \"\"\"Main orchestration method for Gradio UI.\"\"\"\n",
        "        if not audio_filepath:\n",
        "            return \"Please upload an audio file.\"\n",
        "            \n",
        "        if not self.is_ready:\n",
        "            status = self.initialize()\n",
        "            if not self.is_ready:\n",
        "                return status\n",
        "\n",
        "        try:\n",
        "            print(\"Transcribing...\")\n",
        "            transcript = self._transcribe(audio_filepath)\n",
        "            \n",
        "            print(\"Generating minutes...\")\n",
        "            minutes = self._generate_minutes(transcript)\n",
        "            \n",
        "            return minutes\n",
        "        except Exception as e:\n",
        "            return f\"Processing Error: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b8302fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- UI Initialization ---\n",
        "generator = MeetingMinutesGenerator()\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# üìù Meeting Minutes AI Assistant\")\n",
        "    gr.Markdown(\"Upload your meeting recording (mp3, wav, m4a) to generate structured minutes automatically.\")\n",
        "    \n",
        "    with gr.Row():\n",
        "        audio_input = gr.Audio(\n",
        "            type=\"filepath\", \n",
        "            label=\"Meeting Audio\",\n",
        "            sources=[\"upload\", \"microphone\"]\n",
        "        )\n",
        "    \n",
        "    generate_btn = gr.Button(\"Generate Minutes\", variant=\"primary\")\n",
        "    \n",
        "    output_display = gr.Markdown(label=\"Minutes Output\")\n",
        "\n",
        "    generate_btn.click(\n",
        "        fn=generator.process, \n",
        "        inputs=audio_input, \n",
        "        outputs=output_display\n",
        "    )\n",
        "\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
