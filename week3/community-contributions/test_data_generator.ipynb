{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": [
    "# AI-Powered Test Data Generator\n",
    "\n",
    "Generate realistic test data for testing, development, and prototyping using open-source LLMs.\n",
    "\n",
    "## Features:\n",
    "- Generate structured data (users, products, orders, etc.)\n",
    "- Custom schema support\n",
    "- Multiple export formats (CSV, JSON)\n",
    "- Uses HuggingFace Inference API with open-source models\n",
    "- Batch generation support\n",
    "- Deployable on HuggingFace Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-header",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio huggingface_hub pandas python-dotenv -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from huggingface_hub import InferenceClient\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import io\n",
    "import re\n",
    "import tempfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available HuggingFace models for inference\n",
    "AVAILABLE_MODELS = [\n",
    "    \"google/gemma-2-9b-it\",\n",
    "    \"Qwen/Qwen2.5-72B-Instruct\",\n",
    "    \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "]\n",
    "\n",
    "# Predefined data templates\n",
    "DATA_TEMPLATES = {\n",
    "    \"Users\": {\n",
    "        \"fields\": [\"id\", \"first_name\", \"last_name\", \"email\", \"phone\", \"address\", \"city\", \"country\", \"created_at\"],\n",
    "        \"description\": \"User profile data with contact information\"\n",
    "    },\n",
    "    \"Products\": {\n",
    "        \"fields\": [\"id\", \"name\", \"description\", \"category\", \"price\", \"stock_quantity\", \"sku\", \"brand\", \"rating\"],\n",
    "        \"description\": \"E-commerce product catalog data\"\n",
    "    },\n",
    "    \"Orders\": {\n",
    "        \"fields\": [\"order_id\", \"customer_id\", \"product_id\", \"quantity\", \"unit_price\", \"total_amount\", \"status\", \"order_date\", \"shipping_address\"],\n",
    "        \"description\": \"Order transaction data\"\n",
    "    },\n",
    "    \"Employees\": {\n",
    "        \"fields\": [\"employee_id\", \"first_name\", \"last_name\", \"email\", \"department\", \"job_title\", \"salary\", \"hire_date\", \"manager_id\"],\n",
    "        \"description\": \"Employee HR data\"\n",
    "    },\n",
    "    \"Transactions\": {\n",
    "        \"fields\": [\"transaction_id\", \"account_id\", \"transaction_type\", \"amount\", \"currency\", \"timestamp\", \"status\", \"description\"],\n",
    "        \"description\": \"Financial transaction records\"\n",
    "    },\n",
    "    \"Reviews\": {\n",
    "        \"fields\": [\"review_id\", \"product_id\", \"user_id\", \"rating\", \"title\", \"comment\", \"helpful_votes\", \"verified_purchase\", \"review_date\"],\n",
    "        \"description\": \"Product review data\"\n",
    "    },\n",
    "    \"Custom\": {\n",
    "        \"fields\": [],\n",
    "        \"description\": \"Define your own schema\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helper-header",
   "metadata": {},
   "source": [
    "## 4. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helper-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hf_client():\n",
    "    \"\"\"Get HuggingFace Inference client.\"\"\"\n",
    "    token = os.environ.get(\"HF_TOKEN\")\n",
    "    return InferenceClient(token=token)\n",
    "\n",
    "def parse_json_from_response(response: str) -> list:\n",
    "    \"\"\"Extract JSON array from LLM response.\"\"\"\n",
    "\n",
    "    # Clean up the response\n",
    "    text = response.strip()\n",
    "\n",
    "    # Method 1: Try parsing the entire response as JSON first\n",
    "    try:\n",
    "        result = json.loads(text)\n",
    "        if isinstance(result, list):\n",
    "            return result\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    # Method 2: Extract from markdown code blocks\n",
    "    code_block_patterns = [\n",
    "        r'```json\\s*\\n?([\\s\\S]*?)\\n?```',  # ```json ... ```\n",
    "        r'```\\s*\\n?([\\s\\S]*?)\\n?```',       # ``` ... ```\n",
    "    ]\n",
    "\n",
    "    for pattern in code_block_patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            try:\n",
    "                result = json.loads(match.group(1).strip())\n",
    "                if isinstance(result, list):\n",
    "                    return result\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "    # Method 3: Find JSON array by bracket matching\n",
    "    # Find the first '[' and match to its closing ']'\n",
    "    start_idx = text.find('[')\n",
    "    if start_idx != -1:\n",
    "        bracket_count = 0\n",
    "        end_idx = start_idx\n",
    "\n",
    "        for i, char in enumerate(text[start_idx:], start=start_idx):\n",
    "            if char == '[':\n",
    "                bracket_count += 1\n",
    "            elif char == ']':\n",
    "                bracket_count -= 1\n",
    "                if bracket_count == 0:\n",
    "                    end_idx = i\n",
    "                    break\n",
    "\n",
    "        if end_idx > start_idx:\n",
    "            json_str = text[start_idx:end_idx + 1]\n",
    "            try:\n",
    "                result = json.loads(json_str)\n",
    "                if isinstance(result, list):\n",
    "                    return result\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "\n",
    "    # Method 4: Try to fix common JSON issues and parse again\n",
    "    # Remove trailing commas before ] or }\n",
    "    cleaned = re.sub(r',\\s*([}\\]])', r'\\1', text)\n",
    "    # Find array again in cleaned text\n",
    "    start_idx = cleaned.find('[')\n",
    "    if start_idx != -1:\n",
    "        bracket_count = 0\n",
    "        end_idx = start_idx\n",
    "\n",
    "        for i, char in enumerate(cleaned[start_idx:], start=start_idx):\n",
    "            if char == '[':\n",
    "                bracket_count += 1\n",
    "            elif char == ']':\n",
    "                bracket_count -= 1\n",
    "                if bracket_count == 0:\n",
    "                    end_idx = i\n",
    "                    break\n",
    "\n",
    "        if end_idx > start_idx:\n",
    "            json_str = cleaned[start_idx:end_idx + 1]\n",
    "            try:\n",
    "                result = json.loads(json_str)\n",
    "                if isinstance(result, list):\n",
    "                    return result\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llm-header",
   "metadata": {},
   "source": [
    "## 5. LLM Data Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llm-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_with_llm(\n",
    "    model: str,\n",
    "    data_type: str,\n",
    "    fields: list,\n",
    "    num_records: int,\n",
    "    custom_instructions: str = \"\",\n",
    "    locale: str = \"en_US\"\n",
    ") -> tuple[list, str]:\n",
    "    \"\"\"Generate test data using HuggingFace Inference API.\"\"\"\n",
    "    \n",
    "    fields_str = \", \".join(fields)\n",
    "    \n",
    "    prompt = f\"\"\"Generate exactly {num_records} realistic test data records for {data_type}.\n",
    "\n",
    "Required fields: {fields_str}\n",
    "\n",
    "Requirements:\n",
    "- Return ONLY a valid JSON array with {num_records} objects\n",
    "- Each object must have all the specified fields\n",
    "- Use realistic, varied data\n",
    "- Locale preference: {locale}\n",
    "{f'- Additional instructions: {custom_instructions}' if custom_instructions else ''}\n",
    "\n",
    "IMPORTANT: Return ONLY the JSON array, no explanations, no markdown code blocks, just the raw JSON array starting with [ and ending with ].\"\"\"\n",
    "    \n",
    "    try:\n",
    "        client = get_hf_client()\n",
    "        \n",
    "        response = client.chat_completion(\n",
    "            model=model,\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }],\n",
    "            max_tokens=4096,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        response_text = response.choices[0].message.content\n",
    "        data = parse_json_from_response(response_text)\n",
    "        \n",
    "        if not data:\n",
    "            return [], \"Error: Failed to parse LLM response as JSON. Please try again.\"\n",
    "        \n",
    "        # Trim if we got more records than requested\n",
    "        if len(data) > num_records:\n",
    "            data = data[:num_records]\n",
    "        \n",
    "        return data, f\"Successfully generated {len(data)} records using {model.split('/')[-1]}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return [], f\"Error generating data: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-header",
   "metadata": {},
   "source": [
    "## 6. Export Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_csv(data: list) -> str:\n",
    "    \"\"\"Convert data to CSV string.\"\"\"\n",
    "    if not data:\n",
    "        return \"\"\n",
    "    \n",
    "    output = io.StringIO()\n",
    "    writer = csv.DictWriter(output, fieldnames=data[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "    return output.getvalue()\n",
    "\n",
    "def export_to_json(data: list, pretty: bool = True) -> str:\n",
    "    \"\"\"Convert data to JSON string.\"\"\"\n",
    "    if pretty:\n",
    "        return json.dumps(data, indent=2, default=str)\n",
    "    return json.dumps(data, default=str)\n",
    "\n",
    "def save_to_file(content: str, filename: str) -> str:\n",
    "    \"\"\"Save content to a temporary file and return the path.\"\"\"\n",
    "    if not content:\n",
    "        return None\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    filepath = os.path.join(temp_dir, filename)\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(content)\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gradio-header",
   "metadata": {},
   "source": [
    "## 7. Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gradio-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable to store generated data\n",
    "current_data = []\n",
    "\n",
    "def update_fields(data_type: str) -> str:\n",
    "    \"\"\"Update fields textbox based on selected data type.\"\"\"\n",
    "    if data_type in DATA_TEMPLATES:\n",
    "        return \", \".join(DATA_TEMPLATES[data_type][\"fields\"])\n",
    "    return \"\"\n",
    "\n",
    "def generate_data(\n",
    "    model: str,\n",
    "    data_type: str,\n",
    "    fields_str: str,\n",
    "    num_records: int,\n",
    "    custom_instructions: str,\n",
    "    locale: str,\n",
    "    progress=gr.Progress()\n",
    "):\n",
    "    \"\"\"Main function to generate test data.\"\"\"\n",
    "    global current_data\n",
    "    \n",
    "    progress(0, desc=\"Starting generation...\")\n",
    "    \n",
    "    # Parse fields\n",
    "    fields = [f.strip() for f in fields_str.split(\",\") if f.strip()]\n",
    "    \n",
    "    if not fields:\n",
    "        return \"Error: No fields specified\", None, None, None\n",
    "    \n",
    "    if num_records < 1 or num_records > 1000:\n",
    "        return \"Error: Number of records must be between 1 and 1000\", None, None, None\n",
    "    \n",
    "    progress(0.3, desc=\"Generating data with LLM...\")\n",
    "    \n",
    "    # Generate data\n",
    "    data, status = generate_data_with_llm(\n",
    "        model=model,\n",
    "        data_type=data_type,\n",
    "        fields=fields,\n",
    "        num_records=int(num_records),\n",
    "        custom_instructions=custom_instructions,\n",
    "        locale=locale\n",
    "    )\n",
    "    \n",
    "    if not data:\n",
    "        return status, None, None, None\n",
    "    \n",
    "    current_data = data\n",
    "    \n",
    "    progress(0.7, desc=\"Formatting output...\")\n",
    "    \n",
    "    # Create DataFrame for display\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Generate exports\n",
    "    csv_content = export_to_csv(data)\n",
    "    json_content = export_to_json(data)\n",
    "    \n",
    "    # Save files for download\n",
    "    csv_file = save_to_file(csv_content, f\"{data_type.lower()}_data.csv\")\n",
    "    json_file = save_to_file(json_content, f\"{data_type.lower()}_data.json\")\n",
    "    \n",
    "    progress(1.0, desc=\"Complete!\")\n",
    "    \n",
    "    return status, df, csv_file, json_file\n",
    "\n",
    "def create_custom_data(\n",
    "    model: str,\n",
    "    schema_json: str,\n",
    "    num_records: int,\n",
    "    context: str,\n",
    "    progress=gr.Progress()\n",
    "):\n",
    "    \"\"\"Generate data from custom JSON schema.\"\"\"\n",
    "    global current_data\n",
    "    \n",
    "    progress(0, desc=\"Parsing schema...\")\n",
    "    \n",
    "    try:\n",
    "        schema = json.loads(schema_json)\n",
    "    except json.JSONDecodeError as e:\n",
    "        return f\"Error: Invalid JSON schema - {str(e)}\", None, None, None\n",
    "    \n",
    "    if not isinstance(schema, dict):\n",
    "        return \"Error: Schema must be a JSON object with field definitions\", None, None, None\n",
    "    \n",
    "    fields = list(schema.keys())\n",
    "    \n",
    "    # Create detailed prompt with schema\n",
    "    schema_description = \"\\n\".join([f\"- {k}: {v}\" for k, v in schema.items()])\n",
    "    custom_instructions = f\"\"\"Field specifications:\n",
    "{schema_description}\n",
    "\n",
    "Context: {context if context else 'General test data'}\"\"\"\n",
    "    \n",
    "    progress(0.3, desc=\"Generating data with LLM...\")\n",
    "    \n",
    "    data, status = generate_data_with_llm(\n",
    "        model=model,\n",
    "        data_type=\"Custom\",\n",
    "        fields=fields,\n",
    "        num_records=int(num_records),\n",
    "        custom_instructions=custom_instructions\n",
    "    )\n",
    "    \n",
    "    if not data:\n",
    "        return status, None, None, None\n",
    "    \n",
    "    current_data = data\n",
    "    \n",
    "    progress(0.7, desc=\"Formatting output...\")\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    csv_content = export_to_csv(data)\n",
    "    json_content = export_to_json(data)\n",
    "    \n",
    "    csv_file = save_to_file(csv_content, \"custom_data.csv\")\n",
    "    json_file = save_to_file(json_content, \"custom_data.json\")\n",
    "    \n",
    "    progress(1.0, desc=\"Complete!\")\n",
    "    \n",
    "    return status, df, csv_file, json_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ui-header",
   "metadata": {},
   "source": [
    "## 8. Build and Launch UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ui-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Gradio interface\n",
    "with gr.Blocks(\n",
    "    title=\"AI Test Data Generator\",\n",
    "    theme=gr.themes.Soft(),\n",
    "    css=\"\"\"\n",
    "    .container { max-width: 1200px; margin: auto; }\n",
    "    .header { text-align: center; margin-bottom: 20px; }\n",
    "    \"\"\"\n",
    ") as demo:\n",
    "    \n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # AI-Powered Test Data Generator\n",
    "        \n",
    "        Generate realistic test data using open-source LLMs via HuggingFace Inference API.\n",
    "        Choose from predefined templates or create custom schemas.\n",
    "        \n",
    "        **Note:** For best results, set your `HF_TOKEN` environment variable. Get your free token at [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    with gr.Tabs():\n",
    "        # Tab 1: Template-based Generation\n",
    "        with gr.Tab(\"Template Generator\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    model_dropdown = gr.Dropdown(\n",
    "                        choices=AVAILABLE_MODELS,\n",
    "                        value=AVAILABLE_MODELS[0],\n",
    "                        label=\"LLM Model\",\n",
    "                        info=\"Select the HuggingFace model to use\"\n",
    "                    )\n",
    "                    \n",
    "                    data_type_dropdown = gr.Dropdown(\n",
    "                        choices=list(DATA_TEMPLATES.keys()),\n",
    "                        value=\"Users\",\n",
    "                        label=\"Data Type\",\n",
    "                        info=\"Select a predefined template\"\n",
    "                    )\n",
    "                    \n",
    "                    fields_input = gr.Textbox(\n",
    "                        value=\", \".join(DATA_TEMPLATES[\"Users\"][\"fields\"]),\n",
    "                        label=\"Fields (comma-separated)\",\n",
    "                        info=\"Customize the fields to generate\",\n",
    "                        lines=2\n",
    "                    )\n",
    "                    \n",
    "                    num_records_slider = gr.Slider(\n",
    "                        minimum=1,\n",
    "                        maximum=100,\n",
    "                        value=10,\n",
    "                        step=1,\n",
    "                        label=\"Number of Records\"\n",
    "                    )\n",
    "                    \n",
    "                    locale_dropdown = gr.Dropdown(\n",
    "                        choices=[\"en_US\", \"en_GB\", \"de_DE\", \"fr_FR\", \"es_ES\", \"it_IT\", \"ja_JP\", \"zh_CN\", \"pt_BR\", \"in_IN\"],\n",
    "                        value=\"en_US\",\n",
    "                        label=\"Locale\",\n",
    "                        info=\"Regional format for generated data\"\n",
    "                    )\n",
    "                    \n",
    "                    custom_instructions_input = gr.Textbox(\n",
    "                        label=\"Custom Instructions (optional)\",\n",
    "                        placeholder=\"e.g., 'Include only tech companies', 'Use prices in EUR'\",\n",
    "                        lines=2\n",
    "                    )\n",
    "                    \n",
    "                    generate_btn = gr.Button(\"Generate Data\", variant=\"primary\", size=\"lg\")\n",
    "                \n",
    "                with gr.Column(scale=2):\n",
    "                    status_output = gr.Textbox(label=\"Status\", interactive=False)\n",
    "                    data_output = gr.Dataframe(\n",
    "                        label=\"Generated Data\",\n",
    "                        interactive=False,\n",
    "                        wrap=True\n",
    "                    )\n",
    "                    \n",
    "                    with gr.Row():\n",
    "                        csv_download = gr.File(label=\"Download CSV\")\n",
    "                        json_download = gr.File(label=\"Download JSON\")\n",
    "            \n",
    "            # Event handlers for template tab\n",
    "            data_type_dropdown.change(\n",
    "                fn=update_fields,\n",
    "                inputs=[data_type_dropdown],\n",
    "                outputs=[fields_input]\n",
    "            )\n",
    "            \n",
    "            generate_btn.click(\n",
    "                fn=generate_data,\n",
    "                inputs=[\n",
    "                    model_dropdown,\n",
    "                    data_type_dropdown,\n",
    "                    fields_input,\n",
    "                    num_records_slider,\n",
    "                    custom_instructions_input,\n",
    "                    locale_dropdown\n",
    "                ],\n",
    "                outputs=[\n",
    "                    status_output,\n",
    "                    data_output,\n",
    "                    csv_download,\n",
    "                    json_download\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        # Tab 2: Custom Schema Generator\n",
    "        with gr.Tab(\"Custom Schema\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    custom_model_dropdown = gr.Dropdown(\n",
    "                        choices=AVAILABLE_MODELS,\n",
    "                        value=AVAILABLE_MODELS[0],\n",
    "                        label=\"LLM Model\"\n",
    "                    )\n",
    "                    \n",
    "                    schema_input = gr.Code(\n",
    "                        value=\"\"\"{\n",
    "    \"id\": \"unique integer identifier\",\n",
    "    \"company_name\": \"realistic company name\",\n",
    "    \"industry\": \"industry sector\",\n",
    "    \"revenue\": \"annual revenue in millions USD\",\n",
    "    \"employees\": \"number of employees\",\n",
    "    \"founded_year\": \"year company was founded\",\n",
    "    \"headquarters\": \"city and country\",\n",
    "    \"is_public\": \"boolean - publicly traded\"\n",
    "}\"\"\",\n",
    "                        language=\"json\",\n",
    "                        label=\"Schema Definition (JSON)\",\n",
    "                        lines=12\n",
    "                    )\n",
    "                    \n",
    "                    custom_num_records = gr.Slider(\n",
    "                        minimum=1,\n",
    "                        maximum=100,\n",
    "                        value=10,\n",
    "                        step=1,\n",
    "                        label=\"Number of Records\"\n",
    "                    )\n",
    "                    \n",
    "                    context_input = gr.Textbox(\n",
    "                        label=\"Context/Domain (optional)\",\n",
    "                        placeholder=\"e.g., 'Healthcare industry', 'E-commerce platform'\",\n",
    "                        lines=2\n",
    "                    )\n",
    "                    \n",
    "                    custom_generate_btn = gr.Button(\"Generate Custom Data\", variant=\"primary\", size=\"lg\")\n",
    "                \n",
    "                with gr.Column(scale=2):\n",
    "                    custom_status_output = gr.Textbox(label=\"Status\", interactive=False)\n",
    "                    custom_data_output = gr.Dataframe(\n",
    "                        label=\"Generated Data\",\n",
    "                        interactive=False,\n",
    "                        wrap=True\n",
    "                    )\n",
    "                    \n",
    "                    with gr.Row():\n",
    "                        custom_csv_download = gr.File(label=\"Download CSV\")\n",
    "                        custom_json_download = gr.File(label=\"Download JSON\")\n",
    "            \n",
    "            custom_generate_btn.click(\n",
    "                fn=create_custom_data,\n",
    "                inputs=[\n",
    "                    custom_model_dropdown,\n",
    "                    schema_input,\n",
    "                    custom_num_records,\n",
    "                    context_input\n",
    "                ],\n",
    "                outputs=[\n",
    "                    custom_status_output,\n",
    "                    custom_data_output,\n",
    "                    custom_csv_download,\n",
    "                    custom_json_download\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        # Tab 3: Help & Examples\n",
    "        with gr.Tab(\"Help & Examples\"):\n",
    "            gr.Markdown(\n",
    "                \"\"\"\n",
    "                ## How to Use\n",
    "                \n",
    "                ### Setup\n",
    "                \n",
    "                **For HuggingFace Spaces:**\n",
    "                - The app uses HuggingFace Inference API\n",
    "                - Set `HF_TOKEN` as a Space secret for higher rate limits\n",
    "                - Get your free token at: https://huggingface.co/settings/tokens\n",
    "                \n",
    "                **For Local Use:**\n",
    "                - Set environment variable: `export HF_TOKEN=your_token_here`\n",
    "                - Or create a `.env` file with `HF_TOKEN=your_token_here`\n",
    "                \n",
    "                ### Template Generator\n",
    "                1. Select an LLM model from the dropdown\n",
    "                2. Choose a data type template (Users, Products, Orders, etc.)\n",
    "                3. Customize fields if needed\n",
    "                4. Set the number of records to generate\n",
    "                5. Optionally add custom instructions for more specific data\n",
    "                6. Click \"Generate Data\"\n",
    "                \n",
    "                ### Custom Schema\n",
    "                1. Define your schema as a JSON object\n",
    "                2. Each key is a field name, each value describes what data to generate\n",
    "                3. Add context to help the LLM understand the domain\n",
    "                \n",
    "                ### Example Custom Schemas\n",
    "                \n",
    "                **IoT Sensor Data:**\n",
    "                ```json\n",
    "                {\n",
    "                    \"sensor_id\": \"unique sensor identifier\",\n",
    "                    \"device_type\": \"temperature, humidity, or pressure sensor\",\n",
    "                    \"reading\": \"numeric sensor reading\",\n",
    "                    \"unit\": \"measurement unit\",\n",
    "                    \"timestamp\": \"ISO format datetime\",\n",
    "                    \"location\": \"building and room identifier\",\n",
    "                    \"battery_level\": \"percentage 0-100\"\n",
    "                }\n",
    "                ```\n",
    "                \n",
    "                **Medical Records:**\n",
    "                ```json\n",
    "                {\n",
    "                    \"patient_id\": \"unique identifier\",\n",
    "                    \"diagnosis_code\": \"ICD-10 code\",\n",
    "                    \"diagnosis_description\": \"medical condition\",\n",
    "                    \"visit_date\": \"date of visit\",\n",
    "                    \"physician\": \"doctor name\",\n",
    "                    \"department\": \"hospital department\",\n",
    "                    \"treatment_plan\": \"brief treatment description\"\n",
    "                }\n",
    "                ```\n",
    "                \n",
    "                **Event Logs:**\n",
    "                ```json\n",
    "                {\n",
    "                    \"event_id\": \"unique event identifier\",\n",
    "                    \"event_type\": \"login, logout, purchase, error\",\n",
    "                    \"user_id\": \"user identifier\",\n",
    "                    \"timestamp\": \"ISO datetime\",\n",
    "                    \"ip_address\": \"IPv4 address\",\n",
    "                    \"user_agent\": \"browser user agent string\",\n",
    "                    \"status\": \"success or failure\",\n",
    "                    \"metadata\": \"additional JSON data\"\n",
    "                }\n",
    "                ```\n",
    "                \n",
    "                ### Tips\n",
    "                \n",
    "                - For best results, use descriptive field names\n",
    "                - Add custom instructions for domain-specific data\n",
    "                - Smaller models (Phi-3) are faster but may produce less realistic data\n",
    "                - Larger models (Qwen2.5-72B, Llama-3.1-8B) produce better quality but are slower\n",
    "                \"\"\"\n",
    "            )\n",
    "    \n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        ---\n",
    "        Built with Gradio and HuggingFace | Open Source Test Data Generator\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "launch-header",
   "metadata": {},
   "source": [
    "## 9. Launch the Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "launch-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the Gradio app\n",
    "demo.launch(\n",
    "    share=False,  # Set to True to create a public link\n",
    "    server_name=\"0.0.0.0\",  # Allow external connections\n",
    "    show_error=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
