{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HR Synthetic Data Generator\n",
        "\n",
        "Generate synthetic **resumes** and **job postings** for HR and recruiting (NER, resume parsing, job–resume matching, ATS testing). All data and UI are in English.\n",
        "\n",
        "**Requirements:** Set `OPENAI_API_KEY` and `OPENROUTER_API_KEY` in your `.env` (e.g. in the project root).  \n",
        "**Run:** From the repo root use `uv run jupyter notebook` or open this notebook in your IDE with the UV Python kernel, then run all cells and launch the app."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Dependencies\n",
        "\n",
        "Dependencies are provided by the project root `pyproject.toml`: `openai`, `gradio`, `pandas`, `python-dotenv`. Ensure you run the notebook with the UV environment (e.g. `uv run jupyter notebook` from repo root)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import sys\n",
        "import traceback\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "load_dotenv()\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    print(\"OPENAI_API_KEY is not set. Add it to .env for GPT-5 mini.\")\n",
        "if not OPENROUTER_API_KEY:\n",
        "    print(\"OPENROUTER_API_KEY is not set. Add it to .env for Gemini 2.0 Flash.\")\n",
        "if OPENAI_API_KEY and OPENROUTER_API_KEY:\n",
        "    print(\"Both API keys are set.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: API clients and model config\n",
        "\n",
        "Two models: **GPT-5 mini** (OpenAI) and **Gemini 2.0 Flash** (OpenRouter). `get_client_and_model(model_key)` returns the client and model id; raises a clear error if the required API key is missing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
        "\n",
        "MODELS = {\n",
        "    \"GPT-5 mini\": {\n",
        "        \"provider\": \"openai\",\n",
        "        \"model_id\": \"gpt-5-mini\",\n",
        "    },\n",
        "    \"Gemini 2.0 Flash\": {\n",
        "        \"provider\": \"openrouter\",\n",
        "        \"model_id\": \"google/gemini-2.0-flash-001\",\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "def get_client_and_model(model_key):\n",
        "    \"\"\"\n",
        "    Return (client, model_id) for the given model key.\n",
        "    Uses OPENAI_API_KEY for OpenAI and OPENROUTER_API_KEY for OpenRouter.\n",
        "    Raises ValueError if the required key is missing.\n",
        "    \"\"\"\n",
        "    if model_key not in MODELS:\n",
        "        raise ValueError(f\"Unknown model: {model_key}. Choose from {list(MODELS.keys())}\")\n",
        "    info = MODELS[model_key]\n",
        "    model_id = info[\"model_id\"]\n",
        "    if info[\"provider\"] == \"openai\":\n",
        "        if not OPENAI_API_KEY:\n",
        "            raise ValueError(\"OPENAI_API_KEY is not set. Add it to .env for GPT-5 mini.\")\n",
        "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "        return client, model_id\n",
        "    if info[\"provider\"] == \"openrouter\":\n",
        "        if not OPENROUTER_API_KEY:\n",
        "            raise ValueError(\"OPENROUTER_API_KEY is not set. Add it to .env for Gemini 2.0 Flash.\")\n",
        "        client = OpenAI(base_url=OPENROUTER_BASE_URL, api_key=OPENROUTER_API_KEY)\n",
        "        return client, model_id\n",
        "    raise ValueError(f\"Unknown provider: {info.get('provider')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Schemas and prompt building\n",
        "\n",
        "Explicit schemas for **resumes** and **job postings**. All field values must be in English. Dates in YYYY-MM or YYYY; seniority: Junior/Middle/Senior (Senior only when years_experience >= 5). Prompts instruct the model to output JSONL only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RESUME_SCHEMA = \"\"\"\n",
        "- first_name (string)\n",
        "- last_name (string)\n",
        "- email (string, realistic format)\n",
        "- phone (string, realistic format)\n",
        "- experience (array of objects: company, position, start_date, end_date; dates YYYY-MM or YYYY)\n",
        "- skills (array of strings)\n",
        "- education (array of objects: institution, degree, year)\n",
        "- desired_salary_min (number)\n",
        "- desired_salary_max (number)\n",
        "- years_experience (number, total)\n",
        "- seniority: \"Junior\" or \"Middle\" or \"Senior\"; use \"Senior\" only when years_experience >= 5\n",
        "\"\"\"\n",
        "\n",
        "JOB_SCHEMA = \"\"\"\n",
        "- title (string)\n",
        "- company (string)\n",
        "- requirements (string or array of strings)\n",
        "- responsibilities (string or array of strings)\n",
        "- salary_min (number)\n",
        "- salary_max (number)\n",
        "- region (string, e.g. Remote, NYC, London)\n",
        "- industry (string, e.g. IT, Finance, Retail)\n",
        "- employment_type (string: full-time, part-time, remote, contract, etc.)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def build_system_prompt(record_type: str, region: str = \"\") -> str:\n",
        "    \"\"\"Build system prompt for resume or job generation. Enforces English and JSONL.\"\"\"\n",
        "    if record_type == \"resume\":\n",
        "        schema = RESUME_SCHEMA\n",
        "        entity = \"resume\"\n",
        "    else:\n",
        "        schema = JOB_SCHEMA\n",
        "        entity = \"job posting\"\n",
        "    region_note = \"\"\n",
        "    if region and region.strip():\n",
        "        region_note = (\n",
        "            \" When a region or country is specified, use typical first and last names for that region \"\n",
        "            \"(e.g. Finnish names for Finland, Japanese for Japan) and salary amounts in local currency \"\n",
        "            \"appropriate for that market (e.g. EUR for Finland/Europe, local levels). \"\n",
        "        )\n",
        "    return (\n",
        "        f\"You are an expert at generating synthetic HR data. Generate realistic {entity} records. \"\n",
        "        \"Output language for field values: English for companies, skills, cities; use local names when region is set. \"\n",
        "        \"Output format: JSONL only — one JSON object per line. No explanations or extra text. \"\n",
        "        \"Use consistent formats: dates as YYYY-MM or YYYY; seniority only Senior when years_experience >= 5. \"\n",
        "        f\"{region_note}\"\n",
        "        f\"Schema (include these fields): {schema}\"\n",
        "    ).strip()\n",
        "\n",
        "\n",
        "def build_user_prompt(record_type: str, num_rows: int, industry: str = \"\", region: str = \"\") -> str:\n",
        "    \"\"\"Build user prompt with row count and optional industry/region (for both resumes and jobs).\"\"\"\n",
        "    num_rows = max(10, min(200, int(num_rows)))\n",
        "    base = f\"Generate exactly {num_rows} {record_type} records. Output only JSONL: one JSON object per line, no other text.\"\n",
        "    extra = []\n",
        "    if industry:\n",
        "        extra.append(f\"Focus industry: {industry}.\")\n",
        "    if region:\n",
        "        extra.append(f\"Focus region: {region}. Use typical local first and last names and salary in local currency for this region.\")\n",
        "    if extra:\n",
        "        base += \" \" + \" \".join(extra)\n",
        "    return base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Generation and parsing\n",
        "\n",
        "`parse_jsonl(text)` parses line-by-line JSON; skips non-JSON lines. `generate_hr_records(...)` calls the selected API, builds messages from schemas, and returns (status_message, list_of_dicts). num_rows clamped to 10–200."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _extract_jsonl_text(text: str) -> str:\n",
        "    \"\"\"Strip markdown code fences (```json ... ``` or ``` ... ```) so we can parse JSONL.\"\"\"\n",
        "    if not text or not text.strip():\n",
        "        return text\n",
        "    s = text.strip()\n",
        "    for start in (\"```json\", \"```JSON\", \"```\"):\n",
        "        if s.startswith(start):\n",
        "            s = s[len(start):].lstrip(\"\\n\")\n",
        "            break\n",
        "    if s.endswith(\"```\"):\n",
        "        s = s[:-3].rstrip()\n",
        "    return s\n",
        "\n",
        "\n",
        "def parse_jsonl(text: str) -> list[dict]:\n",
        "    \"\"\"Parse lines that look like JSON objects into a list of dicts. Skips non-JSON lines. Handles markdown fences and single JSON array.\"\"\"\n",
        "    if not text or not text.strip():\n",
        "        return []\n",
        "    text = _extract_jsonl_text(text)\n",
        "    records = []\n",
        "    for line in text.split(\"\\n\"):\n",
        "        line = line.strip()\n",
        "        if not line.startswith(\"{\"):\n",
        "            continue\n",
        "        try:\n",
        "            obj = json.loads(line)\n",
        "            if isinstance(obj, dict):\n",
        "                records.append(obj)\n",
        "        except json.JSONDecodeError:\n",
        "            continue\n",
        "    if not records and text.strip().startswith(\"[\"):\n",
        "        try:\n",
        "            arr = json.loads(text)\n",
        "            if isinstance(arr, list):\n",
        "                records = [x for x in arr if isinstance(x, dict)]\n",
        "        except json.JSONDecodeError:\n",
        "            pass\n",
        "    return records\n",
        "\n",
        "\n",
        "def _clean_date(val) -> str:\n",
        "    \"\"\"Return readable string for date; None or 'None' -> 'Present'.\"\"\"\n",
        "    if val is None or val == \"\" or str(val).strip().lower() == \"none\":\n",
        "        return \"Present\"\n",
        "    return str(val).strip()\n",
        "\n",
        "\n",
        "def _format_experience(exp) -> str:\n",
        "    \"\"\"Convert experience array of objects to a single readable string.\"\"\"\n",
        "    if isinstance(exp, str):\n",
        "        return exp\n",
        "    if not isinstance(exp, list):\n",
        "        return str(exp) if exp is not None else \"\"\n",
        "    parts = []\n",
        "    for item in exp:\n",
        "        if isinstance(item, dict):\n",
        "            c = item.get(\"company\") or \"\"\n",
        "            p = item.get(\"position\") or \"\"\n",
        "            s = _clean_date(item.get(\"start_date\"))\n",
        "            e = _clean_date(item.get(\"end_date\"))\n",
        "            parts.append(f\"{c}, {p} ({s}–{e})\".strip())\n",
        "        else:\n",
        "            parts.append(str(item))\n",
        "    return \"; \".join(parts) if parts else \"\"\n",
        "\n",
        "\n",
        "def _format_education(edu) -> str:\n",
        "    \"\"\"Convert education array of objects to a single readable string.\"\"\"\n",
        "    if isinstance(edu, str):\n",
        "        return edu\n",
        "    if not isinstance(edu, list):\n",
        "        return str(edu) if edu is not None else \"\"\n",
        "    parts = []\n",
        "    for item in edu:\n",
        "        if isinstance(item, dict):\n",
        "            inst = item.get(\"institution\") or \"\"\n",
        "            deg = item.get(\"degree\") or \"\"\n",
        "            year = item.get(\"year\")\n",
        "            year_str = \"\" if year is None or str(year).strip().lower() == \"none\" else str(year).strip()\n",
        "            if year_str:\n",
        "                parts.append(f\"{inst}, {deg} ({year_str})\".strip())\n",
        "            else:\n",
        "                parts.append(f\"{inst}, {deg}\".strip() or \"\")\n",
        "        else:\n",
        "            parts.append(str(item))\n",
        "    return \"; \".join(parts) if parts else \"\"\n",
        "\n",
        "\n",
        "def _format_string_list(val) -> str:\n",
        "    \"\"\"Convert array of strings to a single string (for requirements/responsibilities in jobs).\"\"\"\n",
        "    if isinstance(val, str):\n",
        "        return val\n",
        "    if isinstance(val, list):\n",
        "        return \", \".join(str(x).strip() for x in val if x is not None and str(x).strip().lower() != \"none\") if val else \"\"\n",
        "    return str(val) if val is not None else \"\"\n",
        "\n",
        "\n",
        "def flatten_record_for_display(record: dict, record_type: str) -> dict:\n",
        "    \"\"\"Convert experience, education, skills, and list fields to readable strings for display and CSV.\"\"\"\n",
        "    out = dict(record)\n",
        "    if \"experience\" in out:\n",
        "        out[\"experience\"] = _format_experience(out[\"experience\"])\n",
        "    if \"education\" in out:\n",
        "        out[\"education\"] = _format_education(out[\"education\"])\n",
        "    if \"skills\" in out:\n",
        "        out[\"skills\"] = _format_string_list(out[\"skills\"])\n",
        "    if record_type == \"job\":\n",
        "        if \"requirements\" in out:\n",
        "            out[\"requirements\"] = _format_string_list(out[\"requirements\"])\n",
        "        if \"responsibilities\" in out:\n",
        "            out[\"responsibilities\"] = _format_string_list(out[\"responsibilities\"])\n",
        "    # Replace any remaining None values with empty string for CSV\n",
        "    for k, v in list(out.items()):\n",
        "        if v is None or (isinstance(v, str) and v.strip().lower() == \"none\"):\n",
        "            out[k] = \"\"\n",
        "    return out\n",
        "\n",
        "\n",
        "def generate_hr_records(\n",
        "    record_type: str,\n",
        "    num_rows: int,\n",
        "    temperature: float,\n",
        "    model_key: str,\n",
        "    industry: str = \"\",\n",
        "    region: str = \"\",\n",
        ") -> tuple[str, list[dict]]:\n",
        "    \"\"\"\n",
        "    Generate synthetic resume or job records via the selected model API.\n",
        "    Returns (status_message, list_of_dicts). Handles API and parse errors.\n",
        "    \"\"\"\n",
        "    num_rows = max(10, min(200, int(num_rows)))\n",
        "    try:\n",
        "        client, model_id = get_client_and_model(model_key)\n",
        "    except ValueError as e:\n",
        "        return f\"Error: {e}\", []\n",
        "\n",
        "    system = build_system_prompt(record_type, region=region)\n",
        "    user = build_user_prompt(record_type, num_rows, industry=industry, region=region)\n",
        "    messages = [{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}]\n",
        "\n",
        "    # GPT-5 mini only supports temperature=1; use 1.0 for that model\n",
        "    req_temperature = 1.0 if model_id == \"gpt-5-mini\" else float(temperature)\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_id,\n",
        "            messages=messages,\n",
        "            temperature=req_temperature,\n",
        "            max_completion_tokens=8192,\n",
        "        )\n",
        "        content = (response.choices[0].message.content or \"\").strip()\n",
        "    except Exception as e:\n",
        "        return f\"API error: {e}\", []\n",
        "\n",
        "    records = parse_jsonl(content)\n",
        "    if not records:\n",
        "        snippet = (content[:800] + \"...\") if len(content) > 800 else content\n",
        "        print(f\"[parse] No JSONL parsed. Model output snippet:\\n{snippet}\", file=sys.stderr, flush=True)\n",
        "        return \"No valid JSONL rows parsed. Try again or check the model output. See console for raw snippet.\", []\n",
        "    records = [flatten_record_for_display(r, record_type) for r in records]\n",
        "    if len(records) < num_rows:\n",
        "        return f\"Generated {len(records)} of {num_rows} requested rows.\", records\n",
        "    return f\"Generated {len(records)} rows successfully.\", records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: CSV export\n",
        "\n",
        "Save generated records to CSV. Output directory: current directory or temp; filenames `hr_resumes.csv` or `hr_jobs.csv` depending on record type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tempfile\n",
        "\n",
        "OUTPUT_DIR = tempfile.gettempdir()\n",
        "CSV_NAMES = {\"resume\": \"hr_resumes.csv\", \"job\": \"hr_jobs.csv\"}\n",
        "\n",
        "\n",
        "def save_to_csv(records: list[dict], record_type: str, dir_path: str | None = None) -> str | None:\n",
        "    \"\"\"\n",
        "    Save list of dicts to CSV. Returns path for Gradio File download.\n",
        "    record_type is 'resume' or 'job'; filename is hr_resumes.csv or hr_jobs.csv.\n",
        "    \"\"\"\n",
        "    if not records:\n",
        "        return None\n",
        "    base = dir_path or OUTPUT_DIR\n",
        "    filename = CSV_NAMES.get(record_type, \"hr_data.csv\")\n",
        "    path = os.path.join(base, filename)\n",
        "    df = pd.DataFrame(records)\n",
        "    df.to_csv(path, index=False)\n",
        "    return path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Gradio UI\n",
        "\n",
        "Radio choice: **Resumes** or **Job postings**. Model choice (GPT-5 mini / Gemini 2.0 Flash), temperature and number of rows sliders; for jobs, optional Industry and Region. Generate button, Status, Data preview, Download CSV. All labels in English."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_generate(record_type, model_name, temperature, num_rows, industry, region):\n",
        "    \"\"\"Single handler: generate records, build dataframe, save CSV; return (status, df, path).\"\"\"\n",
        "    try:\n",
        "        if not record_type:\n",
        "            return \"Select record type: Resumes or Job postings.\", None, None\n",
        "        record_type = \"resume\" if record_type == \"Resumes\" else \"job\"\n",
        "        print(f\"[UI] Generating {record_type}s: model={model_name}, rows={num_rows}\", flush=True)\n",
        "        status, records = generate_hr_records(\n",
        "            record_type=record_type,\n",
        "            num_rows=num_rows,\n",
        "            temperature=temperature,\n",
        "            model_key=model_name,\n",
        "            industry=industry or \"\",\n",
        "            region=region or \"\",\n",
        "        )\n",
        "        if not records:\n",
        "            print(f\"[UI] No records: {status}\", flush=True)\n",
        "            return status, None, None\n",
        "        df = pd.DataFrame(records)\n",
        "        path = save_to_csv(records, record_type)\n",
        "        print(f\"[UI] OK: {len(records)} rows, CSV -> {path}\", flush=True)\n",
        "        return status, df, path\n",
        "    except Exception as e:\n",
        "        msg = f\"Error: {e}\"\n",
        "        print(f\"[UI] ERROR: {msg}\", file=sys.stderr, flush=True)\n",
        "        traceback.print_exc(file=sys.stderr)\n",
        "        return msg, None, None\n",
        "\n",
        "\n",
        "model_choices = list(MODELS.keys())\n",
        "TEMPERATURE_FIXED_MODEL = \"GPT-5 mini\"  # only temperature=1 supported\n",
        "\n",
        "\n",
        "def update_temperature_ui(model_key):\n",
        "    \"\"\"Disable temperature slider and set to 1.0 for GPT-5 mini; enable for others.\"\"\"\n",
        "    if model_key == TEMPERATURE_FIXED_MODEL:\n",
        "        return gr.update(interactive=False, value=1.0)\n",
        "    return gr.update(interactive=True, value=0.7)\n",
        "\n",
        "\n",
        "with gr.Blocks(title=\"HR Synthetic Data Generator\") as demo:\n",
        "    gr.Markdown(\"## Generate synthetic resumes or job postings\")\n",
        "    record_type_radio = gr.Radio(\n",
        "        choices=[\"Resumes\", \"Job postings\"],\n",
        "        value=\"Resumes\",\n",
        "        label=\"Record type\",\n",
        "    )\n",
        "    with gr.Row():\n",
        "        model_dropdown = gr.Dropdown(\n",
        "            choices=model_choices,\n",
        "            value=model_choices[0],\n",
        "            label=\"Model\",\n",
        "        )\n",
        "        _temp_fixed = model_choices[0] == TEMPERATURE_FIXED_MODEL\n",
        "        temperature_slider = gr.Slider(\n",
        "            0.0, 1.5,\n",
        "            value=1.0 if _temp_fixed else 0.7,\n",
        "            step=0.1,\n",
        "            label=\"Temperature\",\n",
        "            interactive=not _temp_fixed,\n",
        "        )\n",
        "        num_rows_slider = gr.Slider(10, 200, value=30, step=1, label=\"Number of rows\")\n",
        "    with gr.Row():\n",
        "        industry_text = gr.Textbox(label=\"Industry (optional)\", placeholder=\"e.g. IT, Finance, Health Care\")\n",
        "        region_text = gr.Textbox(label=\"Region (names & salaries)\", placeholder=\"e.g. Finland, Japan, Remote, NYC\")\n",
        "    gr.Markdown(\"*Low temperature = more consistent; high = more varied. GPT-5 mini uses fixed temperature (1). Region sets local names and salary currency (e.g. Finland → Finnish names, EUR).*\")\n",
        "    gen_btn = gr.Button(\"Generate\")\n",
        "    status_out = gr.Textbox(label=\"Status\", interactive=False)\n",
        "    # Wider columns for phone, experience, skills, education; wrap so text isn't cut off\n",
        "    PREVIEW_COLUMN_WIDTHS = [\"90px\", \"90px\", \"150px\", \"130px\", \"320px\", \"240px\", \"280px\", \"85px\", \"85px\", \"85px\", \"80px\", \"90px\"]\n",
        "    preview_df = gr.Dataframe(\n",
        "        label=\"Data preview\",\n",
        "        interactive=False,\n",
        "        wrap=True,\n",
        "        column_widths=PREVIEW_COLUMN_WIDTHS,\n",
        "    )\n",
        "    download_file = gr.File(label=\"Download CSV\", interactive=False)\n",
        "\n",
        "    model_dropdown.change(\n",
        "        fn=update_temperature_ui,\n",
        "        inputs=[model_dropdown],\n",
        "        outputs=[temperature_slider],\n",
        "    )\n",
        "    gen_btn.click(\n",
        "        fn=run_generate,\n",
        "        inputs=[record_type_radio, model_dropdown, temperature_slider, num_rows_slider, industry_text, region_text],\n",
        "        outputs=[status_out, preview_df, download_file],\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Launch\n",
        "\n",
        "Run the cell below to start the Gradio app. Use the local URL in your browser. For IDE: run from repo root with `uv run jupyter notebook` or use the UV Python kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "demo.launch(inbrowser=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional:  \n",
        "I also implemented General Purpose Generator using open-source models from Hugging Face Qwen2.5-7B-Instruct and Mistral-7B-Instruct-v0.3                     Link on collab is here: https://colab.research.google.com/drive/1cVSoNRkb714qJOMJmQdWyhEPlOH04UR7\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
