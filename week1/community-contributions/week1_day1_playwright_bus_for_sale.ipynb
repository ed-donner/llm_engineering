{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "from playwright.async_api import async_playwright\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Initialize OpenAI client\n",
    "openai = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# If you get an error running this cell, then please head over to the troubleshooting notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2873e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the below command to install playwright chromium browser.  This must be run from command line in terminal\n",
    "#uv run playwright install chromium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c29a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HOW TO EXTRACT COOKIES AND HEADERS FROM A REAL BROWSER\n",
    "# ============================================================================\n",
    "\n",
    "# METHOD 1: Extract Cookies using JavaScript in Chrome Console\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1. Open the website in Chrome (make sure you can access it)\n",
    "# 2. Open DevTools: Press F12 or Cmd+Option+I (Mac) / Ctrl+Shift+I (Windows)\n",
    "# 3. Go to the Console tab\n",
    "# 4. Paste and run this JavaScript code:\n",
    "#\n",
    "#    // Copy and paste this into Chrome Console to get all cookies:\n",
    "#    (() => {\n",
    "#        const hostname = window.location.hostname;\n",
    "#        const baseDomain = hostname.startsWith('www.') ? hostname.substring(4) : hostname;\n",
    "#        const cookies = document.cookie.split(';').map(c => {\n",
    "#            const [name, ...rest] = c.trim().split('=');\n",
    "#            return {\n",
    "#                name: name.trim(), \n",
    "#                value: rest.join('='), \n",
    "#                domain: '.' + baseDomain,\n",
    "#                path: '/'\n",
    "#            };\n",
    "#        }).filter(c => c.name && c.value);\n",
    "#        console.log('// Copy this output:');\n",
    "#        cookies.forEach(c => console.log(JSON.stringify(c) + ','));\n",
    "#        return cookies;\n",
    "#    })();\n",
    "#\n",
    "# 5. Copy all the output and paste it into the cookies list below\n",
    "\n",
    "# METHOD 2: Extract Cookies from Application Tab\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1. Open DevTools > Application tab (or Storage in older Chrome)\n",
    "# 2. In left sidebar: Cookies > [your website URL]\n",
    "# 3. Manually copy each cookie's name, value, domain, and path\n",
    "\n",
    "# METHOD 3: Extract Headers from Network Tab\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1. Open DevTools > Network tab\n",
    "# 2. Reload the page (Cmd+R or F5)\n",
    "# 3. Click on the first/main request (usually the HTML document)\n",
    "# 4. Look at \"Request Headers\" section\n",
    "# 5. Copy important headers like:\n",
    "#    - Cookie (if you want to use Cookie header instead of cookies list)\n",
    "#    - Referer\n",
    "#    - Origin\n",
    "#    - Authorization (if present)\n",
    "#    - User-Agent (usually not needed, we set it automatically)\n",
    "\n",
    "# ============================================================================\n",
    "# PASTE YOUR COOKIES AND HEADERS HERE\n",
    "# ============================================================================\n",
    "\n",
    "# Replace these with your actual cookies from the browser\n",
    "my_cookies = [\n",
    "    # Example format:\n",
    "    # {\"name\": \"session_id\", \"value\": \"abc123xyz\", \"domain\": \".bizbuysell.com\", \"path\": \"/\"},\n",
    "    # {\"name\": \"csrf_token\", \"value\": \"def456\", \"domain\": \".bizbuysell.com\", \"path\": \"/\"},\n",
    "    # Add more cookies here...\n",
    "]\n",
    "\n",
    "# Replace these with your actual headers (optional, but can help)\n",
    "my_headers = {\n",
    "    # 'Referer': 'https://www.bizbuysell.com/',\n",
    "    'Referer': 'https://www.bizbuysell.com/georgia/restaurants-and-food-businesses-for-sale/?q=bHQ9MzAsNDAsODA%3D',\n",
    "    # 'Origin': 'https://www.bizbuysell.com',\n",
    "    'Origin': 'https://www.bizbuysell.com',\n",
    "    # 'Cookie': 'session_id=abc123; csrf_token=def456',  # Alternative to cookies list\n",
    "}\n",
    "\n",
    "print(\"âœ… Cookie and header extraction helpers loaded!\")\n",
    "print(f\"\\nðŸ“‹ You have {len(my_cookies)} cookies and {len(my_headers)} headers configured\")\n",
    "print(\"\\nðŸ’¡ To use them, call scrape_website() like this:\")\n",
    "print(\"   html = await scrape_website(url, cookies=my_cookies, headers=my_headers)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae53783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to scrape a website using Playwright\n",
    "# Includes retry logic and better error handling for HTTP2 protocol errors\n",
    "# Tries multiple browsers and configurations to handle HTTP2 errors\n",
    "\n",
    "async def scrape_website(url, max_retries=3, timeout=30000, use_firefox_fallback=True, cookies=None, headers=None):\n",
    "    \"\"\"\n",
    "    Scrape a website using Playwright with retry logic and HTTP2 error handling.\n",
    "    \n",
    "    Args:\n",
    "        url: The URL to scrape\n",
    "        max_retries: Maximum number of retry attempts per browser (default: 3)\n",
    "        timeout: Page load timeout in milliseconds (default: 30000)\n",
    "        use_firefox_fallback: Try Firefox if Chromium fails (default: True)\n",
    "        cookies: List of cookie dicts with keys: name, value, domain, path (optional)\n",
    "                Example: [{\"name\": \"session\", \"value\": \"abc123\", \"domain\": \".example.com\", \"path\": \"/\"}]\n",
    "        headers: Dict of HTTP headers to add (optional)\n",
    "                Example: {\"Referer\": \"https://example.com\", \"Cookie\": \"session=abc123\"}\n",
    "    \n",
    "    Returns:\n",
    "        HTML content as string\n",
    "    \"\"\"\n",
    "    last_error = None\n",
    "    \n",
    "    # Try different browser configurations\n",
    "    browser_configs = [\n",
    "        {\n",
    "            'name': 'Chromium (non-headless)',\n",
    "            'browser_type': 'chromium',\n",
    "            'headless': False,  # Some sites work better in non-headless\n",
    "            'args': [\n",
    "                '--disable-http2',\n",
    "                '--disable-blink-features=AutomationControlled',\n",
    "                '--disable-dev-shm-usage',\n",
    "                '--no-sandbox'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'name': 'Chromium (HTTP/2 disabled)',\n",
    "            'browser_type': 'chromium',\n",
    "            'headless': True,\n",
    "            'args': [\n",
    "                '--disable-http2',  # KEY FIX: Disable HTTP/2 to avoid protocol errors\n",
    "                '--disable-blink-features=AutomationControlled',\n",
    "                '--disable-dev-shm-usage',\n",
    "                '--no-sandbox',\n",
    "                '--disable-setuid-sandbox',\n",
    "                '--disable-web-security',\n",
    "                '--disable-features=IsolateOrigins,site-per-process'\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Add Firefox as fallback if enabled\n",
    "    if use_firefox_fallback:\n",
    "        browser_configs.append({\n",
    "            'name': 'Firefox',\n",
    "            'browser_type': 'firefox',\n",
    "            'headless': True,\n",
    "            'args': []\n",
    "        })\n",
    "    \n",
    "    for config in browser_configs:\n",
    "        print(f\"Trying {config['name']}...\")\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                async with async_playwright() as p:\n",
    "                    # Get the browser type\n",
    "                    if config['browser_type'] == 'chromium':\n",
    "                        browser = await p.chromium.launch(\n",
    "                            headless=config['headless'],\n",
    "                            args=config['args']\n",
    "                        )\n",
    "                    elif config['browser_type'] == 'firefox':\n",
    "                        browser = await p.firefox.launch(\n",
    "                            headless=config['headless'],\n",
    "                            args=config['args']\n",
    "                        )\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    # Prepare headers - merge default headers with user-provided headers\n",
    "                    default_headers = {\n",
    "                        'Accept-Language': 'en-US,en;q=0.9',\n",
    "                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "                        'Accept-Encoding': 'gzip, deflate, br',\n",
    "                        'Connection': 'keep-alive',\n",
    "                        'Upgrade-Insecure-Requests': '1'\n",
    "                    }\n",
    "                    \n",
    "                    # Merge with user-provided headers (user headers take precedence)\n",
    "                    if headers:\n",
    "                        default_headers.update(headers)\n",
    "                    \n",
    "                    # Create context with realistic browser settings\n",
    "                    context_options = {\n",
    "                        'user_agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "                        'viewport': {'width': 1920, 'height': 1080},\n",
    "                        'extra_http_headers': default_headers\n",
    "                    }\n",
    "                    \n",
    "                    # Add cookies if provided\n",
    "                    if cookies:\n",
    "                        context_options['storage_state'] = {\n",
    "                            'cookies': cookies,\n",
    "                            'origins': []\n",
    "                        }\n",
    "                        print(f\"ðŸ“‹ Using {len(cookies)} cookies from real browser session\")\n",
    "                    \n",
    "                    context = await browser.new_context(**context_options)\n",
    "                    \n",
    "                    page = await context.new_page()\n",
    "                    \n",
    "                    # Add script to hide webdriver property\n",
    "                    await page.add_init_script(\"\"\"\n",
    "                        Object.defineProperty(navigator, 'webdriver', {\n",
    "                            get: () => undefined\n",
    "                        });\n",
    "                    \"\"\")\n",
    "                    \n",
    "                    # Try to navigate with different wait strategies\n",
    "                    wait_strategies = ['domcontentloaded', 'load']\n",
    "                    \n",
    "                    for strategy in wait_strategies:\n",
    "                        try:\n",
    "                            await page.goto(url, wait_until=strategy, timeout=timeout)\n",
    "                            break\n",
    "                        except Exception as goto_error:\n",
    "                            if strategy == wait_strategies[-1]:  # Last strategy\n",
    "                                raise\n",
    "                            continue  # Try next strategy\n",
    "                    \n",
    "                    # Wait a bit for any dynamic content to load\n",
    "                    await page.wait_for_timeout(2000)\n",
    "                    \n",
    "                    # Get the content\n",
    "                    content = await page.content()\n",
    "                    \n",
    "                    await browser.close()\n",
    "                    print(f\"âœ… Successfully scraped with {config['name']}!\")\n",
    "                    return content\n",
    "                    \n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "                error_str = str(e)\n",
    "                \n",
    "                # Check if it's an HTTP2 error\n",
    "                is_http2_error = 'ERR_HTTP2_PROTOCOL_ERROR' in error_str or 'HTTP2' in error_str.upper()\n",
    "                \n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = (attempt + 1) * 2\n",
    "                    if is_http2_error:\n",
    "                        print(f\"âš ï¸  HTTP2 error on attempt {attempt + 1}. Retrying in {wait_time} seconds...\")\n",
    "                    else:\n",
    "                        print(f\"âš ï¸  Attempt {attempt + 1} failed: {error_str[:100]}... Retrying in {wait_time} seconds...\")\n",
    "                    await asyncio.sleep(wait_time)\n",
    "                else:\n",
    "                    print(f\"âŒ {config['name']} failed after {max_retries} attempts: {error_str[:150]}\")\n",
    "                    # Try next browser config\n",
    "                    break\n",
    "        \n",
    "        # If we got here and have content, return it (shouldn't happen, but safety check)\n",
    "        if 'content' in locals():\n",
    "            return content\n",
    "    \n",
    "    # All configurations failed\n",
    "    raise Exception(f\"Failed to scrape {url} after trying all browser configurations. Last error: {str(last_error)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97089786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test website scraping\n",
    "# If you're getting \"Access Denied\", uncomment the cookies and headers below\n",
    "\n",
    "url = \"https://www.bizbuysell.com/georgia/restaurants-and-food-businesses-for-sale\"\n",
    "\n",
    "# Option 1: Without cookies/headers (may work for some sites)\n",
    "html_content = await scrape_website(url)\n",
    "\n",
    "# Option 2: With cookies and headers from real browser (use if you get access denied)\n",
    "# html_content = await scrape_website(url, cookies=my_cookies, headers=my_headers)\n",
    "\n",
    "print(f\"âœ… Scraped {len(html_content)} characters of HTML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb8417-c5dc-44bc-9bee-2e059d162699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a business buying assistant that analyzes the contents of a website,\n",
    "and provides a list of the businesses for sale that includes business name, location, price, revenue, cashflow and best method to evaluate price of the business.\n",
    "Ignore text that might be navigation related.\n",
    "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0275b1b-7cfe-4f9d-abfa-7650d378da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our user prompt\n",
    "\n",
    "user_prompt_prefix = \"\"\"\n",
    "Here are the contents of a website.\n",
    "Provide a summary for every business listed.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134dfa4-8299-48b5-b444-f2a8c3403c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_prefix + website}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905b9919-aba7-45b5-ae65-81b3d1d78e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "async def summarize(url):\n",
    "    html_content = await scrape_website(url, cookies=my_cookies, headers=my_headers)\n",
    "    #Get only the text parts of the webpage\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    html_text = soup.get_text(separator=' ', strip=True)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4.1-nano\",\n",
    "        messages = messages_for(html_text)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d926d59-450e-4609-92ba-2d6f244f1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the output, using markdown\n",
    "\n",
    "async def display_summary(url):\n",
    "    summary = await summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3018853a-445f-41ff-9560-d925d1774b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "await display_summary(\"https://www.bizbuysell.com/georgia/restaurants-and-food-businesses-for-sale/?q=bHQ9MzAsNDAsODA%3D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4484fcf-8b39-4c3f-9674-37970ed71988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
