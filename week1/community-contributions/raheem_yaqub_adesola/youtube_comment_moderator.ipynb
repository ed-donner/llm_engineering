{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e50e9ac",
   "metadata": {},
   "source": [
    "# ðŸŽ¬ YouTube Comment Moderator AI\n",
    "\n",
    "## Tone Classification & Summary Workflow\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸš¦ Moderation Flow\n",
    "\n",
    "1ï¸âƒ£ **User enters YouTube link**\n",
    "\n",
    "2ï¸âƒ£ **System fetches video comments**\n",
    "\n",
    "3ï¸âƒ£ **AI classifies comments**\n",
    "   - Toxicity\n",
    "   - Spam\n",
    "   - Hate\n",
    "   - Positive\n",
    "   - Neutral\n",
    "\n",
    "4ï¸âƒ£ **AI summarizes overall sentiment & issues**\n",
    "   - Highlights dominant tones\n",
    "   - Flags problematic trends\n",
    "   - Provides actionable insights\n",
    "\n",
    "5ï¸âƒ£ **Show moderation report**\n",
    "   - Visual summary of tone distribution\n",
    "   - Key findings & recommendations\n",
    "\n",
    "---\n",
    "\n",
    "> **Example Output:**\n",
    ">\n",
    "> - **Tone Distribution:** ![Pie Chart Icon](https://img.icons8.com/color/48/000000/pie-chart.png)\n",
    "> - **Summary:** \"Most comments are positive, but 12% show signs of toxicity. Spam detected in 8%.\"\n",
    "> - **Recommendations:** \"Consider moderating toxic and spam comments. Overall sentiment is positive.\"\n",
    "\n",
    "---\n",
    "\n",
    "âœ¨ Use this workflow to generate other cells for each step, making your notebook interactive and visually appealing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59400dec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## STEP 1: Import Required Libraries\n",
    "\n",
    "Below are the libraries needed for the YouTube Comment Moderator AI, as listed in `requirements.txt`:\n",
    "\n",
    "- **google-api-python-client**: For accessing YouTube API and fetching comments\n",
    "- **pandas**: For data manipulation and analysis\n",
    "- **nltk**: For natural language processing and tone classification\n",
    "- **scikit-learn**: For machine learning models and sentiment analysis\n",
    "- **ollama**: For advanced AI and LLM integration\n",
    "\n",
    "> **Next:** Add a code cell to import these libraries and check their installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058cc737",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Import required libraries for YouTube Comment Moderator AI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import ollama  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd73d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=hhrE_SytfyY\"  # Example video URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013484e8",
   "metadata": {},
   "source": [
    "##  STEP 2: Extract Video ID from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6ee8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_video_id(video_url):\n",
    "    pattern = r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\"\n",
    "    match = re.search(pattern, video_url)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "video_id = get_video_id(video_url)\n",
    "video_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faba5f42",
   "metadata": {},
   "source": [
    "##  STEP 2: Fetch Comments from YouTube with your youtube API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92732e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "youtube_api_key = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "openrouter_api_key = os.getenv(\"OPEN_ROUTER_API_KEY\")\n",
    "\n",
    "if not youtube_api_key:\n",
    "    print(\"No API key was found - please be sure to add your key to the .env file, and save the file! Or you can skip the next 2 cells if you don't want to use Gemini\")\n",
    "elif not youtube_api_key.startswith(\"AIz\"):\n",
    "    print(\"An API key was found, but it doesn't start AIz\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n",
    "\n",
    "if not openrouter_api_key:\n",
    "    print(\"No API key was found - please be sure to add your key to the .env file, and save the file! Or you can skip the next 2 cells if you don't want to use Gemini\")\n",
    "elif not openrouter_api_key.startswith(\"sk-or-v1-\"):\n",
    "    print(\"An Open Router API key was found, but it doesn't start sk-or-v1-\")\n",
    "else:\n",
    "    print(\"An Open Router API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e88d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Build the YouTube API client using the API key\n",
    "youtube = build('youtube', 'v3', developerKey=youtube_api_key)\n",
    "\n",
    "def get_all_comments(video_id):\n",
    "    \"\"\"\n",
    "    Fetch all comments from a YouTube video using the YouTube Data API v3.\n",
    "    Handles pagination to ensure all comments are retrieved.\n",
    "    Args:\n",
    "        video_id (str): The ID of the YouTube video.\n",
    "    Returns:\n",
    "        list: A list of comment strings.\n",
    "    \"\"\"\n",
    "    comments = []\n",
    "    # Create the initial API request for comment threads\n",
    "    request = youtube.commentThreads().list(\n",
    "        part=\"snippet\",\n",
    "        videoId=video_id,\n",
    "        maxResults=100,  # Maximum allowed per page\n",
    "        textFormat=\"plainText\"\n",
    "    )\n",
    "    while request:\n",
    "        # Execute the API request\n",
    "        response = request.execute()\n",
    "        # Loop through each comment in the response\n",
    "        for item in response[\"items\"]:\n",
    "            comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "            comments.append(comment)\n",
    "        # Get the next page of results, if any\n",
    "        request = youtube.commentThreads().list_next(request, response)\n",
    "    return comments\n",
    "\n",
    "# Fetch all comments for the given video_id\n",
    "comments = get_all_comments(video_id)\n",
    "# Display the first 5 comments as a sample\n",
    "comments[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f08d57f",
   "metadata": {},
   "source": [
    "##  STEP 3: Classify Comments using Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90499b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(\n",
    "    api_key=openrouter_api_key,\n",
    "    base_url=\"https://openrouter.ai/api/v1\"\n",
    ")\n",
    "\n",
    "def classify_comment(comment):\n",
    "    user_prompt = f\"\"\"\n",
    "    Classify this YouTube comment into one category:\n",
    "\n",
    "    Categories:\n",
    "    - Positive\n",
    "    - Neutral\n",
    "    - Toxic\n",
    "    - Spam\n",
    "    - Hate Speech\n",
    "\n",
    "    Comment: {comment}\n",
    "\n",
    "    Return only the category name.\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"openai/gpt-4o-mini\",   # fast & cheap\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# test\n",
    "classify_comment(\"This video is amazing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae75fd0",
   "metadata": {},
   "source": [
    "## Step 4: Classify All Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for comment in comments:\n",
    "    label = classify_comment(comment)\n",
    "    results.append((comment, label))\n",
    "\n",
    "results[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a8d54b",
   "metadata": {},
   "source": [
    "## Step 5: Convert to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00d76c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\"Comment\", \"Category\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23856d34",
   "metadata": {},
   "source": [
    "## Step 6: Moderation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ada3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_counts = df[\"Category\"].value_counts()\n",
    "summary_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba7fc0a",
   "metadata": {},
   "source": [
    "## Step 7: AI Summary of Moderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(summary):\n",
    "    user_prompt = f\"\"\"\n",
    "    Summarize the moderation results:\n",
    "\n",
    "    {summary.to_dict()}\n",
    "\n",
    "    Explain the overall sentiment and moderation concerns.\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"openai/gpt-4o-mini\",   # fast & cheap\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "summarize_results(summary_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube_comment_moderator (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
