{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a8d5889",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask your technical question:\n",
      "\n",
      " What are the various cloud API keys for llm or close source Model and open source \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are several cloud APIs that offer Large Language Models (LLMs) with varying levels of access, costs, and licensing terms. Here's an overview of some popular cloud APIs for LLMs:\n",
      "\n",
      "**Closed-Source/Commercial Models:**\n",
      "\n",
      "1. **Google Cloud Natural Language API**: Requires a paid subscription to access its LLM capabilities.\n",
      "\t* API Key: Google Cloud Platform API key\n",
      "\t* Pricing: Varies based on usage and region costs (~$0.01 per character)\n",
      "2. **Amazon Textract**: Requires a paid subscription to access its LLM capabilities.\n",
      "\t* Access Token: AWS access token (not an API key)\n",
      "\t* Pricing: Varies based on usage and region costs (~$3 per million units processed)\n",
      "3. **IBM Watson Natural Language Understanding**: Requires a paid subscription to access its LLM capabilities.\n",
      "\t* API Key: IBM Cloud account credentials\n",
      "\t* Pricing: Varies based on usage and region costs (~$0.01 per character)\n",
      "\n",
      "**Open-Source Models (Free/Premium Fees):**\n",
      "\n",
      "1. **Transformers.io - Hugging Face Hub**: Offers a free tier with limited resources, as well as premium options for advanced users.\n",
      "\t* API Key: No explicit key required; use the library's built-in configuration\n",
      "\t* Pricing: Free tier limits character limit to 5 million (~ $20 per month); Premium plans available starting at ~ $100/month\n",
      "2. **BERT**: Based on Hugging Face's Transformer model, which can be used freely but requires attribution.\n",
      "\t* No API Key Required; no explicit fee for academic or personal use as long as you cite the authors\n",
      "3. **LLaMA - OpenAI**: Offers a self-hosted version of the large language model for free with some restrictions.\n",
      "\t* Access Token: Not an API key (use the library's built-in configuration)\n",
      "\t* Pricing: Free; restricted resource allocations (e.g., ~5 million character limit)\n",
      "\n",
      "**Hybrid Models (Open-Source/Limited Licensed Features):**\n",
      "\n",
      "1. **Microsoft Cognitive Services**: Offers a hybrid model combining open-source and commercial features.\n",
      "\t* API Key or Azure Subscription Required\n",
      "\t* Pricing: Commercial tiers with varying costs, while free tier limits are limited (~$15 per million units processed)\n",
      "\n",
      "**Important considerations**:\n",
      "\n",
      "* Licensing terms and conditions vary widely for each service. Some models might be subject to usage statistics tracking or may require attribution in published work.\n",
      "* Be sure to review pricing estimates, as these can change over time due to shifting resource costs.\n",
      "* Many APIs offer both free tiers with restricted usage limitations, along with paid plans that provide more resources and capabilities.\n",
      "\n",
      "Always verify the API documentation for up-to-date information on access keys, pricing, and licensing constraints before choosing a service.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "MODEL_LLAMA = \"llama3.2\"\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=OLLAMA_BASE_URL,\n",
    "    api_key=\"ollama\"\n",
    ")\n",
    "\n",
    "def ask_llama(question):\n",
    "    stream = client.chat.completions.create(\n",
    "        model=MODEL_LLAMA,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a technical Python expert.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    for chunk in stream:\n",
    "        delta = chunk.choices[0].delta.content\n",
    "        if delta:\n",
    "            print(delta, end=\"\", flush=True)\n",
    "\n",
    "    print()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    question = input(\"Ask your technical question:\\n\\n\")\n",
    "    ask_llama(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
