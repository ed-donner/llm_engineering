{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0751a167",
   "metadata": {},
   "source": [
    "Technical Question Explainer\n",
    "\n",
    "A tool that takes a technical question (or code snippet) and returns a structured explanation.  \n",
    "Supports **OpenAI** and **Ollama** (local models) â€” switchable from the Gradio UI.\n",
    "\n",
    "---\n",
    "### Setup\n",
    "```bash\n",
    "uv add openai gradio\n",
    "```\n",
    "For **Ollama**, make sure it's running locally and you've pulled a model:\n",
    "```bash\n",
    "ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4f5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b350f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_MODEL   = \"gpt-4o-mini\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fb518cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "OLLAMA_MODEL    = \"llama3.2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eaf2b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an expert technical educator.\n",
    "When given a technical question or code snippet, provide:\n",
    "1. A clear, concise explanation (2-3 sentences)\n",
    "2. A simple analogy to make it relatable\n",
    "3. A line-by-line or concept breakdown (especially for code)\n",
    "4. Key takeaways as bullet points\n",
    "\n",
    "Keep explanations accessible but accurate. Format your response in clean markdown.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cadc0bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25324701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client(provider: str) -> tuple[OpenAI, str]:\n",
    "    \"\"\"Return (OpenAI client, model name) for the chosen provider.\"\"\"\n",
    "    if provider == \"Ollama (Local)\":\n",
    "        client = OpenAI(\n",
    "            base_url=OLLAMA_BASE_URL,\n",
    "            api_key=\"ollama\",   \n",
    "        )\n",
    "        return client, OLLAMA_MODEL\n",
    "    else:\n",
    "        if not OPENAI_API_KEY :\n",
    "            raise ValueError(\"Please set OPENAI_API_KEY in the Configuration cell.\")\n",
    "        return OpenAI(api_key=OPENAI_API_KEY), OPENAI_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51a4cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_streaming(question: str, provider: str):\n",
    "    \"\"\"Gradio streaming generator â€” yields progressively longer markdown strings.\"\"\"\n",
    "    if not question.strip():\n",
    "        yield \"Please enter a question or code snippet.\"\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        client, model = get_client(provider)\n",
    "    except ValueError as e:\n",
    "        yield f\" **Error:** {e}\"\n",
    "        return\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\",   \"content\": question},\n",
    "    ]\n",
    "\n",
    "    accumulated = f\"*Using **{model}** via {provider}â€¦*\\n\\n---\\n\\n\"\n",
    "    try:\n",
    "        with client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            stream=True,\n",
    "        ) as stream:\n",
    "            for chunk in stream:\n",
    "                delta = chunk.choices[0].delta.content or \"\"\n",
    "                accumulated += delta\n",
    "                yield accumulated\n",
    "    except Exception as e:\n",
    "        yield f\"**API Error:** {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16cfe452",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_QUESTION = question.strip()\n",
    "\n",
    "with gr.Blocks(\n",
    "    title=\"Tech Explainer\",\n",
    "    theme=gr.themes.Base(\n",
    "        primary_hue=\"teal\",\n",
    "        neutral_hue=\"zinc\",\n",
    "        font=[gr.themes.GoogleFont(\"IBM Plex Mono\"), \"monospace\"],\n",
    "    ),\n",
    "    css=\"\"\"\n",
    "        #header { text-align:center; padding:1rem 0 0.25rem; }\n",
    "        #sub    { text-align:center; color:#71717a; margin-bottom:1.5rem; }\n",
    "        footer  { display:none !important; }\n",
    "    \"\"\",\n",
    ") as demo:\n",
    "\n",
    "    gr.Markdown(\"#Technical Question Explainer\", elem_id=\"header\")\n",
    "    gr.Markdown(\n",
    "        \"Paste any code snippet or technical question â€” get a structured explanation instantly.\",\n",
    "        elem_id=\"sub\",\n",
    "    )\n",
    "\n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column(scale=3):\n",
    "            question_box = gr.Textbox(\n",
    "                label=\"Question or Code Snippet\",\n",
    "                placeholder=\"Paste code or ask a technical questionâ€¦\",\n",
    "                lines=6,\n",
    "                value=EXAMPLE_QUESTION,\n",
    "            )\n",
    "            with gr.Row():\n",
    "                submit_btn = gr.Button(\"Explain\", variant=\"primary\", scale=4)\n",
    "                clear_btn  = gr.Button(\"Clear\",  variant=\"secondary\", scale=1)\n",
    "\n",
    "        with gr.Column(scale=1):\n",
    "            provider_radio = gr.Radio(\n",
    "                choices=[\"OpenAI (GPT-4o-mini)\", \"Ollama (Local)\"],\n",
    "                value=\"OpenAI (GPT-4o-mini)\",\n",
    "                label=\"Provider\",\n",
    "            )\n",
    "            gr.Markdown(\n",
    "                \"\"\"**OpenAI** â€” set `OPENAI_API_KEY` in cell 3.\\n\\n\"\"\"\n",
    "                \"\"\"**Ollama** â€” needs [Ollama](https://ollama.com) running locally.  \\n\"\"\"\n",
    "                \"\"\"`ollama pull llama3.2`\"\"\"\n",
    "            )\n",
    "\n",
    "    answer_box = gr.Markdown(\n",
    "        label=\"Explanation\",\n",
    "        value=\"*Your explanation will appear hereâ€¦*\",\n",
    "    )\n",
    "\n",
    "    gr.Examples(\n",
    "        examples=[\n",
    "            [EXAMPLE_QUESTION],\n",
    "            [\"What is the difference between a process and a thread?\"],\n",
    "            [\"Explain Python's GIL and when it actually matters.\"],\n",
    "            [\"What is gradient descent and how does backpropagation use it?\"],\n",
    "            [\"What does async/await do under the hood in Python?\"],\n",
    "            [\"Explain the CAP theorem in distributed systems.\"],\n",
    "        ],\n",
    "        inputs=question_box,\n",
    "        label=\"ðŸ’¡ Example Questions â€” click to load\",\n",
    "    )\n",
    "\n",
    "    submit_btn.click(explain_streaming, [question_box, provider_radio], answer_box)\n",
    "    question_box.submit(explain_streaming, [question_box, provider_radio], answer_box)\n",
    "    clear_btn.click(\n",
    "        lambda: (EXAMPLE_QUESTION, \"*Your explanation will appear hereâ€¦*\"),\n",
    "        outputs=[question_box, answer_box],\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e817c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35a9c6e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
