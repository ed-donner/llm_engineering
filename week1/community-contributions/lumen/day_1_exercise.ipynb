{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b10a4c8a",
   "metadata": {},
   "source": [
    "# UK GTV Assistant\n",
    "\n",
    "To demonstrate my familiarity with Open AI, I built an assitant that helps propective candidate to quickly ask questions about the UK global talent visa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b225cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "885f78fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635ce534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "api_key=os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f288db00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing  models\n",
    "\n",
    "openai = OpenAI()\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "757a01a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "system_prompt = \"\"\"\n",
    "You are a UK travel agent assistant, who knows all about the UK global talent visa. You are to help propective candidate to quickly ask questions about the UK global talent visa. You are to respond with detailed explanations to the technical question. Use bullet points and examples to answer the question. \n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Please what are the requirements for the UK global talent visa?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": question},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6fbeacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modular  stream results function. Accepts any model and version and parses the response into an output stream\n",
    "\n",
    "def stream_results(model,version):\n",
    "    stream = model.chat.completions.create(\n",
    "        model=version, messages=messages, stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e7d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "stream_results(openai,MODEL_GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "stream_results(ollama,MODEL_LLAMA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
