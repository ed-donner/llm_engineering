{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-markdown",
   "metadata": {},
   "source": [
    "# Homework - Week 1 Day 2: Resumidor de Websites com Ollama\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Usar um modelo open-source rodando localmente via **Ollama** para resumir o conteudo de um website em portugues brasileiro.\n",
    "\n",
    "## Como funciona\n",
    "\n",
    "1. **Scraping do website** - A funcao `fetch_website_contents` (do modulo `scraper.py`) faz uma requisicao HTTP ao site, extrai o texto do `<body>` removendo scripts, estilos e imagens, e retorna o titulo + conteudo truncado em 2.000 caracteres.\n",
    "\n",
    "2. **Ollama como backend local** - O Ollama expoe um endpoint compativel com a API da OpenAI em `http://localhost:11434/v1`. Isso permite usar o pacote `openai` do Python como client, apenas apontando o `base_url` para o servidor local. Nenhum dado sai da sua maquina.\n",
    "\n",
    "3. **Prompts em PT-BR** - O system prompt instrui o modelo a responder em portugues brasileiro, com um tom sarcastico e humoristico. O user prompt envia o conteudo extraido do site e pede um resumo.\n",
    "\n",
    "4. **Exibicao em Markdown** - A resposta do modelo e renderizada diretamente como Markdown no notebook.\n",
    "\n",
    "## Pre-requisitos\n",
    "\n",
    "- Ollama instalado e rodando (`ollama serve`)\n",
    "- Modelo baixado (ex: `ollama pull phi3` ou `ollama pull llama3.2`)\n",
    "- Pacotes Python: `openai`, `beautifulsoup4`, `requests`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "setup-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente Ollama configurado com modelo: phi3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from scraper import fetch_website_contents\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "MODEL = \"phi3\"\n",
    "\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\"ollama\")\n",
    "print(f\"Cliente Ollama configurado com modelo: {MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "summarizer-cell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Visit esse site e você vai perceber que ele faz uma mistura entre informações sobre Anthropic - um conglomerado AI ambicioso em transparência, política de responsabilidade crescente do tamanho da moldulação para adicionar fatores sociais na tomada de decisões automatizadas, e modelos únicos. O site parece ser mais uma plataforma democrática onde as pessoas podem se juntar ao debate sobre como a AI afetará o mundo - especialmente no trabalho profissional para coder e em sistemas políticas comuns que reflitam seus valores básicos. Ele também parece ser uma página de marketing, oferecendo serviços incompletos como Claude Code ou a possibilidade de comprar ativamente um modelo sem conhecer a verdadeira utilização e implicações por trás disso...\n",
       "\n",
       "Notícias: Aqui chegamos ao final da seção \"Recent news\" do site, em que parece haver apenas uma pequena notícia sobre o desenvolvimento de um jogo chamado Four Hundred Meters no Marte - possivelmente indicando como a visão desses profissionais dá primazia ao futuro e à exploração espacial.\n",
       "\n",
       "Ofertas: O site apresenta Claude Code, que é uma \"abrangente plataforma de codificação única desenvolvida por [Theseus AI], para permitir a integração de processos humanos em IA atuar como co-profissionais.\" Eles também oferecem um recurso chamado Try Claude, na esperança que você se envolva e experimente as conversões ao lado deles.\n",
       "\n",
       "Sites relacionados parecem ter uma agenda similar: elogiam a Anthropic por seu compromisso com o futuro (embora talvez não esteja dando muita atenção para como essa promessa pode se concretizar), mas em vez de oferecer transparência, apresentam sugestões ambíguas sobre política e economia futuras.\n",
       "\n",
       "O que você precisa saber antes mesmo disso? Eles fazem campanha pela adoção da Claude Consola por \"programadores profissionais\"? Há uma versão dela para crianças do site, a ser lançada em 5 de fevereiro ao lado das atualizações na Anthropic blogue e anúncio? E não é tudo que este sobe - há sugestões sobre transparência. Ou seja, você pode enviar \"um email para o Claude Trust Center\" se precisar saber mais dos 40 por centos de recursos alocados no modelo em pesquisa acadêmica e social da Anthropic?\n",
       "\n",
       "Em suma: parece uma grande marca com promessas ambiciosas, mas pouca informação real para ajudá-lo a tomar decisões bem calculadas sobre como se envolver nisso. Mas você pode sempre entrar em contato diretamente com Clai"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "Voce e um assistente sarcastico que analisa o conteudo de um website\n",
    "e fornece um resumo curto, sarcastico e bem-humorado, ignorando texto de navegacao.\n",
    "Responda sempre em portugues brasileiro.\n",
    "Responda em markdown. Nao coloque o markdown dentro de um bloco de codigo - responda direto com o markdown.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_prefix = \"\"\"\n",
    "Aqui esta o conteudo de um website.\n",
    "Faca um resumo curto deste site.\n",
    "Se houver noticias ou anuncios, resuma-os tambem.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_prefix + website}\n",
    "    ]\n",
    "\n",
    "\n",
    "def summarize(url):\n",
    "    website = fetch_website_contents(url)\n",
    "    response = ollama.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))\n",
    "\n",
    "\n",
    "display_summary(\"https://anthropic.com\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
