{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "5c11defd",
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "from helpers import get_client_and_model, generate_tts, get_system_prompt\n",
        "import warnings\n",
        "\n",
        "TOOL_SUPPORTED_MODELS = {\"GPT\", \"Claude\", \"Gemini\"}\n",
        "\n",
        "def supports_tools(model_choice):\n",
        "    return model_choice in TOOL_SUPPORTED_MODELS\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"gradio\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e7cd4a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install ddgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "ba829a7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"search_web\",\n",
        "            \"description\": \"Search the web for current information on a topic\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"query\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The search query\"\n",
        "                    },\n",
        "                    \"num_results\": {\n",
        "                        \"type\": \"integer\",\n",
        "                        \"description\": \"Number of results to return (default 3)\",\n",
        "                        \"default\": 3\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"query\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "8423e728",
      "metadata": {},
      "outputs": [],
      "source": [
        "from ddgs import DDGS\n",
        "\n",
        "def search_web(query: str, num_results: int = 3) -> dict:\n",
        "    print(\"searching web with query: \", query)\n",
        "    results = []\n",
        "    with DDGS() as ddgs:\n",
        "        for r in ddgs.text(query, max_results=num_results):\n",
        "            results.append({\n",
        "                \"title\": r[\"title\"],\n",
        "                \"url\": r[\"href\"],\n",
        "                \"snippet\": r[\"body\"]\n",
        "            })\n",
        "    return {\"query\": query, \"results\": results}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a921e8e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def handle_function_calls(tool_calls, messages):\n",
        "    for tool_call in tool_calls:\n",
        "        function_name = tool_call.function.name\n",
        "        arguments = json.loads(tool_call.function.arguments)\n",
        "\n",
        "        if function_name == \"search_web\":\n",
        "            query = arguments.get(\"query\", \"\")\n",
        "            num_results = arguments.get(\"num_results\", 3)\n",
        "            result = search_web(query, num_results)\n",
        "            messages.append({\n",
        "                \"role\": \"tool\",\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"content\": json.dumps(result)\n",
        "            })\n",
        "        else:\n",
        "            messages.append({\n",
        "                \"role\": \"tool\",\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"content\": \"Function not implemented.\"\n",
        "            })\n",
        "    return messages\n",
        "\n",
        "def build_assistant_tool_message(reply, tool_calls):\n",
        "    return {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": reply or None,\n",
        "        \"tool_calls\": [\n",
        "            {\n",
        "                \"id\": tc.id,\n",
        "                \"type\": \"function\",\n",
        "                \"function\": {\n",
        "                    \"name\": tc.function.name,\n",
        "                    \"arguments\": tc.function.arguments,\n",
        "                },\n",
        "            }\n",
        "            for tc in tool_calls\n",
        "        ],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "654a0a31",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _stream_reply(response, tool_calls_out=None):\n",
        "    \"\"\"Yield cumulative reply text, optionally collecting tool calls into tool_calls_out dict.\"\"\"\n",
        "    reply = \"\"\n",
        "    for chunk in response:\n",
        "        delta = chunk.choices[0].delta\n",
        "        if delta.content:\n",
        "            reply += delta.content\n",
        "            yield reply\n",
        "        if tool_calls_out is not None and delta.tool_calls:\n",
        "            for tc in delta.tool_calls:\n",
        "                if tc.index not in tool_calls_out:\n",
        "                    tool_calls_out[tc.index] = tc\n",
        "                else:\n",
        "                    tool_calls_out[tc.index].function.arguments += tc.function.arguments\n",
        "\n",
        "\n",
        "def chat_stream(history, model_choice):\n",
        "    messages = [{\"role\": \"system\", \"content\": get_system_prompt()}]\n",
        "    messages += [\n",
        "        {\"role\": h[\"role\"], \"content\": h[\"content\"]}\n",
        "        for h in history if isinstance(h.get(\"content\"), str)\n",
        "    ]\n",
        "\n",
        "    client, model = get_client_and_model(model_choice)\n",
        "    use_tools = supports_tools(model_choice)\n",
        "\n",
        "    kwargs = dict(model=model, messages=messages, stream=True)\n",
        "    if use_tools:\n",
        "        kwargs[\"tools\"] = tools\n",
        "\n",
        "    tool_calls = {} if use_tools else None\n",
        "    reply = \"\"\n",
        "    for reply in _stream_reply(client.chat.completions.create(**kwargs), tool_calls):\n",
        "        history.append({\"role\": \"assistant\", \"content\": reply})\n",
        "        yield history, None\n",
        "        history.pop()\n",
        "\n",
        "    if tool_calls:\n",
        "        collected = list(tool_calls.values())\n",
        "        messages.append(build_assistant_tool_message(reply, collected))\n",
        "        handle_function_calls(collected, messages)\n",
        "\n",
        "        reply = \"\"\n",
        "        for reply in _stream_reply(client.chat.completions.create(model=model, messages=messages, stream=True)):\n",
        "            history.append({\"role\": \"assistant\", \"content\": reply})\n",
        "            yield history, None\n",
        "            history.pop()\n",
        "\n",
        "    history.append({\"role\": \"assistant\", \"content\": reply})\n",
        "    yield history, generate_tts(reply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "5e15cffc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_audio_input(audio_filepath, history, model_choice):\n",
        "    if audio_filepath is None:\n",
        "        return\n",
        "\n",
        "    history.append({\"role\": \"user\", \"content\": gr.Audio(audio_filepath)})\n",
        "\n",
        "    with open(audio_filepath, \"rb\") as f:\n",
        "        transcription = openai.audio.transcriptions.create(model=\"whisper-1\", file=f)\n",
        "\n",
        "    history.append({\"role\": \"user\", \"content\": transcription.text})\n",
        "    yield history, None, None\n",
        "\n",
        "    for updated_history, tts_audio in chat_stream(history, model_choice):\n",
        "        yield updated_history, None, tts_audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1bc2615f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_text_input(message, history, model_choice):\n",
        "    if not message.strip():\n",
        "        return \n",
        "    history.append({\"role\": \"user\", \"content\": message})\n",
        "    for updated_history, tts_audio in chat_stream(history, model_choice):\n",
        "        yield \"\", updated_history, tts_audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "02af01c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "with gr.Blocks(title=\"Technical Q&A Assistant\") as ui:\n",
        "    gr.Markdown(\"# Technical Q&A Assistant\")\n",
        "\n",
        "    with gr.Row():\n",
        "        # for gradio version < 6\n",
        "        # chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
        "        chatbot = gr.Chatbot(height=500)\n",
        "\n",
        "    with gr.Row():\n",
        "        message = gr.Textbox(label=\"Chat with our AI Assistant:\", scale=4)\n",
        "        audio_input = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Voice Input\", scale=1)\n",
        "    \n",
        "    with gr.Row():\n",
        "        audio_output = gr.Audio(label=\"Response Audio\", autoplay=True)\n",
        "\n",
        "    with gr.Row():\n",
        "        model_selector = gr.Dropdown(\n",
        "            choices=[\"GPT\", \"Claude\", \"Gemini\", \"Llama\"],\n",
        "            value=\"GPT\",\n",
        "            label=\"Select Model\",\n",
        "            scale=1,\n",
        "        )\n",
        "        clear = gr.Button(\"Clear\", scale=1)\n",
        "    \n",
        "    message.submit(\n",
        "        process_text_input,\n",
        "        inputs=[message, chatbot, model_selector],\n",
        "        outputs=[message, chatbot, audio_output],\n",
        "    )\n",
        "\n",
        "    audio_input.stop_recording(\n",
        "        process_audio_input,\n",
        "        inputs=[audio_input, chatbot, model_selector],\n",
        "        outputs=[chatbot, audio_input, audio_output],\n",
        "    )\n",
        "\n",
        "    clear.click(lambda: ([], None, None, \"\"), outputs=[chatbot, audio_output, audio_input, message])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ef57d70",
      "metadata": {},
      "outputs": [],
      "source": [
        "ui.launch(inbrowser=True, auth=(\"mrpeski\", \"mrpeski\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8757d12b",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
