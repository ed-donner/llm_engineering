{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from textwrap import indent\n",
    "import nbformat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'gemma3'\n",
    "api = '123...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d51545",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert code reviewer. \n",
    "you are provided with the python or python notebook files. \n",
    "you will review the code and suggest the areas where the code can be made more efficient.\n",
    "you will also review the industry best practises for the code suggest any new edits to be incorporated for the efficient code \n",
    "you will also check for any comments and suggest if there is any improvement. check for any hardcoded values like passwords, or api keys and flag it\n",
    "only the files with extension .py or .ipynb will be considered ignore the rest.\n",
    "you will respond the output in the Markdown format for example: \n",
    "## test.py\n",
    "- please explain what this function def func does\n",
    "- Please dont hard code any passwords\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8743fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_code_fron_ipynb(filePath):\n",
    "    with open(filePath,'r',encoding=\"utf-8\") as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    return \"\\n\\n\".join([c.source for c in nb.cells if c.cell_type=='code'])\n",
    "\n",
    "def get_file_content(filePath):\n",
    "    suffix = Path(filePath).suffix\n",
    "\n",
    "    if suffix == '.py':\n",
    "        return Path(filePath).read_text\n",
    "    elif suffix == '.ipynb':\n",
    "        return extract_code_fron_ipynb(filePath)\n",
    "\n",
    "def get_list_files(filePath):\n",
    "    path = Path(filePath)\n",
    "    files = {\n",
    "        f.name: get_file_content(str(path / f.name)) for f in path.iterdir() if f.suffix in ['.py','.ipynb']\n",
    "    }\n",
    "    return files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = '/Users/mia/myprojects/uv_projects/llm_engineering/week1'\n",
    "filesList = get_list_files(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = f\"\"\"\n",
    "Please explain what this code does and why:\n",
    "the name and code is listed as below json file \n",
    "{filesList}\n",
    "\"\"\"\n",
    "\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5488b92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "openai = OpenAI()\n",
    "stream = openai.chat.completions.create(\n",
    "    model=MODEL_GPT,\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    response += chunk.choices[0].delta.content or ''\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "llama=OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "llama_stream = llama.chat.completions.create(\n",
    "    model=MODEL_LLAMA,\n",
    "    messages=messages\n",
    ")\n",
    "response = llama_stream.choices[0].message.content\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
