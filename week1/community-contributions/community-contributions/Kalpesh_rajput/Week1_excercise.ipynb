{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a868a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "from IPython.display import display, Markdown, update_display\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Load environment variables\n",
    "# --------------------------------------------------\n",
    "load_dotenv()\n",
    "\n",
    "# Make sure GROQ_API_KEY is set\n",
    "if not os.getenv(\"GROQ_API_KEY\"):\n",
    "    raise ValueError(\"‚ùå GROQ_API_KEY not found in environment variables\")\n",
    "\n",
    "# Initialize Groq client\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "# --------------------------------------------------\n",
    "# System Prompt\n",
    "# --------------------------------------------------\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful, professional coding assistant and technical mentor.\n",
    "\n",
    "IMPORTANT:\n",
    "- Always connect new answers to topics discussed earlier in the conversation.\n",
    "- Build upon previously explained concepts and reuse terminology already introduced.\n",
    "- When a new concept appears, relate it to prior knowledge whenever possible.\n",
    "\n",
    "The user will provide source code. Your responsibilities are:\n",
    "1. Carefully read and fully understand the provided code.\n",
    "2. Explain the code line by line using clear, beginner-friendly language.\n",
    "3. Identify bugs, logical issues, or bad practices.\n",
    "4. Provide corrected code when issues are found.\n",
    "5. Suggest improvements for readability, modularity, and maintainability.\n",
    "6. Follow industry best practices and explain WHY changes are useful.\n",
    "\n",
    "Guidelines:\n",
    "- Be precise and structured.\n",
    "- Use clean formatting and code blocks.\n",
    "- Prioritize learning over verbosity.\n",
    "\"\"\"\n",
    "\n",
    "# --------------------------------------------------\n",
    "# State\n",
    "# --------------------------------------------------\n",
    "conversation_history = []\n",
    "question_count = 0\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Welcome Message\n",
    "# --------------------------------------------------\n",
    "print(\"üöÄ Welcome to your AI Code Assistant!\")\n",
    "print(\"üìå Paste code, ask questions, and improve step by step.\")\n",
    "print(\"‚ùå Type 'quit', 'bye', or 'exit' anytime to leave.\\n\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Main Loop\n",
    "# --------------------------------------------------\n",
    "while True:\n",
    "\n",
    "    # Input handling\n",
    "    if question_count == 0:\n",
    "        user_input = input(\"üìÑ Please copy-paste your code here:\\n\")\n",
    "    else:\n",
    "        user_input = input(f\"\\n‚ùì Question {question_count + 1}: What do you want to do next?\\n\")\n",
    "\n",
    "    # Exit condition\n",
    "    if user_input.lower() in [\"quit\", \"bye\", \"exit\"]:\n",
    "        print(\"\\nüëã Thanks for using the AI Code Assistant. Happy coding!\")\n",
    "        break\n",
    "\n",
    "    # Empty input check\n",
    "    if not user_input.strip():\n",
    "        print(\"‚ö†Ô∏è Please enter something.\")\n",
    "        continue\n",
    "\n",
    "    # Store user message\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "    question_count += 1\n",
    "\n",
    "    print(f\"\\nüß† Thinking about:\\n{user_input}\\n\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Groq Streaming Call\n",
    "    # --------------------------------------------------\n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b-instant\",   # ‚úÖ FREE & BEST for coding\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt}\n",
    "        ] + conversation_history,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    # Display streaming response\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "\n",
    "    for chunk in stream:\n",
    "        delta = chunk.choices[0].delta.content\n",
    "        if delta:\n",
    "            response += delta\n",
    "            update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "\n",
    "    # Save assistant response\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": response})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
