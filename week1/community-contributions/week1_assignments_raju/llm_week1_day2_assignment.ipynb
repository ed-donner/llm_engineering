{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP28hiSS2yl50tIGn9jltqy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajuDasa/llm_engineering/blob/day2_branch/week1/community-contributions/week1_assignments_raju/llm_week1_day2_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment:** summarize a webpage using Ollama and openAI library."
      ],
      "metadata": {
        "id": "SF7ix_1tCN74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "id": "sVqhk-gW07yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Ollama server\n",
        "\n",
        "import subprocess\n",
        "\n",
        "# Start the command in a background process\n",
        "process = subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "# The kernel can continue execution while the process runs in the background\n",
        "print(\"The 'ollama serve' process is running in the background.\")"
      ],
      "metadata": {
        "id": "_j3vwuDHDwxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download llama model\n",
        "!ollama pull llama3.2"
      ],
      "metadata": {
        "id": "ymcJjC9Z1c9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test server\n",
        "import requests\n",
        "\n",
        "requests.get(\"http://localhost:11434\").content"
      ],
      "metadata": {
        "id": "jOt2ZQHb3gUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install OpenAI\n",
        "!pip install beautifulsoup4\n",
        "#already installed"
      ],
      "metadata": {
        "id": "-l67vOX13VWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test with library\n",
        "\n",
        "# from openai import OpenAI\n",
        "\n",
        "# OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
        "\n",
        "# ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
        "# response = ollama.chat.completions.create(model=\"llama3.2\", messages=[{\"role\": \"user\", \"content\": \"Tell me a fun fact\"}])\n",
        "# display(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "sJbN7xE01_KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scraping logic:\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "\n",
        "# Standard headers to fetch a website\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "\n",
        "def fetch_website_contents(url):\n",
        "    \"\"\"\n",
        "    Return the title and contents of the website at the given url;\n",
        "    truncate to 2,000 characters as a sensible limit\n",
        "    \"\"\"\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    title = soup.title.string if soup.title else \"No title found\"\n",
        "    if soup.body:\n",
        "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
        "            irrelevant.decompose()\n",
        "        text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
        "    else:\n",
        "        text = \"\"\n",
        "    return (title + \"\\n\\n\" + text)[:2_000]\n"
      ],
      "metadata": {
        "id": "JijzwoT-6nXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now get summary of a website using our model\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "You are a helpful assistant that analyzes the contents of a website,\n",
        "and provides a short, humorous summary, ignoring text that might be navigation related.\n",
        "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
        "\"\"\"\n",
        "\n",
        "user_prompt_prefix = \"\"\"\n",
        "Here are the contents of a website.\n",
        "Provide a short summary of this website.\n",
        "If it includes news or announcements, then summarize these too.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def messages_for(website):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt_prefix + website}\n",
        "    ]\n",
        "\n",
        "def summarize(url):\n",
        "    website = fetch_website_contents(url)\n",
        "    response = ollama.chat.completions.create(\n",
        "        model = \"llama3.2\",\n",
        "        messages = messages_for(website)\n",
        "    )\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "ezTRpcys85au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "def display_summary(url):\n",
        "    summary = summarize(url)\n",
        "    display(Markdown(summary))\n",
        "\n",
        "display_summary(\"https://edwarddonner.com\")\n"
      ],
      "metadata": {
        "id": "b1H8A3WE-MVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Took 2mins to execute and returned only 330 char summary without humor."
      ],
      "metadata": {
        "id": "fw4_0aQnA27e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fetch_website_contents(\"https://edwarddonner.com\") #2000 char"
      ],
      "metadata": {
        "id": "rZ4iyzgABHd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stop ollama server\n",
        "process.kill()"
      ],
      "metadata": {
        "id": "XjJbKYbJBM0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NaC7RywhBszH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}