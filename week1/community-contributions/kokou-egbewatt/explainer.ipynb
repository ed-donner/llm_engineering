{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of Week 1 Exercise: Technical Q&A Tool\n",
    "\n",
    "This notebook demonstrates your familiarity with both the OpenAI API and Ollama by building a tool that answers technical questions with clear explanations. You can use this tool throughout the course to get help with technical concepts.\n",
    "\n",
    "## Instructions\n",
    "- The notebook is fully documented for clarity and reproducibility.\n",
    "- You can ask any technical question in the input cell below.\n",
    "- The tool will respond using either OpenAI or Ollama, depending on your selection.\n",
    "- Make sure you have API keys and/or Ollama installed and running locally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import json\n",
    "from typing import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-or-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-or-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "question = \"\"\"\n",
    "How does transfer learning improve the performance of deep neural networks in domains with limited labeled data?\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer learning improves the performance of deep neural networks in domains with limited labeled data by leveraging knowledge gained from pretrained models on larger, related datasets. Hereâ€™s how it works:\n",
      "\n",
      "1. **Pretraining**: A deep learning model is first trained on a large dataset (often on a general task). During this phase, the model learns to capture general features and representations from the data.\n",
      "\n",
      "2. **Feature Extraction**: The pretrained model can serve as a feature extractor. When applied to a new task with limited labeled data, the model can utilize the learned features rather than starting from scratch. This allows it to make better predictions even when the new dataset is small.\n",
      "\n",
      "3. **Fine-tuning**: The pretrained model can be further fine-tuned on the new dataset. This involves training the model for a few more epochs on the limited data, allowing it to adjust its weights while still retaining the knowledge from the original training. Fine-tuning helps the model adapt to specific characteristics of the new task.\n",
      "\n",
      "4. **Reduced Overfitting**: By starting with a model that has already learned relevant features, transfer learning can reduce the risk of overfitting common in scenarios with limited data. The model's complexity is tempered by the pretrained weights.\n",
      "\n",
      "5. **Faster Training**: Since the model has already learned significant patterns, transfer learning often leads to faster convergence during training, allowing for quicker model iteration and deployment.\n",
      "\n",
      "In summary, transfer learning allows models to leverage existing knowledge from larger datasets to improve learning efficiency and accuracy in new tasks with scarce labeled data, resulting in better performance overall.\n"
     ]
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "# The prompt is concise and focused on technical explanation\n",
    "\n",
    "def stream_gpt4o_answer(question: str, api_key: str) -> Generator[str, None, None]:\n",
    "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": MODEL_GPT,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert technical explainer. Respond with a clear, concise, and accurate explanation to the user's technical question.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        \"stream\": True\n",
    "    }\n",
    "    with requests.post(url, headers=headers, data=json.dumps(data), stream=True) as resp:\n",
    "        for line in resp.iter_lines():\n",
    "            if line:\n",
    "                try:\n",
    "                    # OpenRouter streams lines starting with 'data: '\n",
    "                    if line.startswith(b'data: '):\n",
    "                        payload = line[6:]\n",
    "                        if payload.strip() == b\"[DONE]\":\n",
    "                            break\n",
    "                        chunk = json.loads(payload)\n",
    "                        content = chunk.get('choices', [{}])[0].get('delta', {}).get('content')\n",
    "                        if content:\n",
    "                            yield content\n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing stream: {e}\")\n",
    "answer_stream = stream_gpt4o_answer(question, api_key)\n",
    "print(''.join(answer_stream))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer learning is a machine learning technique that allows pre-trained models to be fine-tuned on new, but possibly limited datasets. By leveraging knowledge acquired from one task (source domain) and adapting it to another task (target domain), transfer learning can significantly improve the performance of deep neural networks in domains with limited labeled data.\n",
      "\n",
      "Here's how transfer learning works:\n",
      "\n",
      "1. **Pre-training**: A pre-trained model is trained on a large, diverse dataset in the source domain. This process allows the model to learn general features and representations that are applicable across multiple tasks.\n",
      "2. **Fine-tuning**: The pre-trained model is then fine-tuned on a smaller, target dataset in the target domain. During this phase, the model's weights are updated based on the new data, allowing it to adapt to the specific task at hand.\n",
      "\n",
      "Transfer learning improves performance in domains with limited labeled data by:\n",
      "\n",
      "* **Reducing overfitting**: Fine-tuning reduces the risk of overfitting, which occurs when a model becomes too specialized to the training data and fails to generalize well to unseen examples.\n",
      "* **Capturing domain-agnostic features**: The pre-trained model has already learned general features that are applicable across multiple tasks, reducing the need for a large target dataset.\n",
      "* **Focusing on task-specific knowledge**: Fine-tuning enables the model to focus on acquiring task-specific knowledge from the limited target data.\n",
      "\n",
      "Some popular techniques used in transfer learning include:\n",
      "\n",
      "* **Domain adaptation**: Adapting pre-trained models to new domains by adjusting the model's weights and regularization parameters.\n",
      "* **Feature extraction**: Using pre-trained models as feature extractors for downstream tasks, where the goal is not to fine-tune the entire model but rather to utilize its learned features.\n",
      "\n",
      "In summary, transfer learning is a powerful technique that enables deep neural networks to perform well on limited datasets by leveraging knowledge from pre-training and adapting it to new domains.\n"
     ]
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "# The prompt is concise and focused on technical explanation\n",
    "\n",
    "def stream_llama_answer(question: str, api_key: str) -> Generator[str, None, None]:\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    # Ollama expects a single prompt string, not messages\n",
    "    prompt = f\"You are an expert technical explainer. Respond with a clear, concise, and accurate explanation to the user's technical question.\\n{question}\"\n",
    "    data = {\n",
    "        \"model\": MODEL_LLAMA,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": True\n",
    "    }\n",
    "    with requests.post(url, headers=headers, data=json.dumps(data), stream=True) as resp:\n",
    "        for line in resp.iter_lines():\n",
    "            if line:\n",
    "                try:\n",
    "                    chunk = json.loads(line)\n",
    "                    content = chunk.get('response', '')\n",
    "                    if content:\n",
    "                        yield content\n",
    "                    if chunk.get('done', False):\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing stream: {e}\")\n",
    "llama_answer_stream = stream_llama_answer(question, \"ollama\")\n",
    "print(''.join(llama_answer_stream))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8805bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMConversation:\n",
    "    def __init__(self, api_key: str, top_k: int = 20, top_p: float = 0.9):\n",
    "        self.api_key = api_key\n",
    "        self.history = []\n",
    "        self.models = {\n",
    "            \"gpt\": MODEL_GPT,\n",
    "            \"llama\": MODEL_LLAMA\n",
    "        }\n",
    "        self.top_k = top_k\n",
    "        self.top_p = top_p\n",
    "\n",
    "    def stream_answer(self, model: str, context: str) -> str:\n",
    "        output = \"\"\n",
    "        if model == \"gpt\":\n",
    "            url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "            messages = [{\"role\": \"system\", \"content\": \"You are a helpful technical explainer.\"}]\n",
    "            messages += [{\"role\": \"user\", \"content\": context}]\n",
    "            data = {\n",
    "                \"model\": self.models[model],\n",
    "                \"messages\": messages,\n",
    "                \"stream\": True,\n",
    "                \"top_p\": self.top_p,\n",
    "                \"max_tokens\": 150\n",
    "            }\n",
    "            print(f\"{model}: \")\n",
    "            with requests.post(url, headers=headers, data=json.dumps(data), stream=True) as resp:\n",
    "                for line in resp.iter_lines():\n",
    "                    if line and line.startswith(b'data: '):\n",
    "                        payload = line[6:]\n",
    "                        if payload.strip() == b\"[DONE]\":\n",
    "                            break\n",
    "                        chunk = json.loads(payload)\n",
    "                        content = chunk.get('choices', [{}])[0].get('delta', {}).get('content')\n",
    "                        if content:\n",
    "                            print(content, end='', flush=True)\n",
    "                            output += content\n",
    "            print()\n",
    "        elif model == \"llama\":\n",
    "            url = \"http://localhost:11434/api/generate\"\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "            prompt = f\"You are a helpful technical explainer.\\n{context}\"\n",
    "            data = {\n",
    "                \"model\": self.models[model],\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": True,\n",
    "                \"top_k\": self.top_k,\n",
    "                \"top_p\": self.top_p,\n",
    "                \"max_tokens\": 150\n",
    "            }\n",
    "            print(f\"{model}: \")\n",
    "            with requests.post(url, headers=headers, data=json.dumps(data), stream=True) as resp:\n",
    "                for line in resp.iter_lines():\n",
    "                    if line:\n",
    "                        try:\n",
    "                            chunk = json.loads(line)\n",
    "                            content = chunk.get('response', '')\n",
    "                            if content:\n",
    "                                print(content, end='', flush=True)\n",
    "                                output += content\n",
    "                            if chunk.get('done', False):\n",
    "                                break\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error parsing stream: {e}\")\n",
    "            print()\n",
    "        return output\n",
    "\n",
    "    def converse(self, topic: str, turns: int = 4, start_with: str = \"gpt\"):\n",
    "        if not self.history:\n",
    "            self.history = [topic]\n",
    "        current = start_with\n",
    "        for i in range(turns):\n",
    "            context = \"\\n\".join(self.history)\n",
    "            print(f\"\\n--- {current.upper()} turn ---\")\n",
    "            answer = self.stream_answer(current, context)\n",
    "            self.history.append(answer)\n",
    "            current = \"llama\" if current == \"gpt\" else \"gpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b03b5e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GPT turn ---\n",
      "gpt: \n",
      "The impact of AI and intelligent agents on software engineering is profound and multifaceted, influencing various stages of the software development lifecycle (SDLC) and transforming traditional practices. Here are some of the key effects:\n",
      "\n",
      "### 1. **Automation of Repetitive Tasks**\n",
      "   - **Code Generation**: AI tools like GitHub Copilot and OpenAI Codex can assist developers by generating code snippets or even entire functions based on natural language prompts. This reduces the time spent on boilerplate code and speeds up development.\n",
      "   - **Testing and Debugging**: AI can automate testing processes, identifying bugs and vulnerabilities more efficiently than manual testing. Tools like Selenium can be enhanced with AI to improve test coverage and accuracy.\n",
      "\n",
      "### 2. **Enhanced Software\n",
      "\n",
      "--- LLAMA turn ---\n",
      "llama: \n",
      "### 2. **Enhanced Software Development**\n",
      "\n",
      "   - **Feature Engineering and Design**: AI agents can assist in feature engineering by suggesting new features based on data analysis, user behavior patterns, and market trends.\n",
      "   - **Code Review and Pair Programming**: AI-powered tools can analyze code reviews, providing suggestions for improvement and suggesting potential bugs or security vulnerabilities. In pair programming, AI agents can offer real-time guidance to developers, facilitating collaboration and reducing errors.\n",
      "\n",
      "### 3. **Increased Productivity**\n",
      "\n",
      "   - **Predictive Analytics and Planning**: AI-driven predictive analytics can help identify trends, forecast demand, and optimize resource allocation, enabling development teams to plan more efficiently.\n",
      "   - **Personalized Development Tools**: AI-based tools can adapt to individual developers' workflows, providing personalized recommendations for improvement and suggesting relevant features or tutorials based on usage patterns.\n",
      "\n",
      "### 4. **Improved Quality Assurance**\n",
      "\n",
      "   - **Automated Code Analysis**: AI-powered code analysis tools can detect security vulnerabilities, adherence to coding standards, and potential performance issues, allowing for proactive bug fixing.\n",
      "   - **Continuous Integration and Delivery**: AI-driven CI/CD pipelines can optimize the deployment process, predicting and preventing failures, reducing downtime, and improving overall application quality.\n",
      "\n",
      "### 5. **Shift in Roles and Responsibilities**\n",
      "\n",
      "   - **Human-AI Collaboration**: As AI assumes more routine tasks, developers will focus on higher-level tasks such as strategy, design, and innovation.\n",
      "   - **Emergence of New Job Roles**: The integration of AI in software engineering gives rise to new job roles, including AI trainers, data scientists, and expert users.\n",
      "\n",
      "### 6. **Data-Driven Decision Making**\n",
      "\n",
      "   - **Real-Time Data Analysis**: AI-powered analytics tools provide real-time insights into application performance, user behavior, and market trends.\n",
      "   - **Predictive Modeling and Forecasting**: AI-driven predictive models enable developers to forecast demand, predict potential issues, and optimize resource allocation.\n",
      "\n",
      "By embracing AI and intelligent agents in software engineering, developers can transform the development process, improving productivity, quality, and innovation while redefining traditional roles and responsibilities.\n",
      "\n",
      "--- GPT turn ---\n",
      "gpt: \n",
      "The integration of AI and intelligent agents into software engineering is indeed reshaping the field in significant ways. Here's a detailed exploration of the effects you've outlined, broken down further to emphasize their implications and potential challenges.\n",
      "\n",
      "### 1. **Automation of Repetitive Tasks**\n",
      "   - **Code Generation**: AI tools are revolutionizing coding practices by converting natural language specifications into functional code. This minimizes mundane tasks, allowing developers to focus on complex problem-solving and innovation. However, reliance on AI-generated code necessitates vigilance regarding code quality and security.\n",
      "   - **Testing and Debugging**: AI-enhanced testing tools are capable of running extensive test cases, learning from previous bugs to improve future testing strategies. This leads to a more robust software product but can\n",
      "\n",
      "--- LLAMA turn ---\n",
      "llama: \n",
      "### Exploring the Effects of AI and Intelligent Agents on Software Engineering\n",
      "\n",
      "#### 1. Automation of Repetitive Tasks\n",
      "   - **Code Generation**: As AI tools like GitHub Copilot and OpenAI Codex further integrate into development workflows, their capabilities expand. These include not only generating code but also assisting in understanding complex algorithms and data structures.\n",
      "     *   **Impact on Development**: AI-assisted code generation allows developers to quickly implement feature ideas without extensive manual coding.\n",
      "     *   **Challenges**: Ensuring the generated code adheres to best practices and meets software quality standards becomes increasingly crucial.\n",
      "\n",
      "#### 2. Enhanced Software Development\n",
      "   - **Feature Engineering and Design**: Leveraging machine learning models, AI can analyze data to identify trends and suggest innovative features that cater to user needs.\n",
      "     *   **Impact on Innovation**: By providing insights from large datasets, AI assists in identifying untapped opportunities for growth and improvement.\n",
      "     *   **Challenges**: Balancing the need for human intuition with the ability of AI to predict success can be a delicate task.\n",
      "\n",
      "#### 3. Increased Productivity\n",
      "   - **Predictive Analytics and Planning**: Advanced analytics tools powered by AI help forecast demand, identify trends, and optimize resource allocation, leading to more efficient planning.\n",
      "     *   **Impact on Team Dynamics**: With better forecasting capabilities, teams can allocate resources more effectively, ensuring projects stay on track and meet deadlines.\n",
      "     *   **Challenges**: The complexity of data analysis increases with the use of AI-driven predictive models, necessitating significant investment in training personnel.\n",
      "\n",
      "#### 4. Improved Quality Assurance\n",
      "   - **Automated Code Analysis**: AI-based tools offer unparalleled depth to code reviews by not only checking syntax but also detecting security vulnerabilities and adherence to coding standards.\n",
      "     *   **Impact on Bug Fixing**: With AI-powered analysis tools, developers can identify potential bugs earlier in the development lifecycle, leading to fewer errors at deployment time.\n",
      "     *   **Challenges**: Ensuring that AI-driven tools accurately detect all potential issues without introducing false positives or requiring excessive manual review is a complex challenge.\n",
      "\n",
      "#### 5. Shift in Roles and Responsibilities\n",
      "   - **Human-AI Collaboration**: As AI takes over routine tasks, developers are left to focus on higher-level tasks such as strategic planning, design, and innovation.\n",
      "     *   **Impact on Team Composition**: Organizations need to adapt by hiring more skilled personnel for high-level roles while maintaining or reducing the number of entry-level positions.\n",
      "     *   **Challenges**: Balancing the skills required for human and AI collaboration poses a significant challenge.\n",
      "\n",
      "#### 6. Data-Driven Decision Making\n",
      "   - **Real-Time Data Analysis**: Real-time analytics tools provide developers with immediate insights into application performance, user behavior, and market trends.\n",
      "     *   **Impact on Development Strategy**: This real-time data analysis allows teams to make informed decisions about future features and development priorities more quickly.\n",
      "     *   **Challenges**: The volume of data generated by AI-driven analytics requires significant investment in infrastructure and personnel training to effectively utilize these insights.\n",
      "\n",
      "By understanding the profound effects of AI and intelligent agents on software engineering, organizations can better prepare for a future where technology plays an increasingly central role.\n"
     ]
    }
   ],
   "source": [
    "llm_chat = LLMConversation(api_key=api_key)\n",
    "llm_chat.converse(\"Effect of AI and agents on software engineering\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
