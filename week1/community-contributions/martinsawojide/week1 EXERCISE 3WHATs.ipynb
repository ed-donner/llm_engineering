{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
      "metadata": {},
      "source": [
        "# End of week 1 exercise\n",
        "\n",
        "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
        "and responds with an explanation. This is a tool that you will be able to use yourself during the course!\n",
        "\n",
        "## Approach: The \"3 Whats\" technique\n",
        "\n",
        "Inspired by the [5 Whys](https://en.wikipedia.org/wiki/Five_whys) root-cause analysis method from Toyota,\n",
        "this notebook uses an iterative **3 Whats** variant to deepen technical explanations.\n",
        "Each follow-up step picks the hardest concept from the previous answer and explains it:\n",
        "\n",
        "1. **What #1** -- General explanation of the code / concept\n",
        "2. **What #2** -- Identify the hardest concept from What #1 and explain it\n",
        "3. **What #3** -- Identify the hardest concept from What #2 and explain it (may reference but not repeat What #2)\n",
        "\n",
        "We run the same chain on both **GPT** (via OpenRouter) and **Llama 3.2** (via Ollama) to compare how each model deepens its reasoning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c1070317-3ed9-4659-abe3-828943230e03",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Markdown, display\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# constants\n",
        "\n",
        "MODEL_GPT = 'gpt-4o-mini'\n",
        "MODEL_LLAMA = 'llama3.2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenRouter API key looks good\n"
          ]
        }
      ],
      "source": [
        "load_dotenv(override=True)\n",
        "\n",
        "openrouter_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "if openrouter_key and len(openrouter_key) > 10:\n",
        "    print(\"OpenRouter API key looks good\")\n",
        "else:\n",
        "    print(\"Set OPENROUTER_API_KEY in your .env file!\")\n",
        "\n",
        "gpt_client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=openrouter_key,\n",
        ")\n",
        "\n",
        "ollama_client = OpenAI(\n",
        "    base_url=\"http://localhost:11434/v1\",\n",
        "    api_key=\"ollama\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
      "metadata": {},
      "outputs": [],
      "source": [
        "# here is the question; type over this to ask something new\n",
        "\n",
        "question = \"\"\"\n",
        "Please explain what this code does and why:\n",
        "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "01716cc3",
      "metadata": {},
      "outputs": [],
      "source": [
        "THREE_WHATS_SYSTEM = (\n",
        "    \"You are a technical educator. Keep every answer to ONE concise paragraph \"\n",
        "    \"(no bullet points, no headings, no code blocks unless essential). \"\n",
        "    \"When asked to go deeper, name the single hardest concept from your \"\n",
        "    \"previous answer and explain only that concept in one paragraph of new \"\n",
        "    \"information. You may reference or allude to earlier explanations but \"\n",
        "    \"never repeat or rephrase them.\"\n",
        ")\n",
        "\n",
        "FOLLOWUP = (\n",
        "    \"What is the single hardest concept in your last answer? \"\n",
        "    \"Explain it in one concise paragraph. You may reference what you said \"\n",
        "    \"before but do not repeat it.\"\n",
        ")\n",
        "\n",
        "\n",
        "def three_whats(question: str, model: str, client: OpenAI, depth: int = 3):\n",
        "    \"\"\"\n",
        "    Run the 3 Whats chain: ask a question, then iteratively pick the\n",
        "    hardest concept from the previous answer and explain it.\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": THREE_WHATS_SYSTEM},\n",
        "        {\"role\": \"user\", \"content\": question},\n",
        "    ]\n",
        "\n",
        "    for i in range(depth):\n",
        "        if i == 0:\n",
        "            label = f\"## Initial explanation ({model})\"\n",
        "        else:\n",
        "            label = f\"## Deep-dive #{i} -- hardest concept from above\"\n",
        "\n",
        "        display(Markdown(label))\n",
        "\n",
        "        stream = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            stream=True,\n",
        "        )\n",
        "\n",
        "        handle = display(Markdown(\"\"), display_id=True)\n",
        "        answer = \"\"\n",
        "        for chunk in stream:\n",
        "            delta = chunk.choices[0].delta.content or \"\"\n",
        "            answer += delta\n",
        "            handle.update(Markdown(answer))\n",
        "\n",
        "        messages.append({\"role\": \"assistant\", \"content\": answer})\n",
        "\n",
        "        if i < depth - 1:\n",
        "            messages.append({\"role\": \"user\", \"content\": FOLLOWUP})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Initial explanation (gpt-4o-mini)"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "This code utilizes a generator expression to yield unique authors from a collection of book dictionaries stored in `books`. It specifically uses the `yield from` statement to yield values from the resulting set, which is created by iterating over each `book` in the `books` list, extracting the \"author\" value when it exists (as checked by `book.get(\"author\")`). The use of a set ensures that any duplicate author names are eliminated, resulting in a clean iteration of unique authors."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "## Deep-dive #1 -- hardest concept from above"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "The hardest concept in the previous explanation is the use of sets for data deduplication. Sets in Python are unordered collections of unique elements, which means that when you insert items into a set, any duplicate entries are automatically removed, guaranteeing that only distinct items remain. This property makes them ideal for tasks where you need to filter out redundancy, such as extracting unique authors from a list of books. Furthermore, set operations are generally more efficient than list operations in terms of membership testing and adding elements, making them a preferable choice for scenarios where uniqueness is crucial."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "## Deep-dive #2 -- hardest concept from above"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "The hardest concept in the last explanation is the efficiency of set operations compared to list operations. In Python, checking for the existence of an item in a set is, on average, O(1) due to its implementation using a hash table, whereas checking membership in a list is O(n) since it requires scanning through the elements sequentially. This efficiency in sets not only speeds up operations such as membership testing but also enhances the performance of operations like adding or removing elements. As a result, sets are preferred when working with collections that require frequent checks for uniqueness and performance is a consideration."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "three_whats(question, model=MODEL_GPT, client=gpt_client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Initial explanation (llama3.2)"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "This line of code is used within a generator function to yield each author name, one at a time, as the function iterates over a list of dictionaries (`books`) that meet a specified condition. The dictionary search operation (`book.get(\"author\")` and `for book in books if book.get(\"author\")`) ensures that each value being yielded is only from those books where an \"author\" key exists. It acts like a filter, to some extent - it won't yield from any dictionaries without the 'author' key, but unlike normal for loops or if statements, you get a generator of individual items instead of just iterating over the remaining boolean outcomes. This can be particularly useful in building lazy iterable data pipelines that require filtering before processing."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "## Deep-dive #1 -- hardest concept from above"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "The hardest concept here is likely to be \"yield from\". In this context, \"yield from\" is a syntax for yielding elements from another iterable as if they came directly from the current generator iteration. Essentially, when used with an expression like `{book.get(\"author\") for book in books if book.get(\"author\")}`, it bypasses the usual generator behavior and allows us to directly iterate over the individual \"authors\", creating an iterable that's built by combining multiple iterables, rather than using lazy evaluation or iteration chaining which might have been implied initially."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "## Deep-dive #2 -- hardest concept from above"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "The hardest concept to grasp here is \"bypassing generator behavior\". Essentially, when using \"yield from\", the outer generator (created by `{book.get(\"author\") for book in books if book.get(\"author\")}`) takes care of its own iteration and yields values directly, rather than storing them all-up until its completion. This means that \"yield from\" doesn't modify an existing iterable but starts a new one from scratch each time, which can be confusing to understand correctly if you're already familiar with the more standard generator syntax."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "three_whats(question, model=MODEL_LLAMA, client=ollama_client)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
