{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a7038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!playwright install # install playwright\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18188abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from openai import NotGiven, OpenAI\n",
    "from playwright.async_api import async_playwright\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "async def fetch_website_contents(url):\n",
    "    \"\"\"\n",
    "    Return the title and contents of the website at the given url using Playwright;\n",
    "    truncate to 2,000 characters as a sensible limit\n",
    "    \"\"\"\n",
    "    if not url:\n",
    "        return \"\"\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(url, wait_until=\"domcontentloaded\", timeout=60_000)\n",
    "        content = await page.content()\n",
    "        await browser.close()\n",
    "        soup = BeautifulSoup(content, \"html.parser\")\n",
    "        title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            text = \"\"\n",
    "        return (title + \"\\n\\n\" + text)[:2_000]\n",
    "\n",
    "\n",
    "def messages_for(website, **args):\n",
    "    \"\"\"\n",
    "    Return message format\n",
    "    \"\"\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": args.get('system_prompt')},\n",
    "        {\"role\": \"user\", \"content\": args.get('user_prompt_prefix') + website}\n",
    "\n",
    "    ]\n",
    "\n",
    "\n",
    "async def summarize(client: OpenAI, **args):\n",
    "    \"\"\"\n",
    "    call OpenAI API, to get content\n",
    "    \"\"\"\n",
    "    model = args.get('model')\n",
    "    if not model:\n",
    "        raise NotGiven('model parameter needed')\n",
    "\n",
    "    website = await fetch_website_contents(args.get('url'))\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages = messages_for(website=website, **args)\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "async def display_summary(client: OpenAI, **args):\n",
    "    \"\"\"\n",
    "    display the output nicely \n",
    "    \"\"\"\n",
    "    summary = await summarize(client, **args)\n",
    "    display(Markdown(summary))\n",
    "\n",
    "    \n",
    "# define system prompt\n",
    "system_prompt = \"\"\"\n",
    "You are a snarky assistant that analyzes the contents of a website,\n",
    "and provides a short, snarky, humorous summary, ignoring text that might be navigation related.\n",
    "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
    "\"\"\"\n",
    "\n",
    "# define user prompt\n",
    "user_prompt_prefix = \"\"\"\n",
    "Here are the contents of a website.\n",
    "Provide a short summary of this website.\n",
    "If it includes news or announcements, then summarize these too.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# create the OpenAI client\n",
    "llama = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "# get nicely summarize\n",
    "urls = [\"https://edwarddonner.com\", \"https://openai.com\"]\n",
    "for url in urls:\n",
    "    print(f\"\"\"\n",
    "    -------------------------------------------------------------\n",
    "    webiste:{url}\n",
    "    -------------------------------------------------------------\n",
    "    \"\"\")\n",
    "    await display_summary(\n",
    "        llama,\n",
    "        model=\"llama3.2\",\n",
    "        url=\"\", \n",
    "        system_prompt=system_prompt, \n",
    "        user_prompt_prefix=user_prompt_prefix\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
