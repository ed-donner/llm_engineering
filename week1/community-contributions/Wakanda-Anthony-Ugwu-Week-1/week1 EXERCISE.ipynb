{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b466edbf",
      "metadata": {},
      "source": [
        "# End of week 1 exercise\n",
        "\n",
        "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
        "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "05d11a18",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "390f3a8c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b]11;?\u001b\\\u001b[6n\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
            "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
            "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
            "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
            "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
            "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
            "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
            "verifying sha256 digest \u001b[K\n",
            "writing manifest \u001b[K\n",
            "success \u001b[K\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ],
      "source": [
        "!ollama pull llama3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "67e492db",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API key found and looks good so far!\n"
          ]
        }
      ],
      "source": [
        "load_dotenv(override=True)\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "if not api_key:\n",
        "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
        "elif not api_key.startswith(\"sk-proj-\"):\n",
        "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
        "else:\n",
        "    print(\"API key found and looks good so far!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56334767",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "cloud_llm = OpenAI()\n",
        "local_llm = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcea23da",
      "metadata": {},
      "outputs": [],
      "source": [
        "TUTOR_INSTRUCTIONS = \"\"\"\\\n",
        "You are a helpful coding mentor. Your job is to break down programming topics \\\n",
        "so they are easy to follow for someone learning to code.\n",
        "\n",
        "Format every answer like this:\n",
        "1. **Quick summary** — one or two sentences capturing the core idea.\n",
        "2. **Detailed walkthrough** — explain step by step with runnable code snippets.\n",
        "3. **Watch-outs** — list 2-3 traps that trip up newcomers.\n",
        "\n",
        "Use real-world analogies whenever they make a concept more intuitive.\n",
        "\n",
        "Below are two sample answers so you know exactly what style to follow.\n",
        "\n",
        "=== Sample A ===\n",
        "\n",
        "Topic: How do Python decorators work?\n",
        "\n",
        "**Quick summary**\n",
        "A decorator is a function that wraps another function to extend its behaviour \\\n",
        "without modifying the original code.\n",
        "\n",
        "**Detailed walkthrough**\n",
        "At its simplest, a decorator takes a function as input and returns a new function:\n",
        "\n",
        "    def shout(func):\n",
        "        def wrapper(*args, **kwargs):\n",
        "            result = func(*args, **kwargs)\n",
        "            return result.upper()\n",
        "        return wrapper\n",
        "\n",
        "    @shout\n",
        "    def greet(name):\n",
        "        return f\"hello {name}\"\n",
        "\n",
        "    greet(\"world\")  # \"HELLO WORLD\"\n",
        "\n",
        "The `@shout` syntax is shorthand for `greet = shout(greet)`. \\\n",
        "Think of it like putting a phone case on your phone — the phone (function) \\\n",
        "still works the same, but the case (decorator) adds extra protection or style.\n",
        "\n",
        "**Watch-outs**\n",
        "- Forgetting `@functools.wraps(func)` inside the wrapper — without it the \\\n",
        "original function's name and docstring get hidden.\n",
        "- Stacking multiple decorators without understanding the order — they apply \\\n",
        "bottom-up, not top-down.\n",
        "- Trying to decorate a function that relies on its own identity (e.g. recursion \\\n",
        "by name) can behave unexpectedly.\n",
        "\n",
        "=== Sample B ===\n",
        "\n",
        "Topic: What is the difference between `==` and `is` in Python?\n",
        "\n",
        "**Quick summary**\n",
        "`==` checks whether two objects have the same *value*; `is` checks whether they \\\n",
        "are the exact *same object* in memory.\n",
        "\n",
        "**Detailed walkthrough**\n",
        "\n",
        "    a = [1, 2, 3]\n",
        "    b = [1, 2, 3]\n",
        "\n",
        "    a == b   # True  — same contents\n",
        "    a is b   # False — two separate list objects\n",
        "\n",
        "    c = a\n",
        "    a is c   # True  — c points to the same list as a\n",
        "\n",
        "Analogy: two identical copies of a book have equal content (`==`), but they are \\\n",
        "not the same physical book (`is`).\n",
        "\n",
        "Python caches small integers (-5 to 256) and short strings, so `is` can \\\n",
        "*accidentally* return True for those — never rely on it for value comparison.\n",
        "\n",
        "**Watch-outs**\n",
        "- Using `is` to compare strings or numbers — works sometimes due to caching, \\\n",
        "fails unpredictably with larger values.\n",
        "- Confusing `is not` with `!=` — they test different things.\n",
        "- Mutating a list through an alias (`c.append(4)` also changes `a`) because \\\n",
        "`is` tells you they share identity.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05d2b7e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_ai_tutor(topic: str, *, model: str, use_local: bool = False):\n",
        "    \"\"\"Stream a mentor-style explanation for *topic*.\n",
        "\n",
        "    Set use_local=True to run against Ollama.\n",
        "    \"\"\"\n",
        "    provider = local_llm if use_local else cloud_llm\n",
        "    tag = f\"local ({model})\" if use_local else f\"cloud ({model})\"\n",
        "\n",
        "    prompt = f\"Please explain the following coding topic using the format from your instructions.\\n\\nTopic: {topic}\"\n",
        "\n",
        "    try:\n",
        "        chunks = provider.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": TUTOR_INSTRUCTIONS},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "            ],\n",
        "            stream=True,\n",
        "        )\n",
        "    except Exception as err:\n",
        "        display(Markdown(f\"**Could not reach {tag}:** {err}\"))\n",
        "        return\n",
        "\n",
        "    answer = \"\"\n",
        "    output_handle = display(Markdown(\"\"), display_id=True)\n",
        "    try:\n",
        "        for part in chunks:\n",
        "            if not part.choices:\n",
        "                continue\n",
        "            token = part.choices[0].delta.content or \"\"\n",
        "            answer += token\n",
        "            update_display(Markdown(answer), display_id=output_handle.display_id)\n",
        "    except Exception as err:\n",
        "        update_display(\n",
        "            Markdown(answer + f\"\\n\\n---\\n**Streaming error ({tag}):** {err}\"),\n",
        "            display_id=output_handle.display_id,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f58d451",
      "metadata": {},
      "outputs": [],
      "source": [
        "my_question = \"\"\"\n",
        "Please explain what this code does and why:\n",
        "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3950686d",
      "metadata": {},
      "source": [
        "### GPT-4.1-mini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27f77b62",
      "metadata": {},
      "outputs": [],
      "source": [
        "ask_ai_tutor(my_question, model=\"gpt-4.1-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab7f387a",
      "metadata": {},
      "source": [
        "### Llama 3.2 (via Ollama)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36a2fa9b",
      "metadata": {},
      "outputs": [],
      "source": [
        "ask_ai_tutor(my_question, model=\"llama3.2\", use_local=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
