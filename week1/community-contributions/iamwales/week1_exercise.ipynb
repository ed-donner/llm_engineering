{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c8f4b6",
   "metadata": {},
   "source": [
    "# Week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!\n",
    "\n",
    "NOTE: Using Openrouter for the openai API and llama3.2:1b for Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8914dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "724a7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2:1b'\n",
    "\n",
    "\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa79d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-or-v1') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key!\")\n",
    "    \n",
    "openai = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    default_headers={\n",
    "        \"HTTP-Referer\": \"http://localhost:8888\",  # or your app/site URL\n",
    "        \"X-Title\": \"llm_engineering_course\"       # optional label\n",
    "    }\n",
    ")\n",
    "\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c30b90dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03d7a1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This line of code is using a combination of Python features: a generator expression (`yield from`) and a set comprehension. Let's break down what it does step by step:\n",
       "\n",
       "1. **Set Comprehension**:\n",
       "   - The expression `{book.get(\"author\") for book in books if book.get(\"author\")}` is a set comprehension.\n",
       "   - It creates a set of authors by iterating over a collection called `books`.\n",
       "   - For each `book` in `books`, it attempts to retrieve the value associated with the key `\"author\"` using `book.get(\"author\")`.\n",
       "   - The `if book.get(\"author\")` condition filters out any `book` entries where the author is `None` or an empty string (i.e., it only includes books that have a valid author).\n",
       "\n",
       "2. **Yield from**:\n",
       "   - The `yield from` statement is used in a generator function to yield all values from another iterable. In this case, it yields each author from the set created by the comprehension.\n",
       "   - Note that using `yield from` with a set means that the function will yield each unique author, one at a time.\n",
       "\n",
       "### Summary\n",
       "In summary, the code effectively generates an iterable of unique author names from a collection of `books`. It ensures that only those authors that are non-empty and valid are considered. This is useful in scenarios where authors may be duplicated across multiple books, and you want to avoid yielding the same author multiple times. \n",
       "\n",
       "### Why Itâ€™s Useful\n",
       "- **Efficiency**: It collects unique authors without having to manually check for duplicates, thanks to the properties of a set.\n",
       "- **Readability**: The use of comprehensions and `yield from` creates a concise and readable expression of the intention to collect and yield unique authors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "\n",
    "stream = openai.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that can answer questions about code.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "          ],\n",
    "        stream=True\n",
    "    )   \n",
    "\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    response += chunk.choices[0].delta.content or ''\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97e5c86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This is a Python code snippet that uses the `yield from` expression to generate an iterator of authors' names. Here's a breakdown of how it works:\n",
       "\n",
       "1. `{book.get(\"author\") for book in books}`: This part of the code creates a generator expression that iterates over each book in the `books` collection and gets its author's name (key `author`) using the `.get()` method.\n",
       "2. `yield from`: This is the key part of the code. When this symbol is encountered, the code will start yielding control to the next line of the generator expression.\n",
       "\n",
       "Key aspects:\n",
       "\n",
       "* The yield keyword in Python is used to produce values over a long period of time, typically in connection with generators, which are special types of functions that can be paused and resumed.\n",
       "* `yield from` allows an iterable (like a list or tuple) to be short-circuited, i.e., it produces values until the end is reached.\n",
       "\n",
       "The purpose of this code snippet likely appears when you're working with large datasets like JSON data loaded into Python. Let's say `books` is a collection of dictionaries, each representing a book in your dataset, and their respective authors (`author`). You're interested in getting only these author names where the value matches an expected key.\n",
       "\n",
       "When used inside a context manager or within another generator function, this code snippet can be quite useful:\n",
       "\n",
       "- It uses the `yield from` expression to avoid the extra `get()` call for each book.\n",
       "- It doesn't require manual iteration through all books in Python's memory; instead, it generates values on-the-fly and can skip some books due to what you want."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "ollama_stream = ollama.chat.completions.create(model=MODEL_LLAMA, messages=[{\"role\": \"user\", \"content\": question}], stream=True)\n",
    "\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in ollama_stream:\n",
    "    response += chunk.choices[0].delta.content or ''\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
