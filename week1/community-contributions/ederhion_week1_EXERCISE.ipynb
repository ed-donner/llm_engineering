{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a03f70",
   "metadata": {},
   "source": [
    "This is a job search utility that fetches and cleans job listings from the Greenhouse API before passing them to an LLM for intelligent role matching. It successfully implements structured JSON outputs via the OpenRouter API to evaluate and return relevant positions based on core responsibilities and skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fa78aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found! Please check your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "OPEN_ROUTER_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
    "client = OpenAI(api_key=api_key, base_url=OPEN_ROUTER_BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb848dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching and Cleaning Data from the API ---\n",
    "def fetch_jobs_from_api(api_url, max_jobs=30):\n",
    "    \"\"\"\n",
    "    Fetches the job list from Greenhouse, including descriptions, and cleans the HTML.\n",
    "    We limit the number of jobs processed to avoid exceeding LLM context limits.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Fetching job data from API: {api_url}...\")\n",
    "    \n",
    "    response = requests.get(api_url)\n",
    "    response.raise_for_status() \n",
    "    \n",
    "    data = response.json()\n",
    "    \n",
    "    simplified_jobs = []\n",
    "    \n",
    "    for job in data.get('jobs', [])[:max_jobs]:\n",
    "        \n",
    "        raw_html = job.get(\"content\", \"\")\n",
    "        \n",
    "        # Strip the HTML tags to get clean, readable text\n",
    "        clean_text = BeautifulSoup(raw_html, \"html.parser\").get_text(separator=\" \", strip=True)\n",
    "        \n",
    "        simplified_jobs.append({\n",
    "            \"title\": job.get(\"title\"),\n",
    "            \"location\": job.get(\"location\", {}).get(\"name\"),\n",
    "            \"url\": job.get(\"absolute_url\"),\n",
    "            # truncate the description to 1500 characters to save tokens \n",
    "            \"description\": clean_text[:1500] \n",
    "        })\n",
    "        \n",
    "    print(f\"Successfully fetched and cleaned {len(simplified_jobs)} jobs.\")\n",
    "    return simplified_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Extracting the Best Match with the LLM ---\n",
    "def find_matching_jobs(jobs_list, desired_job, llm_model=MODEL_GPT):\n",
    "    \"\"\"\n",
    "    Passes the job list to the LLM to find ALL jobs that match the user's preference.\n",
    "    \"\"\"\n",
    "    print(f\"Asking the LLM to find ALL matches for: '{desired_job}'...\")\n",
    "    \n",
    "    system_prompt = (\n",
    "        \"You are an intelligent career matchmaking assistant. \"\n",
    "        \"You will be provided with a JSON list of available company jobs, including their descriptions. \"\n",
    "        \"Your task is to thoroughly read the job descriptions and find ALL jobs that match the user's desired role. \"\n",
    "        \"Do not rely on the job title alone; verify the responsibilities and requirements.\\n\\n\"\n",
    "        \"You MUST return a valid JSON object with a single key called 'matches'. \"\n",
    "        \"'matches' must be a list of objects, where each object has the exact following keys:\\n\"\n",
    "        \"- job_title (string)\\n\"\n",
    "        \"- location (string)\\n\"\n",
    "        \"- url (string)\\n\"\n",
    "        \"- job_description_summary (string - a 2 sentence summary of the role)\\n\"\n",
    "        \"- required_skills (list of strings - extract 3 to 5 core technical or soft skills required)\\n\"\n",
    "        \"- match_description (string - explain briefly why this matches the user's criteria)\\n\\n\"\n",
    "        \"If no jobs match the criteria, return an empty list for 'matches'.\"\n",
    "    )\n",
    "\n",
    "    user_content = f\"Desired Job Role: {desired_job}\\n\\nAvailable Jobs:\\n{json.dumps(jobs_list)}\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_model,\n",
    "        response_format={ \"type\": \"json_object\" }, \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_content}\n",
    "        ],\n",
    "        temperature=0.1 \n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc6c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Execution ---\n",
    "def search_for_jobs(target_job_title, api_url, max_jobs_to_fetch):\n",
    "    \n",
    "    try:\n",
    "        all_jobs = fetch_jobs_from_api(api_url, max_jobs_to_fetch)\n",
    "        \n",
    "        matching_results = find_matching_jobs(all_jobs, target_job_title)\n",
    "        \n",
    "        matches_list = matching_results.get(\"matches\", [])\n",
    "        \n",
    "        if not matches_list:\n",
    "            print(f\"\\nNo jobs found matching '{target_job_title}'.\")\n",
    "        else:\n",
    "            print(f\"\\n FOUND {len(matches_list)} MATCHING JOBS:\\n\")\n",
    "            print(json.dumps(matching_results, indent=4))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_JOBS_TO_FETCH = 30\n",
    "search_for_jobs(\"software engineering\", 'https://boards-api.greenhouse.io/v1/boards/doordashusa/jobs?content=true', MAX_JOBS_TO_FETCH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
