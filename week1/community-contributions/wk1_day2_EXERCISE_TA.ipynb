{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can generate high-quality content such as:\n",
      "\t* News articles: Automated reporting of news events with minimal human intervention.\n",
      "\t* Social media posts: Personalized and engaging content for social media platforms.\n",
      "\t* Product descriptions: AI-generated product descriptions to enhance e-commerce experiences.\n",
      "2. **Marketing and Advertising**:\n",
      "\t* Ad copy generation: AI can create personalized ad copy based on customer preferences, demographics, and behavior.\n",
      "\t* Image and video creation: Generative AI can generate visually appealing images and videos for social media campaigns.\n",
      "\t* Personalized recommendations: AI-powered recommendation engines that suggest products or services to customers based on their past interactions.\n",
      "3. **Customer Service**:\n",
      "\t* Chatbots: Generative AI enables the development of more sophisticated chatbots that can understand context, empathize with users, and provide personalized responses.\n",
      "\t* Automated customer support: AI-powered tools that can respond to common customer inquiries, freeing up human customer support agents for more complex issues.\n",
      "4. **Product Design and Development**:\n",
      "\t* Product design: Generative AI can generate 3D models of products, reducing the time and cost associated with traditional design processes.\n",
      "\t* Prototyping: AI-powered tools can create prototypes quickly, enabling designers to test and refine their ideas faster.\n",
      "5. **Financial Services**: Generative AI is used in various financial applications, including:\n",
      "\t* Risk analysis: AI can analyze large datasets to identify potential risks and opportunities.\n",
      "\t* Credit scoring: AI-powered credit scoring models that assess an individual's creditworthiness more accurately than traditional methods.\n",
      "6. **Healthcare**:\n",
      "\t* Medical imaging analysis: Generative AI can help analyze medical images, such as X-rays and MRIs, to detect diseases like cancer earlier and more accurately.\n",
      "\t* Personalized medicine: AI-powered tools can generate personalized treatment plans based on individual patient profiles.\n",
      "7. **Education and Training**:\n",
      "\t* Adaptive learning systems: Generative AI enables the development of adaptive learning platforms that adjust to individual students' needs and abilities.\n",
      "\t* Virtual teaching assistants: AI-powered virtual teaching assistants that provide personalized support and feedback to students.\n",
      "8. **Supply Chain Management**: Generative AI can optimize supply chain operations by:\n",
      "\t* Predicting demand: AI-powered tools can analyze historical data to predict demand patterns, enabling more accurate forecasting.\n",
      "\t* Inventory management: AI can optimize inventory levels, reducing waste and overstocking.\n",
      "\n",
      "These applications are just a few examples of the many ways in which Generative AI is being applied in business. As the technology continues to evolve, we can expect to see even more innovative uses of Generative AI across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, transforming the way companies operate, innovate, and compete. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI models can create high-quality content such as text (e.g., articles, blog posts), images (e.g., product visuals, advertisements), and videos (e.g., explainer videos, social media clips). This automates the creation of repetitive or mundane content, freeing up human writers and designers to focus on more complex tasks.\n",
      "2. **Marketing Automation**: Generative AI can help personalize marketing campaigns by generating targeted content, emails, and ad copy based on customer behavior, demographics, and preferences. This leads to increased engagement, conversion rates, and customer loyalty.\n",
      "3. **Personalized Customer Service**: Chatbots and virtual assistants powered by generative AI can provide personalized responses to customer inquiries, improving the overall customer experience. These systems learn from interactions and adapt to individual customers' needs over time.\n",
      "4. **Product Design**: Generative AI can be used for product design, creating new prototypes or refinements based on customer feedback, market trends, or competitive analysis. This accelerates the design-to-market process, allowing companies to respond quickly to changing market conditions.\n",
      "5. **Risk Analysis and Compliance**: Generative AI models can analyze vast amounts of data to identify potential risks, detect anomalies, and predict future trends. This enables organizations to proactively address regulatory compliance issues, mitigate risk, and improve overall operational efficiency.\n",
      "6. **Supply Chain Optimization**: By analyzing large datasets on supply chain operations, generative AI can help optimize logistics, predict demand fluctuations, and suggest more efficient routes for transportation. This leads to reduced costs, increased customer satisfaction, and improved supply chain resilience.\n",
      "7. **Predictive Maintenance**: Generative AI models can analyze sensor data from equipment and machinery to predict when maintenance is needed, reducing downtime and increasing overall equipment effectiveness (OEE).\n",
      "8. **Creative Collaboration**: Generative AI can facilitate collaboration between creatives, such as writers, designers, and artists. By providing suggestions, ideas, or even full-fledged content, these models enable teams to work more efficiently and unlock new creative possibilities.\n",
      "9. **Quality Control**: Generative AI-powered quality control systems can analyze data from various sources, identify patterns, and predict potential issues with products or services. This helps companies catch errors earlier, improve product quality, and reduce waste.\n",
      "10. **Innovation Incubation**: Generative AI can facilitate the idea generation process by providing innovative solutions to complex problems or business challenges. By automating ideation tasks, organizations can accelerate innovation and stay ahead of the competition.\n",
      "\n",
      "These examples demonstrate how generative AI is transforming various industries and aspects of businesses, from content creation to supply chain optimization. As these technologies continue to evolve, we can expect even more exciting applications across multiple sectors.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative Artificial Intelligence (AI) has numerous exciting applications in various businesses across different industries. Here are some examples:\n",
      "\n",
      "1. **Visual Design**: Generative AI-powered tools, like DeepDream, Prisma, or Artbreeder, can create stunning visuals by transforming and generating images using existing styles or shapes.\n",
      "\n",
      "Business Applications:\n",
      "\t* Social Media: Use generative AI to create engaging visuals for social media platforms, increasing brand awareness and ad engagement.\n",
      "\t* Advertising Agencies: Leverage AI-generated designs for campaigns, reducing costs and improving efficiency.\n",
      "\t* Brands: Create unique visual content, such as product packaging design, logos, or branding materials.\n",
      "\n",
      "2. **Content Generation**: Generative AI can create high-quality, engaging content in text, speech, and multimedia formats.\n",
      "\n",
      "Business Applications:\n",
      "\t* Content Marketing Agencies: Use AI-generated content to supplement human writing efforts, reducing costs while maintaining quality.\n",
      "\t* E-Learning Platforms: Utilize generative AI to create adaptive learning materials, providing personalized educational experiences for students.\n",
      "\t* Social Media Management Tools: Employ AI-powered content generation to automate social media publishing.\n",
      "\n",
      "3. **Creative Writing**: Generative AI can generate prose or poetry in various styles and genres.\n",
      "\n",
      "Business Applications:\n",
      "\t* Authors and Writers: Use AI-generated writing prompts to spark creativity or improve output efficiency.\n",
      "\t* Copywriters: Apply generative AI to create compelling, customized content for clients.\n",
      "\t* Scriptwriters: Employ AI-powered tools to develop film scripts or TV shows based on human input.\n",
      "\n",
      "4. **Data Analysis**: Generative AI can identify patterns and correlations in vast datasets, providing valuable insights for business decision-making.\n",
      "\n",
      "Business Applications:\n",
      "\t* Insurance Companies: Leverage generative AI to analyze customer behavior and predictive outcomes.\n",
      "\t* Financial Institutions: Apply AI-generated models to optimize credit scoring or investment predictions.\n",
      "\t* Retail Businesses: Use generative AI to study consumer purchasing habits and improve marketing strategies.\n",
      "\n",
      "5. **Speech Analytics**: Generative AI can transcribe, summarize, and analyze conversations in real-time.\n",
      "\n",
      "Business Applications:\n",
      "\t* Customer Service Platforms: Employ AI-powered speech analytics to optimize customer support interactions.\n",
      "\t* Market Research Agencies: Utilize real-time transcription of focus groups or market surveys to refine research findings.\n",
      "\t* HR Departments: Use generative AI to monitor internal communications, detecting sentiment shifts or emotional trends among employees.\n",
      "\n",
      "6. **Predictive Maintenance**: Generative AI can analyze sensor data from machinery and equipment to predict maintenance needs.\n",
      "\n",
      "Business Applications:\n",
      "\t* Manufacturing Industries: Implement generative AI for predictive maintenance in production facilities to minimize downtime.\n",
      "\t* Logistics Companies: Use AI-powered analysis of logistics routes, vehicles, or cargo containers to identify potential transportation issues.\n",
      "\t* Energy Industries: Apply generative AI to optimize energy consumption and identify resource depletion risks.\n",
      "\n",
      "These examples illustrate how Generative AI is transforming various business areas. By tapping into this power, organizations can enhance efficiency, innovation, creativity, and decision-making capabilities.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 1.7 MB/1.1 GB                  \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 5.6 MB/1.1 GB                  \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏  11 MB/1.1 GB                  \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏  20 MB/1.1 GB                  \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏  26 MB/1.1 GB                  \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏  31 MB/1.1 GB                  \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏  44 MB/1.1 GB                  \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏  61 MB/1.1 GB                  \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏  69 MB/1.1 GB                  \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏  80 MB/1.1 GB                  \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏  82 MB/1.1 GB                  \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏  90 MB/1.1 GB   82 MB/s     12s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 116 MB/1.1 GB   82 MB/s     12s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 116 MB/1.1 GB   82 MB/s     12s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 128 MB/1.1 GB   82 MB/s     12s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 140 MB/1.1 GB   82 MB/s     11s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 142 MB/1.1 GB   82 MB/s     11s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 148 MB/1.1 GB   82 MB/s     11s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 174 MB/1.1 GB   82 MB/s     11s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 175 MB/1.1 GB   82 MB/s     11s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 190 MB/1.1 GB   82 MB/s     11s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 199 MB/1.1 GB   98 MB/s      9s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 203 MB/1.1 GB   98 MB/s      9s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 216 MB/1.1 GB   98 MB/s      9s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 227 MB/1.1 GB   98 MB/s      9s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 233 MB/1.1 GB   98 MB/s      8s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 251 MB/1.1 GB   98 MB/s      8s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 261 MB/1.1 GB   98 MB/s      8s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 266 MB/1.1 GB   98 MB/s      8s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 273 MB/1.1 GB   98 MB/s      8s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 294 MB/1.1 GB   98 MB/s      8s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 295 MB/1.1 GB   98 MB/s      8s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 305 MB/1.1 GB   98 MB/s      8s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 324 MB/1.1 GB   98 MB/s      8s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 332 MB/1.1 GB   98 MB/s      8s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 339 MB/1.1 GB   98 MB/s      7s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 347 MB/1.1 GB   98 MB/s      7s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 354 MB/1.1 GB   98 MB/s      7s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 369 MB/1.1 GB   98 MB/s      7s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 380 MB/1.1 GB   98 MB/s      7s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 384 MB/1.1 GB   98 MB/s      7s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 402 MB/1.1 GB  100 MB/s      7s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 411 MB/1.1 GB  100 MB/s      7s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 415 MB/1.1 GB  100 MB/s      7s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 424 MB/1.1 GB  100 MB/s      6s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 448 MB/1.1 GB  100 MB/s      6s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 449 MB/1.1 GB  100 MB/s      6s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 457 MB/1.1 GB  100 MB/s      6s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 473 MB/1.1 GB  100 MB/s      6s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 474 MB/1.1 GB  100 MB/s      6s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 490 MB/1.1 GB  100 MB/s      6s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 501 MB/1.1 GB   99 MB/s      6s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 504 MB/1.1 GB   99 MB/s      6s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 521 MB/1.1 GB   99 MB/s      5s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 532 MB/1.1 GB   99 MB/s      5s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 537 MB/1.1 GB   99 MB/s      5s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 546 MB/1.1 GB   99 MB/s      5s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 565 MB/1.1 GB   99 MB/s      5s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 569 MB/1.1 GB   99 MB/s      5s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 580 MB/1.1 GB   99 MB/s      5s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 593 MB/1.1 GB   99 MB/s      5s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 599 MB/1.1 GB   99 MB/s      5s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 603 MB/1.1 GB  100 MB/s      5s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 629 MB/1.1 GB  100 MB/s      4s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 632 MB/1.1 GB  100 MB/s      4s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 636 MB/1.1 GB  100 MB/s      4s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 648 MB/1.1 GB  100 MB/s      4s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 656 MB/1.1 GB  100 MB/s      4s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 673 MB/1.1 GB  100 MB/s      4s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 679 MB/1.1 GB  100 MB/s      4s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 682 MB/1.1 GB  100 MB/s      4s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 706 MB/1.1 GB  100 MB/s      4s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 710 MB/1.1 GB  101 MB/s      4s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 719 MB/1.1 GB  101 MB/s      3s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 726 MB/1.1 GB  101 MB/s      3s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 737 MB/1.1 GB  101 MB/s      3s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 754 MB/1.1 GB  101 MB/s      3s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 766 MB/1.1 GB  101 MB/s      3s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 772 MB/1.1 GB  101 MB/s      3s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 777 MB/1.1 GB  101 MB/s      3s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 785 MB/1.1 GB  101 MB/s      3s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 798 MB/1.1 GB  101 MB/s      3s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 811 MB/1.1 GB  101 MB/s      3s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 817 MB/1.1 GB  101 MB/s      2s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 833 MB/1.1 GB  101 MB/s      2s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 837 MB/1.1 GB  101 MB/s      2s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 850 MB/1.1 GB  101 MB/s      2s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 867 MB/1.1 GB  101 MB/s      2s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K     ▏ 868 MB/1.1 GB  101 MB/s      2s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K█    ▏ 877 MB/1.1 GB  101 MB/s      2s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K█    ▏ 896 MB/1.1 GB  101 MB/s      2s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K█    ▏ 897 MB/1.1 GB  101 MB/s      2s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K█    ▏ 909 MB/1.1 GB  100 MB/s      2s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K█    ▏ 918 MB/1.1 GB  100 MB/s      1s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K██   ▏ 935 MB/1.1 GB  100 MB/s      1s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K██   ▏ 941 MB/1.1 GB  100 MB/s      1s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K██   ▏ 951 MB/1.1 GB  100 MB/s      1s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K██   ▏ 953 MB/1.1 GB  100 MB/s      1s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K██   ▏ 975 MB/1.1 GB  100 MB/s      1s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K██   ▏ 989 MB/1.1 GB  100 MB/s      1s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K███  ▏ 993 MB/1.1 GB  100 MB/s      1s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K███  ▏ 1.0 GB/1.1 GB  100 MB/s      1s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K███  ▏ 1.0 GB/1.1 GB  104 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K███  ▏ 1.0 GB/1.1 GB  104 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K███  ▏ 1.0 GB/1.1 GB  104 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K███  ▏ 1.0 GB/1.1 GB  104 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K███  ▏ 1.1 GB/1.1 GB  104 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K████ ▏ 1.1 GB/1.1 GB  104 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K████ ▏ 1.1 GB/1.1 GB  104 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K████ ▏ 1.1 GB/1.1 GB  104 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K████ ▏ 1.1 GB/1.1 GB  104 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K████ ▏ 1.1 GB/1.1 GB  104 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K████ ▏ 1.1 GB/1.1 GB  104 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K████ ▏ 1.1 GB/1.1 GB   99 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K████ ▏ 1.1 GB/1.1 GB   99 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K████ ▏ 1.1 GB/1.1 GB   99 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K████ ▏ 1.1 GB/1.1 GB   99 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K████ ▏ 1.1 GB/1.1 GB   99 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K████ ▏ 1.1 GB/1.1 GB   99 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K████ ▏ 1.1 GB/1.1 GB   99 MB/s      0s\u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K█████▏ 1.1 GB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K█████▏ 1.1 GB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K█████▏ 1.1 GB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K█████▏ 1.1 GB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K█████▏ 1.1 GB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K█████▏ 1.1 GB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K█████▏ 1.1 GB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K█████▏ 1.1 GB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K█████▏ 1.1 GB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K█████▏ 1.1 GB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K█████▏ 1.1 GB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K█████▏ 1.1 GB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K██▏  537 B                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K██▏  537 B                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K██▏  537 B                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K██▏  537 B                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K██▏  537 B                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K██▏  537 B                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K██▏  537 B                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K██▏  537 B                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K48 B                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K48 B                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K48 B                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K48 B                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[KB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[KB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[KB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[KB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[KB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[KB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[KB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[KB                         \u001b[K\u001b[?25h\u001b[?2026l\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% ▕██████████████████▏  487 B                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% ▕██████████████████▏  487 B                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% ▕██████████████████▏  487 B                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% ▕██████████████████▏  487 B                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% ▕██████████████████▏  487 B                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% ▕██████████████████▏  487 B                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% ▕██████████████████▏  487 B                         \u001b[K\n",
      "\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 58174d17c07a: 100% ▕██████████████████▏  537 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% ▕██████████████████▏  487 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to understand what keeps myself occupied right now. Maybe it's about finding new ways to approach problems or learning something new. But how exactly? Well, I know that when someone asks for explanations on topics related to things like LLMs (Large Language Models), that's probably because those are complex subjects that require a lot of research and understanding. So, maybe this thought process is guiding me towards exploring these deep technical areas.\n",
      "\n",
      "I remember reading a bit about how LLMs work before. They sound really advanced, but they're basically simulating the way a human learns from data. So I think they use something called neural networks, which are like layers of interconnected neurons in our brains that help us process information.\n",
      "\n",
      "Now, for the technical part: the core concepts behind an LLM involve neural networks and attention mechanisms, especially within something called the transformer model. Hmm, let me break this down. A neural network is a system of several related models or nodes, composed of layers of interconnected processing units which use edge connections to transfer information forward.\n",
      "\n",
      "So, in the context of an LLM, it's probably using multiple layers where each layer is a neural network. The architecture might be something like a recursive composition or a stack of these layers. Each layer can process different types of input data and produce outputs that contribute to the overall understanding of the language being modeled.\n",
      "\n",
      "Then there's attention. I think in traditional recurrent neural networks, models attend to specific parts of sequences without focusing on where those parts are relative to each other. But with the transformer architecture introduced by Vaswani et al., it changed this approach. They use attention to focus on local patches, which is called self-attention or positional attention.\n",
      "\n",
      "Positional encoding must be a key part here. I recall something about embedding words in high-dimensional vectors based on their position in a sequence. This allows the model to consider each word's location relative to others, which seems crucial for understanding context better than just global patterns.\n",
      "\n",
      "The transformer is a type of neural network that processes data in parallel and can handle bidirectional information flow both during inference and training. It uses attention between all positions simultaneously, creating a deeper form of interdependencies between input tokens. This parallel processing allows the model to understand the relationships between words more closely, which is essential for capturing complex meanings.\n",
      "\n",
      "Putting it all together, an LLM uses multiple layers (including self-attentions) that work in parallel. These layers help the model learn features at different levels, from global patterns to local structures. The attention mechanisms within these layers enable each word's embeddings and interactions with others, which is why models like BERT or GPT have such powerful capabilities.\n",
      "\n",
      "I'm still trying to wrap my head around how all this works together. Maybe I should consider an example: training a model on text data could involve feeding it a conversation of sentences. Each layer processes the input sequence sequentially, but in the transformer setup, all positions compute their own attention simultaneously while others are passing through or processing differently. This might mean that each word can interact with others not just locally but also how features from other words carry over to contextually different surrounding areas.\n",
      "\n",
      "I guess this makes LLMs powerful because they can capture various levels of information and relationships in text, which seems incredibly useful for tasks like translation, summarization, or generating coherent language from limited input. But it's still fascinating how such a complicated system could come together so neatly in the field of artificial intelligence.\n",
      "</think>\n",
      "\n",
      "Understanding your current focus on exploring LLMs (Large Language Models) involves delving into their technical foundations and core concepts. Here's a structured explanation:\n",
      "\n",
      "1. **Neural Networks**:\n",
      "   - Neural networks are composed of interconnected layers where each layer processes incoming data through weighted connections between neurons or units. \n",
      "   - A neural network in an LLM consists of multiple layers (e.g., recursion, stack) that progressively process input data. Each layer's output contributes to understanding the language.\n",
      "\n",
      "2. **Attention Mechanisms**:\n",
      "   - Attention in traditional RNNs focuses on individual elements without considering their positions relative to others.\n",
      "   - In transformer models, attention is crucial as it enables each word's embeddings and interactions at different positions to be considered simultaneously. This use of self-attention or positional encoding allows the model to leverage context information from surrounding words effectively.\n",
      "\n",
      "3. **Transformer Architecture**:\n",
      "   - The transformer processes data in parallel and handles bidirectional flow both during inference and training.\n",
      "   - It uses attention between all positions, creating interdependencies among inputs by considering contexts of different word positions simultaneously.\n",
      "\n",
      "4. **Positional Encoding**:\n",
      "   - Words are embedded into high-dimensional vectors based on their position in a sequence, enabling the model to focus on local contexts relative to each other.\n",
      "\n",
      "5. **Benefits**: \n",
      "   - This approach allows LLMs to learn features at various levels (global vs. local patterns). The transformer's ability to process inputs and outputs in parallel results in models that achieve strong capabilities for tasks like translation and summarization, and capable of generating coherent output from limited input.\n",
      "\n",
      "6. **Learning Capabilities**: \n",
      "   - By examining text data through layers with self-attention mechanisms, models can capture complex meanings effectively. This makes LLMs useful for a wide range of applications beyond mere translation and summarization.\n",
      "\n",
      "In essence, the transformer architecture within LLMs combines parallel processing, multi-layered features, and attention to local contexts, making these models powerful tools in AI research.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, \n",
    "# followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8ab96bb-bb56-40e1-a570-3a941b1dcbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries and modules\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88cfed79-3a9a-449f-baf0-779d9c944f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped\n",
    "    \"\"\"\n",
    "    url: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            if not soup.body or len(soup.body.get_text(strip=True)) < 100:\n",
    "                # If content is likely dynamic, use Selenium\n",
    "                self.scrape_with_selenium()\n",
    "            else:\n",
    "                self.extract_from_soup(soup)\n",
    "        except Exception as e:\n",
    "            print(f\"Requests failed for {url}: {e}\")\n",
    "            self.scrape_with_selenium()\n",
    "\n",
    "    def scrape_with_selenium(self):\n",
    "        options = Options()\n",
    "        options.add_argument(\"--headless\")\n",
    "        options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "        options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "        service = Service(\"/usr/local/bin/chromedriver\")\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "        try:\n",
    "            driver.get(self.url)\n",
    "            time.sleep(3)  # wait for JS to load\n",
    "\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            self.extract_from_soup(soup)\n",
    "        finally:\n",
    "            driver.quit()\n",
    "\n",
    "    def extract_from_soup(self, soup):\n",
    "        self.title = soup.title.string.strip() if soup.title else \"No title found\"\n",
    "        for tag in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            tag.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0716b938-0b48-41d5-a21f-8224cb0f0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca718dcd-96df-4828-99af-f71222403d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4de6a5d-4b24-46fe-a7db-4843a9993465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "May 28, 2025\n",
      "Connecting my courses – become an LLM expert and leader\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "# Let's try one out. Change the website and add print statements to follow along.\n",
    "\n",
    "ed = Website(\"https://edwarddonner.com\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2602abd2-57e2-4ce4-89f3-41ff288f2cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are looking at a website titled Home - Edward Donner\n",
      "The contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\n",
      "\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "May 28, 2025\n",
      "Connecting my courses – become an LLM expert and leader\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt_for(ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef839c75-a679-4357-bfad-e515acc27470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an assistant that analyzes the contents of a website and provides a short summary, ignoring text that might be navigation related. Respond in markdown.'},\n",
       " {'role': 'user',\n",
       "  'content': 'You are looking at a website titled Home - Edward Donner\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nWell, hi there.\\nI’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\\nvery\\namateur) and losing myself in\\nHacker News\\n, nodding my head sagely to things I only half understand.\\nI’m the co-founder and CTO of\\nNebula.io\\n. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\\nacquired in 2021\\n.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\\npatented\\nour matching model, and our award-winning platform has happy customers and tons of press coverage.\\nConnect\\nwith me for more!\\nMay 28, 2025\\nConnecting my courses – become an LLM expert and leader\\nMay 18, 2025\\n2025 AI Executive Briefing\\nApril 21, 2025\\nThe Complete Agentic AI Engineering Course\\nJanuary 23, 2025\\nLLM Workshop – Hands-on with Agents – resources\\nNavigation\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nGet in touch\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\nSubscribe to newsletter\\nType your email…\\nSubscribe'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this out, and then try for a few more websites\n",
    "\n",
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85139892-de0f-4fd6-9870-eaeddd85abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = ollama.chat(\n",
    "        model = MODEL,\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b62f24d4-88bb-4dcf-bb82-81f05a3f9301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display the website nicely as a Jupyter output using Markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea9d09a5-4cd4-406a-b231-31afa24818fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# OpenAI Website Summary\n",
       "\n",
       "## Overview\n",
       "OpenAI is an AI research organization and company that provides various AI-powered products and services, including ChatGPT, Sora, API Platform, and more.\n",
       "\n",
       "## News and Announcements\n",
       "The website contains the following recent news and announcements:\n",
       "\n",
       "* **Sam & Jony introduce io**: OpenAI introduced a new product called io, which was announced on May 21, 2025.\n",
       "* **Introducing Codex**: A new release of Codex was announced on May 21, 2025, with details about its features and capabilities.\n",
       "* **OpenAI Expands Leadership with Fidji Simo**: OpenAI expanded its leadership team by appointing Fidji Simo as a board member, announced on May 7, 2025.\n",
       "* **Introducing data residency in Asia**: OpenAI introduced data residency in Asia for its customers, announced on May 7, 2025.\n",
       "* **Evolving OpenAI’s structure**: The company is evolving its structure to improve efficiency and effectiveness.\n",
       "\n",
       "## Research and Developments\n",
       "The website highlights various research and development projects, including:\n",
       "\n",
       "* **Latest Advancements**: OpenAI's latest advancements include the o3 and o4-mini models, GPT-4.5, and more.\n",
       "* **Research Residency**: The company offers a research residency program to support researchers and scientists working on AI-related projects.\n",
       "* **OpenAI o3 and o4-mini**: New releases of OpenAI's o3 and o4-mini models were announced, with details about their features and capabilities.\n",
       "\n",
       "## Products and Services\n",
       "The website offers various products and services, including:\n",
       "\n",
       "* **ChatGPT**: A conversational AI model that can answer questions, provide information, and more.\n",
       "* **Sora**: A platform for building custom applications using OpenAI's models and APIs.\n",
       "* **API Platform**: An API platform for developers to build and deploy their own AI-powered applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary('https://openai.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45bc5fbd-73cd-4fa8-a157-74847aa86b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are the top stories from CNN:\n",
       "\n",
       "1. **Trump's Big, Beautiful Bill**: The President's \"big, beautiful bill\" is expected to be unveiled on Wednesday, which could affect millions of Americans and have far-reaching implications for the country.\n",
       "2. **Israel-Hamas Conflict Escalates**: The conflict between Israel and Hamas has escalated, with both sides exchanging fire and casualties mounting. The situation remains volatile, with tensions running high in the region.\n",
       "3. **Ukraine-Russia War Intensifies**: The war between Ukraine and Russia has intensified, with both sides accusing each other of aggression. The international community is calling for a ceasefire, but so far, no progress has been made.\n",
       "4. **Climate Change: A Growing Concern**: Climate change is becoming an increasingly pressing concern worldwide, with scientists warning that the consequences of inaction will be catastrophic. Governments and individuals are being urged to take immediate action to reduce greenhouse gas emissions.\n",
       "5. **Pope Prays for Chinese Catholics**: Pope Francis has expressed his hopes for the future of China's Catholic community, which has been subject to severe restrictions in recent years. The Pope's words have been seen as a sign of support for the Chinese people.\n",
       "\n",
       "These are just a few of the top stories from CNN. You can find more information and updates on these and other news topics by visiting the CNN website or following us on social media."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary('https://cnn.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d1d31c-77fb-44d8-965a-85e6085fca22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
