{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants    \n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"Openai api key set and ready\")\n",
    "else:\n",
    "    print(\"Check env file to make sure that openai key is set!\")\n",
    "\n",
    "openai = OpenAI()\n",
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key=\"ollama\")\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful programming assistant. When given a technical question about Python, your task is to analyze the question and provide a detailed explanation, formatted in Markdown. Your responses should be clear, concise, and educational, aiming to help the user understand the concept or code in question. Use code blocks, bullet points, and examples as appropriate to illustrate your explanation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37fe7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build messages\n",
    "def build_message(question):\n",
    "  if not question:\n",
    "    print(\"No question provided\")\n",
    "    return\n",
    "\n",
    "  return [\n",
    "      {\"role\": \"system\", \"content\":system_prompt},\n",
    "      {\"role\": \"user\", \"content\":question}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd8fbc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream chat \n",
    "# this function takes the initial response generated and stream it\n",
    "\n",
    "def stream_response(response):\n",
    "  display_handle = display(Markdown(\"\"), display_id=True)\n",
    "  result = \"\"\n",
    "\n",
    "  for chunk in response:\n",
    "    result += chunk.choices[0].delta.content or ''\n",
    "    update_display(Markdown(result), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "def chatOpenAI(question):  \n",
    "  messages = build_message(question)\n",
    "  \n",
    "  if not messages:\n",
    "    print(\"No messages provided\")\n",
    "    return\n",
    "\n",
    "  response = openai.chat.completions.create(\n",
    "                model=MODEL_GPT,\n",
    "                messages=messages,\n",
    "                stream=True\n",
    "              )\n",
    "\n",
    "  return stream_response(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "def chatOllama(question):\n",
    "  messages = build_message(question)\n",
    "  \n",
    "  if not messages:\n",
    "    print(\"No messages provided\")\n",
    "    return\n",
    "    \n",
    "  response = openai.chat.completions.create(\n",
    "                model=MODEL_LLAMA,\n",
    "                messages=messages,\n",
    "                stream=True\n",
    "              )\n",
    "\n",
    "  return stream_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff9d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the openai function\n",
    "chatOpenAI(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362910d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the ollama function\n",
    "chatOllama(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c579554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update question and recall functions\n",
    "chatOpenAI(\"explain the use of enumerate in python\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
