{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8758c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# System prompt\n",
    "system_prompt = \"\"\"\n",
    "You are an expert assistant specialized in analyzing content from  YouTube videos and websites.\n",
    "You will be given the full transcript or text content, and you need to summarize it clearly and concisely.\n",
    "\"\"\"\n",
    "\n",
    "#User prompt\n",
    "userPrompt=\"\"\"\n",
    "Provide the summary of the following content\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5adb72c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(url):\n",
    "    loader = WebBaseLoader(\n",
    "    web_paths=(url,),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    " )\n",
    "\n",
    "    documents=loader.load()\n",
    "    if  documents:\n",
    "          page_text = \"\"\n",
    "          for doc in documents:\n",
    "                    page_text += doc.page_content + \"\\n\"\n",
    "                    if page_text.strip():\n",
    "                        OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "                        ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
    "                        response = ollama.chat.completions.create(model=\"llama3.2\",  messages=[{\"role\":\"system\", \"content\":system_prompt}, {\"role\":\"user\", \"content\":userPrompt + \"\\n\" +page_text}])\n",
    "                        response=response.choices[0].message.content\n",
    "                        display(Markdown(response))\n",
    "                    else:\n",
    "                        display(Markdown(\"Could not extract content from the URL\"))\n",
    "    else:\n",
    "        display(Markdown(\"Could not extract content from the URL\"))\n",
    "                  \n",
    "                  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b8dbae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'll provide a response in the format requested.\n",
       "\n",
       "### Analysis and Insights\n",
       "\n",
       "A plethora of challenges and limitations are discussed regarding LLM-centered agents, including finite context length, long-term planning and task decomposition, and reliability of natural language interfaces. Several potential solutions are proposed or being researched, such as:\n",
       "\n",
       "1.  Vector stores and retrieval to provide access to a larger knowledge pool.\n",
       "2.  Mechanisms like self-reflection to learn from past mistakes with improved context windows.\n",
       "3.  In-context reinforcement learning with algorithm distillation to improve robustness over lengthy histories.\n",
       "\n",
       "Moreover, new techniques are being developed to tackle challenges in tool augmentation, such as API-banking and toolformer, which enable LLMs to effectively utilize external tools.\n",
       "\n",
       "### Research Directions\n",
       "\n",
       "Several research endeavors are actively underway to address these limitations:\n",
       "\n",
       "*   **Optimizing Large Language Models**: Methods for improving the efficiency and effectiveness of LLMs continue to emerge.\n",
       "    *   Techniques such as prompt engineering using chains-of-thought prompts (Weng, 2023) or chain of hindsight alignment (Liu et al., 2023) can help refine model understandings.\n",
       "*   **Integrating External Tools**: Tools like AutoGPT and GPT-Engineer provide platforms for augmenting LLM capabilities with external tools.\n",
       "    *   As developers continue to develop new tool interfaces, we'll likely see more seamless integrations of these LLM-powered agents.\n",
       "\n",
       "### Potential Outcomes\n",
       "\n",
       "When these limitations are addressed using the mentioned techniques, it may allow us to build:\n",
       "\n",
       "*   More robust and adaptive autonomous agents.\n",
       "*   Effective tools for knowledge graph construction, reasoning with ambiguity \n",
       "    such as handling multiple contextual windows effectively.\n",
       "\n",
       "By continuing the research in aforementioned challenges as well in improving models efficiency we can further explore areas such as:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab6d61f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
