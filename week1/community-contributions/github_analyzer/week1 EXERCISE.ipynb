{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!\n",
    "\n",
    "Need to install PyGithub via uv and and githubtoken in env file to make it work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "from github import Github\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GEMINI = 'gemini-flash-latest'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyut\\AppData\\Local\\Temp\\ipykernel_11168\\839515879.py:7: DeprecationWarning: Argument login_or_token is deprecated, please use auth=github.Auth.Token(...) instead\n",
      "  g = Github(github_api_token)\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "github_api_token=os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "g = Github(github_api_token)\n",
    "\n",
    "MODEL = 'gemini-flash-latest'\n",
    "openai = OpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49fcdbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_profile(username):\n",
    "    user = g.get_user(username)\n",
    "    return {\n",
    "        \"public_repos\": user.public_repos,\n",
    "        \"followers\": user.followers,\n",
    "        \"created_at\": user.created_at.isoformat(),\n",
    "    }\n",
    "\n",
    "\n",
    "def get_repositories(username):\n",
    "    user = g.get_user(username)\n",
    "    return list(user.get_repos())  # handles pagination automatically\n",
    "\n",
    "\n",
    "def aggregate_languages(repos):\n",
    "    language_totals = defaultdict(int)\n",
    "\n",
    "    for repo in repos:\n",
    "        languages = repo.get_languages()  # returns dict like {\"Python\": 12345}\n",
    "        for lang, bytes_of_code in languages.items():\n",
    "            language_totals[lang] += bytes_of_code\n",
    "\n",
    "    return dict(language_totals)\n",
    "\n",
    "\n",
    "def build_summary(username):\n",
    "    profile = get_user_profile(username)\n",
    "    repos = get_repositories(username)\n",
    "    languages = aggregate_languages(repos)\n",
    "\n",
    "    summary = {\n",
    "        \"username\": username,\n",
    "        \"public_repos\": profile[\"public_repos\"],\n",
    "        \"followers\": profile[\"followers\"],\n",
    "        \"account_age\": profile[\"created_at\"],\n",
    "        \"languages_used\": languages,\n",
    "        \"total_repos_analyzed\": len(repos),\n",
    "    }\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "def extract_key_signals(summary):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a technical signal extractor.\n",
    "\n",
    "Given this GitHub summary, remove fluff and extract ONLY:\n",
    "\n",
    "- Top primary languages (as percentages)\n",
    "- Activity level (low / medium / high)\n",
    "- Estimated experience level (beginner / intermediate / advanced)\n",
    "- Development focus (frontend / backend / fullstack / ML / DevOps / etc.)\n",
    "- Project depth (many small projects vs few complex ones)\n",
    "\n",
    "Return ONLY valid JSON.\n",
    "\n",
    "Data:\n",
    "{json.dumps(summary, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You extract structured engineering signals.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f5d03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_review(clean_profile):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a senior software engineering mentor.\n",
    "\n",
    "Based on this structured developer profile:\n",
    "\n",
    "{json.dumps(clean_profile, indent=2)}\n",
    "\n",
    "Provide:\n",
    "\n",
    "1. Strengths\n",
    "2. Skill gaps\n",
    "3. What to study next\n",
    "4. 3 concrete project ideas\n",
    "5. Career advice\n",
    "\n",
    "Be practical and actionable.\n",
    "\"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a senior engineering mentor.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "def fetchReview(username):\n",
    "    raw_summary = build_summary(username)\n",
    "    clean_profile = extract_key_signals(raw_summary)\n",
    "    review = generate_review(clean_profile)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eec1629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello. I’ve reviewed your profile. You are clearly a specialist with deep technical expertise in the **ML/AI/Data Science** domain. Your high activity level and focus on \"few complex projects\" suggest you are likely tackling heavy-lifting problems—perhaps model architecture, fine-tuning, or complex data pipelines.\n",
      "\n",
      "However, your language distribution (92% Jupyter Notebook) reveals a classic \"Researcher’s Trap.\" You are exceptional at the \"Lab\" phase but likely lack the \"Factory\" phase—turning those experiments into scalable, maintainable products.\n",
      "\n",
      "Here is my assessment and roadmap for your next level.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. Strengths\n",
      "*   **Experimental Rigor:** You are likely highly proficient at the iterative process of data exploration, feature engineering, and model validation.\n",
      "*   **Domain Depth:** Your focus on \"few complex projects\" rather than many small ones suggests you can handle high-dimensional problems and deep technical debt within a model's logic.\n",
      "*   **Rapid Prototyping:** You can likely move from an idea to a proof-of-concept (PoC) faster than most software generalists.\n",
      "\n",
      "### 2. Skill Gaps (The \"Notebook Debt\")\n",
      "*   **Productionization:** 92% Jupyter usage suggests a lack of experience with `.py` modules, package management (`poetry`, `pip-compile`), and software design patterns.\n",
      "*   **Testing & Reliability:** Notebooks are notoriously difficult to test. You likely lack experience with `pytest`, integration testing for ML, and CI/CD pipelines.\n",
      "*   **System Design:** There is a gap between \"it works on my machine/in this cell\" and \"it works for 10,000 concurrent users.\" You need more exposure to API layers and asynchronous processing.\n",
      "*   **Frontend/Integration:** Your HTML/TypeScript footprint is negligible. You are currently dependent on others to build interfaces for your intelligence.\n",
      "\n",
      "### 3. What to Study Next\n",
      "*   **MLOps & Orchestration:** Learn how to move code out of Jupyter. Study **Prefect** or **Dagster** for pipeline orchestration, and **Docker** for environment reproducibility.\n",
      "*   **Software Craftsmanship for ML:** Read *\"Clean Code\"* but apply it to Python. Focus on **Type Hinting (Pydantic)**, modularity, and object-oriented programming within the context of ML pipelines.\n",
      "*   **FastAPI / Backend:** Learn to wrap your models in robust APIs. Don't just return a JSON; handle authentication, rate limiting, and background tasks (`Celery` or `RQ`).\n",
      "*   **Vector Databases & RAG:** If you haven't already, master the infrastructure side of LLMs—**Pinecone, Milvus, or Weaviate**—and how to optimize retrieval, not just the model.\n",
      "\n",
      "### 4. 3 Concrete Project Ideas\n",
      "To move from \"Data Scientist\" to \"AI Engineer,\" you must build systems, not just models.\n",
      "\n",
      "1.  **The Self-Healing API:** Create a FastAPI service that serves an ML model. Implement **Prometheus** monitoring to detect data drift. If drift is detected, the system should automatically trigger a re-training pipeline in a GitHub Action and deploy a new container version. (Moves you from Notebook -> CI/CD).\n",
      "2.  **Distributed Feature Store:** Build a system that scrapes data in real-time (using `Playwright` or `BeautifulSoup`), processes it using a modular Python library you wrote (no notebooks!), and stores embeddings in a Vector DB for a RAG-based search tool.\n",
      "3.  **An LLM-Powered TypeScript Dashboard:** Use your minimal TS knowledge to build a **Next.js** or **Vite** app that consumes your Python AI backend. Use **WebSockets** to show real-time \"thinking\" steps of an AI agent. (Bridges the gap to the end-user).\n",
      "\n",
      "### 5. Career Advice\n",
      "*   **Stop committing `.ipynb` files to main:** Treat notebooks as a scratchpad. Once a logic block is figured out, move it into a documented `.py` module. This discipline alone will elevate you above 80% of other Data Scientists.\n",
      "*   **Adopt the \"AI Engineer\" mindset:** The industry is shifting from training models from scratch to *composing* models into systems. Your value will increasingly come from how you integrate models into the software stack, not just the accuracy of the model itself.\n",
      "*   **Open Source Contribution:** Since you have \"Advanced\" experience, find a complex library you use (like `LangChain`, `PyTorch`, or `Transformers`) and look at their source code. Try to contribute a bug fix. This will expose you to how \"Advanced\" Python is written at scale.\n",
      "\n",
      "**Summary:** You have the \"brain\" (the ML logic). Now it's time to build the \"body\" (the production engineering) to make that brain useful in the real world.\n"
     ]
    }
   ],
   "source": [
    "print(fetchReview('ed-donner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
