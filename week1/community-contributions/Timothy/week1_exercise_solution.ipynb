{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# End of week 1 exercise\n",
        "\n",
        "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
        "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
      ],
      "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI\n"
      ],
      "execution_count": 13,
      "outputs": [],
      "id": "c1070317-3ed9-4659-abe3-828943230e03"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# constants\n",
        "\n",
        "MODEL_GPT = 'gpt-4o-mini'\n",
        "MODEL_LLAMA = 'llama3.2:1b'"
      ],
      "execution_count": 14,
      "outputs": [],
      "id": "4a456906-915a-4bfd-bb9d-57e505c5093f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# set up environment\n",
        "\n",
        "load_dotenv(override=True)\n",
        "openrouter_api_key = os.getenv('OPENROUTER_API_KEY')\n",
        "\n",
        "if openrouter_api_key and openrouter_api_key.startswith('sk-or-') and len(openrouter_api_key)>10:\n",
        "    print(\"API key looks good so far\")\n",
        "else:\n",
        "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "API key looks good so far\n"
          ]
        }
      ],
      "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# here is the question; type over this to ask something new\n",
        "\n",
        "question = \"\"\"\n",
        "Please explain what this code does and why:\n",
        "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
        "\"\"\"\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [],
      "id": "3f0d0137-52b0-47a8-81a8-11a90a010798"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#prompts\n",
        "system_prompt = \"You are a helpful technical tutor who answers questions about python code, software engineering, data science and LLMs\"\n",
        "user_prompt = \"Please give a detailed explanation to the following question: \" + question"
      ],
      "execution_count": 17,
      "outputs": [],
      "id": "5c6245b6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# messages\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\", \"content\": user_prompt}\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": [],
      "id": "07babe7b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "openrouter_url = \"https://openrouter.ai/api/v1\"\n",
        "\n",
        "openrouter= OpenAI(base_url=openrouter_url, api_key=openrouter_api_key)"
      ],
      "execution_count": 19,
      "outputs": [],
      "id": "ff3585d5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
        "\n",
        "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')"
      ],
      "execution_count": 20,
      "outputs": [],
      "id": "1a0ab5a0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "response=openrouter.chat.completions.create(model=MODEL_GPT,messages=messages)\n",
        "\n",
        "result=response.choices[0].message.content\n",
        "print(result)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The code you've presented uses a combination of Python's `yield` statement and a set comprehension. Let's break down the key components and explain each part.\n",
            "\n",
            "### Breakdown of the Code\n",
            "\n",
            "1. **`books`**: \n",
            "   - This variable is presumably a collection (like a list) of dictionaries, where each dictionary represents a book. Each book dictionary is expected to contain various keys, one of which is \"author\".\n",
            "\n",
            "2. **`book.get(\"author\")`**:\n",
            "   - The `get` method is being called on each `book` dictionary. This retrieves the value associated with the key \"author\". If the key does not exist, `get` will return `None` instead of raising an error.\n",
            "\n",
            "3. **`if book.get(\"author\")`**:\n",
            "   - This is a conditional check. It ensures that only books with a valid (non-None) author are considered. Books that do not have the \"author\" key or whose \"author\" value is `None` will be filtered out of the result.\n",
            "\n",
            "4. **Set Comprehension `{ ... for book in books if book.get(\"author\") }`**:\n",
            "   - This part creates a set. The syntax `{ ... for ... in ... if ... }` is used to construct a set from the filtered authors. The comprehension iterates over each `book` in `books`, checking for authors and adding them to the set.\n",
            "   - Using a set removes any duplicates; if multiple books have the same author, that author will only appear once in the resulting set.\n",
            "\n",
            "5. **`yield from`**:\n",
            "   - The `yield` statement is used in Python to create a generator. A generator is a special type of iterator that allows you to iterate over a sequence of values, but does not store them all in memory at once.\n",
            "   - The `yield from` syntax specifically delegates the yielding of values to another generator or iterable. In this case, it will yield each author from the set of unique authors created by the set comprehension.\n",
            "\n",
            "### What the Code Does\n",
            "\n",
            "Putting it all together, this line of code does the following:\n",
            "\n",
            "- It iterates over a collection of book dictionaries.\n",
            "- It extracts the authors of the books where the author exists (i.e., it is neither `None` nor missing).\n",
            "- It constructs a set of unique authors from that collection to ensure no duplicates.\n",
            "- It then yields each author one by one, allowing this function to be used as a generator.\n",
            "\n",
            "### Example in Context\n",
            "\n",
            "Hereâ€™s an example to illustrate:\n",
            "\n",
            "```python\n",
            "books = [\n",
            "    {'title': 'Book A', 'author': 'Author 1'},\n",
            "    {'title': 'Book B', 'author': 'Author 2'},\n",
            "    {'title': 'Book C', 'author': 'Author 1'},  # Duplicate author\n",
            "    {'title': 'Book D'},  # No author\n",
            "    {'title': 'Book E', 'author': 'Author 3'},\n",
            "]\n",
            "\n",
            "def get_unique_authors(books):\n",
            "    yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
            "\n",
            "# Using the generator function\n",
            "for author in get_unique_authors(books):\n",
            "    print(author)\n",
            "```\n",
            "\n",
            "### Why Using This Approach?\n",
            "\n",
            "1. **Efficient Memory Use**: By using a generator (`yield from`), it only generates the authors as they are needed rather than storing them all at once in memory, which can be beneficial when dealing with large datasets.\n",
            "\n",
            "2. **Elimination of Duplicates**: The use of a set comprehension guarantees that each author will only be yielded once, simplifying downstream processing if the uniqueness of authors is required.\n",
            "\n",
            "3. **Readability**: The combination of comprehensions and `yield from` tends to make the code concise and clear to those who are familiar with Python's features.\n",
            "\n",
            "### Conclusion\n",
            "\n",
            "In summary, this Python code snippet is designed to create a generator that yields unique authors from a list of book dictionaries. It leverages set comprehensions and the `yield from` construct to provide an efficient and clear way to handle the potential presence of duplicates and missing values in the author field.\n"
          ]
        }
      ],
      "id": "b52ab4a4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# streaming function\n",
        "def stream_response(model_type=\"openrouter\"):\n",
        "    if model_type == \"openrouter\":\n",
        "        client, model = openrouter, MODEL_GPT\n",
        "    elif model_type == \"ollama\":\n",
        "        client, model = ollama, MODEL_LLAMA\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model_type '{model_type}'. Choose 'openrouter' or 'ollama'.\")\n",
        "\n",
        "    stream = client.chat.completions.create(model=model, messages=messages, stream=True)\n",
        "\n",
        "    response = \"\"\n",
        "    display_handle = display(Markdown(\"\"), display_id=True)\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or ''\n",
        "        update_display(Markdown(response), display_id=display_handle.display_id)"
      ],
      "execution_count": 21,
      "outputs": [],
      "id": "973bde44"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get gpt-4o-mini to answer, with streaming\n",
        "stream_response(\"openrouter\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get Llama 3.2 to answer\n",
        "requests.get(\"http://localhost:11434\").content"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Ollama is running'"
            ]
          }
        }
      ],
      "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "response=ollama.chat.completions.create(model=MODEL_LLAMA,messages=messages)\n",
        "\n",
        "result=response.choices[0].message.content\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "183145a3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get Llama 3.2 to answer, with streaming\n",
        "stream_response(\"ollama\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ae5b271f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown, HTML\n",
        "\n",
        "SYSTEM_PROMPT = (\n",
        "    \"You are a helpful technical tutor who answers questions about \"\n",
        "    \"Python code, software engineering, data science and LLMs.\"\n",
        ")\n",
        "\n",
        "CHOICE_GPT   = \"openrouter\"\n",
        "CHOICE_LLAMA = \"ollama\"\n",
        "\n",
        "def get_explanation(question: str, model_choice: str) -> str:\n",
        "    msgs = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\",   \"content\": question},\n",
        "    ]\n",
        "    try:\n",
        "        if model_choice == CHOICE_GPT:\n",
        "            stream = openrouter.chat.completions.create(model=MODEL_GPT, messages=msgs, stream=True)\n",
        "        else:\n",
        "            stream = ollama.chat.completions.create(model=MODEL_LLAMA, messages=msgs, stream=True)\n",
        "        return \"\".join(chunk.choices[0].delta.content or \"\" for chunk in stream)\n",
        "    except Exception as e:\n",
        "        return f\"**Error:** {e}\"\n",
        "\n",
        "# â”€â”€ gradient background wrapper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "display(HTML(\"\"\"\n",
        "<style>\n",
        "  #tutor-wrap {\n",
        "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "    border-radius: 14px;\n",
        "    padding: 20px 24px 24px;\n",
        "    width: 560px;\n",
        "    margin-bottom: 4px;\n",
        "  }\n",
        "  #tutor-wrap .tutor-title {\n",
        "    color: #fff;\n",
        "    font-size: 16px;\n",
        "    font-weight: 700;\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\n",
        "    margin-bottom: 14px;\n",
        "    letter-spacing: .3px;\n",
        "  }\n",
        "  /* inactive toggle: solid dark purple, white text */\n",
        "  .tutor-toggle .widget-toggle-button {\n",
        "    background: #4c2e8a !important;\n",
        "    color: #e8d9ff !important;\n",
        "    border: 2px solid #7c5cbf !important;\n",
        "    border-radius: 8px !important;\n",
        "    font-weight: 600 !important;\n",
        "    font-size: 13px !important;\n",
        "  }\n",
        "  /* active toggle: bright white background, deep purple text */\n",
        "  .tutor-toggle .widget-toggle-button.mod-active {\n",
        "    background: #ffffff !important;\n",
        "    color: #4c2e8a !important;\n",
        "    border: 2px solid #ffffff !important;\n",
        "    font-weight: 800 !important;\n",
        "  }\n",
        "  .tutor-textarea textarea {\n",
        "    border-radius: 8px !important;\n",
        "    border: none !important;\n",
        "    background: rgba(255,255,255,0.92) !important;\n",
        "    font-size: 13px !important;\n",
        "    padding: 10px 12px !important;\n",
        "  }\n",
        "  .tutor-ask-btn button {\n",
        "    background: linear-gradient(135deg, #f9a825 0%, #f06292 100%) !important;\n",
        "    color: #fff !important;\n",
        "    border: none !important;\n",
        "    border-radius: 8px !important;\n",
        "    font-weight: 700 !important;\n",
        "    font-size: 13px !important;\n",
        "    letter-spacing: .3px !important;\n",
        "    box-shadow: 0 2px 8px rgba(240,98,146,0.4) !important;\n",
        "  }\n",
        "  .tutor-ask-btn button:hover {\n",
        "    background: linear-gradient(135deg, #fbc02d 0%, #e91e8c 100%) !important;\n",
        "  }\n",
        "  .tutor-loader { color: rgba(255,255,255,0.85); font-size: 13px; }\n",
        "</style>\n",
        "<div id=\"tutor-wrap\">\n",
        "  <div class=\"tutor-title\">ğŸ“ Technical Question Assistant</div>\n",
        "</div>\n",
        "\"\"\"))\n",
        "\n",
        "# â”€â”€ model toggle â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "model_toggle = widgets.ToggleButtons(\n",
        "    options=[(\" GPT-4o-mini\", CHOICE_GPT), (\" Llama 3.2\", CHOICE_LLAMA)],\n",
        "    value=CHOICE_GPT,\n",
        "    style=widgets.ToggleButtonsStyle(button_width=\"150px\"),\n",
        ")\n",
        "model_toggle.add_class(\"tutor-toggle\")\n",
        "\n",
        "# â”€â”€ question input â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "question_box = widgets.Textarea(\n",
        "    placeholder=\"Type your technical question here...\",\n",
        "    layout=widgets.Layout(width=\"100%\", height=\"100px\"),\n",
        ")\n",
        "question_box.add_class(\"tutor-textarea\")\n",
        "\n",
        "# â”€â”€ submit + loader â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "submit_button = widgets.Button(\n",
        "    description=\"Ask \",\n",
        "    layout=widgets.Layout(width=\"90px\", height=\"34px\"),\n",
        ")\n",
        "submit_button.style.button_color = \"#f06292\"\n",
        "submit_button.style.text_color   = \"#ffffff\"\n",
        "\n",
        "loader_label = widgets.Label(value=\"\")\n",
        "loader_label.style.text_color = \"#ffffff\"\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "# â”€â”€ logic (identical to before) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def on_submit(_):\n",
        "    output_area.clear_output()\n",
        "    question = question_box.value.strip()\n",
        "    if not question:\n",
        "        with output_area:\n",
        "            print(\"Please enter a question.\")\n",
        "        return\n",
        "\n",
        "    loader_label.value     = \"â³ Thinking...\"\n",
        "    submit_button.disabled = True\n",
        "\n",
        "    label  = \"GPT-4o-mini\" if model_toggle.value == CHOICE_GPT else \"Llama 3.2\"\n",
        "    answer = get_explanation(question, model_toggle.value)\n",
        "\n",
        "    loader_label.value     = \"\"\n",
        "    submit_button.disabled = False\n",
        "\n",
        "    with output_area:\n",
        "        print(f\" Model: {label}\")\n",
        "        print(f\" Question: {question}\\n\")\n",
        "        display(Markdown(answer))\n",
        "        print(\"\\n--- End of response ---\")\n",
        "\n",
        "submit_button.on_click(on_submit)\n",
        "\n",
        "display(\n",
        "    model_toggle,\n",
        "    question_box,\n",
        "    widgets.HBox([submit_button, loader_label],\n",
        "                 layout=widgets.Layout(align_items=\"center\", margin=\"6px 0 0 0\")),\n",
        "    output_area,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "  #tutor-wrap {\n",
              "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
              "    border-radius: 14px;\n",
              "    padding: 20px 24px 24px;\n",
              "    width: 560px;\n",
              "    margin-bottom: 4px;\n",
              "  }\n",
              "  #tutor-wrap .tutor-title {\n",
              "    color: #fff;\n",
              "    font-size: 16px;\n",
              "    font-weight: 700;\n",
              "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\n",
              "    margin-bottom: 14px;\n",
              "    letter-spacing: .3px;\n",
              "  }\n",
              "  /* inactive toggle: solid dark purple, white text */\n",
              "  .tutor-toggle .widget-toggle-button {\n",
              "    background: #4c2e8a !important;\n",
              "    color: #e8d9ff !important;\n",
              "    border: 2px solid #7c5cbf !important;\n",
              "    border-radius: 8px !important;\n",
              "    font-weight: 600 !important;\n",
              "    font-size: 13px !important;\n",
              "  }\n",
              "  /* active toggle: bright white background, deep purple text */\n",
              "  .tutor-toggle .widget-toggle-button.mod-active {\n",
              "    background: #ffffff !important;\n",
              "    color: #4c2e8a !important;\n",
              "    border: 2px solid #ffffff !important;\n",
              "    font-weight: 800 !important;\n",
              "  }\n",
              "  .tutor-textarea textarea {\n",
              "    border-radius: 8px !important;\n",
              "    border: none !important;\n",
              "    background: rgba(255,255,255,0.92) !important;\n",
              "    font-size: 13px !important;\n",
              "    padding: 10px 12px !important;\n",
              "  }\n",
              "  .tutor-ask-btn button {\n",
              "    background: linear-gradient(135deg, #f9a825 0%, #f06292 100%) !important;\n",
              "    color: #fff !important;\n",
              "    border: none !important;\n",
              "    border-radius: 8px !important;\n",
              "    font-weight: 700 !important;\n",
              "    font-size: 13px !important;\n",
              "    letter-spacing: .3px !important;\n",
              "    box-shadow: 0 2px 8px rgba(240,98,146,0.4) !important;\n",
              "  }\n",
              "  .tutor-ask-btn button:hover {\n",
              "    background: linear-gradient(135deg, #fbc02d 0%, #e91e8c 100%) !important;\n",
              "  }\n",
              "  .tutor-loader { color: rgba(255,255,255,0.85); font-size: 13px; }\n",
              "</style>\n",
              "<div id=\"tutor-wrap\">\n",
              "  <div class=\"tutor-title\">ğŸ“ Technical Question Assistant</div>\n",
              "</div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb476b203b2049e5bc2462d80d685d5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "ToggleButtons(_dom_classes=('tutor-toggle',), options=((' GPT-4o-mini', 'openrouter'), (' Llama 3.2', 'ollama'â€¦"
            ]
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03f9a460adab4aa4ba65d9a37e9748c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Textarea(value='', layout=Layout(height='100px', width='100%'), placeholder='Type your technical question hereâ€¦"
            ]
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8df7d30e31304fe4a78ed4a4dd7ce09b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(Button(description='Ask ', layout=Layout(height='34px', width='90px'), style=ButtonStyle(buttonâ€¦"
            ]
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a58c56e97a0947999c814a1c3f9bb008",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          }
        }
      ],
      "id": "dc58efda"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "execution_count": null,
      "outputs": [],
      "id": "381de78b"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}