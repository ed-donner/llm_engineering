{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
      "metadata": {},
      "source": [
        "# End of week 1 exercise\n",
        "\n",
        "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
        "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1070317-3ed9-4659-abe3-828943230e03",
      "metadata": {},
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# constants\n",
        "\n",
        "MODEL_GPT = 'gpt-4o-mini'\n",
        "MODEL_LLAMA = 'llama3.2:1b'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# set up environment\n",
        "\n",
        "load_dotenv(override=True)\n",
        "openrouter_api_key = os.getenv('OPENROUTER_API_KEY')\n",
        "\n",
        "if openrouter_api_key and openrouter_api_key.startswith('sk-or-') and len(openrouter_api_key)>10:\n",
        "    print(\"API key looks good so far\")\n",
        "else:\n",
        "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
      "metadata": {},
      "outputs": [],
      "source": [
        "# here is the question; type over this to ask something new\n",
        "\n",
        "question = \"\"\"\n",
        "Please explain what this code does and why:\n",
        "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5c6245b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "#prompts\n",
        "system_prompt = \"You are a helpful technical tutor who answers questions about python code, software engineering, data science and LLMs\"\n",
        "user_prompt = \"Please give a detailed explanation to the following question: \" + question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "07babe7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# messages\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\", \"content\": user_prompt}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ff3585d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "openrouter_url = \"https://openrouter.ai/api/v1\"\n",
        "\n",
        "openrouter= OpenAI(base_url=openrouter_url, api_key=openrouter_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1a0ab5a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
        "\n",
        "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b52ab4a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "response=openrouter.chat.completions.create(model=MODEL_GPT,messages=messages)\n",
        "\n",
        "result=response.choices[0].message.content\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "973bde44",
      "metadata": {},
      "outputs": [],
      "source": [
        "# streaming function\n",
        "def stream_response(model_type=\"openrouter\"):\n",
        "    if model_type == \"openrouter\":\n",
        "        client, model = openrouter, MODEL_GPT\n",
        "    elif model_type == \"ollama\":\n",
        "        client, model = ollama, MODEL_LLAMA\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model_type '{model_type}'. Choose 'openrouter' or 'ollama'.\")\n",
        "\n",
        "    stream = client.chat.completions.create(model=model, messages=messages, stream=True)\n",
        "\n",
        "    response = \"\"\n",
        "    display_handle = display(Markdown(\"\"), display_id=True)\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or ''\n",
        "        update_display(Markdown(response), display_id=display_handle.display_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get gpt-4o-mini to answer, with streaming\n",
        "stream_response(\"openrouter\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get Llama 3.2 to answer\n",
        "requests.get(\"http://localhost:11434\").content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "183145a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "response=ollama.chat.completions.create(model=MODEL_LLAMA,messages=messages)\n",
        "\n",
        "result=response.choices[0].message.content\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae5b271f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get Llama 3.2 to answer, with streaming\n",
        "stream_response(\"ollama\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc58efda",
      "metadata": {},
      "outputs": [],
      "source": [
        "#human friendly interface\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "SYSTEM_PROMPT = \"You are a helpful technical tutor who answers questions about Python code, software engineering, data science and LLMs.\"\n",
        "\n",
        "model_toggle = widgets.ToggleButtons(\n",
        "    options=[(\"GPT-4o-mini\", \"openrouter\"), (\"Llama 3.2\", \"ollama\")],\n",
        "    value=\"openrouter\",\n",
        "    description=\"Model:\",\n",
        "    style=widgets.ToggleButtonsStyle(button_width=\"120px\"),\n",
        ")\n",
        "\n",
        "question_box = widgets.Textarea(\n",
        "    placeholder=\"Type your technical question here...\",\n",
        "    description=\"Question:\",\n",
        "    layout=widgets.Layout(width=\"600px\", height=\"100px\"),\n",
        "    style={\"description_width\": \"initial\"},\n",
        ")\n",
        "\n",
        "submit_btn   = widgets.Button(description=\"Ask\", button_style=\"primary\")\n",
        "loader_label = widgets.Label(value=\"\")\n",
        "output_area  = widgets.Output()\n",
        "\n",
        "def on_submit(_):\n",
        "    output_area.clear_output()\n",
        "    q = question_box.value.strip()\n",
        "    if not q:\n",
        "        with output_area:\n",
        "            print(\"Please enter a question.\")\n",
        "        return\n",
        "\n",
        "    loader_label.value    = \"‚è≥ Thinking...\"\n",
        "    submit_btn.disabled   = True\n",
        "\n",
        "    msgs = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}, {\"role\": \"user\", \"content\": q}]\n",
        "    try:\n",
        "        if model_toggle.value == \"openrouter\":\n",
        "            stream = openrouter.chat.completions.create(model=MODEL_GPT, messages=msgs, stream=True)\n",
        "        else:\n",
        "            stream = ollama.chat.completions.create(model=MODEL_LLAMA, messages=msgs, stream=True)\n",
        "        answer = \"\".join(chunk.choices[0].delta.content or \"\" for chunk in stream)\n",
        "    except Exception as e:\n",
        "        answer = f\"**Error:** {e}\"\n",
        "\n",
        "    loader_label.value  = \"\"\n",
        "    submit_btn.disabled = False\n",
        "\n",
        "    with output_area:\n",
        "        print(f\"Model: {model_toggle.label}  |  Question: {q}\\n\")\n",
        "        display(Markdown(answer))\n",
        "\n",
        "submit_btn.on_click(on_submit)\n",
        "\n",
        "display(model_toggle, question_box, widgets.HBox([submit_btn, loader_label]), output_area)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "381de78b",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
