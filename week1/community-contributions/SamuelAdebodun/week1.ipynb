{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT = 'gpt-4.1-mini'\n",
    "MODEL_OLLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee0b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup environment variables   \n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"API key is not valid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technical Question Explainer \u2014 choose input mode below\n",
    "USE_INPUT = False  # Set to True to type your question when you run this cell; False = use hardcoded question\n",
    "\n",
    "DEFAULT_QUESTION = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\"\n",
    "\n",
    "if USE_INPUT:\n",
    "    question = input(\"Enter your technical question (or press Enter for default): \").strip()\n",
    "    if not question:\n",
    "        question = DEFAULT_QUESTION.strip()\n",
    "else:\n",
    "    question = DEFAULT_QUESTION\n",
    "\n",
    "print(\"Question to analyze:\")\n",
    "print(question)\n",
    "\n",
    "# Prompts and messages for the model\n",
    "system_prompt = \"You are a helpful technical tutor who answers questions about Python code, software engineering, data science, and LLMs.\"\n",
    "user_prompt = \"Please give a detailed explanation to the following question: \" + question\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87426c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get answer from OpenAI with streaming\n",
    "client = OpenAI()  # uses OPENAI_API_KEY from environment\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=MODEL_GPT,\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content:\n",
    "        response += chunk.choices[0].delta.content\n",
    "        update_display(Markdown(f\"## OpenAI ({MODEL_GPT}) Response:\\n\\n{response}\"), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3257d842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get answer from Ollama (local) with streaming\n",
    "ollama_response = \"\"\n",
    "ollama_handle = display(Markdown(\"\"), display_id=True)\n",
    "\n",
    "for chunk in ollama.chat(model=MODEL_OLLAMA, messages=messages, stream=True):\n",
    "    part = chunk.get(\"message\", {}).get(\"content\", \"\") or \"\"\n",
    "    if part:\n",
    "        ollama_response += part\n",
    "        update_display(Markdown(f\"## Ollama ({MODEL_OLLAMA}) Response:\\n\\n{ollama_response}\"), display_id=ollama_handle.display_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}