{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful technical assistant.\n",
    "You explain programming, AI, cybersecurity, and software engineering concepts clearly.\n",
    "Give concise but clear explanations with examples where appropriate.\n",
    "Respond in markdown. Do not wrap the markdown in a code block.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_prefix = \"\"\"\n",
    "Answer the following technical question clearly and simply:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(question):\n",
    "    \"\"\"Create message list for the LLM.\"\"\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_prefix + question}\n",
    "    ]\n",
    "\n",
    "\n",
    "def explain(question):\n",
    "    \"\"\"Send technical question to Ollama and get explanation.\"\"\"\n",
    "    ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
    "\n",
    "    response = ollama.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages_for(question)\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating explanation...\n",
      "\n",
      "Gemini is an AI chatbot developed by Google. Launched in 2023, it's designed to simulate conversations with humans, providing information on various topics, answering questions, and even generating creative content.\n",
      "\n",
      " Gemini is built using a range of machine learning algorithms and natural language processing (NLP) techniques, which enable it to understand and respond to human input in a seemingly intelligent way.\n",
      "\n",
      "Initially, Google developed Gemini as an alternative to its previous chatbot, Bard. While both bots share some similarities, Gemini is designed to be more interactive and engaging, often using idioms, puns, and even humor in its responses.\n",
      "\n",
      "However, as Gemini became publicly available, concerns were raised about its potential misuse for misinformation or disinformation dissemination. As a result, Google announced that it would no longer be developed or maintained beyond 2023, due to concerns over its potential impact on society.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main entry point for testing.\"\"\"\n",
    "    question = input(\"Enter a technical question: \")\n",
    "    print(\"\\nGenerating explanation...\\n\")\n",
    "    answer = explain(question)\n",
    "    print(answer)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
