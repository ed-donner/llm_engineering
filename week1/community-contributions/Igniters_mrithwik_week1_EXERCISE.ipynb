{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
      "metadata": {},
      "source": [
        "# End of week 1 exercise\n",
        "\n",
        "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
        "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c1070317-3ed9-4659-abe3-828943230e03",
      "metadata": {},
      "outputs": [],
      "source": [
        "# imports\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Define the models to use\n",
        "MODEL_GPT = 'gpt-4o-mini'\n",
        "MODEL_LLAMA = 'llama3.2'\n",
        "\n",
        "#Load the API key from the environment variable\n",
        "load_dotenv(override=True)\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "#Check if the API key is valid\n",
        "if api_key and api_key.startswith('sk-') and len(api_key) > 10:\n",
        "    print(\"API key found\")\n",
        "else:\n",
        "    print(\"No API key found or is not valid\")\n",
        "\n",
        "# Create an instance of the OpenAI client\n",
        "openai_client = OpenAI(api_key=api_key)\n",
        "print(\"OpenAI client instance created\")\n",
        "\n",
        "# Create an instance of the Ollama client\n",
        "# ollama_client = OpenAI(base_url = OLLAMA_BASE_URL, api_key='ollama')\n",
        "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
        "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
        "print(\"Ollama client instance created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4e8a533",
      "metadata": {},
      "outputs": [],
      "source": [
        "# requests.get(\"http://localhost:11434\").content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82fe3461",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !ollama pull llama3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# set up environment\n",
        "question_system_prompt = \"\"\"\n",
        "You are a helpful assistant that can explain technical concepts in a way that is easy to understand even for non-technical people.\n",
        "With the help of the user, you will be able to explain the concept in a way that is easy to understand.\n",
        "\"\"\"\n",
        "question_user_prompt = \"\"\"\n",
        "Please explain what this code does and why:\n",
        "\n",
        "def fetch_website_contents(url):\n",
        "    \n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    title = soup.title.string if soup.title else \"No title found\"\n",
        "    if soup.body:\n",
        "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
        "            irrelevant.decompose()\n",
        "        text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
        "    else:\n",
        "        text = \"\"\n",
        "    return (title + \"\\n\\n\" + text)[:2_000]\n",
        "# \"\"\"\n",
        "\n",
        "\n",
        "# question_user_prompt = \"\"\"\n",
        "# Please explain what the solution to this math question and also the reasoning behind it:\n",
        "\n",
        "# You toss 2 coins. One of them is heads. What's the probability the other is tails? Answer with the probability only\n",
        "# \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get gpt-4o-mini to answer, with streaming\n",
        "stream = openai_client.chat.completions.create(\n",
        "    model = MODEL_GPT,\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": question_system_prompt},\n",
        "        {\"role\": \"user\", \"content\": question_user_prompt}\n",
        "    ],\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "response = \" \"\n",
        "display_handle = display(Markdown(\"\"), display_id=True)\n",
        "for chunk in stream:\n",
        "    response += chunk.choices[0].delta.content or ''\n",
        "    update_display(Markdown(response), display_id=display_handle.display_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get Llama 3.2 to answer (use same client as in constants: ollama)\n",
        "response = ollama.chat.completions.create(\n",
        "    model = MODEL_LLAMA,\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": question_system_prompt},\n",
        "        {\"role\": \"user\", \"content\": question_user_prompt}\n",
        "    ]\n",
        ")\n",
        "result = response.choices[0].message.content\n",
        "display(Markdown(result))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
