{
    "cells": [
     {
      "cell_type": "markdown",
      "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
      "metadata": {},
      "source": [
       "# End of week 1 exercise\n",
       "\n",
       "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
       "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c1070317-3ed9-4659-abe3-828943230e03",
      "metadata": {},
      "outputs": [],
      "source": [
       "# imports\n",
       "\n",
       "import os\n",
       "import json\n",
       "from dotenv import load_dotenv\n",
       "from IPython.display import Markdown, display, update_display\n",
       "from openai import OpenAI"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
      "metadata": {},
      "outputs": [],
      "source": [
       "# constants\n",
       "\n",
       "MODEL_GPT = 'gpt-4o-mini'\n",
       "MODEL_LLAMA = 'llama3.2'"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "There might be a problem with your API key? Please visit the troubleshooting notebook!\n"
        ]
       }
      ],
      "source": [
       "# set up environment\n",
       "\n",
       "# Initialize and constants\n",
       "\n",
       "load_dotenv(override=True)\n",
       "api_key = os.getenv('OPENROUTER_API_KEY')\n",
       "\n",
       "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
       "    print(\"API key looks good so far\")\n",
       "else:\n",
       "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
       "    \n",
       "MODEL = 'gpt-5-nano'\n",
       "openai = OpenAI()\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
      "metadata": {},
      "outputs": [],
      "source": [
       "# here is the question; type over this to ask something new\n",
       "\n",
       "system_prompt = \"\"\"\n",
       "You are genZ assistant and knows how the explain complex concepts in a simple and relatable way.\n",
       "\"\"\"\n",
       "\n",
       "question = \"\"\"\n",
       "Please explain what the concept of caching on the server-side and client-side is, and how it can improve the performance of web applications. Please provide examples of both server-side and client-side caching, and explain the differences between them.\n",
       "\"\"\"\n",
       "\n",
       "messages=[\n",
       "    {\n",
       "      \"role\": \"system\",\n",
       "      \"content\": system_prompt\n",
       "    },\n",
       "        {\n",
       "      \"role\": \"user\",\n",
       "      \"content\": question\n",
       "    }\n",
       "  ]"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 6,
      "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/markdown": [
          "Alright, let‚Äôs break this down into bite-sized pieces!\n",
          "\n",
          "### What is Caching?\n",
          "\n",
          "At its core, **caching** is a way to store copies of files or data so that the next time you need them, you can get them super quickly without having to fetch them from the original source all over again. Think of it like keeping your favorite snacks in your room instead of having to walk all the way to the kitchen every time you want one.\n",
          "\n",
          "### Client-side Caching\n",
          "\n",
          "**Client-side caching** happens in your web browser. When you visit a website, your browser saves certain resources (like images, scripts, and stylesheets) on your device. The next time you visit that site, your browser can use those saved resources instead of downloading them again.\n",
          "\n",
          "**Example of Client-side Caching:**\n",
          "- **Browser Cache:** If you visit a website with a cool logo, your browser saves that logo file. The next time you visit the same site, your browser loads the logo from your local cache instead of downloading it from the internet, making the page load faster.\n",
          "\n",
          "**Benefits:**\n",
          "- Reduces load times for returning visitors.\n",
          "- Saves bandwidth since less data is sent over the internet.\n",
          "  \n",
          "### Server-side Caching\n",
          "\n",
          "**Server-side caching** happens on the server where the web application is hosted. Instead of generating responses every time someone requests a page (which can be resource-intensive), the server saves a copy of the response after it is generated. The next time someone requests that same page, the server delivers the saved version instead of processing everything again.\n",
          "\n",
          "**Example of Server-side Caching:**\n",
          "- **Database Query Cache:** Suppose a blog site shows a list of the latest posts. When a visitor requests this list, the server might query a database to get the posts. If many users want to see the same list, the server can cache that result. So instead of hitting the database every time, it can just serve the cached list for a specific amount of time.\n",
          "\n",
          "**Benefits:**\n",
          "- Reduces server load and response time.\n",
          "- Improves scalability since the server can handle more requests with cached content.\n",
          "\n",
          "### Key Differences\n",
          "\n",
          "1. **Location**: \n",
          "   - Client-side caching occurs in the user's browser.\n",
          "   - Server-side caching happens on the web server.\n",
          "\n",
          "2. **Control**:\n",
          "   - Users have some control over their browser cache (clearing it, for example).\n",
          "   - Developers have control over server-side caching policies and strategies.\n",
          "\n",
          "3. **Scope**:\n",
          "   - Client-side caching is about improving the experience for individuals.\n",
          "   - Server-side caching optimizes resources for all users accessing the server.\n",
          "\n",
          "### Conclusion\n",
          "\n",
          "Caching is like keeping snacks handy to save time and effort. Whether done on the client-side (browser) or server-side, it‚Äôs all about improving performance and making things snappier for users. By using both types of caching effectively, web applications can deliver content faster, save bandwidth, and provide a smoother experience overall! üç™‚ú®"
         ],
         "text/plain": [
          "<IPython.core.display.Markdown object>"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ],
      "source": [
       "# Get gpt-4o-mini to answer, with streaming\n",
       "\n",
       "client = OpenAI(\n",
       "  base_url=\"https://openrouter.ai/api/v1\",\n",
       "  api_key=api_key,\n",
       ")\n",
       "\n",
       "stream = client.chat.completions.create(\n",
       "  model=MODEL_GPT,\n",
       "  messages=messages,stream=True\n",
       ")\n",
       "\n",
       "response=\"\"\n",
       "display_handle = display(Markdown(\"\"), display_id=True)\n",
       "\n",
       "for chunk in stream:\n",
       "    response += chunk.choices[0].delta.content or ''\n",
       "    update_display(Markdown(response), display_id=display_handle.display_id)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/markdown": [
          "Hey there, squad! Let's talk about caching, shall we?\n",
          "\n",
          "**What is caching?**\n",
          "\n",
          "Caching is like having a mental note or a saved copy of something that you can quickly access later. When it comes to web applications, caching reduces the time it takes for your app to fetch data from slower sources, like databases.\n",
          "\n",
          "Imagine you're looking up a friend's phone number on social media. If you've looked them up before, your device (like a smart phone) will show you their number instantly, because it's already saved in your \"cache\" or memory.\n",
          "\n",
          "**Server-side caching**\n",
          "\n",
          "Now, let's talk about server-side caching!\n",
          "\n",
          "Server-side caching occurs on the web server itself. When a user requests a resource (like an image), the web server doesn't have to fetch that file from the original source every time. Instead, it will save a copy of that file in its cache. The next time someone requests the same file, the web server can just serve this pre-saved copy.\n",
          "\n",
          "Example:\n",
          "\n",
          "Facebook uses server-side caching for images and other media files. When you see an image on your Facebook feed, the first time it loads, the image is saved on the Facebook servers (the cache). Next time you visit that post, Facebook can quickly retrieve the pre-saved image from its cache instead of having to fetch the original file.\n",
          "\n",
          "**Benefits:**\n",
          "\n",
          "Server-side caching reduces the server load and makes web applications faster. Fewer requests to slower sources like databases mean faster response times!\n",
          "\n",
          "**Client-side caching (a.k.a browser caching)**\n",
          "\n",
          "Now, let's dive into client-side caching!\n",
          "\n",
          "Client-side caching occurs within your web browser itself (the cache). When you visit a website for the first time, each file (like images, stylesheets, and scripts) is downloaded to your local browser cache. Each subsequent request will prioritize these saved resources over requesting those assets again from the server.\n",
          "\n",
          "Example:\n",
          "\n",
          "Netflix uses client-side caching for videos. The next time you watch an episode on Netflix, your browser can quickly fetch the pre-saved video files from your cache instead of having to download them again from Netflix's servers.\n",
          "\n",
          "**Benefits:**\n",
          "\n",
          "Client-side caching makes web applications faster and reduces bandwidth usage between your browser and server. Fewer requests also mean less latency (delay)!\n",
          "\n",
          "**Differences:**\n",
          "\n",
          "Here are the key differences between server-side and client-side caching:\n",
          "\n",
          "*   Where does caching occur? (Server or browser)\n",
          "*   When is data retrieved from its source accessed in cached vs new request?\n",
          "*   Types of assets that get stored in caches.\n",
          "\n",
          "So, to summarize: Server-side caching occurs on the web server, reducing server load. Client-side caching happens within your browser, prioritizing resources locally. Both improve web performance!\n",
          "\n",
          "Hope this explanation was clear! Do you have more questions about caching?"
         ],
         "text/plain": [
          "<IPython.core.display.Markdown object>"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ],
      "source": [
       "# Get Llama 3.2 to answer\n",
       "\n",
       "openai = OpenAI()\n",
       "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
       "\n",
       "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
       "stream = ollama.chat.completions.create(model=MODEL_LLAMA, messages=messages,stream=True)\n",
       "\n",
       "response=\"\"\n",
       "display_handle = display(Markdown(\"\"), display_id=True)\n",
       "\n",
       "for chunk in stream:\n",
       "    response += chunk.choices[0].delta.content or ''\n",
       "    update_display(Markdown(response), display_id=display_handle.display_id)"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "llm-engineering",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }
   