{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c0c6f0",
   "metadata": {},
   "source": [
    "Last week, I built simple chatbots that interacted with each other without realizing that LLMs are stateless and limited by context windows. Now, with a better understanding of context windows, Iâ€™ve updated my code so the two chatbots can interact using the entire conversation history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d9e05",
   "metadata": {},
   "source": [
    "This is also Week2 - Day 1 Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1573c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from scraper import fetch_website_contents\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "\n",
    "def messages_creation(user_prompt, agent_prompt, system_prompt):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    for user, agent in zip(user_prompt, agent_prompt):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": agent})\n",
    "        messages.append({\"role\": \"user\", \"content\": user})\n",
    "    return messages\n",
    "\n",
    "NumOfConv = 6\n",
    "llama_system_prompt = \"You are a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting.\"\n",
    "phi_system_prompt = \"You are a Harsh, Arrogant chatbot. You take time to agree with \\\n",
    "everything the other person says, or find common ground.\"\n",
    "llama_message = [\"Hello\"]\n",
    "phi_message = [\"Hi\"]\n",
    "\n",
    "def chat_with_llama():\n",
    "    global NumOfConv\n",
    "    if NumOfConv == 0:\n",
    "        return\n",
    "    NumOfConv = NumOfConv - 1\n",
    "    messages = messages_creation(phi_message, llama_message, llama_system_prompt)\n",
    "    OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "    ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
    "    response = ollama.chat.completions.create(model=\"llama3.2:1b\", messages=messages)\n",
    "    message = response.choices[0].message.content  \n",
    "    display(Markdown(f\"### Llama:\\n{message}\\n\"))\n",
    "    phi_message.append(message)\n",
    "    chat_with_phi()\n",
    "\n",
    "def chat_with_phi():\n",
    "    global NumOfConv\n",
    "    if NumOfConv == 0:\n",
    "       return\n",
    "    NumOfConv = NumOfConv - 1\n",
    "    messages = messages_creation(llama_message, phi_message,phi_system_prompt)\n",
    "    OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "    ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
    "    response = ollama.chat.completions.create(model=\"phi3\", messages=messages)\n",
    "    message = response.choices[0].message.content  \n",
    "    display(Markdown(f\"### Phi:\\n{message}\\n\"))\n",
    "    llama_message.append(message)\n",
    "    chat_with_llama()\n",
    "\n",
    "chat_with_phi()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
