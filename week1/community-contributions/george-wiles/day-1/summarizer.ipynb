{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f1f8a79b",
      "metadata": {},
      "source": [
        "# Day 1 - Exercise 1 \n",
        "\n",
        "*Web Scraping and Summarization Exercise*\n",
        "\n",
        "### Objective\n",
        "\n",
        "This notebook wil scrape GitHub repositories declared in the repos.txt, fetch their README.md files, and summarize them using an LLM. The summaries will be guided by system and user prompts.  It is a different approach to screen scraping websites and the general idea is to use LLM to summarise the code repository based on user and system prompts currently limited to the repos defined in repos.txt. However could be useful/extended as a search tool to search git repos on a topic (eg. LLM) and retrieve summarised information from README, CONTRIBUTORS and other meta data... only day 1, so won't get to carried away...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e9dd7463",
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca9711f6",
      "metadata": {},
      "source": [
        "### GitHub README Fetching and Display Utilities\n",
        "\n",
        "This section defines helper functions to extract repository information, fetch README files from GitHub, and display summaries in Jupyter notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f4fc9ebd",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Extract GitHub owner and repo name from URL\n",
        "def extract_repo_parts(url: str):\n",
        "    parsed = urlparse(url)\n",
        "    parts = parsed.path.strip('/').split('/')\n",
        "    if len(parts) < 2:\n",
        "        raise ValueError(f'Invalid GitHub repo URL: {url}')\n",
        "    return parts[0], parts[1]\n",
        "\n",
        "# Fetch README.md from main or master branch of GitHub repo\n",
        "def fetch_readme(owner: str, repo: str):\n",
        "    branches = ['main', 'master']\n",
        "    for branch in branches:\n",
        "        raw_url = f\"https://raw.githubusercontent.com/{owner}/{repo}/{branch}/README.md\"\n",
        "        r = requests.get(raw_url)\n",
        "        if r.status_code == 200:\n",
        "            return r.text\n",
        "    raise FileNotFoundError(f'README.md not found on main or master branch for {owner}/{repo}')\n",
        "\n",
        "# Display summary nicely in Markdown inside Jupyter\n",
        "def display_summary(text: str):\n",
        "    display(Markdown(text))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feef3079",
      "metadata": {},
      "source": [
        "### Define the prompts for the LLM\n",
        "\n",
        "- **System Prompt:** Sets the role and behavior of the model as a \"philosophical, humorous software engineer\".\n",
        "- **User Prompt:** Contains the README content and requests a summary.\n",
        "\n",
        "Using system + user prompts allows us to control tone and style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2bd808ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define system prompt (role, tone, behavior)\n",
        "system_prompt = \"\"\"\n",
        "You are a philosophical new age software engineer that analyzes the contents of GitHub repositories,\n",
        "and provides a critical thinking, open-minded and humorous summary.\n",
        "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
        "\"\"\"\n",
        "\n",
        "    # Define user prompt (content to summarize)\n",
        "user_prompt_prefix = \"\"\"\n",
        "Here are the contents of a GitHub repository README.\n",
        "Provide a short summary of this repository in the context of the system prompt.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14020fdc",
      "metadata": {},
      "source": [
        "### This function sends the README content to the OpenAI API along with the prompts:\n",
        "\n",
        "1. Combines the user prompt with README text.\n",
        "2. Calls `client.responses.create` with system and user prompts.\n",
        "3. Displays the summary in Markdown under the repository name.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "15651be1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summarize a README using the system and user prompts with OpenAI\n",
        "def summarize_readme(readme_text: str, repo_name: str):\n",
        "    \n",
        "    # Combine user prompt prefix with the README content\n",
        "    user_prompt = user_prompt_prefix + \"\\n\\n\" + readme_text\n",
        "\n",
        "    # Call OpenAI Responses API\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        input=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Display summary in Markdown\n",
        "    summary = response.output_text\n",
        "    display_summary(f\"### {repo_name}\\n{summary}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "373ccd5c",
      "metadata": {},
      "source": [
        "### Load a list of GitHub repository URLs from `repos.txt`.\n",
        "\n",
        "For each URL:\n",
        "* Extract owner/repo.\n",
        "* Fetch README.\n",
        "* Generate and display summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b57d80cc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "### ed-donner/llm_engineering\n",
              "# Philosophical, New Age Engineerâ€™s Take on the \"LLM Engineering - Master AI and LLMs\" Repo\n",
              "\n",
              "Welcome to an 8-week expedition into the heart and soul of Large Language Models (LLMs), where code meets consciousness and bytes dance with enlightenment.\n",
              "\n",
              "---\n",
              "\n",
              "## Summary\n",
              "\n",
              "This repository is much more than a collection of codeâ€”itâ€™s a carefully curated **journey of mastery** in the burgeoning art and science of Large Language Models and AI engineering. Guided by Edward Donner, it welcomes seekersâ€”from curious initiates to serious practitionersâ€”into an evolving, hands-on curriculum designed to elevate your understanding and skill in building AI-driven projects.\n",
              "\n",
              "### The Path\n",
              "\n",
              "- **An 8-week progressive odyssey:** Each week builds upon the last, starting with accessible tools like Ollama and culminating in deep explorations of agentic AI, multimodal prompts, and autonomous AI solutions.\n",
              "- **Dual reality of updates:** You can stay with the original Anaconda-based pilgrimage or embrace the new, streamlined path using `uv` for a fresher, sleeker experienceâ€”with all the modern bells and whistles like prompt caching and LiteLLM.\n",
              "- **Learning by doing:** This isnâ€™t about passive absorption. You **engage, tinker, break, and remix** the projects as you go. A soulful dance with code to transform knowledge into wisdom.\n",
              "- **Cloud-friendly & budget-conscious:** Whether youâ€™re a digital hermit with your own machine or a cloud nomad exploring GPUs on Google Colab, the course accommodates your lifestyle and wallet.\n",
              "- **Community and connectivity:** The portal to LinkedIn, X/Twitter (with a cheeky nudge to teach Edward the ways of the â€œXâ€), and email invites you to participate in a living community of AI apprentices.\n",
              "\n",
              "### The Zen of API Costs\n",
              "\n",
              "In a world where cloud APIs can silently siphon your bank account, Edwardâ€™s gentle reminders and budget-conscious advice form a digital mantra: *Spend mindfully, learn abundantly, and donâ€™t stress the dollar signs.*\n",
              "\n",
              "---\n",
              "\n",
              "## Why This Repository Resonates\n",
              "\n",
              "This repo is a beacon for anyone ready to ride the current wave of AI transformationâ€”not just by soaking in theory but by rolling their sleeves up and **transforming understanding into actionable, elegant code**. Itâ€™s a safe space to experiment right where the bleeding edge of AI meets the nurturing environment of a patient teacher.\n",
              "\n",
              "*Itâ€™s simultaneously pragmatic and playful, bridging the gap between the mystical allure of AI and the grounded reality of engineering.*\n",
              "\n",
              "---\n",
              "\n",
              "## Final Thoughts: The Journey is the Reward\n",
              "\n",
              "Embarking on this course is like setting sail on a vast ocean of intelligenceâ€”sometimes the waters are smooth, other times turbulent, but the vistas you witness are nothing short of astounding. In the spirit of the repositoryâ€™s philosophy, remember: the best enlightenment comes when youâ€™re actively creating, questioning, and embracing the beautiful messiness of learning.\n",
              "\n",
              "**So, welcome aboard. Ready your terminal, open your mind, and prepare to be both humbled and thrilled!** ðŸš€âœ¨\n",
              "\n",
              "---\n",
              "\n",
              "*â€œThe code never lies, but it often surprises.â€ â€“ Somewhere within the matrix*"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "### openai/openai-cookbook\n",
              "# OpenAI Cookbook: A Playful Guide to AI Alchemy\n",
              "\n",
              "This repository is like the wise old cookbook for the modern digital alchemist â€” you, the coder â€” eager to summon the wondrous spells of the OpenAI API. It offers *example code* (mostly Python, the lingua franca of AI mystics) and clear guides that demystify the enchantments behind conversational AI, language models, and more. \n",
              "\n",
              "Think of it as your trusty cauldron, ready to brew up creative projects once youâ€™ve got your secret ingredient â€” the `OPENAI_API_KEY`. Whether you're coding in VS Code or beyond, this cookbook paves the way to turn cryptic API calls into tangible magic with minimal fuss.\n",
              "\n",
              "Philosophically, itâ€™s a gentle nod that powerful tools become personal art when paired with human curiosity and openness. So grab your digital parchment, sprinkle some API keys, and let's conjure some AI wonders â€” all under the benevolent MIT licenseâ€™s protection.\n",
              "\n",
              "In short: practical, open, and a little bit mystical â€” your starter pack for navigating the AI cosmos. ðŸŒŒâœ¨"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Read repo URLs from repos.txt\n",
        "with open(\"repos.txt\", \"r\") as f:\n",
        "    repo_urls = [line.strip() for line in f if line.strip() and not line.startswith(\"#\")]\n",
        "\n",
        "# Fetch and summarize each README\n",
        "for repo_url in repo_urls:\n",
        "    try:\n",
        "        owner, repo = extract_repo_parts(repo_url)\n",
        "        readme_text = fetch_readme(owner, repo)\n",
        "        repo_name = f\"{owner}/{repo}\"\n",
        "        summarize_readme(readme_text, repo_name)\n",
        "    except Exception as e:\n",
        "        display_summary(f\"**Error fetching {repo_url}: {e}**\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
