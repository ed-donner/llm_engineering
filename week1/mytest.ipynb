{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a40acb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 (Generative Pre-trained Transformer 4) is a highly advanced, large multimodal model developed by **OpenAI**. It was officially launched in March 2023 and represents a significant leap forward in AI capabilities compared to its predecessors, like GPT-3.5 (the model powering the initial free version of ChatGPT).\n",
      "\n",
      "Here's a breakdown of its key features, improvements, and implications:\n",
      "\n",
      "### Key Features and Improvements of GPT-4:\n",
      "\n",
      "1.  **Enhanced Reasoning and Problem-Solving:**\n",
      "    *   GPT-4 can handle much more complex instructions and intricate problem-solving tasks. It performs significantly better on various professional and academic benchmarks, often scoring in the top percentile (e.g., passing a simulated bar exam with a score around the top 10% of test-takers, compared to GPT-3.5's bottom 10%).\n",
      "    *   It exhibits a greater ability to understand nuance, follow multi-step instructions, and grasp abstract concepts.\n",
      "\n",
      "2.  **Multimodality (Vision Capabilities):**\n",
      "    *   This is one of GPT-4's most groundbreaking features. It can accept **images as input** in addition to text.\n",
      "    *   Users can upload an image and ask GPT-4 questions about it, for example, describing its contents, identifying objects, explaining a diagram, or even interpreting a meme.\n",
      "    *   *Important Note:* While it can *understand* image input, its primary *output* is still text.\n",
      "\n",
      "3.  **Larger Context Window:**\n",
      "    *   GPT-4 can handle significantly more text in a single conversation or prompt. The initial versions could process up to 8,000 tokens (about 6,000 words), and a more advanced version (GPT-4 Turbo) extends this to 128,000 tokens (around 300 pages of text). This allows for much longer conversations, analysis of longer documents, and more complex instructions without losing context.\n",
      "\n",
      "4.  **Improved Accuracy and Factuality:**\n",
      "    *   While still prone to \"hallucinations\" (generating incorrect but plausible-sounding information), GPT-4 shows a marked improvement in factual accuracy compared to previous models. It's less likely to make things up, especially when given specific constraints.\n",
      "\n",
      "5.  **Steerability and Controllability:**\n",
      "    *   GPT-4 is more controllable and \"steerable.\" Users can specify a \"system message\" or \"custom instructions\" that guide the AI's persona, tone, and behavior throughout a conversation. This allows for more consistent and tailored responses.\n",
      "\n",
      "6.  **Enhanced Creativity and Code Generation:**\n",
      "    *   It's more capable of generating creative content, including poems, scripts, musical pieces, and complex code in various programming languages, often with fewer errors and more logical structures.\n",
      "\n",
      "7.  **Safety and Alignment:**\n",
      "    *   OpenAI invested significant resources into safety research for GPT-4. It's trained to be less likely to respond to requests for harmful content (hate speech, self-harm advice, illegal activities) and generally adheres to safety guidelines more robustly than prior models.\n",
      "\n",
      "### How to Access GPT-4:\n",
      "\n",
      "*   **ChatGPT Plus Subscription:** Users can access GPT-4 through the paid ChatGPT Plus subscription, which offers access to the latest model versions, including GPT-4 and GPT-4 Turbo, often with web browsing capabilities (via Bing Search), DALL-E 3 image generation, and advanced data analysis features.\n",
      "*   **OpenAI API:** Developers can integrate GPT-4 into their own applications and services via the OpenAI API, allowing them to build custom solutions on top of the model.\n",
      "*   **Microsoft Copilot (formerly Bing Chat):** Microsoft integrates GPT-4 (and later versions) into its Copilot features across various products, including Windows, Edge browser, and Microsoft 365.\n",
      "*   **Third-Party Applications:** Many other applications and services have integrated GPT-4 to power their AI features.\n",
      "\n",
      "### Limitations:\n",
      "\n",
      "Despite its advancements, GPT-4 still has limitations:\n",
      "\n",
      "*   **Knowledge Cut-off:** Like its predecessors, GPT-4's training data has a specific cut-off date (initially September 2021, later updated for GPT-4 Turbo, but still not real-time unless connected to a search engine). It won't know about events or information that occurred after its last training update unless specifically given access to current web browsing tools.\n",
      "*   **Hallucinations:** While reduced, it can still generate incorrect or nonsensical information, especially when pressed for specifics it doesn't know.\n",
      "*   **Bias:** It can still reflect biases present in its vast training data from the internet.\n",
      "*   **Lack of True Understanding:** It doesn't \"understand\" in the way humans do; it's a sophisticated pattern-matching and prediction machine.\n",
      "*   **Computational Cost:** Running GPT-4 is computationally intensive and therefore more expensive than running smaller models.\n",
      "\n",
      "### Impact:\n",
      "\n",
      "GPT-4 has accelerated the adoption of AI across numerous industries, proving its value in:\n",
      "\n",
      "*   **Education:** Personalized tutoring, content creation.\n",
      "*   **Software Development:** Code generation, debugging, documentation.\n",
      "*   **Customer Service:** More sophisticated chatbots.\n",
      "*   **Content Creation:** Marketing, writing assistance, summarization.\n",
      "*   **Healthcare:** Research assistance, summarizing medical literature.\n",
      "*   **Accessibility:** Describing images for visually impaired users.\n",
      "\n",
      "GPT-4 represents a significant milestone in AI development, pushing the boundaries of what large language models can achieve and paving the way for even more powerful future iterations.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True)\n",
    "Gemni_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "Client = OpenAI(base_url=Gemni_url, api_key=api_key)\n",
    "\n",
    "response = Client.chat.completions.create(\n",
    "    model='gemini-2.5-flash',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'Tell me about the gpt 4 model'\n",
    "\n",
    "    }]\n",
    ")\n",
    "\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31879d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 (Generative Pre-trained Transformer 4) is the **fourth major iteration of OpenAI's highly advanced large language model (LLM)**, released in March 2023. It represents a significant leap forward in AI capabilities compared to its predecessors, particularly GPT-3.5 and earlier versions.\n",
      "\n",
      "Here's a breakdown of its key characteristics, capabilities, and implications:\n",
      "\n",
      "## Key Characteristics and Improvements over GPT-3.5:\n",
      "\n",
      "1.  **Multimodality (Image & Text Input):** This is one of the most groundbreaking features. GPT-4 can not only process and understand text but also **interpret images as input**. For example, you can show it a picture of a fridge's contents and ask for recipe suggestions, or show it a graph and ask it to explain the data. While the output is primarily text, its ability to \"see\" and understand visual information is transformative. (Note: this feature's availability varies across different access points, and some interfaces like standard ChatGPT might only accept text).\n",
      "\n",
      "2.  **Advanced Reasoning and Problem-Solving:** GPT-4 exhibits significantly improved reasoning abilities. It can handle more complex instructions, understand nuances, and perform better on challenging cognitive tasks.\n",
      "    *   **Academic Benchmarks:** It passed simulated bar exams, SATs, and other professional and academic tests with scores that place it among top human test-takers (e.g., scoring in the 90th percentile on the Uniform Bar Exam, compared to GPT-3.5's 10th percentile).\n",
      "    *   **Complex Instructions:** It can follow more elaborate and specific instructions, even when they involve multiple constraints or steps.\n",
      "\n",
      "3.  **Increased Context Window:** GPT-4 can process and generate much longer pieces of text, remembering more of the conversation or document it's working with. This allows for more coherent and extended interactions, and the ability to summarize or analyze larger documents. Original GPT-4 offered up to 32k tokens, with later versions like GPT-4 Turbo expanding this even further (up to 128k tokens, roughly 300 pages of text).\n",
      "\n",
      "4.  **Enhanced Creativity:** It's better at generating creative and original content, including poetry, scripts, musical compositions, and adapting writing styles.\n",
      "\n",
      "5.  **Improved Accuracy and Reduced Hallucinations:** While still prone to errors and \"hallucinations\" (generating plausible-sounding but false information), GPT-4 is generally more factually accurate and less likely to invent information compared to its predecessors.\n",
      "\n",
      "6.  **Steerability:** Developers and users have more control over GPT-4's behavior and tone. Through \"system messages,\" you can instruct the model to adopt a specific persona, follow particular rules, or respond in a certain style.\n",
      "\n",
      "7.  **Safety and Alignment:** OpenAI invested heavily in making GPT-4 safer and more aligned with human values. It's more difficult to prompt it to generate harmful, biased, or inappropriate content.\n",
      "\n",
      "8.  **Coding Prowess:** It's remarkably good at generating, debugging, and explaining code in various programming languages.\n",
      "\n",
      "## How it Works (Simplified):\n",
      "\n",
      "Like its predecessors, GPT-4 is a **transformer-based neural network**. It has been trained on an immense dataset of text and image data from the internet and other sources. Its core function is to predict the next word (or \"token\") in a sequence given the preceding ones. Through this predictive capability, it can generate coherent, contextually relevant, and creative text. The sheer scale of its training data and the number of parameters it utilizes allow it to build a complex understanding of language, facts, and reasoning patterns.\n",
      "\n",
      "## Common Use Cases:\n",
      "\n",
      "*   **Content Creation:** Writing articles, blog posts, marketing copy, scripts, creative stories, and poetry.\n",
      "*   **Summarization:** Condensing long documents, emails, or articles into key points.\n",
      "*   **Code Generation and Debugging:** Writing code, finding errors, and explaining complex programming concepts.\n",
      "*   **Question Answering:** Providing comprehensive answers to a wide range of queries.\n",
      "*   **Translation:** Translating text between different languages.\n",
      "*   **Brainstorming and Ideation:** Generating ideas for projects, businesses, or creative endeavors.\n",
      "*   **Education:** Explaining complex topics, assisting with homework, and creating study materials.\n",
      "*   **Customer Support:** Powering advanced chatbots capable of nuanced interactions.\n",
      "*   **Accessibility:** Describing images for visually impaired users.\n",
      "\n",
      "## Limitations and Concerns:\n",
      "\n",
      "*   **Hallucinations:** Despite improvements, GPT-4 can still generate incorrect or fabricated information. Users must verify critical information.\n",
      "*   **Factual Accuracy:** It's a language model, not a knowledge base. Its knowledge is based on its training data up to a certain cutoff point, and it doesn't have real-time access to the internet unless integrated with specific tools (like Microsoft Copilot or ChatGPT with browsing enabled).\n",
      "*   **Bias:** It can reflect biases present in its training data, leading to potentially discriminatory or unfair outputs.\n",
      "*   **Lack of Real-World Understanding:** It doesn't \"understand\" the world in the way humans do. It processes patterns in data but lacks common sense, consciousness, or personal experience.\n",
      "*   **Ethical Concerns:** Potential for misuse (e.g., generating deepfakes, misinformation, automated phishing), job displacement, and copyright issues related to its training data.\n",
      "*   **Computational Cost:** Running and training models of this scale is extremely expensive.\n",
      "\n",
      "## Accessing GPT-4:\n",
      "\n",
      "*   **ChatGPT Plus:** A paid subscription service for OpenAI's ChatGPT interface, which gives access to GPT-4 (and newer models like GPT-4o).\n",
      "*   **OpenAI API:** Developers can integrate GPT-4 into their own applications and services via the API.\n",
      "*   **Microsoft Products:** GPT-4 powers features in Microsoft's Copilot (formerly Bing Chat), which is integrated into Windows, Edge, and Microsoft 365.\n",
      "*   **Third-Party Applications:** Many other applications and services integrate GPT-4 via the API to enhance their features.\n",
      "\n",
      "GPT-4 represents a monumental step forward in AI capabilities, demonstrating unprecedented proficiency in language understanding, generation, and complex reasoning. It has become a foundational model for many cutting-edge AI applications and continues to evolve with ongoing updates and new versions like GPT-4 Turbo and GPT-4o."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "GEMINI_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "client = OpenAI(base_url=GEMINI_URL, api_key=api_key)\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Tell me about the GPT-4 model\"}\n",
    "    ],\n",
    "    stream=True   # ðŸ”¥ THIS is the key\n",
    ")\n",
    "\n",
    "# Print tokens as they arrive\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a24e6880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The core pillars of LangChain, often considered its foundational components, are:\n",
      "\n",
      "1.  **Models**\n",
      "2.  **Prompts**\n",
      "3.  **Chains**\n",
      "4.  **Retrieval**\n",
      "5.  **Agents**"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "base_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "\n",
    "client = OpenAI(base_url=base_url, api_key=api_key)\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model= 'gemini-2.5-flash',\n",
    "    messages=[\n",
    "        {'role' : 'user','content':'tell me a the just name of pillars of langchain'}\n",
    "\n",
    "    ],\n",
    "    stream = True\n",
    ")\n",
    "\n",
    "\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end='', flush=True)\n",
    "\n",
    "#response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bede58e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Llama\n",
      "* Index"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "gemini_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "client = OpenAI(base_url=gemini_url, api_key=api_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='gemini-2.5-flash',\n",
    "    messages=[\n",
    "        {'role':'user','content':'tell the just the name of pillars of lamaindex'}\n",
    "\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10726c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Engineering (UV)",
   "language": "python",
   "name": "llm-engineering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
