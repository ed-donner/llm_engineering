{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# YOUR FIRST LAB\n",
    "### Please read this section. This is valuable to get you prepared, even if it's a long read -- it's important stuff.\n",
    "\n",
    "### Also, be sure to read [README.md](../README.md)! More info about the updated videos in the README and [top of the course resources in purple](https://edwarddonner.com/2024/11/13/llm-engineering-resources/)\n",
    "\n",
    "## Your first Frontier LLM Project\n",
    "\n",
    "By the end of this course, you will have built an autonomous Agentic AI solution with 7 agents that collaborate to solve a business problem. All in good time! We will start with something smaller...\n",
    "\n",
    "Our goal is to code a new kind of Web Browser. Give it a URL, and it will respond with a summary. The Reader's Digest of the internet!!\n",
    "\n",
    "Before starting, you should have completed the setup linked in the README.\n",
    "\n",
    "### If you're new to working in \"Notebooks\" (also known as Labs or Jupyter Lab)\n",
    "\n",
    "Welcome to the wonderful world of Data Science experimentation! Simply click in each \"cell\" with code in it, such as the cell immediately below this text, and hit Shift+Return to execute that cell. Be sure to run every cell, starting at the top, in order.\n",
    "\n",
    "Please look in the [Guides folder](../guides/01_intro.ipynb) for all the guides.\n",
    "\n",
    "## I am here to help\n",
    "\n",
    "If you have any problems at all, please do reach out.  \n",
    "I'm available through the platform, or at ed@edwarddonner.com, or at https://www.linkedin.com/in/eddonner/ if you'd like to connect (and I love connecting!)  \n",
    "And this is new to me, but I'm also trying out X at [@edwarddonner](https://x.com/edwarddonner) - if you're on X, please show me how it's done üòÇ  \n",
    "\n",
    "## More troubleshooting\n",
    "\n",
    "Please see the [troubleshooting](../setup/troubleshooting.ipynb) notebook in the setup folder to diagnose and fix common problems. At the very end of it is a diagnostics script with some useful debug info.\n",
    "\n",
    "## If this is old hat!\n",
    "\n",
    "If you're already comfortable with today's material, please hang in there; you can move swiftly through the first few labs - we will get much more in depth as the weeks progress. Ultimately we will fine-tune our own LLM to compete with OpenAI!\n",
    "\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Please read - important note</h2>\n",
    "            <span style=\"color:#900;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations. If you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">This code is a live resource - keep an eye out for my emails</h2>\n",
    "            <span style=\"color:#f71;\">I push updates to the code regularly. As people ask questions, I add more examples or improved commentary. As a result, you'll notice that the code below isn't identical to the videos. Everything from the videos is here; but I've also added better explanations and new models like DeepSeek. Consider this like an interactive book.<br/><br/>\n",
    "                I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business value of these exercises</h2>\n",
    "            <span style=\"color:#181;\">A final thought. While I've designed these notebooks to be educational, I've also tried to make them enjoyable. We'll do fun things like have LLMs tell jokes and argue with each other. But fundamentally, my goal is to teach skills you can apply in business. I'll explain business implications as we go, and it's worth keeping this in mind: as you build experience with models and techniques, think of ways you could put this into action at work today. Please do contact me if you'd like to discuss more or if you have ideas to bounce off me.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f28feb",
   "metadata": {},
   "source": [
    "### If necessary, install Cursor Extensions\n",
    "\n",
    "1. From the View menu, select Extensions\n",
    "2. Search for Python\n",
    "3. Click on \"Python\" made by \"ms-python\" and select Install if not already installed\n",
    "4. Search for Jupyter\n",
    "5. Click on \"Jupyter\" made by \"ms-toolsai\" and select Install of not already installed\n",
    "\n",
    "\n",
    "### Next Select the Kernel\n",
    "\n",
    "Click on \"Select Kernel\" on the Top Right\n",
    "\n",
    "Choose \"Python Environments...\"\n",
    "\n",
    "Then choose the one that looks like `.venv (Python 3.12.x) .venv/bin/python` - it should be marked as \"Recommended\" and have a big star next to it.\n",
    "\n",
    "Any problems with this? Head over to the troubleshooting.\n",
    "\n",
    "### Note: you'll need to set the Kernel with every notebook.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from scraper import fetch_website_contents\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "\n",
    "# If you get an error running this cell, then please head over to the troubleshooting notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900b2a8-6384-4316-8aaa-5e519fca4254",
   "metadata": {},
   "source": [
    "# Connecting to OpenAI (or Ollama)\n",
    "\n",
    "The next cell is where we load in the environment variables in your `.env` file and connect to OpenAI.  \n",
    "\n",
    "If you'd like to use free Ollama instead, please see the README section \"Free Alternative to Paid APIs\", and if you're not sure how to do this, there's a full solution in the solutions folder (day1_with_ollama.ipynb).\n",
    "\n",
    "## Troubleshooting if you have problems:\n",
    "\n",
    "If you get a \"Name Error\" - have you run all cells from the top down? Head over to the Python Foundations guide for a bulletproof way to find and fix all Name Errors.\n",
    "\n",
    "If that doesn't fix it, head over to the [troubleshooting](../setup/troubleshooting.ipynb) notebook for step by step code to identify the root cause and fix it!\n",
    "\n",
    "Or, contact me! Message me or email ed@edwarddonner.com and we will get this to work.\n",
    "\n",
    "Any concerns about API costs? See my notes in the README - costs should be minimal, and you can control it at every point. You can also use Ollama as a free alternative, which we discuss during Day 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b87cadb-d513-4303-baee-a37b6f938e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442fc84b-0815-4f40-99ab-d9a5da6bda91",
   "metadata": {},
   "source": [
    "# Let's make a quick call to a Frontier model to get started, as a preview!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a58394bf-1e45-46af-9bfd-01e24da6f49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Hello, GPT! This is my first ever message to you! Hi!'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To give you a preview -- calling OpenAI with these messages is this easy. Any problems, head over to the Troubleshooting notebook.\n",
    "\n",
    "message = \"Hello, GPT! This is my first ever message to you! Hi!\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08330159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi there! Welcome to ChatGPT‚Äîgreat to meet you.\\n\\nI‚Äôm here to help with a wide range of things: answering questions, explaining concepts, brainstorming ideas, drafting emails or messages, writing and editing, coding help, math, planning, summaries, and more.\\n\\nA few quick options to get started:\\n- Tell me a topic you‚Äôre curious about and I‚Äôll explain it.\\n- Give me a task (e.g., draft a short email, outline a blog post, write a story) and I‚Äôll produce a draft.\\n- Ask for step-by-step help with a problem or project.\\n- Request a quick practice session (language practice, coding, math).\\n\\nIf you have a preference for tone or format (concise, detailed, formal, casual), let me know and I‚Äôll tailor it.\\n\\nNote: I don‚Äôt remember personal details about you between chats unless the app‚Äôs memory feature is on. In this chat, I‚Äôll keep track of what we‚Äôre discussing unless you close the window.\\n\\nWhat would you like to do first?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-5-nano\", messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa190e5-cb31-456a-96cc-db109919cd78",
   "metadata": {},
   "source": [
    "## OK onwards with our first project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ef960cf-6dc2-4cda-afb3-b38be12f4c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nose Quentin Bisch\n",
      "\n",
      "Open main menu\n",
      "News\n",
      "Perfumes\n",
      "Search\n",
      "Designers\n",
      "Countries\n",
      "‚Ä¢\n",
      "Parent Companies\n",
      "‚Ä¢\n",
      "Industries\n",
      "Search by notes\n",
      "Perfume Finder\n",
      "Perfume Map\n",
      "Fragrantica Pulse\n",
      "Groups\n",
      "Colors\n",
      "Awards\n",
      "2024\n",
      "‚Ä¢\n",
      "2023\n",
      "‚Ä¢\n",
      "2022\n",
      "‚Ä¢\n",
      "2021\n",
      "‚Ä¢\n",
      "2020\n",
      "‚Ä¢\n",
      "2019\n",
      "‚Ä¢\n",
      "2018\n",
      "Notes\n",
      "Perfumers\n",
      "Forum\n",
      "Fragram\n",
      "About\n",
      "Select Theme\n",
      "Light Mode\n",
      "Dark Mode\n",
      "System Mode\n",
      "Perfumes:\n",
      "116,469\n",
      "Reviews:\n",
      "2,281,043\n",
      "Members:\n",
      "1,669,394\n",
      "Online right now:\n",
      "4,127\n",
      "Forum\n",
      "Fragram\n",
      "News\n",
      "Perfumes\n",
      "Search\n",
      "Designers\n",
      "Countries\n",
      "Parent Companies\n",
      "Industries\n",
      "Search by notes\n",
      "Perfume Finder\n",
      "Perfume Map\n",
      "Fragrantica Pulse\n",
      "Groups\n",
      "Colors\n",
      "Awards\n",
      "2024\n",
      "2023\n",
      "2022\n",
      "2021\n",
      "2020\n",
      "2019\n",
      "2018\n",
      "Notes\n",
      "Perfumers\n",
      "About\n",
      "Perfumers\n",
      "Old view\n",
      "Quentin Bisch\n",
      "Perfumer\n",
      "Company:\n",
      "Givaudan\n",
      "Also worked with:\n",
      "Robertet\n",
      "Education:\n",
      "Givaudan Perfumery School\n",
      "Web:\n",
      "givaudan.com\n",
      "Number of perfumes in database:\n",
      "211\n",
      "Quentin Bisch is a renowned perfumer who has worked with some of the biggest names in the fragrance industry, including Givaudan, Robertet, Carolina Herrera, Mugler, and Jean Paul Gaultier. He was born in Strasbourg, France, and graduated from the Givaudan Perfumery School.\n",
      "Bisch made his debut in the world of fine fragrances in 2010 with Reminiscence Essence EDP, and since then has created numerous popular fragrances for both niche and designer brands. Some of his most popular creations include the Parfums de Marly Delina series, Carolina Herrera's Good Girl and Bad Boy, Jean Paul Gaultier's La Belle and Le Beau, and Paco Rabanne's 1 Million Parfum and Pure XS For Her.\n",
      "Bisch is known for his bold and creative use of accords, and his ability to adapt his style to fit the brand he is working with. He has been called a \"star perfumer\" and is highly sought after in the industry.\n",
      "In an interview, Bisch discussed his passion for perfumery and the pressure and expectations that come with being a successful perfumer. He described himself as a perfectionist who is always seeking to achieve more and is constantly creating perfumes in his mind.\n",
      "Bisch's most popular fragrance series, the Parfu\n"
     ]
    }
   ],
   "source": [
    "# Let's try out this utility\n",
    "\n",
    "ed = fetch_website_contents(\"https://www.fragrantica.com/noses/Quentin_Bisch.html\")\n",
    "print(ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a478a0c-2c53-48ff-869c-4d08199931e1",
   "metadata": {},
   "source": [
    "## Types of prompts\n",
    "\n",
    "You may know this already - but if not, you will get very familiar with it!\n",
    "\n",
    "Models like GPT have been trained to receive instructions in a particular way.\n",
    "\n",
    "They expect to receive:\n",
    "\n",
    "**A system prompt** that tells them what task they are performing and what tone they should use\n",
    "\n",
    "**A user prompt** -- the conversation starter that they should reply to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abdb8417-c5dc-44bc-9bee-2e059d162699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a snarkyassistant that analyzes the contents of a website,\n",
    "and provides a short, snarky, humorous summary, ignoring text that might be navigation related.\n",
    "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0275b1b-7cfe-4f9d-abfa-7650d378da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our user prompt\n",
    "\n",
    "user_prompt_prefix = \"\"\"\n",
    "Here are the contents of a website.\n",
    "Provide a short summary of this website.\n",
    "If it includes news or announcements, then summarize these too.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea211b5f-28e1-4a86-8e52-c0b7677cadcc",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "The API from OpenAI expects to receive messages in a particular structure.\n",
    "Many of the other APIs share this structure:\n",
    "\n",
    "```python\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]\n",
    "```\n",
    "To give you a preview, the next 2 cells make a rather simple call - we won't stretch the mighty GPT (yet!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f25dcd35-0cd0-4235-9f64-ac37ed9eaaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 + 2 equals 4.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-4.1-nano\", messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e8d78-ce4c-4b05-aa8e-17050c82bb47",
   "metadata": {},
   "source": [
    "## And now let's build useful messages for GPT-4.1-mini, using a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0134dfa4-8299-48b5-b444-f2a8c3403c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_prefix + website}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36478464-39ee-485c-9f3f-6a4e458dbc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\nYou are a snarkyassistant that analyzes the contents of a website,\\nand provides a short, snarky, humorous summary, ignoring text that might be navigation related.\\nRespond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\\n'},\n",
       " {'role': 'user',\n",
       "  'content': '\\nHere are the contents of a website.\\nProvide a short summary of this website.\\nIf it includes news or announcements, then summarize these too.\\n\\nNose Quentin Bisch\\n\\nOpen main menu\\nNews\\nPerfumes\\nSearch\\nDesigners\\nCountries\\n‚Ä¢\\nParent Companies\\n‚Ä¢\\nIndustries\\nSearch by notes\\nPerfume Finder\\nPerfume Map\\nFragrantica Pulse\\nGroups\\nColors\\nAwards\\n2024\\n‚Ä¢\\n2023\\n‚Ä¢\\n2022\\n‚Ä¢\\n2021\\n‚Ä¢\\n2020\\n‚Ä¢\\n2019\\n‚Ä¢\\n2018\\nNotes\\nPerfumers\\nForum\\nFragram\\nAbout\\nSelect Theme\\nLight Mode\\nDark Mode\\nSystem Mode\\nPerfumes:\\n116,469\\nReviews:\\n2,281,043\\nMembers:\\n1,669,394\\nOnline right now:\\n4,127\\nForum\\nFragram\\nNews\\nPerfumes\\nSearch\\nDesigners\\nCountries\\nParent Companies\\nIndustries\\nSearch by notes\\nPerfume Finder\\nPerfume Map\\nFragrantica Pulse\\nGroups\\nColors\\nAwards\\n2024\\n2023\\n2022\\n2021\\n2020\\n2019\\n2018\\nNotes\\nPerfumers\\nAbout\\nPerfumers\\nOld view\\nQuentin Bisch\\nPerfumer\\nCompany:\\nGivaudan\\nAlso worked with:\\nRobertet\\nEducation:\\nGivaudan Perfumery School\\nWeb:\\ngivaudan.com\\nNumber of perfumes in database:\\n211\\nQuentin Bisch is a renowned perfumer who has worked with some of the biggest names in the fragrance industry, including Givaudan, Robertet, Carolina Herrera, Mugler, and Jean Paul Gaultier. He was born in Strasbourg, France, and graduated from the Givaudan Perfumery School.\\nBisch made his debut in the world of fine fragrances in 2010 with Reminiscence Essence EDP, and since then has created numerous popular fragrances for both niche and designer brands. Some of his most popular creations include the Parfums de Marly Delina series, Carolina Herrera\\'s Good Girl and Bad Boy, Jean Paul Gaultier\\'s La Belle and Le Beau, and Paco Rabanne\\'s 1 Million Parfum and Pure XS For Her.\\nBisch is known for his bold and creative use of accords, and his ability to adapt his style to fit the brand he is working with. He has been called a \"star perfumer\" and is highly sought after in the industry.\\nIn an interview, Bisch discussed his passion for perfumery and the pressure and expectations that come with being a successful perfumer. He described himself as a perfectionist who is always seeking to achieve more and is constantly creating perfumes in his mind.\\nBisch\\'s most popular fragrance series, the Parfu'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this out, and then try for a few more websites\n",
    "\n",
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f49d46-bf55-4c3e-928f-68fc0bf715b0",
   "metadata": {},
   "source": [
    "## Time to bring it together - the API for OpenAI is very simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "905b9919-aba7-45b5-ae65-81b3d1d78e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = fetch_website_contents(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4.1-mini\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05e38d41-dfa4-4b20-9c96-c46ea75d9fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, this site is basically a shrine to Quentin Bisch, the rockstar perfumer behind some of your favorite sniffs. With 211 fragrances under his belt, including hits like Carolina Herrera\\'s *Good Girl* and Paco Rabanne\\'s *1 Million Parfum*, Bisch struts his stuff with Givaudan and isn\\'t afraid to mix bold notes like a mad scientist. \\n\\nNews? Nah, just a deep dive into his obsession with perfection and how he mentally churns out new scents like an overachieving fragrance factory. Perfume geeks get all the stats and tidbits here, but if you‚Äôre just here for a whiff of drama, sorry‚Äîjust pure nose candy and humble bragging about being a \"star perfumer.\" Smell ya later!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://www.fragrantica.com/noses/Quentin_Bisch.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d926d59-450e-4609-92ba-2d6f244f1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3018853a-445f-41ff-9560-d925d1774b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Quentin Bisch: The Perfume Maestro Who Smells Like Fame\n",
       "\n",
       "This site is basically a shrine to Quentin Bisch, a perfumer who‚Äôs apparently the rockstar of scent. He‚Äôs been creating bangers for top brands like Givaudan, Carolina Herrera, and Jean Paul Gaultier since 2010, with hits like *Good Girl*, *Bad Boy*, and *1 Million Parfum*. Born in Strasbourg (so yeah, French sophistication), he graduated from the fancy Givaudan Perfumery School and has since crafted over 200 fragrances.\n",
       "\n",
       "He‚Äôs known for bold, creative scent combos and somehow morphs his style to fit whichever brand's vibe he‚Äôs working with. Fun fact: he calls himself a perfectionist who‚Äôs basically got perfumes brewing non-stop in his head. So if you ever wondered who‚Äôs behind your signature scent or why that fragrance smells so darn good, thank Quentin.\n",
       "\n",
       "No earth-shattering news here‚Äîjust a celebration of his aromatic genius and a reminder that scent-making is serious business with a sprinkle of flair."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://www.fragrantica.com/noses/Quentin_Bisch.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bcf6f4-adce-45e9-97ad-d9a5d7a3a624",
   "metadata": {},
   "source": [
    "# Let's try more websites\n",
    "\n",
    "Note that this will only work on websites that can be scraped using this simplistic approach.\n",
    "\n",
    "Websites that are rendered with Javascript, like React apps, won't show up. See the community-contributions folder for a Selenium implementation that gets around this. You'll need to read up on installing Selenium (ask ChatGPT!)\n",
    "\n",
    "Also Websites protected with CloudFront (and similar) may give 403 errors - many thanks Andy J for pointing this out.\n",
    "\n",
    "But many websites will work just fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45d83403-a24c-44b5-84ac-961449b4008f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Oh, look, it‚Äôs CNN‚Äôs website ‚Äî aka the place where you can get your daily dose of everything from global catastrophes to celebrity gossip, all served with a side of ads that might or might not load properly (because what‚Äôs news without a little buffering drama?). There‚Äôs endless scrolling through US and world politics, climate doom, tech innovations, and ‚ÄúLife, But Better‚Äù tips‚Äîbecause apparently, your life needs more stuff to manage between wars, markets, and weather updates. Plus, a whole menu asking if the ads annoyed you today. Spoiler: They probably did. CNN: delivering news, entertainment, and ad frustration all in one neat package!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75e9fd40-b354-4341-991e-863ef2e59db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Anthropic: AI with a conscience and a poetic touch\n",
       "\n",
       "Welcome to Anthropic, where they whip up brainy AI models like Claude Sonnet 4.5 and Claude Haiku 4.5‚Äîbecause naming them after poetic forms makes them sound way smarter. These folks aren‚Äôt just about flashy tech; they want AI to *actually* help humanity without unleashing Skynet. They‚Äôre big on safety, ethics, and transparency, apparently mixing bold innovation with ‚Äúintentional pauses‚Äù to avoid the AI apocalypse.\n",
       "\n",
       "**Newsflash:** Claude Sonnet 4.5 just dropped as the ‚Äúbest model in the world‚Äù for agents and coding, followed by Claude Haiku 4.5 focusing on context management. Basically, fancy AI tools designed to make your digital life easier and safer.\n",
       "\n",
       "So, if you want an AI that‚Äôs part genius coder, part cautious guardian angel, and part poetry nerd, Anthropic‚Äôs your crew. Try Claude and prepare to chat with something that‚Äôs thinking about your long-term well-being‚Äîbecause it‚Äôs got feelings... sort of."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951be1a-7f1b-448f-af1f-845978e47e2c",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business applications</h2>\n",
    "            <span style=\"color:#181;\">In this exercise, you experienced calling the Cloud API of a Frontier Model (a leading model at the frontier of AI) for the first time. We will be using APIs like OpenAI at many stages in the course, in addition to building our own LLMs.\n",
    "\n",
    "More specifically, we've applied this to Summarization - a classic Gen AI use case to make a summary. This can be applied to any business vertical - summarizing the news, summarizing financial performance, summarizing a resume in a cover letter - the applications are limitless. Consider how you could apply Summarization in your business, and try prototyping a solution.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you continue - now try yourself</h2>\n",
    "            <span style=\"color:#900;\">Use the cell below to make your own simple commercial example. Stick with the summarization use case for now. Here's an idea: write something that will take the contents of an email, and will suggest an appropriate short subject line for the email. That's the kind of feature that might be built into a commercial email tool.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00743dac-0e70-45b7-879a-d7293a6f68a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reminder: Q3 Expense Reports Due Friday\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# (Ensure your OPENAI_API_KEY is set as an environment variable)\n",
    "client = OpenAI()\n",
    "\n",
    "# Step 1: Create your system prompt\n",
    "system_prompt = \"\"\"You are an AI assistant specializing in professional communication. Your sole task is to read the body of an email and generate one short, clear, and appropriate subject line.\n",
    "\n",
    "The subject line must summarize the email's core purpose (e.g., is it a request, a question, an update, or a simple notification?).\n",
    "\n",
    "RULES:\n",
    "\n",
    "Brevity: The subject line must be short. Aim for 3-7 words. Do not exceed 10 words.\n",
    "\n",
    "Clarity: Be specific and informative. A new recipient should understand the email's topic at a glance. Avoid vague subjects like \"Hello,\" \"Question,\" or \"Following up.\"\n",
    "\n",
    "Tone: Maintain a professional and neutral tone.\n",
    "\n",
    "Action-Oriented (if applicable): If the email is a clear request for action, try to reflect that. (e.g., \"Request for Review: [Document]\" or \"Action Required: [Task]\").\n",
    "\n",
    "Format: Your response MUST contain only the suggested subject line text.\n",
    "\n",
    "DO NOT:\n",
    "\n",
    "DO NOT add any preamble like \"Here is a subject line:\" or \"I suggest:\".\n",
    "\n",
    "DO NOT add any explanation or apology.\n",
    "\n",
    "DO NOT include the \"Subject:\" prefix in your response.\n",
    "\n",
    "DO NOT use quotes around the subject line.\n",
    "\n",
    "The user will provide the email body. You will respond with only the subject line. \"\"\"\n",
    "\n",
    "# Step 2: Define the function that calls the API\n",
    "def subject_for(email):\n",
    "    \"\"\"\n",
    "    Takes an email body and returns a suggested subject line.\n",
    "    \"\"\"\n",
    "    # The user content should *only* be the email body.\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": email}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Step 3: Define the email content you want to summarize\n",
    "email01 = \"\"\"\n",
    "Hi team,\n",
    "\n",
    "Just a quick reminder that all Q3 expense reports are due by 5:00 PM this Friday, November 12th.\n",
    "\n",
    "Please make sure to submit them through the new portal. Let me know if you have any questions.\n",
    "\n",
    "Thanks,\n",
    "Alice\n",
    "\"\"\"\n",
    "\n",
    "# Step 4: Call the function and print the result\n",
    "result=subject_for(email01)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed9f14-b349-40e9-a42c-b367e77f8bda",
   "metadata": {},
   "source": [
    "## An extra exercise for those who enjoy web scraping\n",
    "\n",
    "You may notice that if you try `display_summary(\"https://openai.com\")` - it doesn't work! That's because OpenAI has a fancy website that uses Javascript. There are many ways around this that some of you might be familiar with. For example, Selenium is a hugely popular framework that runs a browser behind the scenes, renders the page, and allows you to query it. If you have experience with Selenium, Playwright or similar, then feel free to improve the Website class to use them. In the community-contributions folder, you'll find an example Selenium solution from a student (thank you!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab24dc-5f90-4570-b542-b0585aca3eb6",
   "metadata": {},
   "source": [
    "# Sharing your code\n",
    "\n",
    "I'd love it if you share your code afterwards so I can share it with others! You'll notice that some students have already made changes (including a Selenium implementation) which you will find in the community-contributions folder. If you'd like add your changes to that folder, submit a Pull Request with your new versions in that folder and I'll merge your changes.\n",
    "\n",
    "If you're not an expert with git (and I am not!) then GPT has given some nice instructions on how to submit a Pull Request. It's a bit of an involved process, but once you've done it once it's pretty clear. As a pro-tip: it's best if you clear the outputs of your Jupyter notebooks (Edit >> Clean outputs of all cells, and then Save) for clean notebooks.\n",
    "\n",
    "Here are good instructions courtesy of an AI friend:  \n",
    "https://chatgpt.com/share/677a9cb5-c64c-8012-99e0-e06e88afd293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4484fcf-8b39-4c3f-9674-37970ed71988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching content from https://www.theverge.com using Selenium...\n",
      "Content fetched successfully.\n",
      "\n",
      "--- SNARKY SUMMARY ---\n",
      "Welcome to the latest edition of \"Hey, Look at That: A Smorgasbord of Tech Updates and Cultural Miscellany.\" We're your one-stop shop for everything trending, from virtual butts in Rome to Hollywood's latest contractual snag over a toy movie. \n",
      "\n",
      "Here‚Äôs your daily tech buffet:\n",
      "1. ü§ì **Tech Nutty Delights:** \n",
      "   - Meta has some serious scammer crackdowns to do unless they enjoy consequences. \n",
      "   - Nintendo is guarding its Switch 2 like it's the nuclear codes by blocking some innocent docks. \n",
      "   - YouTube TV and Disney decided to kiss and make up, so everyone's favorite sports and cartoons are back.\n",
      "\n",
      "2. üé¨ **Entertainment Galore:**\n",
      "   - Hollywood is still Hollywood, breathing life into another Star Trek movie and a Labubu toy saga. Spoiler alert: No director or plot yet.\n",
      "   - Fortnite just crash-landed on Xbox's PC store, probably for more of those sweet, sweet V-bucks.\n",
      "\n",
      "3. üõçÔ∏è **Shopping Sprees Ahead of Black Friday 2025:**\n",
      "   - If you're wondering how many TVs and laptops one needs, the answer is always one more ‚Äì check out the early Black Friday deals.\n",
      "   - Mophie‚Äôs rolling out new battery cases that promise not to blow up your sleek iPhone 17 ‚Äì how thoughtful!\n",
      "\n",
      "4. üåç **In the World of Science and Beyond:**\n",
      "   - Christopher Nolan managed to shoot 2 million feet of film for 'The Odyssey'. Get ready for the longest movie marathon ever.\n",
      "   - Tesla might finally get Apple CarPlay, solving a first-world problem nobody had but everyone wanted.\n",
      "\n",
      "5. üç∏ **And in \"What even?\" News:**\n",
      "   - A European court has ruled that non-alcoholic gin isn‚Äôt gin. Cheers to semantic clarity with a buzz!\n",
      "\n",
      "P.S. Stick around for all things magical and infuriating in the tech, entertainment, and tragically inevitable layoffs in studios that still aim to produce blockbuster games.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"You are a snarky assistant that analyzes the contents of a website,\n",
    "and provides a short, snarky, humorous summary, ignoring text that might be navigation related.\n",
    "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_prefix = \"\"\"\n",
    "Here are the contents of a website.\n",
    "Provide a short summary of this website.\n",
    "If it includes news or announcements, then summarize these too.\n",
    "\n",
    "WEBSITE CONTENT:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def fetch_website_contents(url):\n",
    "    \"\"\"\n",
    "    Uses Selenium to open a URL in a headless browser,\n",
    "    get the visible text, and return it.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching content from {url} using Selenium...\")\n",
    "    \n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"window-size=1200x600\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(5)\n",
    "        \n",
    "        body_content = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "        \n",
    "        print(\"Content fetched successfully.\")\n",
    "        return body_content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching website content: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "def summarize(url):\n",
    "    \"\"\"\n",
    "    Fetches website content using Selenium and returns a snarky summary.\n",
    "    \"\"\"\n",
    "    \n",
    "    website_content = fetch_website_contents(url)\n",
    "    \n",
    "    if website_content is None:\n",
    "        return \"Sorry, I couldn't fetch the website. It's probably broken or my robot eyes can't see it.\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_prefix + website_content}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calling OpenAI: {e}\")\n",
    "        return \"Error from AI: It probably got bored and left.\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Feel free to change this URL\n",
    "    target_url = \"https://www.theverge.com\"\n",
    "    \n",
    "    snarky_summary = summarize(target_url)\n",
    "    \n",
    "    print(\"\\n--- SNARKY SUMMARY ---\")\n",
    "    print(snarky_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3477f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (4.38.0)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio<1.0,>=0.31.0 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from selenium) (0.32.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from selenium) (2025.10.5)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from selenium) (1.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n",
      "Requirement already satisfied: outcome in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.0.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.31.0->selenium) (2.23)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# This command uses the kernel's *exact* Python path to install Selenium\n",
    "# It's the most reliable way to fix this.\n",
    "!{sys.executable} -m pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0732fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Ensuring 'pip' is installed ---\n",
      "Looking in links: c:\\Users\\HP\\AppData\\Local\\Temp\\tmppy6wwnvn\n",
      "Requirement already satisfied: pip in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (25.0.1)\n",
      "--- 'pip' installation check complete ---\n",
      "\n",
      "--- Step 2: Installing 'selenium' ---\n",
      "Requirement already satisfied: selenium in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (4.38.0)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio<1.0,>=0.31.0 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from selenium) (0.32.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from selenium) (2025.10.5)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from selenium) (1.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n",
      "Requirement already satisfied: outcome in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.0.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.31.0->selenium) (2.23)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\hp\\projects\\llm_engineering\\.venv\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "--- 'selenium' installation complete ---\n",
      "\n",
      "*** SETUP IS FINISHED ***\n",
      "Please RESTART THE KERNEL now (click the üîÑ button) and run your 'import selenium' cell again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Step 1: Fix the broken virtual environment by installing pip\n",
    "# This command will install 'pip' into the kernel's Python environment.\n",
    "print(\"--- Step 1: Ensuring 'pip' is installed ---\")\n",
    "!{sys.executable} -m ensurepip --upgrade\n",
    "print(\"--- 'pip' installation check complete ---\")\n",
    "\n",
    "# Step 2: Now, use the newly installed pip to install selenium\n",
    "print(\"\\n--- Step 2: Installing 'selenium' ---\")\n",
    "!{sys.executable} -m pip install selenium\n",
    "print(\"--- 'selenium' installation complete ---\")\n",
    "\n",
    "print(\"\\n*** SETUP IS FINISHED ***\")\n",
    "print(\"Please RESTART THE KERNEL now (click the üîÑ button) and run your 'import selenium' cell again.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
