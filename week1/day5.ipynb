{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98030af-fcd1-4d63-a36e-38ba053498fa",
   "metadata": {},
   "source": [
    "# A full business solution\n",
    "\n",
    "## Now we will take our project from Day 1 to the next level\n",
    "\n",
    "### BUSINESS CHALLENGE:\n",
    "\n",
    "Create a product that builds a Brochure for a company to be used for prospective clients, investors and potential recruits.\n",
    "\n",
    "We will be provided a company name and their primary website.\n",
    "\n",
    "See the end of this notebook for examples of real-world business applications.\n",
    "\n",
    "And remember: I'm always available if you have problems or ideas! Please do reach out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b08506-dc8b-4443-9201-5f1848161363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv #no nned for ollama\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from scraper import fetch_website_links, fetch_website_contents\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc5d8880-f2ee-4c06-af16-ecbc0262af61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL = 'gpt-5-nano'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4fd732",
   "metadata": {},
   "source": [
    "# I will be using ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5c74477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Ollama is running'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.get(\"http://localhost:11434\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21ed75a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b481ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "from openai import OpenAI\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30d8128-933b-44cc-81c8-ab4c9d86589a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#about',\n",
       " '#education',\n",
       " '#research',\n",
       " '#projects',\n",
       " '#skills',\n",
       " '#experience',\n",
       " '#contact',\n",
       " '#cv',\n",
       " '#about',\n",
       " '#contact',\n",
       " 'https://drive.google.com/file/d/1vpVZQZMdddl-lyYXsE03T3hKZWrSqqi2/view?usp=drive_link',\n",
       " 'https://drive.google.com/file/d/18LPhozjqo-WKTq83NEwYE-vnDuJbnRpy/view?usp=sharing',\n",
       " 'https://drive.google.com/file/d/1pXTrq3WtxePYmgT3U3wV0EFVgUJbA0YM/view?usp=drive_link',\n",
       " 'https://github.com/marufmullah50/Casting-Defect-identify',\n",
       " 'https://github.com/marufmullah50/Fish-detection-app',\n",
       " 'https://github.com/marufmullah50/Photo-background-editor-Streamlit-App',\n",
       " 'https://github.com/marufmullah50/Surface_Roughness_Prediction',\n",
       " 'https://github.com/marufmullah50/Dhaka_Wind_Property_Prediction',\n",
       " 'mailto:md.marufmullah50@gmail.com',\n",
       " 'tel:+8801609099183',\n",
       " 'https://www.linkedin.com/in/marufmullah50',\n",
       " 'https://github.com/marufmullah50',\n",
       " 'https://github.com/marufmullah50/CV_Resume']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = fetch_website_links(\"https://marufmullah50.github.io/\")\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771af9c-717a-4fca-bbbe-8a95893312c3",
   "metadata": {},
   "source": [
    "## First step: Have ollama figure out which links are relevant\n",
    "\n",
    "### Use a call to llama3.2 to read the links on a webpage, and respond in structured JSON.  \n",
    "It should decide which links are relevant, and replace relative links such as \"/about\" with \"https://company.com/about\".  \n",
    "We will use \"one shot prompting\" in which we provide an example of how it should respond in the prompt.\n",
    "\n",
    "This is an excellent use case for an LLM, because it requires nuanced understanding. Imagine trying to code this without LLMs by parsing and analyzing the webpage - it would be very hard!\n",
    "\n",
    "Sidenote: there is a more advanced technique called \"Structured Outputs\" in which we require the model to respond according to a spec. We cover this technique in Week 8 during our autonomous Agentic AI project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6957b079-0d96-45f7-a26a-3487510e9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"\"\"\n",
    "You are provided with a list of links found on a webpage.\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company,\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
    "You should respond in JSON as in this example:\n",
    "\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e1f601b-2eaf-499d-b6b8-c99050c9d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(url):\n",
    "    user_prompt = f\"\"\"\n",
    "Here is the list of links on the website {url} -\n",
    "Please decide which of these are relevant web links for a brochure about the company, \n",
    "respond with the full https URL in JSON format.\n",
    "Do not include Terms of Service, Privacy, email links.\n",
    "\n",
    "Links (some might be relative links):\n",
    "\n",
    "\"\"\"\n",
    "    links = fetch_website_links(url)\n",
    "    user_prompt += \"\\n\".join(links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bcbfa78-6395-4685-b92c-22d592050fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is the list of links on the website https://marufmullah50.github.io/ -\n",
      "Please decide which of these are relevant web links for a brochure about the company, \n",
      "respond with the full https URL in JSON format.\n",
      "Do not include Terms of Service, Privacy, email links.\n",
      "\n",
      "Links (some might be relative links):\n",
      "\n",
      "#about\n",
      "#education\n",
      "#research\n",
      "#projects\n",
      "#skills\n",
      "#experience\n",
      "#contact\n",
      "#cv\n",
      "#about\n",
      "#contact\n",
      "https://drive.google.com/file/d/1vpVZQZMdddl-lyYXsE03T3hKZWrSqqi2/view?usp=drive_link\n",
      "https://drive.google.com/file/d/18LPhozjqo-WKTq83NEwYE-vnDuJbnRpy/view?usp=sharing\n",
      "https://drive.google.com/file/d/1pXTrq3WtxePYmgT3U3wV0EFVgUJbA0YM/view?usp=drive_link\n",
      "https://github.com/marufmullah50/Casting-Defect-identify\n",
      "https://github.com/marufmullah50/Fish-detection-app\n",
      "https://github.com/marufmullah50/Photo-background-editor-Streamlit-App\n",
      "https://github.com/marufmullah50/Surface_Roughness_Prediction\n",
      "https://github.com/marufmullah50/Dhaka_Wind_Property_Prediction\n",
      "mailto:md.marufmullah50@gmail.com\n",
      "tel:+8801609099183\n",
      "https://www.linkedin.com/in/marufmullah50\n",
      "https://github.com/marufmullah50\n",
      "https://github.com/marufmullah50/CV_Resume\n"
     ]
    }
   ],
   "source": [
    "print(get_links_user_prompt(\"https://marufmullah50.github.io/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e1fd2f",
   "metadata": {},
   "source": [
    "# for open ollama change openai with ollama \n",
    "```python\n",
    "def select_relevant_links(url):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=ollama,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(url)}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    links = json.loads(result)\n",
    "    return links\n",
    "`````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "effeb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_links(url):\n",
    "    response = ollama.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(url)}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "\n",
    "    result = response.choices[0].message.content\n",
    "    links = json.loads(result)\n",
    "    return links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490de841",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d5b1ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'about page', 'url': 'https://marufmullah50.github.io/'},\n",
       "  {'type': 'contact page', 'url': 'https://marufmullah50.github.io/'},\n",
       "  {'type': 'LinkedIn profile',\n",
       "   'url': 'https://www.linkedin.com/in/marufmullah50'},\n",
       "  {'type': 'GitHub profiles (Portfolio)',\n",
       "   'url': 'https://github.com/marufmullah50'}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_relevant_links(\"https://marufmullah50.github.io/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b84c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26709d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52a215cf",
   "metadata": {},
   "source": [
    "````python\n",
    "def select_relevant_links(url):\n",
    "    print(f\"Selecting relevant links for {url} by calling {MODEL}\")\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(url)}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    links = json.loads(result)\n",
    "    print(f\"Found {len(links['links'])} relevant links\")\n",
    "    return links\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a29aca19-ca13-471c-a4b4-5abbfa813f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_links(url):\n",
    "    print(f\"Selecting relevant links for {url} by calling {MODEL}\")\n",
    "    response = ollama.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(url)}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    links = json.loads(result)\n",
    "    print(f\"Found {len(links['links'])} relevant links\")\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74a827a0-2782-4ae5-b210-4a242a8b4cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting relevant links for https://www.anthropic.com/ by calling llama3.2\n",
      "Found 10 relevant links\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'about page', 'url': 'https://www.anthropic.com/'},\n",
       "  {'type': 'company page', 'url': 'https://www.anthropic.com/company'},\n",
       "  {'type': 'careers page', 'url': 'https://www.anthropic.com/careers'},\n",
       "  {'type': 'engineering page', 'url': 'https://www.anthropic.com/engineering'},\n",
       "  {'type': 'research page', 'url': 'https://www.anthropic.com/research'},\n",
       "  {'type': 'economy page',\n",
       "   'url': 'https://www.anthropic.com/economic-futures'},\n",
       "  {'type': 'constitution and transparency page',\n",
       "   'url': 'https://www.anthropic.com/constitution'},\n",
       "  {'type': 'news and announcements page',\n",
       "   'url': 'https://www.anthropic.com/news'},\n",
       "  {'type': 'learn more page', 'url': 'https://www.anthropic.com/learn'},\n",
       "  {'type': 'trust center page', 'url': 'http://trust.anthropic.com/'}]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_relevant_links(\"https://www.anthropic.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3d583e2-dcc4-40cc-9b28-1e8dbf402924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting relevant links for https://huggingface.co by calling llama3.2\n",
      "Found 11 relevant links\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'brand page', 'url': 'https://huggingface.co'},\n",
       "  {'url': '/brands'},\n",
       "  {'type': 'About us page', 'url': './'},\n",
       "  {'type': 'Company/Innovation pages', 'url': 'spaces'},\n",
       "  {'type': 'Enterprise page', 'url': 'enterprise'},\n",
       "  {'type': 'Pricing page', 'url': '/pricing'},\n",
       "  {'type': 'Model cards ', 'url': 'https://huggingface.co/models'},\n",
       "  {'type': 'Dataset page', 'url': 'https://huggingface.co/datasets'},\n",
       "  {'url': '/models'},\n",
       "  {'type': 'Login/Account pages', 'url': '/login'},\n",
       "  {'type': 'Careers/Jobs page', 'url': '/join'}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_relevant_links(\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74128e-dfb6-47ec-9549-288b621c838c",
   "metadata": {},
   "source": [
    "## Second step: make the brochure!\n",
    "\n",
    "Assemble all the details into another prompt to GPT-5-nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85a5b6e2-e7ef-44a9-bc7f-59ede71037b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page_and_all_relevant_links(url):\n",
    "    contents = fetch_website_contents(url)\n",
    "    relevant_links = select_relevant_links(url)\n",
    "    result = f\"## Landing Page:\\n\\n{contents}\\n## Relevant Links:\\n\"\n",
    "    for link in relevant_links['links']:\n",
    "        result += f\"\\n\\n### Link: {link['type']}\\n\"\n",
    "        result += fetch_website_contents(link[\"url\"])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5099bd14-076d-4745-baf3-dac08d8e5ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting relevant links for https://huggingface.co by calling llama3.2\n",
      "Found 11 relevant links\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Landing Page:\n",
      "\n",
      "Hugging Face ‚Äì The AI community building the future.\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 2M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "moonshotai/Kimi-K2.5\n",
      "Updated\n",
      "about 8 hours ago\n",
      "‚Ä¢\n",
      "32.4k\n",
      "‚Ä¢\n",
      "1.24k\n",
      "nvidia/personaplex-7b-v1\n",
      "Updated\n",
      "2 days ago\n",
      "‚Ä¢\n",
      "62.1k\n",
      "‚Ä¢\n",
      "1.52k\n",
      "Tongyi-MAI/Z-Image\n",
      "Updated\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "2.89k\n",
      "‚Ä¢\n",
      "717\n",
      "deepseek-ai/DeepSeek-OCR-2\n",
      "Updated\n",
      "1 day ago\n",
      "‚Ä¢\n",
      "64.6k\n",
      "‚Ä¢\n",
      "575\n",
      "Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice\n",
      "Updated\n",
      "2 days ago\n",
      "‚Ä¢\n",
      "198k\n",
      "‚Ä¢\n",
      "806\n",
      "Browse 2M+ models\n",
      "Spaces\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "Featured\n",
      "1.04k\n",
      "Qwen3-TTS Demo\n",
      "üéô\n",
      "1.04k\n",
      "Transform text into natural-sounding speech with custom voices\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "Featured\n",
      "1.28k\n",
      "Qwen Image Multiple Angles 3D Camera\n",
      "üé•\n",
      "1.28k\n",
      "Adjust camera angles in images using 3D controls or sliders\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "1.91k\n",
      "Z Image Turbo\n",
      "üñº\n",
      "1.91k\n",
      "Generate stunning AI images from text descriptions in seconds\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "Featured\n",
      "392\n",
      "FLUX.2 [Klein] 9B\n",
      "üíª\n",
      "392\n",
      "Generate or edit images from text prompts or existing photos\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "529\n",
      "Wan2.2 14B Preview\n",
      "üêå\n",
      "529\n",
      "generate a video from an image with a text prompt\n",
      "Browse 1M+ applications\n",
      "Datasets\n",
      "opendatalab/ChartVerse-SFT-1800K\n",
      "Updated\n",
      "1 day ago\n",
      "‚Ä¢\n",
      "2.07k\n",
      "‚Ä¢\n",
      "114\n",
      "Qwen/DeepPlanning\n",
      "Updated\n",
      "4 days ago\n",
      "‚Ä¢\n",
      "110\n",
      "‚Ä¢\n",
      "83\n",
      "Alibaba-Apsara/Superior-Reasoning-SFT-gpt-oss-120b\n",
      "Updated\n",
      "16 days ago\n",
      "‚Ä¢\n",
      "30.7k\n",
      "‚Ä¢\n",
      "310\n",
      "sojuL/RubricHub_v1\n",
      "Updated\n",
      "11 days ago\n",
      "‚Ä¢\n",
      "747\n",
      "‚Ä¢\n",
      "152\n",
      "mercor/apex-agents\n",
      "Updated\n",
      "9 days ago\n",
      "‚Ä¢\n",
      "6.89k\n",
      "‚Ä¢\n",
      "73\n",
      "Browse 500k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We \n",
      "## Relevant Links:\n",
      "\n",
      "\n",
      "### Link: About page\n",
      "Hugging Face ‚Äì The AI community building the future.\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 2M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "moonshotai/Kimi-K2.5\n",
      "Updated\n",
      "about 8 hours ago\n",
      "‚Ä¢\n",
      "32.4k\n",
      "‚Ä¢\n",
      "1.24k\n",
      "nvidia/personaplex-7b-v1\n",
      "Updated\n",
      "2 days ago\n",
      "‚Ä¢\n",
      "62.1k\n",
      "‚Ä¢\n",
      "1.52k\n",
      "Tongyi-MAI/Z-Image\n",
      "Updated\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "2.89k\n",
      "‚Ä¢\n",
      "717\n",
      "deepseek-ai/DeepSeek-OCR-2\n",
      "Updated\n",
      "1 day ago\n",
      "‚Ä¢\n",
      "64.6k\n",
      "‚Ä¢\n",
      "576\n",
      "Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice\n",
      "Updated\n",
      "2 days ago\n",
      "‚Ä¢\n",
      "198k\n",
      "‚Ä¢\n",
      "807\n",
      "Browse 2M+ models\n",
      "Spaces\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "Featured\n",
      "1.04k\n",
      "Qwen3-TTS Demo\n",
      "üéô\n",
      "1.04k\n",
      "Transform text into natural-sounding speech with custom voices\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "Featured\n",
      "1.28k\n",
      "Qwen Image Multiple Angles 3D Camera\n",
      "üé•\n",
      "1.28k\n",
      "Adjust camera angles in images using 3D controls or sliders\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "1.91k\n",
      "Z Image Turbo\n",
      "üñº\n",
      "1.91k\n",
      "Generate stunning AI images from text descriptions in seconds\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "Featured\n",
      "392\n",
      "FLUX.2 [Klein] 9B\n",
      "üíª\n",
      "392\n",
      "Generate or edit images from text prompts or existing photos\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "529\n",
      "Wan2.2 14B Preview\n",
      "üêå\n",
      "529\n",
      "generate a video from an image with a text prompt\n",
      "Browse 1M+ applications\n",
      "Datasets\n",
      "opendatalab/ChartVerse-SFT-1800K\n",
      "Updated\n",
      "1 day ago\n",
      "‚Ä¢\n",
      "2.07k\n",
      "‚Ä¢\n",
      "114\n",
      "Qwen/DeepPlanning\n",
      "Updated\n",
      "4 days ago\n",
      "‚Ä¢\n",
      "110\n",
      "‚Ä¢\n",
      "83\n",
      "Alibaba-Apsara/Superior-Reasoning-SFT-gpt-oss-120b\n",
      "Updated\n",
      "16 days ago\n",
      "‚Ä¢\n",
      "30.7k\n",
      "‚Ä¢\n",
      "310\n",
      "sojuL/RubricHub_v1\n",
      "Updated\n",
      "11 days ago\n",
      "‚Ä¢\n",
      "747\n",
      "‚Ä¢\n",
      "152\n",
      "mercor/apex-agents\n",
      "Updated\n",
      "9 days ago\n",
      "‚Ä¢\n",
      "6.89k\n",
      "‚Ä¢\n",
      "73\n",
      "Browse 500k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We \n",
      "\n",
      "### Link: Company page\n",
      "Brand assets - Hugging Face\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Hugging Face ¬∑ Brand assets\n",
      "HF Logos\n",
      ".svg\n",
      ".png\n",
      ".ai\n",
      ".svg\n",
      ".png\n",
      ".ai\n",
      ".svg\n",
      ".png\n",
      ".ai\n",
      "HF Colors\n",
      "#FFD21E\n",
      "#FF9D00\n",
      "#6B7280\n",
      "HF Bio\n",
      "Hugging Face is the collaboration platform for the machine learning community.\n",
      "\n",
      "The Hugging Face Hub works as a central place where anyone can share, explore, discover, and experiment with open-source ML. HF empowers the next generation of machine learning engineers, scientists, and end users to learn, collaborate and share their work to build an open and ethical AI future together.\n",
      "\n",
      "With the fast-growing community, some of the most used open-source ML libraries and tools, and a talented science team exploring the edge of tech, Hugging Face is at the heart of the AI revolution.\n",
      "Copy to clipboard\n",
      "HF Universe\n",
      "Find other assets available for use from the Hugging Face brand universe\n",
      "here\n",
      ".\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Careers\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "### Link: Careers/Jobs page\n",
      "Hugging Face - Current Openings\n",
      "\n",
      "\n",
      "\n",
      "### Link: Docs/transformers\n",
      "Transformers\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Transformers documentation\n",
      "Transformers\n",
      "Transformers\n",
      "üè° View all docs\n",
      "AWS Trainium & Inferentia\n",
      "Accelerate\n",
      "Argilla\n",
      "AutoTrain\n",
      "Bitsandbytes\n",
      "Chat UI\n",
      "Dataset viewer\n",
      "Datasets\n",
      "Deploying on AWS\n",
      "Diffusers\n",
      "Distilabel\n",
      "Evaluate\n",
      "Google Cloud\n",
      "Google TPUs\n",
      "Gradio\n",
      "Hub\n",
      "Hub Python Library\n",
      "Huggingface.js\n",
      "Inference Endpoints (dedicated)\n",
      "Inference Providers\n",
      "Kernels\n",
      "LeRobot\n",
      "Leaderboards\n",
      "Lighteval\n",
      "Microsoft Azure\n",
      "Optimum\n",
      "PEFT\n",
      "Reachy Mini\n",
      "Safetensors\n",
      "Sentence Transformers\n",
      "TRL\n",
      "Tasks\n",
      "Text Embeddings Inference\n",
      "Text Generation Inference\n",
      "Tokenizers\n",
      "Trackio\n",
      "Transformers\n",
      "Transformers.js\n",
      "smolagents\n",
      "timm\n",
      "Search documentation\n",
      "main\n",
      "v5.0.0\n",
      "v4.57.6\n",
      "v4.56.2\n",
      "v4.55.4\n",
      "v4.53.3\n",
      "v4.52.3\n",
      "v4.51.3\n",
      "v4.50.0\n",
      "v4.49.0\n",
      "v4.48.2\n",
      "v4.47.1\n",
      "v4.46.3\n",
      "v4.45.2\n",
      "v4.44.2\n",
      "v4.43.4\n",
      "v4.42.4\n",
      "v4.41.2\n",
      "v4.40.2\n",
      "v4.39.3\n",
      "v4.38.2\n",
      "v4.37.2\n",
      "v4.36.1\n",
      "v4.35.2\n",
      "v4.34.1\n",
      "v4.33.3\n",
      "v4.32.1\n",
      "v4.31.0\n",
      "v4.30.0\n",
      "v4.29.1\n",
      "v4.28.1\n",
      "v4.27.2\n",
      "v4.26.1\n",
      "v4.25.1\n",
      "v4.24.0\n",
      "v4.23.1\n",
      "v4.22.2\n",
      "v4.21.3\n",
      "v4.20.1\n",
      "v4.19.4\n",
      "v4.18.0\n",
      "v4.17.0\n",
      "v4.16.2\n",
      "v4.15.0\n",
      "v4.14.1\n",
      "v4.13.0\n",
      "v4.12.5\n",
      "v4.11.3\n",
      "v4.10.1\n",
      "v4.9.2\n",
      "v4.8.2\n",
      "v4.7.0\n",
      "v4.6.0\n",
      "v4.5.1\n",
      "v4.4.2\n",
      "v4.3.3\n",
      "v4.2.2\n",
      "v4.1.1\n",
      "v4.0.1\n",
      "v3.5.1\n",
      "v3.4.0\n",
      "v3.3.1\n",
      "v3.2.0\n",
      "v3.1.0\n",
      "v3.0.2\n",
      "v2.11.0\n",
      "v2.10.0\n",
      "v2.9.1\n",
      "v2.8.0\n",
      "v2.7.0\n",
      "v2.6.0\n",
      "v2.5.1\n",
      "v2.4.1\n",
      "v2.3.0\n",
      "v2.2.2\n",
      "v2.1.1\n",
      "v2.0.0\n",
      "v1.2.0\n",
      "v1.1.0\n",
      "v1.0.0\n",
      "doc-builder-html\n",
      "AR\n",
      "DE\n",
      "EN\n",
      "ES\n",
      "FR\n",
      "HI\n",
      "IT\n",
      "JA\n",
      "KO\n",
      "PT\n",
      "ZH\n",
      "Get started\n",
      "Transformers\n",
      "Installation\n",
      "Quickstart\n",
      "Base classes\n",
      "Inference\n",
      "Training\n",
      "Quantization\n",
      "Ecosystem integrations\n",
      "Resources\n",
      "Contribute\n",
      "API\n",
      "Join the Hugging Face community\n",
      "and get access to the augmented documentation experience\n",
      "Collaborate on models, datasets and Spaces\n",
      "Faster examples with accelerated inference\n",
      "Switch between documentation themes\n",
      "Sign Up\n",
      "to get started\n",
      "Copy page\n",
      "Transformers\n",
      "Transformers acts as the model-definition framework for state-of-the-art machine learning models in text, computer\n",
      "vision, audio, video, and multimodal model, for both inference and training.\n",
      "It centralizes the model definition so that this defin\n",
      "\n",
      "### Link: Docs/diffusers\n",
      "Diffusers\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Diffusers documentation\n",
      "Diffusers\n",
      "Diffusers\n",
      "üè° View all docs\n",
      "AWS Trainium & Inferentia\n",
      "Accelerate\n",
      "Argilla\n",
      "AutoTrain\n",
      "Bitsandbytes\n",
      "Chat UI\n",
      "Dataset viewer\n",
      "Datasets\n",
      "Deploying on AWS\n",
      "Diffusers\n",
      "Distilabel\n",
      "Evaluate\n",
      "Google Cloud\n",
      "Google TPUs\n",
      "Gradio\n",
      "Hub\n",
      "Hub Python Library\n",
      "Huggingface.js\n",
      "Inference Endpoints (dedicated)\n",
      "Inference Providers\n",
      "Kernels\n",
      "LeRobot\n",
      "Leaderboards\n",
      "Lighteval\n",
      "Microsoft Azure\n",
      "Optimum\n",
      "PEFT\n",
      "Reachy Mini\n",
      "Safetensors\n",
      "Sentence Transformers\n",
      "TRL\n",
      "Tasks\n",
      "Text Embeddings Inference\n",
      "Text Generation Inference\n",
      "Tokenizers\n",
      "Trackio\n",
      "Transformers\n",
      "Transformers.js\n",
      "smolagents\n",
      "timm\n",
      "Search documentation\n",
      "main\n",
      "v0.36.0\n",
      "v0.35.1\n",
      "v0.34.0\n",
      "v0.33.1\n",
      "v0.32.2\n",
      "v0.31.0\n",
      "v0.30.3\n",
      "v0.29.2\n",
      "v0.28.2\n",
      "v0.27.2\n",
      "v0.26.3\n",
      "v0.25.1\n",
      "v0.24.0\n",
      "v0.23.1\n",
      "v0.22.3\n",
      "v0.21.0\n",
      "v0.20.0\n",
      "v0.19.3\n",
      "v0.18.2\n",
      "v0.17.1\n",
      "v0.16.0\n",
      "v0.15.0\n",
      "v0.14.0\n",
      "v0.13.0\n",
      "v0.12.0\n",
      "v0.11.0\n",
      "v0.10.2\n",
      "v0.9.0\n",
      "v0.8.0\n",
      "v0.7.0\n",
      "v0.6.0\n",
      "v0.5.1\n",
      "v0.4.1\n",
      "v0.3.0\n",
      "v0.2.4\n",
      "EN\n",
      "JA\n",
      "KO\n",
      "PT\n",
      "ZH\n",
      "Get started\n",
      "Diffusers\n",
      "Installation\n",
      "Quickstart\n",
      "Basic performance\n",
      "Pipelines\n",
      "Adapters\n",
      "Inference\n",
      "Inference optimization\n",
      "Hybrid Inference\n",
      "Modular Diffusers\n",
      "Training\n",
      "Quantization\n",
      "Model accelerators and hardware\n",
      "Specific pipeline examples\n",
      "Resources\n",
      "API\n",
      "Join the Hugging Face community\n",
      "and get access to the augmented documentation experience\n",
      "Collaborate on models, datasets and Spaces\n",
      "Faster examples with accelerated inference\n",
      "Switch between documentation themes\n",
      "Sign Up\n",
      "to get started\n",
      "Copy page\n",
      "Diffusers\n",
      "Diffusers is a library of state-of-the-art pretrained diffusion models for generating videos, images, and audio.\n",
      "The library revolves around the\n",
      "DiffusionPipeline\n",
      ", an API designed for:\n",
      "easy inference with only a few lines of code\n",
      "flexibility to mix-and-match pipeline components (models, schedulers)\n",
      "loading and using adapters like LoRA\n",
      "Diffusers also comes with optimizations - such as offloading and quantization - to ensure even the largest models are accessible on memory-constrained devices. If memory is not an issu\n",
      "\n",
      "### Link: Docs/safetensors\n",
      "Safetensors\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Safetensors documentation\n",
      "Safetensors\n",
      "Safetensors\n",
      "üè° View all docs\n",
      "AWS Trainium & Inferentia\n",
      "Accelerate\n",
      "Argilla\n",
      "AutoTrain\n",
      "Bitsandbytes\n",
      "Chat UI\n",
      "Dataset viewer\n",
      "Datasets\n",
      "Deploying on AWS\n",
      "Diffusers\n",
      "Distilabel\n",
      "Evaluate\n",
      "Google Cloud\n",
      "Google TPUs\n",
      "Gradio\n",
      "Hub\n",
      "Hub Python Library\n",
      "Huggingface.js\n",
      "Inference Endpoints (dedicated)\n",
      "Inference Providers\n",
      "Kernels\n",
      "LeRobot\n",
      "Leaderboards\n",
      "Lighteval\n",
      "Microsoft Azure\n",
      "Optimum\n",
      "PEFT\n",
      "Reachy Mini\n",
      "Safetensors\n",
      "Sentence Transformers\n",
      "TRL\n",
      "Tasks\n",
      "Text Embeddings Inference\n",
      "Text Generation Inference\n",
      "Tokenizers\n",
      "Trackio\n",
      "Transformers\n",
      "Transformers.js\n",
      "smolagents\n",
      "timm\n",
      "Search documentation\n",
      "main\n",
      "v0.5.0-rc.0\n",
      "v0.3.2\n",
      "v0.2.9\n",
      "EN\n",
      "Getting started\n",
      "ü§ó Safetensors\n",
      "Speed Comparison\n",
      "Tensor Sharing in Pytorch\n",
      "Metadata Parsing\n",
      "Convert weights to safetensors\n",
      "API\n",
      "Torch API\n",
      "Tensorflow API\n",
      "PaddlePaddle API\n",
      "Flax API\n",
      "Numpy API\n",
      "You are viewing\n",
      "main\n",
      "version, which requires\n",
      "installation from source\n",
      ". If you'd like\n",
      "\t\t\tregular pip install, checkout the latest stable version (\n",
      "v0.5.0-rc.0\n",
      ").\n",
      "Join the Hugging Face community\n",
      "and get access to the augmented documentation experience\n",
      "Collaborate on models, datasets and Spaces\n",
      "Faster examples with accelerated inference\n",
      "Switch between documentation themes\n",
      "Sign Up\n",
      "to get started\n",
      "Copy page\n",
      "Safetensors\n",
      "Safetensors is a new simple format for storing tensors safely (as opposed to pickle) and that is still fast (zero-copy). Safetensors is really\n",
      "fast üöÄ\n",
      ".\n",
      "Installation\n",
      "with pip:\n",
      "Copied\n",
      "pip\n",
      "install\n",
      "safetensors\n",
      "with conda:\n",
      "Copied\n",
      "conda\n",
      "install\n",
      "-c huggingface safetensors\n",
      "Usage\n",
      "Load tensors\n",
      "Copied\n",
      "from\n",
      "safetensors\n",
      "import\n",
      "safe_open\n",
      "\n",
      "tensors = {}\n",
      "with\n",
      "safe_open(\n",
      "\"model.safetensors\"\n",
      ", framework=\n",
      "\"pt\"\n",
      ", device=\n",
      "0\n",
      ")\n",
      "as\n",
      "f:\n",
      "for\n",
      "k\n",
      "in\n",
      "f.keys():\n",
      "        tensors[k] = f.get_tensor(k)\n",
      "Loading only part of the tensors (interesting when running on multiple GPU)\n",
      "Copied\n",
      "from\n",
      "safetensors\n",
      "import\n",
      "safe_open\n",
      "\n",
      "tensors = {}\n",
      "with\n",
      "safe_open(\n",
      "\"model.safetensors\"\n",
      ", framework=\n",
      "\"pt\"\n",
      ", device=\n",
      "0\n",
      ")\n",
      "\n",
      "### Link: Docs/tokenizers\n",
      "Tokenizers\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Tokenizers documentation\n",
      "Tokenizers\n",
      "Tokenizers\n",
      "üè° View all docs\n",
      "AWS Trainium & Inferentia\n",
      "Accelerate\n",
      "Argilla\n",
      "AutoTrain\n",
      "Bitsandbytes\n",
      "Chat UI\n",
      "Dataset viewer\n",
      "Datasets\n",
      "Deploying on AWS\n",
      "Diffusers\n",
      "Distilabel\n",
      "Evaluate\n",
      "Google Cloud\n",
      "Google TPUs\n",
      "Gradio\n",
      "Hub\n",
      "Hub Python Library\n",
      "Huggingface.js\n",
      "Inference Endpoints (dedicated)\n",
      "Inference Providers\n",
      "Kernels\n",
      "LeRobot\n",
      "Leaderboards\n",
      "Lighteval\n",
      "Microsoft Azure\n",
      "Optimum\n",
      "PEFT\n",
      "Reachy Mini\n",
      "Safetensors\n",
      "Sentence Transformers\n",
      "TRL\n",
      "Tasks\n",
      "Text Embeddings Inference\n",
      "Text Generation Inference\n",
      "Tokenizers\n",
      "Trackio\n",
      "Transformers\n",
      "Transformers.js\n",
      "smolagents\n",
      "timm\n",
      "Search documentation\n",
      "main\n",
      "v0.20.3\n",
      "v0.13.4.rc2\n",
      "v0.10.0\n",
      "v0.9.4\n",
      "EN\n",
      "Getting started\n",
      "ü§ó Tokenizers\n",
      "Quicktour\n",
      "Installation\n",
      "The tokenization pipeline\n",
      "Components\n",
      "Training from memory\n",
      "API\n",
      "Input Sequences\n",
      "Encode Inputs\n",
      "Tokenizer\n",
      "Encoding\n",
      "Added Tokens\n",
      "Models\n",
      "Normalizers\n",
      "Pre-tokenizers\n",
      "Post-processors\n",
      "Trainers\n",
      "Decoders\n",
      "Visualizer\n",
      "Join the Hugging Face community\n",
      "and get access to the augmented documentation experience\n",
      "Collaborate on models, datasets and Spaces\n",
      "Faster examples with accelerated inference\n",
      "Switch between documentation themes\n",
      "Sign Up\n",
      "to get started\n",
      "Tokenizers\n",
      "Fast State-of-the-art tokenizers, optimized for both research and\n",
      "production\n",
      "ü§ó Tokenizers\n",
      "provides an\n",
      "implementation of today‚Äôs most used tokenizers, with a focus on\n",
      "performance and versatility. These tokenizers are also used in\n",
      "ü§ó Transformers\n",
      ".\n",
      "Main features:\n",
      "Train new vocabularies and tokenize, using today‚Äôs most used tokenizers.\n",
      "Extremely fast (both training and tokenization), thanks to the Rust implementation. Takes less than 20 seconds to tokenize a GB of text on a server‚Äôs CPU.\n",
      "Easy to use, but also extremely versatile.\n",
      "Designed for both research and production.\n",
      "Full alignment tracking. Even with destructive normalization, it‚Äôs always possible to get the part of the original sentence that corresponds to any token.\n",
      "Does all the pre-processing: Truncati\n",
      "\n",
      "### Link: Docs/trl\n",
      "TRL - Transformer Reinforcement Learning\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "TRL documentation\n",
      "TRL - Transformer Reinforcement Learning\n",
      "TRL\n",
      "üè° View all docs\n",
      "AWS Trainium & Inferentia\n",
      "Accelerate\n",
      "Argilla\n",
      "AutoTrain\n",
      "Bitsandbytes\n",
      "Chat UI\n",
      "Dataset viewer\n",
      "Datasets\n",
      "Deploying on AWS\n",
      "Diffusers\n",
      "Distilabel\n",
      "Evaluate\n",
      "Google Cloud\n",
      "Google TPUs\n",
      "Gradio\n",
      "Hub\n",
      "Hub Python Library\n",
      "Huggingface.js\n",
      "Inference Endpoints (dedicated)\n",
      "Inference Providers\n",
      "Kernels\n",
      "LeRobot\n",
      "Leaderboards\n",
      "Lighteval\n",
      "Microsoft Azure\n",
      "Optimum\n",
      "PEFT\n",
      "Reachy Mini\n",
      "Safetensors\n",
      "Sentence Transformers\n",
      "TRL\n",
      "Tasks\n",
      "Text Embeddings Inference\n",
      "Text Generation Inference\n",
      "Tokenizers\n",
      "Trackio\n",
      "Transformers\n",
      "Transformers.js\n",
      "smolagents\n",
      "timm\n",
      "Search documentation\n",
      "main\n",
      "v0.27.1\n",
      "v0.26.2\n",
      "v0.25.1\n",
      "v0.24.0\n",
      "v0.23.1\n",
      "v0.22.2\n",
      "v0.21.0\n",
      "v0.20.0\n",
      "v0.19.1\n",
      "v0.18.1\n",
      "v0.17.0\n",
      "v0.16.1\n",
      "v0.15.2\n",
      "v0.14.0\n",
      "v0.13.0\n",
      "v0.12.2\n",
      "v0.11.4\n",
      "v0.10.1\n",
      "v0.9.6\n",
      "v0.8.6\n",
      "v0.7.11\n",
      "v0.6.0\n",
      "v0.5.0\n",
      "v0.4.7\n",
      "v0.3.1\n",
      "v0.2.1\n",
      "v0.1.1\n",
      "EN\n",
      "Getting started\n",
      "TRL\n",
      "Installation\n",
      "Quickstart\n",
      "Conceptual Guides\n",
      "Dataset Formats\n",
      "Paper Index\n",
      "Trainers\n",
      "DPO\n",
      "GRPO\n",
      "Reward\n",
      "RLOO\n",
      "SFT\n",
      "How-to guides\n",
      "Command Line Interface (CLI)\n",
      "Training using Jobs\n",
      "Customizing the Training\n",
      "Reducing Memory Usage\n",
      "Speeding Up Training\n",
      "Distributing Training\n",
      "Using Trained Models\n",
      "Integrations\n",
      "DeepSpeed\n",
      "Kernels Hub\n",
      "Liger Kernel\n",
      "PEFT\n",
      "RapidFire AI\n",
      "Trackio\n",
      "Unsloth\n",
      "vLLM\n",
      "Examples\n",
      "Example Overview\n",
      "Community Tutorials\n",
      "LoRA Without Regret\n",
      "API\n",
      "Utilities\n",
      "Chat Template Utilities\n",
      "Data Utilities\n",
      "Model Utilities\n",
      "Script Utilities\n",
      "Callbacks\n",
      "Reward Functions\n",
      "Others\n",
      "Experimental\n",
      "Experimental Overview\n",
      "OpenEnv Integration\n",
      "BEMA for Reference Model\n",
      "BCO\n",
      "CPO\n",
      "GFPO\n",
      "GKD\n",
      "GOLD\n",
      "GRPO With Replay Buffer\n",
      "GSPO-token\n",
      "Judges\n",
      "KTO\n",
      "MergeModelCallback\n",
      "MiniLLM\n",
      "Nash-MD\n",
      "Online DPO\n",
      "ORPO\n",
      "PAPO\n",
      "PPO\n",
      "PRM\n",
      "WinRateCallback\n",
      "XPO\n",
      "Join the Hugging Face community\n",
      "and get access to the augmented documentation experience\n",
      "Collaborate on models, datasets and Spaces\n",
      "Faster examples with accelerated inference\n",
      "Switch between documentation themes\n",
      "Sign Up\n",
      "to get started\n",
      "Copy page\n",
      "T\n",
      "\n",
      "### Link: Models page\n",
      "Models ‚Äì Hugging Face\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Edit Models filters\n",
      "Main\n",
      "Tasks\n",
      "Libraries\n",
      "Languages\n",
      "Licenses\n",
      "Other\n",
      "Tasks\n",
      "Text Generation\n",
      "Any-to-Any\n",
      "Image-Text-to-Text\n",
      "Image-to-Text\n",
      "Image-to-Image\n",
      "Text-to-Image\n",
      "Text-to-Video\n",
      "Text-to-Speech\n",
      "+ 44\n",
      "Parameters\n",
      "Reset Parameters\n",
      "< 1B\n",
      "6B\n",
      "12B\n",
      "32B\n",
      "128B\n",
      "> 500B\n",
      "< 1B\n",
      "> 500B\n",
      "Libraries\n",
      "PyTorch\n",
      "google-tensorflow\n",
      "TensorFlow\n",
      "JAX\n",
      "Transformers\n",
      "Diffusers\n",
      "sentence-transformers\n",
      "Safetensors\n",
      "ONNX\n",
      "GGUF\n",
      "Transformers.js\n",
      "MLX\n",
      "+ 41\n",
      "Apps\n",
      "vLLM\n",
      "TGI\n",
      "llama.cpp\n",
      "MLX LM\n",
      "LM Studio\n",
      "Ollama\n",
      "Jan\n",
      "+ 7\n",
      "Inference Providers\n",
      "Groq\n",
      "Novita\n",
      "Cerebras\n",
      "SambaNova\n",
      "Nscale\n",
      "fal\n",
      "Hyperbolic\n",
      "Together AI\n",
      "+ 10\n",
      "Apply filters\n",
      "Models\n",
      "Full-text search\n",
      "Inference Available\n",
      "Add filters\n",
      "Sort:¬†\n",
      "\t\tTrending\n",
      "moonshotai/Kimi-K2.5\n",
      "Image-Text-to-Text\n",
      "‚Ä¢\n",
      "Updated\n",
      "about 8 hours ago\n",
      "‚Ä¢\n",
      "32.4k\n",
      "‚Ä¢\n",
      "‚Ä¢\n",
      "1.24k\n",
      "nvidia/personaplex-7b-v1\n",
      "Audio-to-Audio\n",
      "‚Ä¢\n",
      "Updated\n",
      "2 days ago\n",
      "‚Ä¢\n",
      "62.1k\n",
      "‚Ä¢\n",
      "1.52k\n",
      "Tongyi-MAI/Z-Image\n",
      "Text-to-Image\n",
      "‚Ä¢\n",
      "Updated\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "2.89k\n",
      "‚Ä¢\n",
      "‚Ä¢\n",
      "717\n",
      "deepseek-ai/DeepSeek-OCR-2\n",
      "Image-Text-to-Text\n",
      "‚Ä¢\n",
      "3B\n",
      "‚Ä¢\n",
      "Updated\n",
      "1 day ago\n",
      "‚Ä¢\n",
      "64.6k\n",
      "‚Ä¢\n",
      "576\n",
      "Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice\n",
      "Text-to-Speech\n",
      "‚Ä¢\n",
      "2B\n",
      "‚Ä¢\n",
      "Updated\n",
      "2 days ago\n",
      "‚Ä¢\n",
      "198k\n",
      "‚Ä¢\n",
      "807\n",
      "tencent/HunyuanImage-3.0-Instruct\n",
      "Image-to-Image\n",
      "‚Ä¢\n",
      "83B\n",
      "‚Ä¢\n",
      "Updated\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "84\n",
      "‚Ä¢\n",
      "‚Ä¢\n",
      "438\n",
      "microsoft/VibeVoice-ASR\n",
      "Automatic Speech Recognition\n",
      "‚Ä¢\n",
      "9B\n",
      "‚Ä¢\n",
      "Updated\n",
      "4 days ago\n",
      "‚Ä¢\n",
      "125k\n",
      "‚Ä¢\n",
      "748\n",
      "zai-org/GLM-4.7-Flash\n",
      "Text Generation\n",
      "‚Ä¢\n",
      "31B\n",
      "‚Ä¢\n",
      "Updated\n",
      "2 days ago\n",
      "‚Ä¢\n",
      "726k\n",
      "‚Ä¢\n",
      "‚Ä¢\n",
      "1.35k\n",
      "PaddlePaddle/PaddleOCR-VL-1.5\n",
      "Image-Text-to-Text\n",
      "‚Ä¢\n",
      "1.0B\n",
      "‚Ä¢\n",
      "Updated\n",
      "1 day ago\n",
      "‚Ä¢\n",
      "1k\n",
      "‚Ä¢\n",
      "243\n",
      "lightonai/LightOnOCR-2-1B\n",
      "Image-Text-to-Text\n",
      "‚Ä¢\n",
      "1B\n",
      "‚Ä¢\n",
      "Updated\n",
      "about 20 hours ago\n",
      "‚Ä¢\n",
      "28.7k\n",
      "‚Ä¢\n",
      "448\n",
      "Qwen/Qwen3-ASR-1.7B\n",
      "Automatic Speech Recognition\n",
      "‚Ä¢\n",
      "2B\n",
      "‚Ä¢\n",
      "Updated\n",
      "1 day ago\n",
      "‚Ä¢\n",
      "8.35k\n",
      "‚Ä¢\n",
      "220\n",
      "numind/NuMarkdown-8B-Thinking\n",
      "Image-to-Text\n",
      "‚Ä¢\n",
      "8B\n",
      "‚Ä¢\n",
      "Updated\n",
      "Nov 13, 2025\n",
      "‚Ä¢\n",
      "1.09M\n",
      "‚Ä¢\n",
      "406\n",
      "Comfy-Org/z_image\n",
      "Updated\n",
      "4 days ago\n",
      "‚Ä¢\n",
      "49.5k\n",
      "‚Ä¢\n",
      "154\n",
      "Qwen/Qwen3-TTS-12Hz-1.7B-Base\n",
      "Updated\n",
      "8 days ago\n",
      "‚Ä¢\n",
      "197k\n",
      "‚Ä¢\n",
      "261\n",
      "RuneXX/LTX-2-Workflows\n",
      "Updated\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "181\n",
      "FlashLabs/Chroma-4B\n",
      "Any-to-Any\n",
      "‚Ä¢\n",
      "6B\n",
      "‚Ä¢\n",
      "Updated\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "7.44k\n",
      "\n",
      "\n",
      "### Link: Spaces page\n",
      "Spaces - Hugging Face\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Spaces\n",
      "¬∑\n",
      "The AI App Directory\n",
      "New Space\n",
      "Get PRO\n",
      "Learn more\n",
      "Reachy\n",
      "new\n",
      "Image Generation\n",
      "Video Generation\n",
      "Text Generation\n",
      "Language Translation\n",
      "Speech Synthesis\n",
      "3D Modeling\n",
      "Object Detection\n",
      "Text Analysis\n",
      "Image Editing\n",
      "Code Generation\n",
      "Question Answering\n",
      "Data Visualization\n",
      "Voice Cloning\n",
      "Background Removal\n",
      "Image Upscaling\n",
      "OCR\n",
      "Document Analysis\n",
      "Visual QA\n",
      "Image Captioning\n",
      "Chatbots\n",
      "Sentiment Analysis\n",
      "Text Summarization\n",
      "Music Generation\n",
      "Medical Imaging\n",
      "Financial Analysis\n",
      "Game AI\n",
      "Model Benchmarking\n",
      "Fine Tuning Tools\n",
      "Dataset Creation\n",
      "Pose Estimation\n",
      "Face Recognition\n",
      "Anomaly Detection\n",
      "Recommendation Systems\n",
      "Character Animation\n",
      "Style Transfer\n",
      "RL Environment\n",
      "Image\n",
      "Spaces of the week\n",
      "26 Jan 2026\n",
      "Filters\n",
      "(0)\n",
      "Sort:¬†\n",
      "\t\tRelevance\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "Featured\n",
      "1.04k\n",
      "Qwen3-TTS Demo\n",
      "üéô\n",
      "Transform text into natural-sounding speech with custom voices\n",
      "Qwen\n",
      "2 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "Featured\n",
      "50\n",
      "Waypoint 1 Small\n",
      "üéÆ\n",
      "Explore and navigate through AI-generated worlds in real-time\n",
      "Overworld\n",
      "8 days ago\n",
      "Running\n",
      "MCP\n",
      "Featured\n",
      "11\n",
      "Small Object Detection with YOLO26\n",
      "üëÄ\n",
      "Small object detection & segmentation using YOLO26 + SAHI\n",
      "farukalamai\n",
      "6 days ago\n",
      "Running\n",
      "Featured\n",
      "26\n",
      "Pocket TTS ONNX Web Demo\n",
      "üåñ\n",
      "Real-time voice cloning entirely in your browser! (CPU)\n",
      "KevinAHM\n",
      "10 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "Featured\n",
      "92\n",
      "Qwen Image Edit Object Manipulator\n",
      "üî•\n",
      "Text-Guided Object Manipulation Using Qwen Image Edit + LoRA\n",
      "prithivMLmods\n",
      "4 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "Featured\n",
      "80\n",
      "LightOnOCR 2 1B Demo\n",
      "üê®\n",
      "Extract and recognize text from images and PDFs\n",
      "lightonai\n",
      "4 days ago\n",
      "Running\n",
      "Featured\n",
      "11\n",
      "RWKV-8 ROSA-QKV-1bit Demo\n",
      "üåπ\n",
      "Jellyfish042\n",
      "8 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "Featured\n",
      "19\n",
      "SAMTok\n",
      "üé®\n",
      "SAMTok provides a unified mask-token interface for MLLMs.\n",
      "insomnia7\n",
      "8 days ago\n",
      "All running apps, trending first\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "Featured\n",
      "1.04k\n",
      "Qwen3-TTS Demo\n",
      "üéô\n",
      "Transform text into natural-sounding speech with custom voices\n",
      "Qwen\n",
      "2 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "Featured\n",
      "1\n",
      "\n",
      "### Link: Changelog page\n",
      "No title found\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fetch_page_and_all_relevant_links(\"https://huggingface.co\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b863a55-f86c-4e3f-8a79-94e24c1a8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brochure_system_prompt = \"\"\"\n",
    "# You are an assistant that analyzes the contents of several relevant pages from a company website\n",
    "# and creates a short brochure about the company for prospective customers, investors and recruits.\n",
    "# Respond in markdown without code blocks.\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\n",
    "# \"\"\"\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "brochure_system_prompt = \"\"\"\n",
    "You are an assistant that analyzes the contents of several relevant pages from a company website\n",
    "and creates a short, humorous, entertaining, witty brochure about the company for prospective customers, investors and recruits.\n",
    "Respond in markdown without code blocks.\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ab83d92-d36b-4ce0-8bcc-5bb4c2f8ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"\"\"\n",
    "You are looking at a company called: {company_name}\n",
    "Here are the contents of its landing page and other relevant pages;\n",
    "use this information to build a short brochure of the company in markdown without code blocks.\\n\\n\n",
    "\"\"\"\n",
    "    user_prompt += fetch_page_and_all_relevant_links(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd909e0b-1312-4ce2-a553-821e795d7572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting relevant links for https://huggingface.co by calling llama3.2\n",
      "Found 6 relevant links\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nYou are looking at a company called: HuggingFace\\nHere are the contents of its landing page and other relevant pages;\\nuse this information to build a short brochure of the company in markdown without code blocks.\\n\\n\\n## Landing Page:\\n\\nHugging Face ‚Äì The AI community building the future.\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 2M+ models\\nTrending on\\nthis week\\nModels\\nmoonshotai/Kimi-K2.5\\nUpdated\\nabout 8 hours ago\\n‚Ä¢\\n32.4k\\n‚Ä¢\\n1.24k\\nnvidia/personaplex-7b-v1\\nUpdated\\n2 days ago\\n‚Ä¢\\n62.1k\\n‚Ä¢\\n1.52k\\nTongyi-MAI/Z-Image\\nUpdated\\n3 days ago\\n‚Ä¢\\n2.89k\\n‚Ä¢\\n717\\ndeepseek-ai/DeepSeek-OCR-2\\nUpdated\\n1 day ago\\n‚Ä¢\\n64.6k\\n‚Ä¢\\n576\\nQwen/Qwen3-TTS-12Hz-1.7B-CustomVoice\\nUpdated\\n2 days ago\\n‚Ä¢\\n198k\\n‚Ä¢\\n807\\nBrowse 2M+ models\\nSpaces\\nRunning\\non\\nZero\\nFeatured\\n1.04k\\nQwen3-TTS Demo\\nüéô\\n1.04k\\nTransform text into natural-sounding speech with custom voices\\nRunning\\non\\nZero\\nFeatured\\n1.28k\\nQwen Image Multiple Angles 3D Camera\\nüé•\\n1.28k\\nAdjust camera angles in images using 3D controls or sliders\\nRunning\\non\\nZero\\nMCP\\n1.91k\\nZ Image Turbo\\nüñº\\n1.91k\\nGenerate stunning AI images from text descriptions in seconds\\nRunning\\non\\nZero\\nMCP\\nFeatured\\n392\\nFLUX.2 [Klein] 9B\\nüíª\\n392\\nGenerate or edit images from text prompts or existing photos\\nRunning\\non\\nZero\\nMCP\\n529\\nWan2.2 14B Preview\\nüêå\\n529\\ngenerate a video from an image with a text prompt\\nBrowse 1M+ applications\\nDatasets\\nopendatalab/ChartVerse-SFT-1800K\\nUpdated\\n1 day ago\\n‚Ä¢\\n2.07k\\n‚Ä¢\\n114\\nQwen/DeepPlanning\\nUpdated\\n4 days ago\\n‚Ä¢\\n110\\n‚Ä¢\\n83\\nAlibaba-Apsara/Superior-Reasoning-SFT-gpt-oss-120b\\nUpdated\\n16 days ago\\n‚Ä¢\\n30.7k\\n‚Ä¢\\n310\\nsojuL/RubricHub_v1\\nUpdated\\n11 days ago\\n‚Ä¢\\n747\\n‚Ä¢\\n152\\nmercor/apex-agents\\nUpdated\\n9 days ago\\n‚Ä¢\\n6.89k\\n‚Ä¢\\n73\\nBrowse 500k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe \\n## Relevant Links:\\n\\n\\n### Link: Company page\\nHugging Face ‚Äì The AI community building the future.\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 2M+ models\\nTrending on\\nthis week\\nModels\\nmoonshotai/Kimi-K2.5\\nUpdated\\nabout 8 hours ago\\n‚Ä¢\\n32.4k\\n‚Ä¢\\n1.24k\\nnvidia/personaplex-7b-v1\\nUpdated\\n2 days ago\\n‚Ä¢\\n62.1k\\n‚Ä¢\\n1.52k\\nTongyi-MAI/Z-Image\\nUpdated\\n3 days ago\\n‚Ä¢\\n2.89k\\n‚Ä¢\\n717\\ndeepseek-ai/DeepSeek-OCR-2\\nUpdated\\n1 day ago\\n‚Ä¢\\n64.6k\\n‚Ä¢\\n576\\nQwen/Qwen3-TTS-12Hz-1.7B-CustomVoice\\nUpdated\\n2 days ago\\n‚Ä¢\\n198k\\n‚Ä¢\\n807\\nBrowse 2M+ models\\nSpaces\\nRunning\\non\\nZero\\nFeatured\\n1.04k\\nQwen3-TTS Demo\\nüéô\\n1.04k\\nTransform text into natural-sounding speech with custom voices\\nRunning\\non\\nZero\\nFeatured\\n1.28k\\nQwen Image Multiple Angles 3D Camera\\nüé•\\n1.28k\\nAdjust camera angles in images using 3D controls or sliders\\nRunning\\non\\nZero\\nMCP\\n1.91k\\nZ Image Turbo\\nüñº\\n1.91k\\nGenerate stunning AI images from text descriptions in seconds\\nRunning\\non\\nZero\\nMCP\\nFeatured\\n392\\nFLUX.2 [Klein] 9B\\nüíª\\n392\\nGenerate or edit images from text prompts or existing photos\\nRunning\\non\\nZero\\nMCP\\n529\\nWan2.2 14B Preview\\nüêå\\n529\\ngenerate a video from an image with a text prompt\\nBrowse 1M+ applications\\nDatasets\\nopendatalab/ChartVerse-SFT-1800K\\nUpdated\\n1 day ago\\n‚Ä¢\\n2.07k\\n‚Ä¢\\n114\\nQwen/DeepPlanning\\nUpdated\\n4 days ago\\n‚Ä¢\\n110\\n‚Ä¢\\n83\\nAlibaba-Apsara/Superior-Reasoning-SFT-gpt-oss-120b\\nUpdated\\n16 days ago\\n‚Ä¢\\n30.7k\\n‚Ä¢\\n310\\nsojuL/RubricHub_v1\\nUpdated\\n11 days ago\\n‚Ä¢\\n747\\n‚Ä¢\\n152\\nmercor/apex-agents\\nUpdated\\n9 days ago\\n‚Ä¢\\n6.89k\\n‚Ä¢\\n73\\nBrowse 500k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe \\n\\n### Link: About page\\nHugging Face ‚Äì Blog\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nCommunity Blog & Articles\\nNew Article\\ncommunity\\nguide\\nopen source collab\\npartnerships\\nresearch\\nNLP\\nAudio\\nCV\\nRL\\nethics\\nDiffusion\\nGame Development\\nRLHF\\nLeaderboard\\nCase Studies\\nLeRobot\\nInference Providers\\nCommunity Articles\\nview all\\nRexRerankers: SOTA Rankers for Product Discovery and AI Assistants\\n7 days ago\\n‚Ä¢\\n41\\n**NVIDIA Earth-2 Open Models Span the Whole Weather Stack**\\n5 days ago\\n‚Ä¢\\n30\\nLightOnOCR-2-1B: a lightweight high-performance end-to-end OCR model family\\n12 days ago\\n‚Ä¢\\n73\\nTruthTensor: LLM Evalution in Prediction Markets Under Drift and Market Baseline\\n1 day ago\\n‚Ä¢\\n16\\nWhy Your AI St'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_brochure_user_prompt(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b45846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    response = ollama.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ],\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b123615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting relevant links for https://www.anthropic.com/ by calling llama3.2\n",
      "Found 8 relevant links\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Anthropic: Empowering AI for Humanity's Long-Term Well-Being**\n",
       "\n",
       "Welcome to Anthropic, a public benefit corporation dedicated to securing the benefits and mitigating the risks of artificial intelligence. Our mission is to build AI that serves humanity's long-term well-being.\n",
       "\n",
       "**Our Values**\n",
       "\n",
       "At Anthropic, we are guided by a set of core values:\n",
       "\n",
       "* **AI Safety**: We believe that AI should be designed to prioritize human safety and well-being.\n",
       "* **Responsible Scaling**: We strive to ensure that our technology is scalable in a responsible and transparent manner.\n",
       "* **Humility**: We recognize the limits of our knowledge and are committed to continuous learning and improvement.\n",
       "\n",
       "**Our Research**\n",
       "\n",
       "Anthropic is at the forefront of AI research, with a focus on advancing the state-of-the-art in AI safety, explainability, and alignment. Our work includes:\n",
       "\n",
       "* **Economic Futures**: Exploring the potential impacts of AI on the economy and society.\n",
       "* **Commitments**: Defining our principles for responsible AI development and deployment.\n",
       "* **Initiatives**: Engaging with stakeholders to develop and implement best practices for AI ethics.\n",
       "\n",
       "**Our Products**\n",
       "\n",
       "We are proud to offer a range of products and tools that advance the field of AI safety and alignment:\n",
       "\n",
       "* **Claude**: Our flagship model, designed to provide interpretability and explainability of complex AI systems.\n",
       "* **Claude Opus 4.5**: The most advanced model in the world for coding, agents, computer use, and enterprise workflows.\n",
       "\n",
       "**Join Us**\n",
       "\n",
       "At Anthropic, we are passionate about creating a better future through AI. Join us as we shape the future of artificial intelligence.\n",
       "\n",
       "**Careers**\n",
       "\n",
       "We offer exciting opportunities to work with our talented team:\n",
       "\n",
       "* **Engineering**: Development of cutting-edge AI technologies.\n",
       "* **Research**: Advancing the state-of-the-art in AI safety and alignment.\n",
       "* **Academy**: Training and education for individuals interested in AI ethics and responsibility.\n",
       "\n",
       "**Get In Touch**\n",
       "\n",
       "Contact us to learn more about Anthropic's mission, research, and products."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure(\"Anthropic\", \"https://www.anthropic.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eaaab7-0b47-4b29-82d4-75d474ad8d18",
   "metadata": {},
   "source": [
    "## Finally - a minor improvement\n",
    "\n",
    "With a small adjustment, we can change this so that the results stream back from OpenAI,\n",
    "with the familiar typewriter animation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddfc62f",
   "metadata": {},
   "source": [
    "#here S this line sometimes tries to read .content when it doesn‚Äôt exist:\n",
    "\n",
    "chunk.choices[0].delta.content\n",
    "```python\n",
    "def stream_brochure(company_name, url):\n",
    "    stream = ollama.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "```\n",
    "# solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51db0e49-f261-4137-aabe-92dd601f7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    stream = ollama.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "\n",
    "\n",
    "    for chunk in stream:\n",
    "        delta = chunk.choices[0].delta\n",
    "        if delta and delta.content:\n",
    "            response += delta.content\n",
    "            update_display(\n",
    "                Markdown(response),\n",
    "                display_id=display_handle.display_id\n",
    "            )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6dfaef",
   "metadata": {},
   "source": [
    "#Change in system prompt (2nd one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56bf0ae3-ee9d-4a72-9cd6-edcac67ceb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting relevant links for https://www.anthropic.com/ by calling llama3.2\n",
      "Found 15 relevant links\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Anthropic Brochure\n",
       "\n",
       "Welcome to Anthropic, a pioneering public benefit corporation dedicated to harnessing the power of AI for humanity's long-term well-being.\n",
       "\n",
       "## Our Mission\n",
       "\n",
       "At Anthropic, we believe that Artificial Intelligence holds immense potential to shape the world. However, its benefits must be secured and risks mitigated. We're committed to building AI that prioritizes safety, interpretability, and alignment with human values.\n",
       "\n",
       "### The Claude Advantage\n",
       "\n",
       "Meet Claude, our cutting-edge AI platform that enables developers to build, deploy, and manage AI models at scale. With Claude Opus 4.5, the world's most advanced model for coding, agents, computer use, and enterprise workflows, we're redefining the future of AI development.\n",
       "\n",
       "### What We're Working Towards\n",
       "\n",
       "We're pushing the boundaries of what's possible with AI in several exciting areas:\n",
       "\n",
       "* **Mars Exploration**: Our AI-powered systems have successfully assisted the first AI-assisted drive on another planet, opening up new frontiers for human exploration and discovery.\n",
       "* **AI Safety**: Our research focuses on developling interpretable AI models that prioritize alignment with human values, ensuring AI serves humanity's long-term well-being.\n",
       "\n",
       "### Our Culture\n",
       "\n",
       "At Anthropic, we prioritize a culture of empathy, diversity, and inclusivity. We believe that by coming together, we can achieve more than any individual could alone. With our dedicated team of experts, you'll find:\n",
       "\n",
       "* **Expertise**: From computer vision to natural language processing, our team has the expertise to tackle some of AI's most complex challenges.\n",
       "* **Innovation**: Our commitment to innovation drives us to push the boundaries of what's possible with AI, resulting in new breakthroughs and discoveries.\n",
       "\n",
       "### Join Our Journey\n",
       "\n",
       "Ready to be part of a mission-driven company that's shaping the future of AI? Explore our careers page to learn about job opportunities and how you can contribute to our mission.\n",
       "\n",
       "**Log in to Claude**\n",
       "[Download app](https://example.com/download-app)\n",
       "**Learn more about Claude**\n",
       "[Website](https://anthropic.ai)\n",
       "\n",
       "### Stay Connected\n",
       "\n",
       "Sign up for our newsletter to stay updated on the latest developments, research updates, and news from Anthropic.\n",
       "\n",
       "**Contact Us**\n",
       "[Email](mailto:info@anthropic.ai)\n",
       "[Social Media](https://facebook.com/anthropic.ai)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Anthropic_english = stream_brochure(\"Anthropic\", \"https://www.anthropic.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ec1d47",
   "metadata": {},
   "source": [
    "#Translating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "164d7075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, update_display\n",
    "\n",
    "def stream_translate_to_bengali(brochure_text):\n",
    "    if not brochure_text:\n",
    "        raise ValueError(\"Brochure text is empty. Cannot translate.\")\n",
    "\n",
    "    stream = ollama.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": \"Translate the following text into natural Bengali. Preserve formatting and tone. Do not add explanations.\"},\n",
    "            {\"role\": \"user\", \"content\": brochure_text}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    translated_text = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "\n",
    "    for chunk in stream:\n",
    "        delta = chunk.choices[0].delta\n",
    "        if delta and delta.content:\n",
    "            translated_text += delta.content\n",
    "            update_display(Markdown(translated_text), display_id=display_handle.display_id)\n",
    "\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5848585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "‡¶Ü‡¶®‡ßç‡¶•‡ßç‡¶∞‡ßã‡¶™‡¶ø‡¶ï ‡¶™‡ßç‡¶Ø‡¶æ‡¶ü‡¶æ‡¶∞‡ßç‡¶®‡¶∂‡ßÄ‡¶™ ‡¶¨‡¶∞‡ßç‡¶£‡¶æ‡¶≤‡¶ø \n",
       "\n",
       "‡¶Æ‡¶®‡ßá ‡¶π‡ßü, ‡¶¨‡¶ø‡¶∂‡ßç‡¶¨‡ßá‡¶∞ ‡¶∏‡¶Ç‡¶ó‡¶§‡¶ø‡¶ï ‡¶ñ‡¶¨‡¶∞ ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶Ö‡¶®‡ßç‡¶Ø‡¶¶‡ßá‡¶∞ ‡¶•‡ßá‡¶ï‡ßá ‡¶≠‡¶æ‡¶≤ ‡¶ñ‡¶æ‡¶á‡¶¨‡•§"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "‡¶â‡¶á‡¶≤‡¶ï‡¶æ‡¶Æ ‡¶ü‡ßÅ ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶•‡ßç‡¶∞‡ßã‡¶™‡¶ø‡¶ï, ‡¶è‡¶ï‡¶ü‡¶ø ‡¶¶‡¶∞‡ßç‡¶∂‡¶®‡ßÄ‡¶Ø‡¶º ‡¶∏‡¶æ‡¶Æ‡¶æ‡¶ú‡¶ø‡¶ï ‡¶≤‡¶æ‡¶≠ ‡¶∏‡¶Ç‡¶∏‡ßç‡¶•‡¶æ ‡¶Ø‡¶æ‡¶∞ ‡¶≤‡¶ï‡ßç‡¶∑‡ßç‡¶Ø ‡¶π'‡¶≤ ‡¶Ü‡¶á ‡¶®‡ßá‡¶ü‡¶ø‡¶≠‡¶ú‡ßá‡¶∞ ‡¶∂‡¶ï‡ßç‡¶§‡¶ø ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶Æ‡¶æ‡¶®‡¶¨‡¶ú‡¶ó‡¶§‡ßá‡¶∞ ‡¶¶‡ßÄ‡¶∞‡ßç‡¶ò‡¶Æ‡ßá‡¶Ø‡¶º‡¶æ‡¶¶‡ßÄ ‡¶â‡¶®‡ßç‡¶®‡¶§‡¶ø‡•§\n",
       "\n",
       " \n",
       "‡¶Ü‡¶á ‡¶∏‡¶ø\n",
       "\n",
       "AI"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## ‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ ‡¶â‡¶¶‡ßç‡¶Ø‡ßã‡¶ó\n",
       "### ‡¶∏‡¶®‡ßç‡¶ß‡¶ø‡¶™‡ßç‡¶∞‡¶ø‡¶§‡¶ø‡¶∂‡ßç‡¶ö‡¶ø‡¶§  ‡¶≠‡¶¨‡¶ø‡¶∑‡ßç‡¶Ø‡¶§, ‡¶è‡¶ï‡¶ü‡¶ø ‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶™‡¶∞‡¶ø‡¶∑‡ßá‡¶¨‡¶æ ‡¶â‡¶™‡¶ú‡¶æ‡¶§ ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá, ‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ ‡¶ä‡¶∞‡ßç‡¶ß‡ßç‡¶¨‡¶≤‡ßã‡¶ï‡ßá ‡¶Ø‡¶æ‡¶Å‡¶∞‡¶æ ‡¶è‡¶ü‡¶ø ‡¶ñ‡ßÅ‡¶¨‡¶á ‡¶ó‡¶≠‡ßÄ‡¶∞‡¶≠‡¶æ‡¶¨‡ßá ‡¶Ö‡¶®‡ßç‡¶§‡¶∞‡ßç‡¶¶‡ßÉ‡¶∑‡ßç‡¶ü‡¶ø‡¶™‡ßç‡¶∞‡¶æ‡¶™‡ßç‡¶§ ‡¶π‡ßü, ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶§‡¶æ‡¶¶‡ßá‡¶∞ ‡¶â‡¶ö‡¶ø‡¶§ ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶ï‡ßç‡¶∑‡¶Æ ‡¶™‡¶õ‡¶®‡ßç‡¶¶ ‡¶∂‡ßã‡¶®‡¶æ‡¶á ‡¶è‡¶≠‡¶æ‡¶¨‡ßá ‡¶®‡¶ø‡¶ú‡ßá‡¶¶‡ßá‡¶∞‡¶ï‡ßá ‡¶∏‡¶æ‡¶∞‡ßç‡¶≠‡¶° ‡¶ï‡¶∞‡¶ø ‡¶Ø‡¶æ ‡¶Ö‡¶®‡¶®‡ßç‡¶Ø ‡¶Ü‡¶∞ ‡¶è‡¶´‡¶ü‡¶ø ‡¶Ø‡ßã‡¶ó‡ßç‡¶Ø‡•§"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "‡¶Ö‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶•‡ßç‡¶∞‡ßã‡¶™‡¶ø‡¶ï‡ßá ‡¶¨‡¶ø‡¶∂‡ßç‡¶¨‡¶æ‡¶∏ ‡¶ï‡¶∞‡¶ø ‡¶Ø‡ßá ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶∞‡ßç‡¶ü‡¶ø‡¶´‡¶ø‡¶∂‡¶ø‡¶Ø‡¶º‡¶æ‡¶≤ ‡¶á‡¶®‡ßç‡¶ü‡ßá‡¶≤‡¶ø‡¶ú‡ßá‡¶®‡ßç‡¶∏ ‡¶¶‡ßÅ‡¶É‡¶ñ‡¶ø‡¶§ ‡¶¨‡¶ø‡¶∂‡ßç‡¶¨‡¶ï‡ßá ‡¶™‡¶∞‡¶ø‡¶¨‡ßÇ‡¶π ‡¶π‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡•§  ‡¶è‡¶∞ ‡¶´‡¶≤‡ßá ‡¶Ü‡¶∏‡¶æ ‡¶∏‡ßÅ‡¶¨‡¶ø‡¶ß‡¶æ‡¶ó‡ßÅ‡¶≤‡¶ø ‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡¶ø‡¶§ ‡¶ï‡¶∞‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶ù‡ßÅ‡¶Å‡¶ï‡¶ø ‡¶π‡ßç‡¶∞‡¶æ‡¶∏ ‡¶ï‡¶∞‡¶æ ‡¶Ö‡¶™‡¶∞‡¶ø‡¶π‡¶æ‡¶∞‡ßç‡¶Ø‡•§  ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶¶‡ßÉ‡¶¢‡¶º‡¶≠‡¶æ‡¶¨‡ßá ‡¶ú‡¶°‡¶º‡¶ø‡¶§, ‡¶®‡¶ø‡¶∞‡ßç‡¶≠‡¶ø‡¶Ø‡¶º‡ßã‡¶ó‡¶§‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑‡ßá‡¶∞ ‡¶Æ‡ßÇ‡¶≤‡ßç‡¶Ø‡¶¨‡ßã‡¶ß‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶∏‡¶æ‡¶∞‡¶ø‡¶¨‡¶∞‡¶æ‡¶ì ‡¶π‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶≠‡¶ø‡¶ú‡ßç‡¶Ø‡ßÅ‡¶Ø‡¶º‡¶æ‡¶≤‡ßá‡¶∞ ‡¶è‡¶ï-‡¶™‡¶æ‡¶∂ ‡¶â‡¶™‡¶Ø‡ßã‡¶ó‡ßÄ ‡¶Ü‡¶á ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶Ö‡¶ô‡ßç‡¶ó‡ßÄ‡¶ï‡¶æ‡¶∞ ‡¶∞‡¶æ‡¶ñ‡¶ø‡•§"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ‡¶ï‡ßç‡¶≤‡ßã‡¶° ‡¶∏‡ßÅ‡¶¨‡¶ø‡¶ß‡¶æ \n",
       "\n",
       "### What is the Claude Advantage?\n",
       "#### ‡¶ï‡ßç‡¶≤‡ßã‡¶¶ ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶°‡¶≠‡¶æ‡¶Ç‡¶ü‡ßá‡¶ú ‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ø‡ßá-‡¶ï‡ßÄ?\r\n",
       "### Our unique approach combines human judgment with AI-driven insights to deliver accurate and actionable information. \n",
       " #### ‡¶Æ‡¶æ‡¶®‡¶¨ ‡¶ú‡ßÅ‡¶ó‡¶≤‡¶§‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶á-‡¶°‡ßç‡¶∞‡¶æ‡¶á‡¶≠‡ßá‡¶° ‡¶á‡¶®‡¶∏‡¶æ‡¶á‡¶ü, ‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ø‡ßá ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞? \n",
       "### Unlike conventional solutions that rely solely on AI or human analysis, our approach combines the strengths of both to provide a comprehensive and accurate solution. \n",
       "#### ‡¶ï‡ßç‡¶∑‡¶Æ‡¶§‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶¶‡ßÅ‡¶∞‡ßç‡¶¨‡¶≤‡¶§‡¶æ‡¶∞ ‡¶™‡¶ø‡¶õ‡¶®‡ßá ‡¶Ø‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£ ‡¶Ö‡¶≠‡¶ø‡¶Ø‡ßã‡¶ú‡¶®‡¶ü‡¶ø, ‡¶Ü‡¶™‡¶®‡¶æ‡¶ï‡ßá ‡¶Ø‡ßá ‡¶Æ‡¶æ‡¶® ‡¶¶‡ßá‡¶Ø‡¶º?\n",
       "### Learn how our unique approach combines the best of human judgment and AI-driven insights to deliver accurate and actionable information. \n",
       "#### ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ï‡ßç‡¶≤‡ßã‡¶¶ ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶°‡¶≠‡¶æ‡¶Ç‡¶ü‡ßá‡¶ú‡ßá‡¶∞ ‡¶Ö‡¶≠‡¶ø‡¶¨‡ßç‡¶Ø‡¶ñ‡ßç‡¶Ø‡¶æ‡¶®\n",
       "### Stay ahead of the competition with our innovative solution that combines human judgment and AI-driven insights. \n",
       "#### ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶∞‡ßã‡¶ß\n",
       "‡¶ï‡ßç‡¶≤‡ßã‡¶¶ ‡¶Ü‡¶™‡¶®‡¶æ‡¶ï‡ßá ‡¶∂‡¶ï‡ßç‡¶§‡¶ø‡¶∂‡¶æ‡¶≤‡ßÄ‡¶≠‡¶æ‡¶¨‡ßá, ‡¶®‡¶ø‡¶∞‡ßç‡¶≠‡¶∞‡¶Ø‡ßã‡¶ó‡ßç‡¶Ø‡¶≠‡¶æ‡¶¨‡ßá, ‡¶è‡¶¨‡¶Ç ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ú‡ßç‡¶û‡¶æ‡¶§ ‡¶∏‡¶ø‡¶¶‡ßç‡¶ß‡¶æ‡¶®‡ßç‡¶§ ‡¶ó‡ßç‡¶∞‡¶π‡¶£‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶™‡ßç‡¶∞‡¶∏‡ßç‡¶§‡ßÅ‡¶§ ‡¶ï‡¶∞‡¶æ. \n",
       "‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ø‡ßá ‡¶ö‡ßÇ‡¶°‡¶º‡¶æ‡¶®‡ßç‡¶§ ‡¶â‡¶™‡¶≤‡¶¨‡ßç‡¶ß‡¶ø?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "‡¶Æ‡¶ø‡¶†‡ßÅ‡¶®‡ßá ‡¶Ü‡¶õ‡ßá, ‡¶™‡¶∞‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º‡¶ï‡ßç‡¶∞‡¶Æ‡ßá‡¶∞ ‡¶è‡¶á ‡¶¨‡¶∞‡ßç‡¶ß‡¶ø‡¶§ ‡¶ñ‡¶¨‡¶∞‡¶æ-‡¶ñ‡¶ø‡¶§ ‡¶ú‡ßç‡¶û‡¶æ‡¶®‡¶ø ‡¶∏‡¶ø‡¶∏‡ßç‡¶ü‡ßá‡¶Æ ‡¶Ø‡¶æ ‡¶â‡¶®‡ßç‡¶®‡¶Ø‡¶º‡¶®‡¶ï‡¶æ‡¶∞‡ßÄ‡¶¶‡ßá‡¶∞ ‡¶∏‡ßç‡¶ï‡ßá‡¶≤‡ßá ‡¶≠‡¶°‡¶º‡¶ò‡¶∞ ‡¶™‡ßç‡¶∞‡¶¨‡¶∞‡ßç‡¶§‡¶ï, ‡¶¶‡¶ï‡ßç‡¶∑‡¶ø‡¶£‡¶æ‡¶ô‡ßç‡¶ó ‡¶è‡¶® ‡¶ú‡¶ø‡¶∞‡ßã ‡¶´‡¶ø‡¶ü ‡¶Ü‡¶á ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø ‡¶è‡¶¨‡¶Ç ‡¶ö‡¶≤‡¶æ‡¶Ø ‡¶¨‡ßÉ‡¶¶‡ßç‡¶ß‡¶ø ‡¶™‡ßá‡¶§‡ßá ‡¶∏‡¶ï‡ßç‡¶∑‡¶Æ ‡¶ï‡¶∞‡ßá‡•§ ‡¶ï‡ßç‡¶≤‡ßÅ‡¶°‡¶ø‡¶Ø‡¶º‡¶æ ‡¶ì‡¶™‡¶æ‡¶∏ 4.5 ‡¶∂‡ßá‡¶ñ‡¶æ‡¶∞ ‡¶¶‡ßÅ‡¶®‡ßÄ‡¶Ø‡¶º‡¶§‡¶Æ ‡¶Æ‡¶°‡ßá‡¶≤, ‡¶ï‡ßã‡¶°‡¶ø‡¶Ç, ‡¶è‡¶ú‡ßá‡¶®‡ßç‡¶ü, ‡¶ï‡¶Æ‡ßç‡¶™‡¶ø‡¶â‡¶ü‡¶æ‡¶∞ ‡¶Ü‡¶ö‡¶∞‡¶£ ‡¶è‡¶¨‡¶Ç ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶®‡¶ø‡¶ï ‡¶∏‡ßç‡¶¨‡¶æ‡¶Ø‡¶º‡¶§‡ßç‡¶§‡¶∂‡¶æ‡¶∏‡¶®‡ßá‡¶∞ ‡¶≤‡¶æ‡¶ó‡¶®‡¶æ‡¶Ø‡¶º,   ‡¶Ü‡¶Æ‡¶∞‡¶æ AI ‡¶â‡¶®‡ßç‡¶®‡¶Ø‡¶º‡¶®‡ßá‡¶∞ ‡¶≠‡¶¨‡¶ø‡¶∑‡ßç‡¶Ø‡ßé‡¶ï‡ßá ‡¶™‡ßÅ‡¶®‡¶É‡¶®‡¶ø‡¶∞‡ßç‡¶Æ‡¶ø‡¶§ ‡¶ï‡¶∞‡ßá ‡•§"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶ï‡ßÄ‡¶≠‡¶æ‡¶¨‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶∂‡ßç‡¶∞‡ßÅ‡¶§‡¶ø ‡¶¶‡¶ø‡¶ö‡ßç‡¶õ‡¶ø \n",
       "\n",
       "‡¶Ø‡ßã‡¶ó‡¶æ‡¶Ø‡ßã‡¶ó\n",
       "‡¶¶‡ßá‡¶ì‡ßü‡¶æ: ‡ß©-‡ß¨‡ß´‡ß©‡ßÆ‡ßß‚Äì‡ß≠  [email¬†protected]](mailto:support@yourwebsite.com )\n",
       "\n",
       "‡¶â‡¶§‡ßç‡¶§‡¶∞‡¶¶‡¶æ‡¶§‡¶æ‡¶∞ ‡¶Ö‡¶®‡ßÅ‡¶∞‡ßã‡¶ß: ‡¶°‡¶ø‡¶∞‡ßá‡¶ï‡ßç‡¶ü‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶≤-‡¶Æ‡ßá‡¶á‡¶≤ (1)\n",
       "\n",
       "‡¶∞‡¶ø‡¶≠‡¶ø‡¶â\n",
       "‡¶∞‡¶ø‡ßü‡ßá‡¶∏‡ßç‡¶ü ‡¶Ü‡¶∞‡ßç‡¶ü‡¶ø‡¶ï‡¶≤\n",
       "\n",
       "‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø\n",
       "‡¶ï‡¶®‡ßç‡¶ü‡¶æ‡¶ï‡¶ü ‡¶Ü‡¶∏\n",
       "‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™‡ßç‡¶≤‡¶ø‡¶ï‡ßá‡¶∂‡¶® ‡¶´‡¶∞‡ßç‡¶Æ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ ‡¶ó ‡¶®‡¶æ ‡¶ï‡ßü‡ßá‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶∏‡ßç‡¶Ø"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paragraphs = Anthropic_english.split(\"\\n\\n\")\n",
    "bengali_brochure = \"\"\n",
    "for p in paragraphs:\n",
    "    bengali_brochure += stream_translate_to_bengali(p) + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fdb3f8d8-a3eb-41c8-b1aa-9f60686a653b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting relevant links for https://www.tritechbd.com/ by calling llama3.2\n",
      "Found 8 relevant links\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Welcome to Tritechbd: Your Partner in HVAC Solutions\n",
       "\n",
       "At Tritechbd, we're passionate about providing the best HVAC solutions for our customers across Bangladesh. Our journey began with a dream to deliver innovative and reliable cooling systems that meet the unique needs of different industries.\n",
       "\n",
       "## Who We Are\n",
       "\n",
       "As a leading HVAC supplier, we pride ourselves on being a trusted partner to various sectors, including:\n",
       "\n",
       "* Hospitality\n",
       "* Healthcare\n",
       "* Education\n",
       "* Government Buildings\n",
       "* Food & Pharma\n",
       "\n",
       "We're dedicated to helping businesses and organizations maintain optimal temperatures, ensuring comfort, productivity, and efficiency.\n",
       "\n",
       "## Our Products and Solutions\n",
       "\n",
       "Our comprehensive range of products includes:\n",
       "\n",
       "* VRF AC Systems (Daikin VRV System, LG VRF System, Midea VRF System)\n",
       "* Electric Chillers (Dunham Bush Chiller, Daikin Chillers, Midea Chillers)\n",
       "* Industrial Dehumidifiers (Fisair Dehumidifier, YAKE Dehumidifier)\n",
       "* Clean Room Solutions (AHU, Ventilation Fan, Refrigeration Systems)\n",
       "* Modular Cold Rooms\n",
       "* Air Conditioning Solutions for Hotels and Hospitals\n",
       "\n",
       "## Our Culture\n",
       "\n",
       "At Tritechbd, we value:\n",
       "\n",
       "* **Innovation**: We're committed to staying at the forefront of HVAC technology.\n",
       "* **Customer Satisfaction**: Your satisfaction is our top priority!\n",
       "* **Teamwork**: Collaboration and communication are essential aspects of our team culture.\n",
       "* **Quality**: We strive for excellence in every product and service.\n",
       "\n",
       "## Join Our Team\n",
       "\n",
       "Ready to be part of a dynamic team that makes a difference? Check out our current job openings: [link]\n",
       "\n",
       "Get in touch with us today:\n",
       "\n",
       "Email: support@tritechbd.com\n",
       "Phone: +8801786337711\n",
       "Address: JCX Business Tower, Plot - 1136/A, Japan Street, Block - I, Basundhara R/A, Dhaka 1229\n",
       "\n",
       "Let's cool things down together!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream_brochure(\"Tritechbd\", \"https://www.tritechbd.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27bf9e0-665f-4645-b66b-9725e2a959b5",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business applications</h2>\n",
    "            <span style=\"color:#181;\">In this exercise we extended the Day 1 code to make multiple LLM calls, and generate a document.\n",
    "\n",
    "This is perhaps the first example of Agentic AI design patterns, as we combined multiple calls to LLMs. This will feature more in Week 2, and then we will return to Agentic AI in a big way in Week 8 when we build a fully autonomous Agent solution.\n",
    "\n",
    "Generating content in this way is one of the very most common Use Cases. As with summarization, this can be applied to any business vertical. Write marketing content, generate a product tutorial from a spec, create personalized email content, and so much more. Explore how you can apply content generation to your business, and try making yourself a proof-of-concept prototype. See what other students have done in the community-contributions folder -- so many valuable projects -- it's wild!</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2454b-8ef8-4b5c-b928-053a15e0d553",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you move to Week 2 (which is tons of fun)</h2>\n",
    "            <span style=\"color:#900;\">Please see the week1 EXERCISE notebook for your challenge for the end of week 1. This will give you some essential practice working with Frontier APIs, and prepare you well for Week 2.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b64f0f-7d33-4493-985a-033d06e8db08",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">A reminder on 3 useful resources</h2>\n",
    "            <span style=\"color:#f71;\">1. The resources for the course are available <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">here.</a><br/>\n",
    "            2. I'm on LinkedIn <a href=\"https://www.linkedin.com/in/eddonner/\">here</a> and I love connecting with people taking the course!<br/>\n",
    "            3. I'm trying out X/Twitter and I'm at <a href=\"https://x.com/edwarddonner\">@edwarddonner<a> and hoping people will teach me how it's done..  \n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48e42e-fa7a-495f-a5d4-26bfc24d60b6",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/thankyou.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#090;\">Finally! I have a special request for you</h2>\n",
    "            <span style=\"color:#090;\">\n",
    "                My editor tells me that it makes a MASSIVE difference when students rate this course on Udemy - it's one of the main ways that Udemy decides whether to show it to others. If you're able to take a minute to rate this, I'd be so very grateful! And regardless - always please reach out to me at ed@edwarddonner.com if I can help at any point.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
