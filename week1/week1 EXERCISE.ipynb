{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, requests\n",
    "from IPython.display import Markdown,display\n",
    "from openai import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "openai=OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "system_prompt='''You are an excellent programming and coding mentor whose task is to explain in detail about \n",
    "the topics or questions asked in the most efficient and easy-to-understand way as possible. \n",
    "Respond in markdown. Include examples to better the understanding of user.'''\n",
    "user_prompt=f'''You are given a question that you need to contruct an explanation for. \n",
    "Use human-friendly language like a teacher explaining the concept for the first time to its student.\n",
    "Here is the question: {question}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b9a1fa0-aa63-4091-92d4-866a48214ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Understanding `yield from` Keyword**\n",
       "=====================================\n",
       "\n",
       "Imagine you're at a library, and you want to list all the authors of a collection of books. The author's name is stored within each book object.\n",
       "\n",
       "The given code snippet utilizes a powerful keyword called `yield from`. Before we dive into explaining what it does, let's understand its sibling concept, `yield`.\n",
       "\n",
       "**What is `yield`?**\n",
       "\n",
       "In Python, `yield` is used to create generators. A generator is a type of iterable that produces a single value at a time, rather than computing them all at once and returning them in a list. Think of it like a vending machine: instead of dispensing an entire can of soda at once, the machine gives you one can at a time.\n",
       "\n",
       "When we use `yield` within a function, it pauses execution until the next value is requested. This allows us to compute multiple values without allocating excessive memory.\n",
       "\n",
       "**What does `yield from` do?**\n",
       "\n",
       "Now that we understand `yield`, let's move on to its cousin, `yield from`. When we see `yield from`, Python knows we want to delegate the responsibility of computing the values to another generator.\n",
       "\n",
       "The phrase \"delegate\" means handing over control to someone else. In this case, it's yielding control from our current function to another generator. Here's how it works:\n",
       "\n",
       "If a function contains a `yield` statement and also includes an expression enclosed in parentheses (like `{book.get(\"author\") for book in books}`), what it does is delegate the computation of that expression to another generator. When we encounter the first `yield`, Python checks if there's an enclosing expression like this one.\n",
       "\n",
       "If there is, Python executes that expression and passes its output (one value at a time) when we get back to our original function and see the second `yield`. It stops here and resumes execution once it gets an output from the delegated generator.\n",
       "\n",
       "The example provided earlier can be analyzed in this light:\n",
       "\n",
       "```python\n",
       "# books.py module\n",
       "\n",
       "class Book:\n",
       "    def __init__(self, author):\n",
       "        self.author = author\n",
       "\n",
       "books = [\n",
       "    {\"author\": \"Aristotle\"},\n",
       "    {\"author\": \"Alexander the Great\"},\n",
       "]\n",
       "\n",
       "def get_author_names(books_list: list) -> iter:\n",
       "    book_authors = ({book.get(\"author\") for book in books_list})\n",
       "    if book_authors:\n",
       "        yield from book_authors\n",
       "# or simply\n",
       "# return book_authors\n",
       "\n",
       "get_author_names([Book({\"author\": \"Aristotle\"}), Book({\"author\": \"Alexander the Great\"})])\n",
       "```\n",
       "If you run this program and collect it inside a list, here is what you get:\n",
       "\n",
       "```python\n",
       "['Aristotle', 'Alexander the Great']\n",
       "```\n",
       "\n",
       "The value is obtained by processing (`delegating`) each book by fetching the output as soon as they were available."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages=[\n",
    "    {'role':'system', 'content':system_prompt},\n",
    "    {'role':'user','content':user_prompt}\n",
    "]\n",
    "response=openai.chat.completions.create(model=MODEL_LLAMA,messages=messages)\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747feb2e-2fea-45ff-919e-538f2e86a9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
