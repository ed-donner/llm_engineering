{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from scraper import fetch_website_links, fetch_website_contents\n",
    "from IPython.display import Markdown, display, update_display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_GEMMA = 'gemma3:270m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key looks good \n"
     ]
    }
   ],
   "source": [
    "# setup the environment\n",
    "\n",
    "load_dotenv(override = True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key) > 10:\n",
    "    print('API Key looks good ')\n",
    "else:\n",
    "    print('There might be a problem with your api key? Please visit the troubleshooting notebook!')\n",
    "\n",
    "openai = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = \"you are a helpful assistant who is an expert in python code and provide detailed explanations to how this code works, the process, and explain it like i am a 5 year old kid.\"\n",
    "user_prompt = \"what is the code print('hello world mean?')\"\n",
    "\n",
    "messages = [\n",
    "\n",
    "    {'role': 'system', 'content' : system_prompt},\n",
    "    {'role' : 'user', 'content' : user_prompt}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let’s break it down simply! \n",
       "\n",
       "Imagine you have a magic book that can say things out loud for you. When you want to say something, you just have to tell the book what to say.\n",
       "\n",
       "Now, let’s look at the code you showed me:\n",
       "\n",
       "```python\n",
       "print('hello world mean?')\n",
       "```\n",
       "\n",
       "1. **print**: This is like telling the magic book to say something. It’s a special command in Python (the language we use to talk to the computer) that makes the computer show us words on the screen.\n",
       "\n",
       "2. **'hello world mean?'**: This part is what we want to say. It’s like writing a note to the magic book. Whatever we put inside those quotes (‘ ’) is what the book will say out loud. In this case, it's “hello world mean?”\n",
       "\n",
       "So, when we run this code, the computer listens to the command (print), and then it looks at the note (the words inside the quotes) and shows it on the screen. \n",
       "\n",
       "In this example, the computer would show:\n",
       "```\n",
       "hello world mean?\n",
       "```\n",
       "\n",
       "It’s like if you told your friend to shout “hello world mean?” and they did! \n",
       "\n",
       "That’s all there is to it! The computer just prints out those words for us to see. Isn’t that cool?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "response = openai.chat.completions.create(model = MODEL_GPT, messages = messages, stream=True)\n",
    "\n",
    "full_text = \"\"\n",
    "\n",
    "for chunk in response:\n",
    "    delta = chunk.choices[0].delta\n",
    "    if hasattr(delta, \"content\") and delta.content:\n",
    "        full_text += delta.content\n",
    "\n",
    "display(Markdown(full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Ollama is running'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Gemma3:270m to answer\n",
    "\n",
    "# get gemma \n",
    "import requests\n",
    "requests.get('http://localhost:11434').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac5efef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 735af2139dc6: 100% ▕██████████████████▏ 291 MB                         \u001b[K\n",
      "pulling 4b19ac7dd2fb: 100% ▕██████████████████▏  476 B                         \u001b[K\n",
      "pulling 3e2c24001f9e: 100% ▕██████████████████▏ 8.4 KB                         \u001b[K\n",
      "pulling 339e884a40f6: 100% ▕██████████████████▏   61 B                         \u001b[K\n",
      "pulling 74156d92caf6: 100% ▕██████████████████▏  490 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull gemma3:270m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b876bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay! Let's learn how to print \"Hello World\"! \n",
      "\n",
      "Imagine you have a big box of LEGOs. You're looking for the number of LEGOs in that box.\n",
      "\n",
      "*   **We're going to use 'print' to show you what we're looking for.**\n",
      "*   **\"Print\" means to tell the computer to print something to the screen.**\n",
      "*   **\"Hello World\" means to show you the result of printing the number of LEGOs in the box.**\n",
      "\n",
      "So, \"Hello World\" is like saying \"Hello, world!\" because it's telling our computer that it's printed!\n",
      "\n",
      "So, to make \"Hello World\" really clear, we can print it as:\n",
      "\n",
      "```python\n",
      "print('Hello World')\n",
      "```\n",
      "\n",
      "That's it!  It's a simple way to tell the computer you've printed \"Hello World.\"  It's like showing the computer the LEGOs in the box.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gemma_base_url = 'http://localhost:11434/v1'\n",
    "\n",
    "gemma = OpenAI(base_url = gemma_base_url, api_key = 'ollama')\n",
    "\n",
    "response = gemma.chat.completions.create(model = MODEL_GEMMA, messages = messages)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
